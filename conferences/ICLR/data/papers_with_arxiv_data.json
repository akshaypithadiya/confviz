[{"title": "RTFM: Generalising to New Environment Dynamics via Reading", "authors": "Victor Zhong, Tim Rockt\u00e4schel, Edward Grefenstette"}, {"title": "LEARNING EXECUTION THROUGH NEURAL CODE FUSION", "authors": "Zhan Shi, Kevin Swersky, Daniel Tarlow, Parthasarathy Ranganathan, Milad Hashemi", "link": "", "summary": ""}, {"title": "Neural Text Generation With Unlikelihood Training", "authors": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, Jason Weston", "link": "https://arxiv.org/abs/1908.04319", "summary": "Neural text generation is a key tool in natural language applications, but it\nis well known there are major problems at its core. In particular, standard\nlikelihood training and decoding leads to dull and repetitive outputs. While\nsome post-hoc fixes have been proposed, in particular top-$k$ and nucleus\nsampling, they do not address the fact that the token-level probabilities\npredicted by the model are poor. In this paper we show that the likelihood\nobjective itself is at fault, resulting in a model that assigns too much\nprobability to sequences containing repeats and frequent words, unlike those\nfrom the human training distribution. We propose a new objective, unlikelihood\ntraining, which forces unlikely generations to be assigned lower probability by\nthe model. We show that both token and sequence level unlikelihood training\ngive less repetitive, less dull text while maintaining perplexity, giving\nsuperior generations using standard greedy or beam search. According to human\nevaluations, our approach with standard beam search also outperforms the\ncurrently popular decoding methods of nucleus sampling or beam blocking, thus\nproviding a strong alternative to existing techniques."}, {"title": "SNOW: Subscribing to Knowledge via Channel Pooling for Transfer & Lifelong Learning of Convolutional Neural Networks", "authors": "Chungkuk Yoo, Bumsoo Kang, Minsik Cho"}, {"title": "Spike-based causal inference for weight alignment", "authors": "Jordan Guerguiev, Konrad Kording, Blake Richards", "link": "https://arxiv.org/abs/1910.01689", "summary": "In artificial neural networks trained with gradient descent, the weights used\nfor processing stimuli are also used during backward passes to calculate\ngradients. For the real brain to approximate gradients, gradient information\nwould have to be propagated separately, such that one set of synaptic weights\nis used for processing and another set is used for backward passes. This\nproduces the so-called \"weight transport problem\" for biological models of\nlearning, where the backward weights used to calculate gradients need to mirror\nthe forward weights used to process stimuli. This weight transport problem has\nbeen considered so hard that popular proposals for biological learning assume\nthat the backward weights are simply random, as in the feedback alignment\nalgorithm. However, such random weights do not appear to work well for large\nnetworks. Here we show how the discontinuity introduced in a spiking system can\nlead to a solution to this problem. The resulting algorithm is a special case\nof an estimator used for causal inference in econometrics, regression\ndiscontinuity design. We show empirically that this algorithm rapidly makes the\nbackward weights approximate the forward weights. As the backward weights\nbecome correct, this improves learning performance over feedback alignment on\ntasks such as Fashion-MNIST, SVHN, CIFAR-10 and VOC. Our results demonstrate\nthat a simple learning rule in a spiking network can allow neurons to produce\nthe right backward connections and thus solve the weight transport problem."}, {"title": "Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware", "authors": "Xiandong Zhao, Ying Wang, Xuyi Cai, Cheng Liu, Lei Zhang"}, {"title": "Composing Task-Agnostic Policies with Deep Reinforcement Learning", "authors": "Ahmed H. Qureshi, Jacob J. Johnson, Yuzhe Qin, Taylor Henderson, Byron Boots, Michael C. Yip"}, {"title": "Improving Generalization in Meta Reinforcement Learning using Learned Objectives", "authors": "Louis Kirsch, Sjoerd van Steenkiste, Juergen Schmidhuber", "link": "https://arxiv.org/abs/1910.04098", "summary": "Biological evolution has distilled the experiences of many learners into the\ngeneral learning algorithms of humans. Our novel meta reinforcement learning\nalgorithm MetaGenRL is inspired by this process. MetaGenRL distills the\nexperiences of many complex agents to meta-learn a low-complexity neural\nobjective function that decides how future individuals will learn. Unlike\nrecent meta-RL algorithms, MetaGenRL can generalize to new environments that\nare entirely different from those used for meta-training. In some cases, it\neven outperforms human-engineered RL algorithms. MetaGenRL uses off-policy\nsecond-order gradients during meta-training that greatly increase its sample\nefficiency."}, {"title": "End to End Trainable Active Contours via Differentiable Rendering", "authors": "Shir Gur, Tal Shaharabany, Lior Wolf", "link": "https://arxiv.org/abs/1912.00367", "summary": "We present an image segmentation method that iteratively evolves a polygon.\nAt each iteration, the vertices of the polygon are displaced based on the local\nvalue of a 2D shift map that is inferred from the input image via an\nencoder-decoder architecture. The main training loss that is used is the\ndifference between the polygon shape and the ground truth segmentation mask.\nThe network employs a neural renderer to create the polygon from its vertices,\nmaking the process fully differentiable. We demonstrate that our method\noutperforms the state of the art segmentation networks and deep active contour\nsolutions in a variety of benchmarks, including medical imaging and aerial\nimages. Our code is available at https://github.com/shirgur/ACDRNet."}, {"title": "Learning Self-Correctable Policies and Value Functions from Demonstrations with Negative Sampling", "authors": "Yuping Luo, Huazhe Xu, Tengyu Ma", "link": "https://arxiv.org/abs/1907.05634", "summary": "Imitation learning, followed by reinforcement learning algorithms, is a\npromising paradigm to solve complex control tasks sample-efficiently. However,\nlearning from demonstrations often suffers from the covariate shift problem,\nwhich results in cascading errors of the learned policy. We introduce a notion\nof conservatively-extrapolated value functions, which provably lead to policies\nwith self-correction. We design an algorithm Value Iteration with Negative\nSampling (VINS) that practically learns such value functions with conservative\nextrapolation. We show that VINS can correct mistakes of the behavioral cloning\npolicy on simulated robotics benchmark tasks. We also propose the algorithm of\nusing VINS to initialize a reinforcement learning algorithm, which is shown to\noutperform significantly prior works in sample efficiency."}, {"title": "Exploration in Reinforcement Learning with Deep Covering Options", "authors": "Yuu Jinnai, Jee Won Park, Marlos C. Machado, George Konidaris"}, {"title": "Universal Approximation with Certified Networks", "authors": "Maximilian Baader, Matthew Mirman, Martin Vechev", "link": "https://arxiv.org/abs/1909.13846", "summary": "Training neural networks to be certifiably robust is critical to ensure their\nsafety against adversarial attacks. However, it is currently very difficult to\ntrain a neural network that is both accurate and certifiably robust. In this\nwork we take a step towards addressing this challenge. We prove that for every\ncontinuous function $f$, there exists a network $n$ such that: (i) $n$\napproximates $f$ arbitrarily close, and (ii) simple interval bound propagation\nof a region $B$ through $n$ yields a result that is arbitrarily close to the\noptimal output of $f$ on $B$. Our result can be seen as a Universal\nApproximation Theorem for interval-certified ReLU networks. To the best of our\nknowledge, this is the first work to prove the existence of accurate,\ninterval-certified networks."}, {"title": "Why Not to Use Zero Imputation? Correcting Sparsity Bias in Training Neural Networks", "authors": "Joonyoung Yi, Juhyuk Lee, Kwang Joon Kim, Sung Ju Hwang, Eunho Yang"}, {"title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "authors": "David Brandfonbrener, Joan Bruna", "link": "https://arxiv.org/abs/1905.12185", "summary": "While there are convergence guarantees for temporal difference (TD) learning\nwhen using linear function approximators, the situation for nonlinear models is\nfar less understood, and divergent examples are known. Here we take a first\nstep towards extending theoretical convergence guarantees to TD learning with\nnonlinear function approximation. More precisely, we consider the expected\nlearning dynamics of the TD(0) algorithm for value estimation. As the step-size\nconverges to zero, these dynamics are defined by a nonlinear ODE which depends\non the geometry of the space of function approximators, the structure of the\nunderlying Markov chain, and their interaction. We find a set of function\napproximators that includes ReLU networks and has geometry amenable to TD\nlearning regardless of environment, so that the solution performs about as well\nas linear TD in the worst case. Then, we show how environments that are more\nreversible induce dynamics that are better for TD learning and prove global\nconvergence to the true value function for well-conditioned function\napproximators. Finally, we generalize a divergent counterexample to a family of\ndivergent problems to demonstrate how the interaction between approximator and\nenvironment can go wrong and to motivate the assumptions needed to prove\nconvergence."}, {"title": "PairNorm: Tackling Oversmoothing in GNNs", "authors": "Lingxiao Zhao, Leman Akoglu", "link": "https://arxiv.org/abs/1909.12223", "summary": "The performance of graph neural nets (GNNs) is known to gradually decrease\nwith increasing number of layers. This decay is partly attributed to\noversmoothing, where repeated graph convolutions eventually make node\nembeddings indistinguishable. We take a closer look at two different\ninterpretations, aiming to quantify oversmoothing. Our main contribution is\nPairNorm, a novel normalization layer that is based on a careful analysis of\nthe graph convolution operator, which prevents all node embeddings from\nbecoming too similar. What is more, PairNorm is fast, easy to implement without\nany change to network architecture nor any additional parameters, and is\nbroadly applicable to any GNN. Experiments on real-world graphs demonstrate\nthat PairNorm makes deeper GCN, GAT, and SGC models more robust against\noversmoothing, and significantly boosts performance for a new problem setting\nthat benefits from deeper GNNs. Code is available at\nhttps://github.com/LingxiaoShawn/PairNorm."}, {"title": "Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks", "authors": "Arsalan Sharifnassab, Saber Salehkaleybar, S. Jamaloddin Golestani"}, {"title": "Robust Local Features for Improving the Generalization of Adversarial Training", "authors": "Chuanbiao Song, Kun He, Jiadong Lin, Liwei Wang, John E. Hopcroft", "link": "https://arxiv.org/abs/1909.10147", "summary": "Adversarial training has been demonstrated as one of the most effective\nmethods for training robust models to defend against adversarial examples.\nHowever, adversarially trained models often lack adversarially robust\ngeneralization on unseen testing data. Recent works show that adversarially\ntrained models are more biased towards global structure features. Instead, in\nthis work, we would like to investigate the relationship between the\ngeneralization of adversarial training and the robust local features, as the\nrobust local features generalize well for unseen shape variation. To learn the\nrobust local features, we develop a Random Block Shuffle (RBS) transformation\nto break up the global structure features on normal adversarial examples. We\ncontinue to propose a new approach called Robust Local Features for Adversarial\nTraining (RLFAT), which first learns the robust local features by adversarial\ntraining on the RBS-transformed adversarial examples, and then transfers the\nrobust local features into the training of normal adversarial examples. To\ndemonstrate the generality of our argument, we implement RLFAT in currently\nstate-of-the-art adversarial training frameworks. Extensive experiments on\nSTL-10, CIFAR-10 and CIFAR-100 show that RLFAT significantly improves both the\nadversarially robust generalization and the standard generalization of\nadversarial training. Additionally, we demonstrate that our models capture more\nlocal features of the object on the images, aligning better with human\nperception."}, {"title": "Curriculum Loss: Robust Learning and Generalization  against Label Corruption", "authors": "Yueming Lyu, Ivor W. Tsang", "link": "https://arxiv.org/abs/1905.10045", "summary": "Deep neural networks (DNNs) have great expressive power, which can even\nmemorize samples with wrong labels. It is vitally important to reiterate\nrobustness and generalization in DNNs against label corruption. To this end,\nthis paper studies the 0-1 loss, which has a monotonic relationship with an\nempirical adversary (reweighted) risk~\\citep{hu2016does}. Although the 0-1 loss\nhas some robust properties, it is difficult to optimize. To efficiently\noptimize the 0-1 loss while keeping its robust properties, we propose a very\nsimple and efficient loss, i.e. curriculum loss (CL). Our CL is a tighter upper\nbound of the 0-1 loss compared with conventional summation based surrogate\nlosses. Moreover, CL can adaptively select samples for model training. As a\nresult, our loss can be deemed as a novel perspective of curriculum sample\nselection strategy, which bridges a connection between curriculum learning and\nrobust learning. Experimental results on benchmark datasets validate the\nrobustness of the proposed loss."}, {"title": "Incorporating BERT into Neural Machine Translation", "authors": "Jinhua Zhu, Yingce Xia, Lijun Wu, Di He, Tao Qin, Wengang Zhou, Houqiang Li, Tieyan Liu", "link": "https://arxiv.org/abs/2002.06823", "summary": "The recently proposed BERT has shown great power on a variety of natural\nlanguage understanding tasks, such as text classification, reading\ncomprehension, etc. However, how to effectively apply BERT to neural machine\ntranslation (NMT) lacks enough exploration. While BERT is more commonly used as\nfine-tuning instead of contextual embedding for downstream language\nunderstanding tasks, in NMT, our preliminary exploration of using BERT as\ncontextual embedding is better than using for fine-tuning. This motivates us to\nthink how to better leverage BERT for NMT along this direction. We propose a\nnew algorithm named BERT-fused model, in which we first use BERT to extract\nrepresentations for an input sequence, and then the representations are fused\nwith each layer of the encoder and decoder of the NMT model through attention\nmechanisms. We conduct experiments on supervised (including sentence-level and\ndocument-level translations), semi-supervised and unsupervised machine\ntranslation, and achieve state-of-the-art results on seven benchmark datasets.\nOur code is available at \\url{https://github.com/bert-nmt/bert-nmt}."}, {"title": "Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling", "authors": "Hao Zhang, Bo Chen, Long Tian, Zhengjue Wang, Mingyuan Zhou"}, {"title": "Simple and Effective Regularization Methods for Training on Noisily Labeled Data with Generalization Guarantee", "authors": "Wei Hu, Zhiyuan Li, Dingli Yu", "link": "https://arxiv.org/abs/1905.11368", "summary": "Over-parameterized deep neural networks trained by simple first-order methods\nare known to be able to fit any labeling of data. Such over-fitting ability\nhinders generalization when mislabeled training examples are present. On the\nother hand, simple regularization methods like early-stopping can often achieve\nhighly nontrivial performance on clean test data in these scenarios, a\nphenomenon not theoretically understood. This paper proposes and analyzes two\nsimple and intuitive regularization methods: (i) regularization by the distance\nbetween the network parameters to initialization, and (ii) adding a trainable\nauxiliary variable to the network output for each training example.\nTheoretically, we prove that gradient descent training with either of these two\nmethods leads to a generalization guarantee on the clean data distribution\ndespite being trained using noisy labels. Our generalization analysis relies on\nthe connection between wide neural network and neural tangent kernel (NTK). The\ngeneralization bound is independent of the network size, and is comparable to\nthe bound one can get when there is no label noise. Experimental results verify\nthe effectiveness of these methods on noisily labeled datasets."}, {"title": "Differentially Private Meta-Learning", "authors": "Jeffrey Li, Mikhail Khodak, Sebastian Caldas, Ameet Talwalkar", "link": "https://arxiv.org/abs/1909.05830", "summary": "Parameter-transfer is a well-known and versatile approach for meta-learning,\nwith applications including few-shot learning, federated learning, and\nreinforcement learning. However, parameter-transfer algorithms often require\nsharing models that have been trained on the samples from specific tasks, thus\nleaving the task-owners susceptible to breaches of privacy. We conduct the\nfirst formal study of privacy in this setting and formalize the notion of\ntask-global differential privacy as a practical relaxation of more commonly\nstudied threat models. We then propose a new differentially private algorithm\nfor gradient-based parameter transfer that not only satisfies this privacy\nrequirement but also retains provable transfer learning guarantees in convex\nsettings. Empirically, we apply our analysis to the problems of federated\nlearning with personalization and few-shot classification, showing that\nallowing the relaxation to task-global privacy from the more commonly studied\nnotion of local privacy leads to dramatically increased performance in\nrecurrent neural language modeling and image classification."}, {"title": "Deep Semi-Supervised Anomaly Detection", "authors": "Lukas Ruff, Robert A. Vandermeulen, Nico G\u00f6rnitz, Alexander Binder, Emmanuel M\u00fcller, Klaus-Robert M\u00fcller, Marius Kloft", "link": "https://arxiv.org/abs/1906.02694", "summary": "Deep approaches to anomaly detection have recently shown promising results\nover shallow methods on large and complex datasets. Typically anomaly detection\nis treated as an unsupervised learning problem. In practice however, one may\nhave---in addition to a large set of unlabeled samples---access to a small pool\nof labeled samples, e.g. a subset verified by some domain expert as being\nnormal or anomalous. Semi-supervised approaches to anomaly detection aim to\nutilize such labeled samples, but most proposed methods are limited to merely\nincluding labeled normal samples. Only a few methods take advantage of labeled\nanomalies, with existing deep approaches being domain-specific. In this work we\npresent Deep SAD, an end-to-end deep methodology for general semi-supervised\nanomaly detection. We further introduce an information-theoretic framework for\ndeep anomaly detection based on the idea that the entropy of the latent\ndistribution for normal data should be lower than the entropy of the anomalous\ndistribution, which can serve as a theoretical interpretation for our method.\nIn extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with\nother anomaly detection benchmark datasets, we demonstrate that our method is\non par or outperforms shallow, hybrid, and deep competitors, yielding\nappreciable performance improvements even when provided with only little\nlabeled data."}, {"title": "Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill Discovery", "authors": "Kristian Hartikainen, Xinyang Geng, Tuomas Haarnoja, Sergey Levine", "link": "https://arxiv.org/abs/1907.08225", "summary": "Reinforcement learning requires manual specification of a reward function to\nlearn a task. While in principle this reward function only needs to specify the\ntask goal, in practice reinforcement learning can be very time-consuming or\neven infeasible unless the reward function is shaped so as to provide a smooth\ngradient towards a successful outcome. This shaping is difficult to specify by\nhand, particularly when the task is learned from raw observations, such as\nimages. In this paper, we study how we can automatically learn dynamical\ndistances: a measure of the expected number of time steps to reach a given goal\nstate from any other state. These dynamical distances can be used to provide\nwell-shaped reward functions for reaching new goals, making it possible to\nlearn complex tasks efficiently. We show that dynamical distances can be used\nin a semi-supervised regime, where unsupervised interaction with the\nenvironment is used to learn the dynamical distances, while a small amount of\npreference supervision is used to determine the task goal, without any manually\nengineered reward function or goal examples. We evaluate our method both on a\nreal-world robot and in simulation. We show that our method can learn to turn a\nvalve with a real-world 9-DoF hand, using raw image observations and just ten\npreference labels, without any other supervision. Videos of the learned skills\ncan be found on the project website:\nhttps://sites.google.com/view/dynamical-distance-learning."}, {"title": "AE-OT: A NEW GENERATIVE MODEL BASED ON EXTENDED SEMI-DISCRETE OPTIMAL TRANSPORT", "authors": "Dongsheng An, Yang Guo, Na Lei, Zhongxuan Luo, Shing-Tung Yau, Xianfeng Gu"}, {"title": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty", "authors": "Dan Hendrycks, Norman Mu, Ekin Dogus Cubuk, Barret Zoph, Justin Gilmer, Balaji Lakshminarayanan", "link": "https://arxiv.org/abs/1912.02781", "summary": "Modern deep neural networks can achieve high accuracy when the training\ndistribution and test distribution are identically distributed, but this\nassumption is frequently violated in practice. When the train and test\ndistributions are mismatched, accuracy can plummet. Currently there are few\ntechniques that improve robustness to unforeseen data shifts encountered during\ndeployment. In this work, we propose a technique to improve the robustness and\nuncertainty estimates of image classifiers. We propose AugMix, a data\nprocessing technique that is simple to implement, adds limited computational\noverhead, and helps models withstand unforeseen corruptions. AugMix\nsignificantly improves robustness and uncertainty measures on challenging image\nclassification benchmarks, closing the gap between previous methods and the\nbest possible performance in some cases by more than half."}, {"title": "Black-Box Adversarial Attack with Transferable Model-based Embedding", "authors": "Zhichao Huang, Tong Zhang", "link": "https://arxiv.org/abs/1911.07140", "summary": "We present a new method for black-box adversarial attack. Unlike previous\nmethods that combined transfer-based and scored-based methods by using the\ngradient or initialization of a surrogate white-box model, this new method\ntries to learn a low-dimensional embedding using a pretrained model, and then\nperforms efficient search within the embedding space to attack an unknown\ntarget network. The method produces adversarial perturbations with high level\nsemantic patterns that are easily transferable. We show that this approach can\ngreatly improve the query efficiency of black-box adversarial attack across\ndifferent target network architectures. We evaluate our approach on MNIST,\nImageNet and Google Cloud Vision API, resulting in a significant reduction on\nthe number of queries. We also attack adversarially defended networks on\nCIFAR10 and ImageNet, where our method not only reduces the number of queries,\nbut also improves the attack success rate."}, {"title": "Learning to solve the credit assignment problem", "authors": "Benjamin James Lansdell, Prashanth Ravi Prakash, Konrad Paul Kording", "link": "https://arxiv.org/abs/1906.00889", "summary": "Backpropagation is driving today's artificial neural networks (ANNs).\nHowever, despite extensive research, it remains unclear if the brain implements\nthis algorithm. Among neuroscientists, reinforcement learning (RL) algorithms\nare often seen as a realistic alternative: neurons can randomly introduce\nchange, and use unspecific feedback signals to observe their effect on the cost\nand thus approximate their gradient. However, the convergence rate of such\nlearning scales poorly with the number of involved neurons. Here we propose a\nhybrid learning approach. Each neuron uses an RL-type strategy to learn how to\napproximate the gradients that backpropagation would provide. We provide proof\nthat our approach converges to the true gradient for certain classes of\nnetworks. In both feedforward and convolutional networks, we empirically show\nthat our approach learns to approximate the gradient, and can match or the\nperformance of exact gradient-based learning. Learning feedback weights\nprovides a biologically plausible mechanism of achieving good performance,\nwithout the need for precise, pre-specified learning rules."}, {"title": "Picking Winning Tickets Before Training by Preserving Gradient Flow", "authors": "Chaoqi Wang, Guodong Zhang, Roger Grosse"}, {"title": "Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention", "authors": "Chen Zhao, Chenyan Xiong, Corby Rosset, Xia Song, Paul Bennett, Saurabh Tiwary"}, {"title": "FEW-SHOT LEARNING ON GRAPHS VIA SUPER-CLASSES BASED ON GRAPH SPECTRAL MEASURES", "authors": "Jatin Chauhan, Deepak Nathani, Manohar Kaul"}, {"title": "Meta-Q-Learning", "authors": "Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, Alexander J. Smola", "link": "", "summary": ""}, {"title": "Meta-Learning with Warped Gradient Descent", "authors": "Sebastian Flennerhag, Andrei A. Rusu, Razvan Pascanu, Francesco Visin, Hujun Yin, Raia Hadsell", "link": "https://arxiv.org/abs/1909.00025", "summary": "Learning an efficient update rule from data that promotes rapid learning of\nnew tasks from the same distribution remains an open problem in meta-learning.\nTypically, previous works have approached this issue either by attempting to\ntrain a neural network that directly produces updates or by attempting to learn\nbetter initialisations or scaling factors for a gradient-based update rule.\nBoth of these approaches pose challenges. On one hand, directly producing an\nupdate forgoes a useful inductive bias and can easily lead to non-converging\nbehaviour. On the other hand, approaches that try to control a gradient-based\nupdate rule typically resort to computing gradients through the learning\nprocess to obtain their meta-gradients, leading to methods that can not scale\nbeyond few-shot task adaptation. In this work, we propose Warped Gradient\nDescent (WarpGrad), a method that intersects these approaches to mitigate their\nlimitations. WarpGrad meta-learns an efficiently parameterised preconditioning\nmatrix that facilitates gradient descent across the task distribution.\nPreconditioning arises by interleaving non-linear layers, referred to as\nwarp-layers, between the layers of a task-learner. Warp-layers are meta-learned\nwithout backpropagating through the task training process in a manner similar\nto methods that learn to directly produce updates. WarpGrad is computationally\nefficient, easy to implement, and can scale to arbitrarily large meta-learning\nproblems. We provide a geometrical interpretation of the approach and evaluate\nits effectiveness in a variety of settings, including few-shot, standard\nsupervised, continual and reinforcement learning."}, {"title": "SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine", "link": "https://arxiv.org/abs/1905.11108", "summary": "Learning to imitate expert behavior from demonstrations can be challenging,\nespecially in environments with high-dimensional, continuous observations and\nunknown dynamics. Supervised learning methods based on behavioral cloning (BC)\nsuffer from distribution shift: because the agent greedily imitates\ndemonstrated actions, it can drift away from demonstrated states due to error\naccumulation. Recent methods based on reinforcement learning (RL), such as\ninverse RL and generative adversarial imitation learning (GAIL), overcome this\nissue by training an RL agent to match the demonstrations over a long horizon.\nSince the true reward function for the task is unknown, these methods learn a\nreward function from the demonstrations, often using complex and brittle\napproximation techniques that involve adversarial training. We propose a simple\nalternative that still uses RL, but does not require learning a reward\nfunction. The key idea is to provide the agent with an incentive to match the\ndemonstrations over a long horizon, by encouraging it to return to demonstrated\nstates upon encountering new, out-of-distribution states. We accomplish this by\ngiving the agent a constant reward of r=+1 for matching the demonstrated action\nin a demonstrated state, and a constant reward of r=0 for all other behavior.\nOur method, which we call soft Q imitation learning (SQIL), can be implemented\nwith a handful of minor modifications to any standard Q-learning or off-policy\nactor-critic algorithm. Theoretically, we show that SQIL can be interpreted as\na regularized variant of BC that uses a sparsity prior to encourage\nlong-horizon imitation. Empirically, we show that SQIL outperforms BC and\nachieves competitive results compared to GAIL, on a variety of image-based and\nlow-dimensional tasks in Box2D, Atari, and MuJoCo."}, {"title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning", "authors": "Ali Mousavi, Lihong Li, Qiang Liu, Denny Zhou", "link": "https://arxiv.org/abs/2003.11126", "summary": "Off-policy estimation for long-horizon problems is important in many\nreal-life applications such as healthcare and robotics, where high-fidelity\nsimulators may not be available and on-policy evaluation is expensive or\nimpossible. Recently, \\cite{liu18breaking} proposed an approach that avoids the\n\\emph{curse of horizon} suffered by typical importance-sampling-based methods.\nWhile showing promising results, this approach is limited in practice as it\nrequires data be drawn from the \\emph{stationary distribution} of a\n\\emph{known} behavior policy. In this work, we propose a novel approach that\neliminates such limitations. In particular, we formulate the problem as solving\nfor the fixed point of a certain operator. Using tools from Reproducing Kernel\nHilbert Spaces (RKHSs), we develop a new estimator that computes importance\nratios of stationary distributions, without knowledge of how the off-policy\ndata are collected. We analyze its asymptotic consistency and finite-sample\ngeneralization. Experiments on benchmarks verify the effectiveness of our\napproach."}, {"title": "What graph neural networks cannot learn: depth vs width", "authors": "Andreas Loukas"}, {"title": "Imitation Learning via Off-Policy Distribution Matching", "authors": "Ilya Kostrikov, Ofir Nachum, Jonathan Tompson", "link": "https://arxiv.org/abs/1912.05032", "summary": "When performing imitation learning from expert demonstrations, distribution\nmatching is a popular approach, in which one alternates between estimating\ndistribution ratios and then using these ratios as rewards in a standard\nreinforcement learning (RL) algorithm. Traditionally, estimation of the\ndistribution ratio requires on-policy data, which has caused previous work to\neither be exorbitantly data-inefficient or alter the original objective in a\nmanner that can drastically change its optimum. In this work, we show how the\noriginal distribution ratio estimation objective may be transformed in a\nprincipled manner to yield a completely off-policy objective. In addition to\nthe data-efficiency that this provides, we are able to show that this objective\nalso renders the use of a separate RL optimization unnecessary.Rather, an\nimitation policy may be learned directly from this objective without the use of\nexplicit rewards. We call the resulting algorithm ValueDICE and evaluate it on\na suite of popular imitation learning benchmarks, finding that it can achieve\nstate-of-the-art sample efficiency and performance."}, {"title": "A Closer Look at the Optimization Landscapes of Generative Adversarial Networks", "authors": "Hugo Berard, Gauthier Gidel, Amjad Almahairi, Pascal Vincent, Simon Lacoste-Julien", "link": "https://arxiv.org/abs/1906.04848", "summary": "Generative adversarial networks have been very successful in generative\nmodeling, however they remain relatively challenging to train compared to\nstandard deep neural networks. In this paper, we propose new visualization\ntechniques for the optimization landscapes of GANs that enable us to study the\ngame vector field resulting from the concatenation of the gradient of both\nplayers. Using these visualization techniques we try to bridge the gap between\ntheory and practice by showing empirically that the training of GANs exhibits\nsignificant rotations around Local Stable Stationary Points (LSSP), similar to\nthe one predicted by theory on toy examples. Moreover, we provide empirical\nevidence that GAN training converge to a stable stationary point which is a\nsaddle point for the generator loss, not a minimum, while still achieving\nexcellent performance."}, {"title": "Scaling Autoregressive Video Models", "authors": "Dirk Weissenborn, Oscar T\u00e4ckstr\u00f6m, Jakob Uszkoreit", "link": "https://arxiv.org/abs/1906.02634", "summary": "Due to the statistical complexity of video, the high degree of inherent\nstochasticity, and the sheer amount of data, generating natural video remains a\nchallenging task. State-of-the-art video generation models often attempt to\naddress these issues by combining sometimes complex, usually video-specific\nneural network architectures, latent variable models, adversarial training and\na range of other methods. Despite their often high complexity, these approaches\nstill fall short of generating high quality video continuations outside of\nnarrow domains and often struggle with fidelity. In contrast, we show that\nconceptually simple autoregressive video generation models based on a\nthree-dimensional self-attention mechanism achieve competitive results across\nmultiple metrics on popular benchmark datasets, for which they produce\ncontinuations of high fidelity and realism. We also present results from\ntraining our models on Kinetics, a large scale action recognition dataset\ncomprised of YouTube videos exhibiting phenomena such as camera movement,\ncomplex object interactions and diverse human movement. While modeling these\nphenomena consistently remains elusive, we hope that our results, which include\noccasional realistic continuations encourage further research on comparatively\ncomplex, large scale datasets such as Kinetics."}, {"title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization", "authors": "Fan-Yun Sun, Jordan Hoffman, Vikas Verma, Jian Tang", "link": "https://arxiv.org/abs/1908.01000", "summary": "This paper studies learning the representations of whole graphs in both\nunsupervised and semi-supervised scenarios. Graph-level representations are\ncritical in a variety of real-world applications such as predicting the\nproperties of molecules and community analysis in social networks. Traditional\ngraph kernel based methods are simple, yet effective for obtaining fixed-length\nrepresentations for graphs but they suffer from poor generalization due to\nhand-crafted designs. There are also some recent methods based on language\nmodels (e.g. graph2vec) but they tend to only consider certain substructures\n(e.g. subtrees) as graph representatives. Inspired by recent progress of\nunsupervised representation learning, in this paper we proposed a novel method\ncalled InfoGraph for learning graph-level representations. We maximize the\nmutual information between the graph-level representation and the\nrepresentations of substructures of different scales (e.g., nodes, edges,\ntriangles). By doing so, the graph-level representations encode aspects of the\ndata that are shared across different scales of substructures. Furthermore, we\nfurther propose InfoGraph*, an extension of InfoGraph for semi-supervised\nscenarios. InfoGraph* maximizes the mutual information between unsupervised\ngraph representations learned by InfoGraph and the representations learned by\nexisting supervised methods. As a result, the supervised encoder learns from\nunlabeled data while preserving the latent semantic space favored by the\ncurrent supervised task. Experimental results on the tasks of graph\nclassification and molecular property prediction show that InfoGraph is\nsuperior to state-of-the-art baselines and InfoGraph* can achieve performance\ncompetitive with state-of-the-art semi-supervised models."}, {"title": "Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework", "authors": "Zirui Wang, Jiateng Xie, Ruochen Xu, Yiming Yang, Graham Neubig, Jaime G. Carbonell", "link": "https://arxiv.org/abs/1910.04708", "summary": "Learning multilingual representations of text has proven a successful method\nfor many cross-lingual transfer learning tasks. There are two main paradigms\nfor learning such representations: (1) alignment, which maps different\nindependently trained monolingual representations into a shared space, and (2)\njoint training, which directly learns unified multilingual representations\nusing monolingual and cross-lingual objectives jointly. In this paper, we first\nconduct direct comparisons of representations learned using both of these\nmethods across diverse cross-lingual tasks. Our empirical results reveal a set\nof pros and cons for both methods, and show that the relative performance of\nalignment versus joint training is task-dependent. Stemming from this analysis,\nwe propose a simple and novel framework that combines these two previously\nmutually-exclusive approaches. Extensive experiments demonstrate that our\nproposed framework alleviates limitations of both approaches, and outperforms\nexisting methods on the MUSE bilingual lexicon induction (BLI) benchmark. We\nfurther show that this framework can generalize to contextualized\nrepresentations such as Multilingual BERT, and produces state-of-the-art\nresults on the CoNLL cross-lingual NER benchmark."}, {"title": "Neural Outlier Rejection for Self-Supervised Keypoint Learning", "authors": "Jiexiong Tang, Hanme Kim, Vitor Guizilini, Sudeep Pillai, Rares Ambrus", "link": "https://arxiv.org/abs/1912.10615", "summary": "Identifying salient points in images is a crucial component for visual\nodometry, Structure-from-Motion or SLAM algorithms. Recently, several learned\nkeypoint methods have demonstrated compelling performance on challenging\nbenchmarks. However, generating consistent and accurate training data for\ninterest-point detection in natural images still remains challenging,\nespecially for human annotators. We introduce IO-Net (i.e. InlierOutlierNet), a\nnovel proxy task for the self-supervision of keypoint detection, description\nand matching. By making the sampling of inlier-outlier sets from point-pair\ncorrespondences fully differentiable within the keypoint learning framework, we\nshow that are able to simultaneously self-supervise keypoint description and\nimprove keypoint matching. Second, we introduce KeyPointNet, a keypoint-network\narchitecture that is especially amenable to robust keypoint detection and\ndescription. We design the network to allow local keypoint aggregation to avoid\nartifacts due to spatial discretizations commonly used for this task, and we\nimprove fine-grained keypoint descriptor performance by taking advantage of\nefficient sub-pixel convolutions to upsample the descriptor feature-maps to a\nhigher operating resolution. Through extensive experiments and ablative\nanalysis, we show that the proposed self-supervised keypoint learning method\ngreatly improves the quality of feature matching and homography estimation on\nchallenging benchmarks over the state-of-the-art."}, {"title": "Editable Neural Networks", "authors": "Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitry Pyrkin, Sergei Popov, Artem Babenko", "link": "https://arxiv.org/abs/2004.00345", "summary": "These days deep neural networks are ubiquitously used in a wide range of\ntasks, from image classification and machine translation to face identification\nand self-driving cars. In many applications, a single model error can lead to\ndevastating financial, reputational and even life-threatening consequences.\nTherefore, it is crucially important to correct model mistakes quickly as they\nappear. In this work, we investigate the problem of neural network editing $-$\nhow one can efficiently patch a mistake of the model on a particular sample,\nwithout influencing the model behavior on other samples. Namely, we propose\nEditable Training, a model-agnostic training technique that encourages fast\nediting of the trained model. We empirically demonstrate the effectiveness of\nthis method on large-scale image classification and machine translation tasks."}, {"title": "Behaviour Suite for Reinforcement Learning", "authors": "Ian Osband, Yotam Doron, Matteo Hessel, John Aslanides, Eren Sezener, Andre Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari, Satinder Singh, Benjamin Van Roy, Richard Sutton, David Silver, Hado Van Hasselt", "link": "https://arxiv.org/abs/1908.03568", "summary": "This paper introduces the Behaviour Suite for Reinforcement Learning, or\nbsuite for short. bsuite is a collection of carefully-designed experiments that\ninvestigate core capabilities of reinforcement learning (RL) agents with two\nobjectives. First, to collect clear, informative and scalable problems that\ncapture key issues in the design of general and efficient learning algorithms.\nSecond, to study agent behaviour through their performance on these shared\nbenchmarks. To complement this effort, we open source\ngithub.com/deepmind/bsuite, which automates evaluation and analysis of any\nagent on bsuite. This library facilitates reproducible and accessible research\non the core issues in RL, and ultimately the design of superior learning\nalgorithms. Our code is Python, and easy to use within existing projects. We\ninclude examples with OpenAI Baselines, Dopamine as well as new reference\nimplementations. Going forward, we hope to incorporate more excellent\nexperiments from the research community, and commit to a periodic review of\nbsuite from a committee of prominent researchers."}, {"title": "Language GANs Falling Short", "authors": "Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, Laurent Charlin", "link": "", "summary": ""}, {"title": "Data-dependent Gaussian Prior Objective for Language Generation", "authors": "Zuchao Li, Rui Wang, Kehai Chen, Masso Utiyama, Eiichiro Sumita, Zhuosheng Zhang, Hai Zhao"}, {"title": "Information Geometry of Orthogonal Initializations and Training", "authors": "Piotr Aleksander Sok\u00f3\u0142, Il Memming Park", "link": "https://arxiv.org/abs/1810.03785", "summary": "Recently mean field theory has been successfully used to analyze properties\nof wide, random neural networks. It gave rise to a prescriptive theory for\ninitializing feed-forward neural networks with orthogonal weights, which\nensures that both the forward propagated activations and the backpropagated\ngradients are near $\\ell_2$ isometries and as a consequence training is orders\nof magnitude faster. Despite strong empirical performance, the mechanisms by\nwhich critical initializations confer an advantage in the optimization of deep\nneural networks are poorly understood. Here we show a novel connection between\nthe maximum curvature of the optimization landscape (gradient smoothness) as\nmeasured by the Fisher information matrix (FIM) and the spectral radius of the\ninput-output Jacobian, which partially explains why more isometric networks can\ntrain much faster. Furthermore, given that orthogonal weights are necessary to\nensure that gradient norms are approximately preserved at initialization, we\nexperimentally investigate the benefits of maintaining orthogonality throughout\ntraining, from which we conclude that manifold optimization of weights performs\nwell regardless of the smoothness of the gradients. Moreover, motivated by\nexperimental results we show that a low condition number of the FIM is not\npredictive of faster learning."}, {"title": "DivideMix: Learning with Noisy Labels as Semi-supervised Learning", "authors": "Junnan Li, Richard Socher, Steven C.H. Hoi", "link": "https://arxiv.org/abs/2002.07394", "summary": "Deep neural networks are known to be annotation-hungry. Numerous efforts have\nbeen devoted to reducing the annotation cost when learning with deep networks.\nTwo prominent directions include learning with noisy labels and semi-supervised\nlearning by exploiting unlabeled data. In this work, we propose DivideMix, a\nnovel framework for learning with noisy labels by leveraging semi-supervised\nlearning techniques. In particular, DivideMix models the per-sample loss\ndistribution with a mixture model to dynamically divide the training data into\na labeled set with clean samples and an unlabeled set with noisy samples, and\ntrains the model on both the labeled and unlabeled data in a semi-supervised\nmanner. To avoid confirmation bias, we simultaneously train two diverged\nnetworks where each network uses the dataset division from the other network.\nDuring the semi-supervised training phase, we improve the MixMatch strategy by\nperforming label co-refinement and label co-guessing on labeled and unlabeled\nsamples, respectively. Experiments on multiple benchmark datasets demonstrate\nsubstantial improvements over state-of-the-art methods. Code is available at\nhttps://github.com/LiJunnan1992/DivideMix ."}, {"title": "Adversarial Policies: Attacking Deep Reinforcement Learning", "authors": "Adam Gleave, Michael Dennis, Cody Wild, Neel Kant, Sergey Levine, Stuart Russell", "link": "https://arxiv.org/abs/1905.10615", "summary": "Deep reinforcement learning (RL) policies are known to be vulnerable to\nadversarial perturbations to their observations, similar to adversarial\nexamples for classifiers. However, an attacker is not usually able to directly\nmodify another agent's observations. This might lead one to wonder: is it\npossible to attack an RL agent simply by choosing an adversarial policy acting\nin a multi-agent environment so as to create natural observations that are\nadversarial? We demonstrate the existence of adversarial policies in zero-sum\ngames between simulated humanoid robots with proprioceptive observations,\nagainst state-of-the-art victims trained via self-play to be robust to\nopponents. The adversarial policies reliably win against the victims but\ngenerate seemingly random and uncoordinated behavior. We find that these\npolicies are more successful in high-dimensional environments, and induce\nsubstantially different activations in the victim policy network than when the\nvictim plays against a normal opponent. Videos are available at\nhttps://adversarialpolicies.github.io/."}, {"title": "Semi-Supervised Generative Modeling for Controllable Speech Synthesis", "authors": "Raza Habib, Soroosh Mariooryad, Matt Shannon, Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, David Kao, Tom Bagby", "link": "https://arxiv.org/abs/1910.01709", "summary": "We present a novel generative model that combines state-of-the-art neural\ntext-to-speech (TTS) with semi-supervised probabilistic latent variable models.\nBy providing partial supervision to some of the latent variables, we are able\nto force them to take on consistent and interpretable purposes, which\npreviously hasn't been possible with purely unsupervised TTS models. We\ndemonstrate that our model is able to reliably discover and control important\nbut rarely labelled attributes of speech, such as affect and speaking rate,\nwith as little as 1% (30 minutes) supervision. Even at such low supervision\nlevels we do not observe a degradation of synthesis quality compared to a\nstate-of-the-art baseline. Audio samples are available on the web."}, {"title": "Synthesizing Programmatic Policies that Inductively Generalize", "authors": "Jeevana Priya Inala, Osbert Bastani, Zenna Tavares, Armando Solar-Lezama"}, {"title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "authors": "Alexei Baevski, Steffen Schneider, Michael Auli", "link": "https://arxiv.org/abs/1910.05453", "summary": "We propose vq-wav2vec to learn discrete representations of audio segments\nthrough a wav2vec-style self-supervised context prediction task. The algorithm\nuses either a gumbel softmax or online k-means clustering to quantize the dense\nrepresentations. Discretization enables the direct application of algorithms\nfrom the NLP community which require discrete inputs. Experiments show that\nBERT pre-training achieves a new state of the art on TIMIT phoneme\nclassification and WSJ speech recognition."}, {"title": "On Identifiability in Transformers", "authors": "Gino Brunner, Yang Liu, Damian Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer", "link": "https://arxiv.org/abs/1908.04211", "summary": "In this paper we delve deep in the Transformer architecture by investigating\ntwo of its core components: self-attention and contextual embeddings. In\nparticular, we study the identifiability of attention weights and token\nembeddings, and the aggregation of context into hidden tokens. We show that,\nfor sequences longer than the attention head dimension, attention weights are\nnot identifiable. We propose effective attention as a complementary tool for\nimproving explanatory interpretations based on attention. Furthermore, we show\nthat input tokens retain to a large degree their identity across the model. We\nalso find evidence suggesting that identity information is mainly encoded in\nthe angle of the embeddings and gradually decreases with depth. Finally, we\ndemonstrate strong mixing of input information in the generation of contextual\nembeddings by means of a novel quantification method based on gradient\nattribution. Overall, we show that self-attention distributions are not\ndirectly interpretable and present tools to better understand and further\ninvestigate Transformer models."}, {"title": "On the Relationship between Self-Attention and Convolutional Layers", "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, Martin Jaggi", "link": "https://arxiv.org/abs/1911.03584", "summary": "Recent trends of incorporating attention mechanisms in vision have led\nresearchers to reconsider the supremacy of convolutional layers as a primary\nbuilding block. Beyond helping CNNs to handle long-range dependencies,\nRamachandran et al. (2019) showed that attention can completely replace\nconvolution and achieve state-of-the-art performance on vision tasks. This\nraises the question: do learned attention layers operate similarly to\nconvolutional layers? This work provides evidence that attention layers can\nperform convolution and, indeed, they often learn to do so in practice.\nSpecifically, we prove that a multi-head self-attention layer with sufficient\nnumber of heads is at least as expressive as any convolutional layer. Our\nnumerical experiments then show that self-attention layers attend to pixel-grid\npatterns similarly to CNN layers, corroborating our analysis. Our code is\npublicly available."}, {"title": "Learn to Explain Efficiently via Neural Logic Inductive Learning", "authors": "Yuan Yang, Le Song"}, {"title": "Query2box: Reasoning over Knowledge Graphs in Vector Space Using Box Embeddings", "authors": "Hongyu Ren, Weihua Hu, Jure Leskovec"}, {"title": "DBA: Distributed Backdoor Attacks against Federated Learning", "authors": "Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li"}, {"title": "Sharing Knowledge in Multi-Task Deep Reinforcement Learning", "authors": "Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli, Jan Peters"}, {"title": "Deep Graph Matching Consensus", "authors": "Matthias Fey, Jan E. Lenssen, Christopher Morris, Jonathan Masci, Nils M. Kriege", "link": "https://arxiv.org/abs/2001.09621", "summary": "This work presents a two-stage neural architecture for learning and refining\nstructural correspondences between graphs. First, we use localized node\nembeddings computed by a graph neural network to obtain an initial ranking of\nsoft correspondences between nodes. Secondly, we employ synchronous message\npassing networks to iteratively re-rank the soft correspondences to reach a\nmatching consensus in local neighborhoods between graphs. We show,\ntheoretically and empirically, that our message passing scheme computes a\nwell-founded measure of consensus for corresponding neighborhoods, which is\nthen used to guide the iterative re-ranking process. Our purely local and\nsparsity-aware architecture scales well to large, real-world inputs while still\nbeing able to recover global correspondences consistently. We demonstrate the\npractical effectiveness of our method on real-world tasks from the fields of\ncomputer vision and entity alignment between knowledge graphs, on which we\nimprove upon the current state-of-the-art. Our source code is available under\nhttps://github.com/rusty1s/ deep-graph-matching-consensus."}, {"title": "Federated Adversarial Domain Adaptation", "authors": "Xingchao Peng, Zijun Huang, Yizhe Zhu, Kate Saenko", "link": "https://arxiv.org/abs/1911.02054", "summary": "Federated learning improves data privacy and efficiency in machine learning\nperformed over networks of distributed devices, such as mobile phones, IoT and\nwearable devices, etc. Yet models trained with federated learning can still\nfail to generalize to new devices due to the problem of domain shift. Domain\nshift occurs when the labeled data collected by source nodes statistically\ndiffers from the target node's unlabeled data. In this work, we present a\nprincipled approach to the problem of federated domain adaptation, which aims\nto align the representations learned among the different nodes with the data\ndistribution of the target node. Our approach extends adversarial adaptation\ntechniques to the constraints of the federated setting. In addition, we devise\na dynamic attention mechanism and leverage feature disentanglement to enhance\nknowledge transfer. Empirically, we perform extensive experiments on several\nimage and text classification tasks and show promising results under\nunsupervised federated domain adaptation setting."}, {"title": "NeurQuRI: Neural Question Requirement Inspector for Answerability Prediction in Machine Reading Comprehension", "authors": "Seohyun Back, Sai Chetan Chinthakindi, Akhil Kedia, Haejun Lee, Jaegul Choo"}, {"title": "Pay Attention to Features, Transfer Learn Faster CNNs", "authors": "Kafeng Wang, Xitong Gao, Yiren Zhao, Xingjian Li, Dejing Dou, Cheng-Zhong Xu"}, {"title": "Fast Neural Network Adaptation via Parameter Remapping and Architecture Search", "authors": "Jiemin Fang, Yuzhu Sun, Kangjian Peng, Qian Zhang, Yuan Li, Wenyu Liu, Xinggang Wang"}, {"title": "Scale-Equivariant Steerable Networks", "authors": "Ivan Sosnovik, Micha\u0142 Szmaja, Arnold Smeulders", "link": "https://arxiv.org/abs/1910.11093", "summary": "The effectiveness of Convolutional Neural Networks (CNNs) has been\nsubstantially attributed to their built-in property of translation\nequivariance. However, CNNs do not have embedded mechanisms to handle other\ntypes of transformations. In this work, we pay attention to scale changes,\nwhich regularly appear in various tasks due to the changing distances between\nthe objects and the camera. First, we introduce the general theory for building\nscale-equivariant convolutional networks with steerable filters. We develop\nscale-convolution and generalize other common blocks to be scale-equivariant.\nWe demonstrate the computational efficiency and numerical stability of the\nproposed method. We compare the proposed models to the previously developed\nmethods for scale equivariance and local scale invariance. We demonstrate\nstate-of-the-art results on MNIST-scale dataset and on STL-10 dataset in the\nsupervised learning setting."}, {"title": "On the \"steerability\" of generative adversarial networks", "authors": "Ali Jahanian, Lucy Chai, Phillip Isola", "link": "https://arxiv.org/abs/1907.07171", "summary": "An open secret in contemporary machine learning is that many models work\nbeautifully on standard benchmarks but fail to generalize outside the lab. This\nhas been attributed to biased training data, which provide poor coverage over\nreal world events. Generative models are no exception, but recent advances in\ngenerative adversarial networks (GANs) suggest otherwise - these models can now\nsynthesize strikingly realistic and diverse images. Is generative modeling of\nphotos a solved problem? We show that although current GANs can fit standard\ndatasets very well, they still fall short of being comprehensive models of the\nvisual manifold. In particular, we study their ability to fit simple\ntransformations such as camera movements and color changes. We find that the\nmodels reflect the biases of the datasets on which they are trained (e.g.,\ncentered objects), but that they also exhibit some capacity for generalization:\nby \"steering\" in latent space, we can shift the distribution while still\ncreating realistic images. We hypothesize that the degree of distributional\nshift is related to the breadth of the training data distribution. Thus, we\nconduct experiments to quantify the limits of GAN transformations and introduce\ntechniques to mitigate the problem. Code is released on our project page:\nhttps://ali-design.github.io/gan_steerability/"}, {"title": "Computation Reallocation for Object Detection", "authors": "Feng Liang, Chen Lin, Ronghao Guo, Ming Sun, Wei Wu, Junjie Yan, Wanli Ouyang", "link": "https://arxiv.org/abs/1912.11234", "summary": "The allocation of computation resources in the backbone is a crucial issue in\nobject detection. However, classification allocation pattern is usually adopted\ndirectly to object detector, which is proved to be sub-optimal. In order to\nreallocate the engaged computation resources in a more efficient way, we\npresent CR-NAS (Computation Reallocation Neural Architecture Search) that can\nlearn computation reallocation strategies across different feature resolution\nand spatial position diectly on the target detection dataset. A two-level\nreallocation space is proposed for both stage and spatial reallocation. A novel\nhierarchical search procedure is adopted to cope with the complex search space.\nWe apply CR-NAS to multiple backbones and achieve consistent improvements. Our\nCR-ResNet50 and CR-MobileNetV2 outperforms the baseline by 1.9% and 1.7% COCO\nAP respectively without any additional computation budget. The models\ndiscovered by CR-NAS can be equiped to other powerful detection neck/head and\nbe easily transferred to other dataset, e.g. PASCAL VOC, and other vision\ntasks, e.g. instance segmentation. Our CR-NAS can be used as a plugin to\nimprove the performance of various networks, which is demanding."}, {"title": "Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity", "authors": "Jingzhao Zhang, Tianxing He, Suvrit Sra, Ali Jadbabaie"}, {"title": "The Implicit Bias of Depth: How Incremental Learning Drives Generalization", "authors": "Daniel Gissin, Shai Shalev-Shwartz, Amit Daniely", "link": "https://arxiv.org/abs/1909.12051", "summary": "A leading hypothesis for the surprising generalization of neural networks is\nthat the dynamics of gradient descent bias the model towards simple solutions,\nby searching through the solution space in an incremental order of complexity.\nWe formally define the notion of incremental learning dynamics and derive the\nconditions on depth and initialization for which this phenomenon arises in deep\nlinear models. Our main theoretical contribution is a dynamical depth\nseparation result, proving that while shallow models can exhibit incremental\nlearning dynamics, they require the initialization to be exponentially small\nfor these dynamics to present themselves. However, once the model becomes\ndeeper, the dependence becomes polynomial and incremental learning can arise in\nmore natural settings. We complement our theoretical findings by experimenting\nwith deep matrix sensing, quadratic neural networks and with binary\nclassification using diagonal and convolutional linear networks, showing all of\nthese models exhibit incremental learning."}, {"title": "Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control", "authors": "Nir Levine, Yinlam Chow, Rui Shu, Ang Li, Mohammad Ghavamzadeh, Hung Bui", "link": "https://arxiv.org/abs/1909.01506", "summary": "Many real-world sequential decision-making problems can be formulated as\noptimal control with high-dimensional observations and unknown dynamics. A\npromising approach is to embed the high-dimensional observations into a\nlower-dimensional latent representation space, estimate the latent dynamics\nmodel, then utilize this model for control in the latent space. An important\nopen question is how to learn a representation that is amenable to existing\ncontrol algorithms? In this paper, we focus on learning representations for\nlocally-linear control algorithms, such as iterative LQR (iLQR). By formulating\nand analyzing the representation learning problem from an optimal control\nperspective, we establish three underlying principles that the learned\nrepresentation should comprise: 1) accurate prediction in the observation\nspace, 2) consistency between latent and observation space dynamics, and 3) low\ncurvature in the latent space transitions. These principles naturally\ncorrespond to a loss function that consists of three terms: prediction,\nconsistency, and curvature (PCC). Crucially, to make PCC tractable, we derive\nan amortized variational bound for the PCC loss function. Extensive experiments\non benchmark domains demonstrate that the new variational-PCC learning\nalgorithm benefits from significantly more stable and reproducible training,\nand leads to superior control performance. Further ablation studies give\nsupport to the importance of all three PCC components for learning a good\nlatent space for control."}, {"title": "Unsupervised Clustering using Pseudo-semi-supervised Learning", "authors": "Divam Gupta, Ramachandran Ramjee, Nipun Kwatra, Muthian Sivathanu"}, {"title": "Harnessing Structures for Value-Based Planning and Reinforcement Learning", "authors": "Yuzhe Yang, Guo Zhang, Zhi Xu, Dina Katabi", "link": "https://arxiv.org/abs/1909.12255", "summary": "Value-based methods constitute a fundamental methodology in planning and deep\nreinforcement learning (RL). In this paper, we propose to exploit the\nunderlying structures of the state-action value function, i.e., Q function, for\nboth planning and deep RL. In particular, if the underlying system dynamics\nlead to some global structures of the Q function, one should be capable of\ninferring the function better by leveraging such structures. Specifically, we\ninvestigate the low-rank structure, which widely exists for big data matrices.\nWe verify empirically the existence of low-rank Q functions in the context of\ncontrol and deep RL tasks. As our key contribution, by leveraging Matrix\nEstimation (ME) techniques, we propose a general framework to exploit the\nunderlying low-rank structure in Q functions. This leads to a more efficient\nplanning procedure for classical control, and additionally, a simple scheme\nthat can be applied to value-based RL techniques to consistently achieve better\nperformance on \"low-rank\" tasks. Extensive experiments on control tasks and\nAtari games confirm the efficacy of our approach."}, {"title": "Depth-Adaptive Transformer", "authors": "Maha Elbayad, Jiatao Gu, Edouard Grave, Michael Auli", "link": "https://arxiv.org/abs/1910.10073", "summary": "State of the art sequence-to-sequence models for large scale tasks perform a\nfixed number of computations for each input sequence regardless of whether it\nis easy or hard to process. In this paper, we train Transformer models which\ncan make output predictions at different stages of the network and we\ninvestigate different ways to predict how much computation is required for a\nparticular sequence. Unlike dynamic computation in Universal Transformers,\nwhich applies the same set of layers iteratively, we apply different layers at\nevery step to adjust both the amount of computation as well as the model\ncapacity. On IWSLT German-English translation our approach matches the accuracy\nof a well tuned baseline Transformer while using less than a quarter of the\ndecoder layers."}, {"title": "Measuring and Improving the Use of Graph Information in Graph Neural Networks", "authors": "Yifan Hou, Jian Zhang, James Cheng, Kaili Ma, Richard T. B. Ma, Hongzhi Chen, Ming-Chang Yang"}, {"title": "Towards neural networks that provably know when they don't know", "authors": "Alexander Meinke, Matthias Hein", "link": "https://arxiv.org/abs/1909.12180", "summary": "It has recently been shown that ReLU networks produce arbitrarily\nover-confident predictions far away from the training data. Thus, ReLU networks\ndo not know when they don't know. However, this is a highly important property\nin safety critical applications. In the context of out-of-distribution\ndetection (OOD) there have been a number of proposals to mitigate this problem\nbut none of them are able to make any mathematical guarantees. In this paper we\npropose a new approach to OOD which overcomes both problems. Our approach can\nbe used with ReLU networks and provides provably low confidence predictions far\naway from the training data as well as the first certificates for low\nconfidence predictions in a neighborhood of an out-distribution point. In the\nexperiments we show that state-of-the-art methods fail in this worst-case\nsetting whereas our model can guarantee its performance while retaining\nstate-of-the-art OOD performance."}, {"title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks", "authors": "Kaifeng Lyu, Jian Li", "link": "https://arxiv.org/abs/1906.05890", "summary": "In this paper, we study the implicit regularization of the gradient descent\nalgorithm in homogeneous neural networks, including fully-connected and\nconvolutional neural networks with ReLU or LeakyReLU activations. In\nparticular, we study the gradient descent or gradient flow (i.e., gradient\ndescent with infinitesimal step size) optimizing the logistic loss or\ncross-entropy loss of any homogeneous model (possibly non-smooth), and show\nthat if the training loss decreases below a certain threshold, then we can\ndefine a smoothed version of the normalized margin which increases over time.\nWe also formulate a natural constrained optimization problem related to margin\nmaximization, and prove that both the normalized margin and its smoothed\nversion converge to the objective value at a KKT point of the optimization\nproblem. Our results generalize the previous results for logistic regression\nwith one-layer or multi-layer linear networks, and provide more quantitative\nconvergence results with weaker assumptions than previous results for\nhomogeneous smooth neural networks. We conduct several experiments to justify\nour theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is\nclosely related to robustness, we discuss potential benefits of training longer\nfor improving the robustness of the model."}, {"title": "BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget", "authors": "Jack Turner, Elliot J. Crowley, Michael O'Boyle, Amos Storkey, Gavin Gray", "link": "https://arxiv.org/abs/1906.04113", "summary": "The desire to map neural networks to varying-capacity devices has led to the\ndevelopment of a wealth of compression techniques, many of which involve\nreplacing standard convolutional blocks in a large network with cheap\nalternative blocks. However, not all blocks are created equally; for a required\ncompute budget there may exist a potent combination of many different cheap\nblocks, though exhaustively searching for such a combination is prohibitively\nexpensive. In this work, we develop BlockSwap: a fast algorithm for choosing\nnetworks with interleaved block types by passing a single minibatch of training\ndata through randomly initialised networks and gauging their Fisher potential.\nThese networks can then be used as students and distilled with the original\nlarge network as a teacher. We demonstrate the effectiveness of the chosen\nnetworks across CIFAR-10 and ImageNet for classification, and COCO for\ndetection, and provide a comprehensive ablation study of our approach.\nBlockSwap quickly explores possible block configurations using a simple\narchitecture ranking system, yielding highly competitive networks in orders of\nmagnitude less time than most architecture search techniques (e.g. under 5\nminutes on a single GPU for CIFAR-10). Code is available at\nhttps://github.com/BayesWatch/pytorch-blockswap."}, {"title": "GenDICE: Generalized Offline Estimation of Stationary Values", "authors": "Ruiyi Zhang, Bo Dai, Lihong Li, Dale Schuurmans"}, {"title": "RGBD-GAN: Unsupervised 3D Representation Learning From Natural Image Datasets via RGBD Image Synthesis", "authors": "Atsuhiro Noguchi, Tatsuya Harada", "link": "", "summary": ""}, {"title": "Empirical Bayes Transductive Meta-Learning with Synthetic Gradients", "authors": "Shell Xu Hu, Pablo Moreno, Yang Xiao, Xi Shen, Guillaume Obozinski, Neil Lawrence, Andreas Damianou"}, {"title": "The Local Elasticity of Neural Networks", "authors": "Hangfeng He, Weijie Su", "link": "https://arxiv.org/abs/1910.06943", "summary": "This paper presents a phenomenon in neural networks that we refer to as\n\\textit{local elasticity}. Roughly speaking, a classifier is said to be locally\nelastic if its prediction at a feature vector $\\bx'$ is \\textit{not}\nsignificantly perturbed, after the classifier is updated via stochastic\ngradient descent at a (labeled) feature vector $\\bx$ that is\n\\textit{dissimilar} to $\\bx'$ in a certain sense. This phenomenon is shown to\npersist for neural networks with nonlinear activation functions through\nextensive simulations on real-life and synthetic datasets, whereas this is not\nobserved in linear classifiers. In addition, we offer a geometric\ninterpretation of local elasticity using the neural tangent kernel\n\\citep{jacot2018neural}. Building on top of local elasticity, we obtain\npairwise similarity measures between feature vectors, which can be used for\nclustering in conjunction with $K$-means. The effectiveness of the clustering\nalgorithm on the MNIST and CIFAR-10 datasets in turn corroborates the\nhypothesis of local elasticity of neural networks on real-life data. Finally,\nwe discuss some implications of local elasticity to shed light on several\nintriguing aspects of deep neural networks."}, {"title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning", "authors": "Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, Andrew Gordon Wilson", "link": "https://arxiv.org/abs/1902.03932", "summary": "The posteriors over neural network weights are high dimensional and\nmultimodal. Each mode typically characterizes a meaningfully different\nrepresentation of the data. We develop Cyclical Stochastic Gradient MCMC\n(SG-MCMC) to automatically explore such distributions. In particular, we\npropose a cyclical stepsize schedule, where larger steps discover new modes,\nand smaller steps characterize each mode. We also prove non-asymptotic\nconvergence of our proposed algorithm. Moreover, we provide extensive\nexperimental results, including ImageNet, to demonstrate the scalability and\neffectiveness of cyclical SG-MCMC in learning complex multimodal distributions,\nespecially for fully Bayesian inference with modern deep neural networks."}, {"title": "CLN2INV: Learning Loop Invariants with Continuous Logic Networks", "authors": "Gabriel Ryan, Justin Wong, Jianan Yao, Ronghui Gu, Suman Jana", "link": "https://arxiv.org/abs/1909.11542", "summary": "Program verification offers a framework for ensuring program correctness and\ntherefore systematically eliminating different classes of bugs. Inferring loop\ninvariants is one of the main challenges behind automated verification of\nreal-world programs which often contain many loops. In this paper, we present\nContinuous Logic Network (CLN), a novel neural architecture for automatically\nlearning loop invariants directly from program execution traces. Unlike\nexisting neural networks, CLNs can learn precise and explicit representations\nof formulas in Satisfiability Modulo Theories (SMT) for loop invariants from\nprogram execution traces. We develop a new sound and complete semantic mapping\nfor assigning SMT formulas to continuous truth values that allows CLNs to be\ntrained efficiently. We use CLNs to implement a new inference system for loop\ninvariants, CLN2INV, that significantly outperforms existing approaches on the\npopular Code2Inv dataset. CLN2INV is the first tool to solve all 124\ntheoretically solvable problems in the Code2Inv dataset. Moreover, CLN2INV\ntakes only 1.1 seconds on average for each problem, which is 40 times faster\nthan existing approaches. We further demonstrate that CLN2INV can even learn 12\nsignificantly more complex loop invariants than the ones required for the\nCode2Inv dataset."}, {"title": "Convolutional Conditional Neural Processes", "authors": "Jonathan Gordon, Wessel P. Bruinsma, Andrew Y. K. Foong, James Requeima, Yann Dubois, Richard E. Turner", "link": "https://arxiv.org/abs/1910.13556", "summary": "We introduce the Convolutional Conditional Neural Process (ConvCNP), a new\nmember of the Neural Process family that models translation equivariance in the\ndata. Translation equivariance is an important inductive bias for many learning\nproblems including time series modelling, spatial data, and images. The model\nembeds data sets into an infinite-dimensional function space as opposed to a\nfinite-dimensional vector space. To formalize this notion, we extend the theory\nof neural representations of sets to include functional representations, and\ndemonstrate that any translation-equivariant embedding can be represented using\na convolutional deep set. We evaluate ConvCNPs in several settings,\ndemonstrating that they achieve state-of-the-art performance compared to\nexisting NPs. We demonstrate that building in translation equivariance enables\nzero-shot generalization to challenging, out-of-domain tasks."}, {"title": "BackPACK: Packing more into Backprop", "authors": "Felix Dangel, Frederik Kunstner, Philipp Hennig", "link": "https://arxiv.org/abs/1912.10985", "summary": "Automatic differentiation frameworks are optimized for exactly one thing:\ncomputing the average mini-batch gradient. Yet, other quantities such as the\nvariance of the mini-batch gradients or many approximations to the Hessian can,\nin theory, be computed efficiently, and at the same time as the gradient. While\nthese quantities are of great interest to researchers and practitioners,\ncurrent deep-learning software does not support their automatic calculation.\nManually implementing them is burdensome, inefficient if done naively, and the\nresulting code is rarely shared. This hampers progress in deep learning, and\nunnecessarily narrows research to focus on gradient descent and its variants;\nit also complicates replication studies and comparisons between newly developed\nmethods that require those quantities, to the point of impossibility. To\naddress this problem, we introduce BackPACK, an efficient framework built on\ntop of PyTorch, that extends the backpropagation algorithm to extract\nadditional information from first- and second-order derivatives. Its\ncapabilities are illustrated by benchmark reports for computing additional\nquantities on deep neural networks, and an example application by testing\nseveral recent curvature approximations for optimization."}, {"title": "Convergence of Gradient Methods on Bilinear Zero-Sum Games", "authors": "Guojun Zhang, Yaoliang Yu", "link": "https://arxiv.org/abs/1908.05699", "summary": "Min-max formulations have attracted great attention in the ML community due\nto the rise of deep generative models and adversarial methods, while\nunderstanding the dynamics of gradient algorithms for solving such formulations\nhas remained a grand challenge. As a first step, we restrict to bilinear\nzero-sum games and give a systematic analysis of popular gradient updates, for\nboth simultaneous and alternating versions. We provide exact conditions for\ntheir convergence and find the optimal parameter setup and convergence rates.\nIn particular, our results offer formal evidence that alternating updates\nconverge \"better\" than simultaneous ones."}, {"title": "LAMOL: LAnguage MOdeling for Lifelong Language Learning", "authors": "Fan-Keng Sun, Cheng-Hao Ho, Hung-Yi Lee", "link": "", "summary": ""}, {"title": "Learning deep graph matching with channel-independent embedding and Hungarian attention", "authors": "Tianshu Yu, Runzhong Wang, Junchi Yan, Baoxin Li"}, {"title": "Learning Nearly Decomposable Value Functions Via Communication Minimization", "authors": "Tonghan Wang, Jianhao Wang, Chongyi Zheng, Chongjie Zhang"}, {"title": "B-Spline CNNs on Lie groups", "authors": "Erik J Bekkers", "link": "", "summary": ""}, {"title": "BatchEnsemble: an Alternative Approach to Efficient Ensemble and Lifelong Learning", "authors": "Yeming Wen, Dustin Tran, Jimmy Ba", "link": "https://arxiv.org/abs/2002.06715", "summary": "Ensembles, where multiple neural networks are trained individually and their\npredictions are averaged, have been shown to be widely successful for improving\nboth the accuracy and predictive uncertainty of single neural networks.\nHowever, an ensemble's cost for both training and testing increases linearly\nwith the number of networks, which quickly becomes untenable.\n  In this paper, we propose BatchEnsemble, an ensemble method whose\ncomputational and memory costs are significantly lower than typical ensembles.\nBatchEnsemble achieves this by defining each weight matrix to be the Hadamard\nproduct of a shared weight among all ensemble members and a rank-one matrix per\nmember. Unlike ensembles, BatchEnsemble is not only parallelizable across\ndevices, where one device trains one member, but also parallelizable within a\ndevice, where multiple ensemble members are updated simultaneously for a given\nmini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and\nout-of-distribution tasks, BatchEnsemble yields competitive accuracy and\nuncertainties as typical ensembles; the speedup at test time is 3X and memory\nreduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to\nlifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable\nperformance to progressive neural networks while having a much lower\ncomputational and memory costs. We further show that BatchEnsemble can easily\nscale up to lifelong learning on Split-ImageNet which involves 100 sequential\nlearning tasks."}, {"title": "A Baseline for Few-Shot Image Classification", "authors": "Guneet Singh Dhillon, Pratik Chaudhari, Avinash Ravichandran, Stefano Soatto", "link": "https://arxiv.org/abs/1909.02729", "summary": "Fine-tuning a deep network trained with the standard cross-entropy loss is a\nstrong baseline for few-shot learning. When fine-tuned transductively, this\noutperforms the current state-of-the-art on standard datasets such as\nMini-ImageNet, Tiered-ImageNet, CIFAR-FS and FC-100 with the same\nhyper-parameters. The simplicity of this approach enables us to demonstrate the\nfirst few-shot learning results on the ImageNet-21k dataset. We find that using\na large number of meta-training classes results in high few-shot accuracies\neven for a large number of few-shot classes. We do not advocate our approach as\nthe solution for few-shot learning, but simply use the results to highlight\nlimitations of current benchmarks and few-shot protocols. We perform extensive\nstudies on benchmark datasets to propose a metric that quantifies the\n\"hardness\" of a few-shot episode. This metric can be used to report the\nperformance of few-shot algorithms in a more systematic way."}, {"title": "Contrastive Representation Distillation", "authors": "Yonglong Tian, Dilip Krishnan, Phillip Isola", "link": "https://arxiv.org/abs/1910.10699", "summary": "Often we wish to transfer representational knowledge from one neural network\nto another. Examples include distilling a large network into a smaller one,\ntransferring knowledge from one sensory modality to a second, or ensembling a\ncollection of models into a single estimator. Knowledge distillation, the\nstandard approach to these problems, minimizes the KL divergence between the\nprobabilistic outputs of a teacher and student network. We demonstrate that\nthis objective ignores important structural knowledge of the teacher network.\nThis motivates an alternative objective by which we train a student to capture\nsignificantly more information in the teacher's representation of the data. We\nformulate this objective as contrastive learning. Experiments demonstrate that\nour resulting new objective outperforms knowledge distillation and other\ncutting-edge distillers on a variety of knowledge transfer tasks, including\nsingle model compression, ensemble distillation, and cross-modal transfer. Our\nmethod sets a new state-of-the-art in many transfer tasks, and sometimes even\noutperforms the teacher network when combined with knowledge distillation.\nCode: http://github.com/HobbitLong/RepDistiller."}, {"title": "Generative Ratio Matching Networks", "authors": "Akash Srivastava, Kai Xu, Michael U. Gutmann, Charles Sutton", "link": "https://arxiv.org/abs/1806.00101", "summary": "Deep generative models can learn to generate realistic-looking images, but\nmany of the most effective methods are adversarial and involve a saddlepoint\noptimization, which requires a careful balancing of training between a\ngenerator network and a critic network. Maximum mean discrepancy networks\n(MMD-nets) avoid this issue by using kernel as a fixed adversary, but\nunfortunately, they have not on their own been able to match the generative\nquality of adversarial training. In this work, we take their insight of using\nkernels as fixed adversaries further and present a novel method for training\ndeep generative models that does not involve saddlepoint optimization. We call\nour method generative ratio matching or GRAM for short. In GRAM, the generator\nand the critic networks do not play a zero-sum game against each other,\ninstead, they do so against a fixed kernel. Thus GRAM networks are not only\nstable to train like MMD-nets but they also match and beat the generative\nquality of adversarially trained generative networks."}, {"title": "Higher-Order Function Networks for Learning Composable 3D Object Representations", "authors": "Eric Mitchell, Selim Engin, Volkan Isler, Daniel D Lee", "link": "https://arxiv.org/abs/1907.10388", "summary": "We present a new approach to 3D object representation where a neural network\nencodes the geometry of an object directly into the weights and biases of a\nsecond 'mapping' network. This mapping network can be used to reconstruct an\nobject by applying its encoded transformation to points randomly sampled from a\nsimple geometric space, such as the unit sphere. We study the effectiveness of\nour method through various experiments on subsets of the ShapeNet dataset. We\nfind that the proposed approach can reconstruct encoded objects with accuracy\nequal to or exceeding state-of-the-art methods with orders of magnitude fewer\nparameters. Our smallest mapping network has only about 7000 parameters and\nshows reconstruction quality on par with state-of-the-art object decoder\narchitectures with millions of parameters. Further experiments on feature\nmixing through the composition of learned functions show that the encoding\ncaptures a meaningful subspace of objects."}, {"title": "Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification", "authors": "Bennet Breier, Arno Onken"}, {"title": "Stochastic AUC Maximization with Deep Neural Networks", "authors": "Mingrui Liu, Zhuoning Yuan, Yiming Ying, Tianbao Yang", "link": "https://arxiv.org/abs/1908.10831", "summary": "Stochastic AUC maximization has garnered an increasing interest due to better\nfit to imbalanced data classification. However, existing works are limited to\nstochastic AUC maximization with a linear predictive model, which restricts its\npredictive power when dealing with extremely complex data. In this paper, we\nconsider stochastic AUC maximization problem with a deep neural network as the\npredictive model. Building on the saddle point reformulation of a surrogated\nloss of AUC, the problem can be cast into a {\\it non-convex concave} min-max\nproblem. The main contribution made in this paper is to make stochastic AUC\nmaximization more practical for deep neural networks and big data with\ntheoretical insights as well. In particular, we propose to explore\nPolyak-\\L{}ojasiewicz (PL) condition that has been proved and observed in deep\nlearning, which enables us to develop new stochastic algorithms with even\nfaster convergence rate and more practical step size scheme. An AdaGrad-style\nalgorithm is also analyzed under the PL condition with adaptive convergence\nrate. Our experimental results demonstrate the effectiveness of the proposed\nalgorithms."}, {"title": "Evaluating The Search Phase of Neural Architecture Search", "authors": "Kaicheng Yu, Christian Sciuto, Martin Jaggi, Claudiu Musat, Mathieu Salzmann", "link": "https://arxiv.org/abs/1902.08142", "summary": "Neural Architecture Search (NAS) aims to facilitate the design of deep\nnetworks for new tasks. Existing techniques rely on two stages: searching over\nthe architecture space and validating the best architecture. NAS algorithms are\ncurrently compared solely based on their results on the downstream task. While\nintuitive, this fails to explicitly evaluate the effectiveness of their search\nstrategies. In this paper, we propose to evaluate the NAS search phase. To this\nend, we compare the quality of the solutions obtained by NAS search policies\nwith that of random architecture selection. We find that: (i) On average, the\nstate-of-the-art NAS algorithms perform similarly to the random policy; (ii)\nthe widely-used weight sharing strategy degrades the ranking of the NAS\ncandidates to the point of not reflecting their true performance, thus reducing\nthe effectiveness of the search process. We believe that our evaluation\nframework will be key to designing NAS strategies that consistently discover\narchitectures superior to random ones."}, {"title": "Episodic Reinforcement Learning with Associative Memory", "authors": "Guangxiang Zhu, Zichuan Lin, Guangwen Yang, Chongjie Zhang"}, {"title": "Sample Efficient Policy Gradient Methods with Recursive Variance Reduction", "authors": "Pan Xu, Felicia Gao, Quanquan Gu"}, {"title": "SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum", "authors": "Jianyu Wang, Vinayak Tantia, Nicolas Ballas, Michael Rabbat", "link": "https://arxiv.org/abs/1910.00643", "summary": "Distributed optimization is essential for training large models on large\ndatasets. Multiple approaches have been proposed to reduce the communication\noverhead in distributed training, such as synchronizing only after performing\nmultiple local SGD steps, and decentralized methods (e.g., using gossip\nalgorithms) to decouple communications among workers. Although these methods\nrun faster than AllReduce-based methods, which use blocking communication\nbefore every update, the resulting models may be less accurate after the same\nnumber of updates. Inspired by the BMUF method of Chen & Huo (2016), we propose\na slow momentum (SlowMo) framework, where workers periodically synchronize and\nperform a momentum update, after multiple iterations of a base optimization\nalgorithm. Experiments on image classification and machine translation tasks\ndemonstrate that SlowMo consistently yields improvements in optimization and\ngeneralization performance relative to the base optimizer, even when the\nadditional overhead is amortized over many updates so that the SlowMo runtime\nis on par with that of the base optimizer. We provide theoretical convergence\nguarantees showing that SlowMo converges to a stationary point of smooth\nnon-convex losses. Since BMUF can be expressed through the SlowMo framework,\nour results also correspond to the first theoretical convergence guarantees for\nBMUF."}, {"title": "Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data", "authors": "Sergei Popov, Stanislav Morozov, Artem Babenko", "link": "https://arxiv.org/abs/1909.06312", "summary": "Nowadays, deep neural networks (DNNs) have become the main instrument for\nmachine learning tasks within a wide range of domains, including vision, NLP,\nand speech. Meanwhile, in an important case of heterogenous tabular data, the\nadvantage of DNNs over shallow counterparts remains questionable. In\nparticular, there is no sufficient evidence that deep learning machinery allows\nconstructing methods that outperform gradient boosting decision trees (GBDT),\nwhich are often the top choice for tabular problems. In this paper, we\nintroduce Neural Oblivious Decision Ensembles (NODE), a new deep learning\narchitecture, designed to work with any tabular data. In a nutshell, the\nproposed NODE architecture generalizes ensembles of oblivious decision trees,\nbut benefits from both end-to-end gradient-based optimization and the power of\nmulti-layer hierarchical representation learning. With an extensive\nexperimental comparison to the leading GBDT packages on a large number of\ntabular datasets, we demonstrate the advantage of the proposed NODE\narchitecture, which outperforms the competitors on most of the tasks. We\nopen-source the PyTorch implementation of NODE and believe that it will become\na universal framework for machine learning on tabular data."}, {"title": "Self-Supervised Learning of Appliance Usage", "authors": "Chen-Yu Hsu, Abbas Zeitoun, Guang-He Lee, Dina Katabi, Tommi Jaakkola"}, {"title": "Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP", "authors": "Yuanhao Wang, Kefan Dong, Xiaoyu Chen, Liwei Wang", "link": "https://arxiv.org/abs/1901.09311", "summary": "A fundamental question in reinforcement learning is whether model-free\nalgorithms are sample efficient. Recently, Jin et al. \\cite{jin2018q} proposed\na Q-learning algorithm with UCB exploration policy, and proved it has nearly\noptimal regret bound for finite-horizon episodic MDP. In this paper, we adapt\nQ-learning with UCB-exploration bonus to infinite-horizon MDP with discounted\nrewards \\emph{without} accessing a generative model. We show that the\n\\textit{sample complexity of exploration} of our algorithm is bounded by\n$\\tilde{O}({\\frac{SA}{\\epsilon^2(1-\\gamma)^7}})$. This improves the previously\nbest known result of $\\tilde{O}({\\frac{SA}{\\epsilon^4(1-\\gamma)^8}})$ in this\nsetting achieved by delayed Q-learning \\cite{strehl2006pac}, and matches the\nlower bound in terms of $\\epsilon$ as well as $S$ and $A$ except for\nlogarithmic factors."}, {"title": "You Only Train Once: Loss-Conditional Training of Deep Networks", "authors": "Alexey Dosovitskiy, Josip Djolonga"}, {"title": "Diverse Trajectory Forecasting with Determinantal Point Processes", "authors": "Ye Yuan, Kris M. Kitani", "link": "https://arxiv.org/abs/1907.04967", "summary": "The ability to forecast a set of likely yet diverse possible future behaviors\nof an agent (e.g., future trajectories of a pedestrian) is essential for\nsafety-critical perception systems (e.g., autonomous vehicles). In particular,\na set of possible future behaviors generated by the system must be diverse to\naccount for all possible outcomes in order to take necessary safety\nprecautions. It is not sufficient to maintain a set of the most likely future\noutcomes because the set may only contain perturbations of a single outcome.\nWhile generative models such as variational autoencoders (VAEs) have been shown\nto be a powerful tool for learning a distribution over future trajectories,\nrandomly drawn samples from the learned implicit likelihood model may not be\ndiverse -- the likelihood model is derived from the training data distribution\nand the samples will concentrate around the major mode that has most data. In\nthis work, we propose to learn a diversity sampling function (DSF) that\ngenerates a diverse and likely set of future trajectories. The DSF maps\nforecasting context features to a set of latent codes which can be decoded by a\ngenerative model (e.g., VAE) into a set of diverse trajectory samples.\nConcretely, the process of identifying the diverse set of samples is posed as a\nparameter estimation of the DSF. To learn the parameters of the DSF, the\ndiversity of the trajectory samples is evaluated by a diversity loss based on a\ndeterminantal point process (DPP). Gradient descent is performed over the DSF\nparameters, which in turn move the latent codes of the sample set to find an\noptimal diverse and likely set of trajectories. Our method is a novel\napplication of DPPs to optimize a set of items (trajectories) in continuous\nspace. We demonstrate the diversity of the trajectories produced by our\napproach on both low-dimensional 2D trajectory data and high-dimensional human\nmotion data."}, {"title": "Low-Resource Knowledge-Grounded Dialogue Generation", "authors": "Xueliang Zhao, Wei Wu, Chongyang Tao, Can Xu, Dongyan Zhao, Rui Yan", "link": "https://arxiv.org/abs/2002.10348", "summary": "Responding with knowledge has been recognized as an important capability for\nan intelligent conversational agent. Yet knowledge-grounded dialogues, as\ntraining data for learning such a response generation model, are difficult to\nobtain. Motivated by the challenge in practice, we consider knowledge-grounded\ndialogue generation under a natural assumption that only limited training\nexamples are available. In such a low-resource setting, we devise a\ndisentangled response decoder in order to isolate parameters that depend on\nknowledge-grounded dialogues from the entire generation model. By this means,\nthe major part of the model can be learned from a large number of ungrounded\ndialogues and unstructured documents, while the remaining small parameters can\nbe well fitted using the limited training examples. Evaluation results on two\nbenchmarks indicate that with only 1/8 training data, our model can achieve the\nstate-of-the-art performance and generalize well on out-of-domain knowledge."}, {"title": "Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection", "authors": "Michael Tsang, Dehua Cheng, Hanpeng Liu, Xue Feng, Eric Zhou, Yan Liu"}, {"title": "Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks", "authors": "Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft", "link": "https://arxiv.org/abs/1908.06281", "summary": "Deep learning models are vulnerable to adversarial examples crafted by\napplying human-imperceptible perturbations on benign inputs. However, under the\nblack-box setting, most existing adversaries often have a poor transferability\nto attack other defense models. In this work, from the perspective of regarding\nthe adversarial example generation as an optimization process, we propose two\nnew methods to improve the transferability of adversarial examples, namely\nNesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant\nattack Method (SIM). NI-FGSM aims to adapt Nesterov accelerated gradient into\nthe iterative attacks so as to effectively look ahead and improve the\ntransferability of adversarial examples. While SIM is based on our discovery on\nthe scale-invariant property of deep learning models, for which we leverage to\noptimize the adversarial perturbations over the scale copies of the input\nimages so as to avoid \"overfitting\" on the white-box model being attacked and\ngenerate more transferable adversarial examples. NI-FGSM and SIM can be\nnaturally integrated to build a robust gradient-based attack to generate more\ntransferable adversarial examples against the defense models. Empirical results\non ImageNet dataset demonstrate that our attack methods exhibit higher\ntransferability and achieve higher attack success rates than state-of-the-art\ngradient-based attacks."}, {"title": "Intensity-Free Learning of Temporal Point Processes", "authors": "Oleksandr Shchur, Marin Bilo\u0161, Stephan G\u00fcnnemann", "link": "https://arxiv.org/abs/1909.12127", "summary": "Temporal point processes are the dominant paradigm for modeling sequences of\nevents happening at irregular intervals. The standard way of learning in such\nmodels is by estimating the conditional intensity function. However,\nparameterizing the intensity function usually incurs several trade-offs. We\nshow how to overcome the limitations of intensity-based approaches by directly\nmodeling the conditional distribution of inter-event times. We draw on the\nliterature on normalizing flows to design models that are flexible and\nefficient. We additionally propose a simple mixture model that matches the\nflexibility of flow-based models, but also permits sampling and computing\nmoments in closed form. The proposed models achieve state-of-the-art\nperformance in standard prediction tasks and are suitable for novel\napplications, such as learning sequence embeddings and imputing missing data."}, {"title": "Composition-based Multi-Relational Graph Convolutional Networks", "authors": "Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, Partha Talukdar"}, {"title": "The Ingredients of Real World Robotic Reinforcement Learning", "authors": "Henry Zhu, Justin Yu, Abhishek Gupta, Dhruv Shah, Kristian Hartikainen, Avi Singh, Vikash Kumar, Sergey Levine"}, {"title": "Lookahead: A Far-sighted Alternative of Magnitude-based Pruning", "authors": "Sejun Park, Jaeho Lee, Sangwoo Mo, Jinwoo Shin", "link": "https://arxiv.org/abs/2002.04809", "summary": "Magnitude-based pruning is one of the simplest methods for pruning neural\nnetworks. Despite its simplicity, magnitude-based pruning and its variants\ndemonstrated remarkable performances for pruning modern architectures. Based on\nthe observation that magnitude-based pruning indeed minimizes the Frobenius\ndistortion of a linear operator corresponding to a single layer, we develop a\nsimple pruning method, coined lookahead pruning, by extending the single layer\noptimization to a multi-layer optimization. Our experimental results\ndemonstrate that the proposed method consistently outperforms magnitude-based\npruning on various networks, including VGG and ResNet, particularly in the\nhigh-sparsity regime. See https://github.com/alinlab/lookahead_pruning for\ncodes."}, {"title": "Truth or backpropaganda? An empirical investigation of deep learning theory", "authors": "Micah Goldblum, Jonas Geiping, Avi Schwarzschild, Michael Moeller, Tom Goldstein"}, {"title": "Learning from Rules Generalizing Labeled Exemplars", "authors": "Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, Sunita Sarawagi"}, {"title": "Neural Network Branching for Neural Network Verification ", "authors": "Jingyue Lu, M. Pawan Kumar", "link": "https://arxiv.org/abs/1912.01329", "summary": "Formal verification of neural networks is essential for their deployment in\nsafety-critical areas. Many available formal verification methods have been\nshown to be instances of a unified Branch and Bound (BaB) formulation. We\npropose a novel framework for designing an effective branching strategy for\nBaB. Specifically, we learn a graph neural network (GNN) to imitate the strong\nbranching heuristic behaviour. Our framework differs from previous methods for\nlearning to branch in two main aspects. Firstly, our framework directly treats\nthe neural network we want to verify as a graph input for the GNN. Secondly, we\ndevelop an intuitive forward and backward embedding update schedule.\nEmpirically, our framework achieves roughly $50\\%$ reduction in both the number\nof branches and the time required for verification on various convolutional\nnetworks when compared to the best available hand-designed branching strategy.\nIn addition, we show that our GNN model enjoys both horizontal and vertical\ntransferability. Horizontally, the model trained on easy properties performs\nwell on properties of increased difficulty levels. Vertically, the model\ntrained on small neural networks achieves similar performance on large neural\nnetworks."}, {"title": "Learning from Unlabelled Videos Using Contrastive Predictive Neural 3D Mapping", "authors": "Adam W. Harley, Shrinidhi K. Lakshmikanth, Fangyu Li, Xian Zhou, Hsiao-Yu Fish Tung, Katerina Fragkiadaki", "link": "https://arxiv.org/abs/1906.03764", "summary": "Predictive coding theories suggest that the brain learns by predicting\nobservations at various levels of abstraction. One of the most basic prediction\ntasks is view prediction: how would a given scene look from an alternative\nviewpoint? Humans excel at this task. Our ability to imagine and fill in\nmissing information is tightly coupled with perception: we feel as if we see\nthe world in 3 dimensions, while in fact, information from only the front\nsurface of the world hits our retinas. This paper explores the role of view\nprediction in the development of 3D visual recognition. We propose neural 3D\nmapping networks, which take as input 2.5D (color and depth) video streams\ncaptured by a moving camera, and lift them to stable 3D feature maps of the\nscene, by disentangling the scene content from the motion of the camera. The\nmodel also projects its 3D feature maps to novel viewpoints, to predict and\nmatch against target views. We propose contrastive prediction losses to replace\nthe standard color regression loss, and show that this leads to better\nperformance on complex photorealistic data. We show that the proposed model\nlearns visual representations useful for (1) semi-supervised learning of 3D\nobject detectors, and (2) unsupervised learning of 3D moving object detectors,\nby estimating the motion of the inferred 3D feature maps in videos of dynamic\nscenes. To the best of our knowledge, this is the first work that empirically\nshows view prediction to be a scalable self-supervised task beneficial to 3D\nobject detection."}, {"title": "Pruned Graph Scattering Transforms", "authors": "Vassilis N. Ioannidis, Siheng Chen, Georgios B. Giannakis"}, {"title": "Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information", "authors": "Yichi Zhou, Tongzheng Ren, Jialian Li, Dong Yan, Jun Zhu", "link": "https://arxiv.org/abs/1810.04433", "summary": "Counterfactual regret minimization (CFR) is the most popular algorithm on\nsolving two-player zero-sum extensive games with imperfect information and\nachieves state-of-the-art performance in practice. However, the performance of\nCFR is not fully understood, since empirical results on the regret are much\nbetter than the upper bound proved in \\cite{zinkevich2008regret}. Another issue\nis that CFR has to traverse the whole game tree in each round, which is\ntime-consuming in large scale games. In this paper, we present a novel\ntechnique, lazy update, which can avoid traversing the whole game tree in CFR,\nas well as a novel analysis on the regret of CFR with lazy update. Our analysis\ncan also be applied to the vanilla CFR, resulting in a much tighter regret\nbound than that in \\cite{zinkevich2008regret}. Inspired by lazy update, we\nfurther present a novel CFR variant, named Lazy-CFR. Compared to traversing\n$O(|\\mathcal{I}|)$ information sets in vanilla CFR, Lazy-CFR needs only to\ntraverse $O(\\sqrt{|\\mathcal{I}|})$ information sets per round while keeping the\nregret bound almost the same, where $\\mathcal{I}$ is the class of all\ninformation sets. As a result, Lazy-CFR shows better convergence result\ncompared with vanilla CFR. Experimental results consistently show that Lazy-CFR\noutperforms the vanilla CFR significantly."}, {"title": "Neural tangent kernels, transportation mappings, and universal approximation", "authors": "Ziwei Ji, Matus Telgarsky, Ruicheng Xian", "link": "https://arxiv.org/abs/1910.06956", "summary": "This paper establishes rates of universal approximation for the shallow\nneural tangent kernel (NTK): network weights are only allowed microscopic\nchanges from random initialization, which entails that activations are mostly\nunchanged, and the network is nearly equivalent to its linearization.\nConcretely, the paper has two main contributions: a generic scheme to\napproximate functions with the NTK by sampling from transport mappings between\nthe initial weights and their desired values, and the construction of transport\nmappings via Fourier transforms. Regarding the first contribution, the proof\nscheme provides another perspective on how the NTK regime arises from\nrescaling: redundancy in the weights due to resampling allows individual\nweights to be scaled down. Regarding the second contribution, the most notable\ntransport mapping asserts that roughly $1 / \\delta^{10d}$ nodes are sufficient\nto approximate continuous functions, where $\\delta$ depends on the continuity\nproperties of the target function. By contrast, nearly the same proof yields a\nbound of $1 / \\delta^{2d}$ for shallow ReLU networks; this gap suggests a\ntantalizing direction for future work, separating shallow ReLU networks and\ntheir linearization."}, {"title": "Gap-Aware Mitigation of Gradient Staleness", "authors": "Saar Barkai, Ido Hakimi, Assaf Schuster", "link": "https://arxiv.org/abs/1909.10802", "summary": "Cloud computing is becoming increasingly popular as a platform for\ndistributed training of deep neural networks. Synchronous stochastic gradient\ndescent (SSGD) suffers from substantial slowdowns due to stragglers if the\nenvironment is non-dedicated, as is common in cloud computing. Asynchronous SGD\n(ASGD) methods are immune to these slowdowns but are scarcely used due to\ngradient staleness, which encumbers the convergence process. Recent techniques\nhave had limited success mitigating the gradient staleness when scaling up to\nmany workers (computing nodes). In this paper we define the Gap as a measure of\ngradient staleness and propose Gap-Aware (GA), a novel asynchronous-distributed\nmethod that penalizes stale gradients linearly to the Gap and performs well\neven when scaling to large numbers of workers. Our evaluation on the CIFAR,\nImageNet, and WikiText-103 datasets shows that GA outperforms the currently\nacceptable gradient penalization method, in final test accuracy. We also\nprovide convergence rate proof for GA. Despite prior beliefs, we show that if\nGA is applied, momentum becomes beneficial in asynchronous environments, even\nwhen the number of workers scales up."}, {"title": "Locally Constant Networks", "authors": "Guang-He Lee, Tommi S. Jaakkola", "link": "", "summary": ""}, {"title": "CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning", "authors": "Jiachen Yang, Alireza Nakhaei, David Isele, Kikuo Fujimura, Hongyuan Zha", "link": "https://arxiv.org/abs/1809.05188", "summary": "A variety of cooperative multi-agent control problems require agents to\nachieve individual goals while contributing to collective success. This\nmulti-goal multi-agent setting poses difficulties for recent algorithms, which\nprimarily target settings with a single global reward, due to two new\nchallenges: efficient exploration for learning both individual goal attainment\nand cooperation for others' success, and credit-assignment for interactions\nbetween actions and goals of different agents. To address both challenges, we\nrestructure the problem into a novel two-stage curriculum, in which\nsingle-agent goal attainment is learned prior to learning multi-agent\ncooperation, and we derive a new multi-goal multi-agent policy gradient with a\ncredit function for localized credit assignment. We use a function augmentation\nscheme to bridge value and policy functions across the curriculum. The complete\narchitecture, called CM3, learns significantly faster than direct adaptations\nof existing algorithms on three challenging multi-goal multi-agent problems:\ncooperative navigation in difficult formations, negotiating multi-vehicle lane\nchanges in the SUMO traffic simulator, and strategic cooperation in a Checkers\nenvironment."}, {"title": "Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models", "authors": "Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren", "link": "https://arxiv.org/abs/1911.06194", "summary": "The impressive performance of neural networks on natural language processing\ntasks attributes to their ability to model complicated word and phrase\ninteractions. Existing flat, word level explanations of predictions hardly\nunveil how neural networks handle compositional semantics to reach predictions.\nTo tackle the challenge, we study hierarchical explanation of neural network\npredictions. We identify non-additivity and independent importance attributions\nwithin hierarchies as two desirable properties for highlighting word and phrase\ninteractions. We show prior efforts on hierarchical explanations, e.g.\ncontextual decomposition, however, do not satisfy the desired properties\nmathematically. In this paper, we propose a formal way to quantify the\nimportance of each word or phrase for hierarchical explanations. Following the\nformulation, we propose Sampling and Contextual Decomposition (SCD) algorithm\nand Sampling and Occlusion (SOC) algorithm. Human and metrics evaluation on\nboth LSTM models and BERT Transformer models on multiple datasets show that our\nalgorithms outperform prior hierarchical explanation algorithms. Our algorithms\napply to hierarchical visualization of compositional semantics, extraction of\nclassification rules and improving human trust of models."}, {"title": "Meta-learning curiosity algorithms", "authors": "Ferran Alet, Martin F. Schneider, Tomas Lozano-Perez, Leslie Pack Kaelbling", "link": "http://arxiv.org/abs/2003.05325", "summary": "We hypothesize that curiosity is a mechanism found by evolution that\nencourages meaningful exploration early in an agent's life in order to expose\nit to experiences that enable it to obtain high rewards over the course of its\nlifetime. We formulate the problem of generating curious behavior as one of\nmeta-learning: an outer loop will search over a space of curiosity mechanisms\nthat dynamically adapt the agent's reward signal, and an inner loop will\nperform standard reinforcement learning using the adapted reward signal.\nHowever, current meta-RL methods based on transferring neural network weights\nhave only generalized between very similar tasks. To broaden the\ngeneralization, we instead propose to meta-learn algorithms: pieces of code\nsimilar to those designed by humans in ML papers. Our rich language of programs\ncombines neural networks with other building blocks such as buffers,\nnearest-neighbor modules and custom loss functions. We demonstrate the\neffectiveness of the approach empirically, finding two novel curiosity\nalgorithms that perform on par or better than human-designed published\ncuriosity algorithms in domains as disparate as grid navigation with image\ninputs, acrobot, lunar lander, ant and hopper."}, {"title": "Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps", "authors": "Tri Dao, Nimit Sohoni, Albert Gu, Matthew Eichhorn, Amit Blonder, Megan Leszczynski, Atri Rudra, Christopher R\u00e9"}, {"title": "Improving Neural Language Generation with Spectrum Control", "authors": "Lingxiao Wang, Jing Huang, Kevin Huang, Ziniu Hu, Guangtao Wang, Quanquan Gu"}, {"title": "RNA Secondary Structure Prediction By Learning Unrolled Algorithms", "authors": "Xinshi Chen, Yu Li, Ramzan Umarov, Xin Gao, Le Song"}, {"title": "Single Episode Policy Transfer in Reinforcement Learning", "authors": "Jiachen Yang, Brenden Petersen, Hongyuan Zha, Daniel Faissol", "link": "https://arxiv.org/abs/1910.07719", "summary": "Transfer and adaptation to new unknown environmental dynamics is a key\nchallenge for reinforcement learning (RL). An even greater challenge is\nperforming near-optimally in a single attempt at test time, possibly without\naccess to dense rewards, which is not addressed by current methods that require\nmultiple experience rollouts for adaptation. To achieve single episode transfer\nin a family of environments with related dynamics, we propose a general\nalgorithm that optimizes a probe and an inference model to rapidly estimate\nunderlying latent variables of test dynamics, which are then immediately used\nas input to a universal control policy. This modular approach enables\nintegration of state-of-the-art algorithms for variational inference or RL.\nMoreover, our approach does not require access to rewards at test time,\nallowing it to perform in settings where existing adaptive approaches cannot.\nIn diverse experimental domains with a single episode test constraint, our\nmethod significantly outperforms existing adaptive approaches and shows\nfavorable performance against baselines for robust transfer."}, {"title": "Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing", "authors": "Jinyuan Jia, Xiaoyu Cao, Binghui Wang, Neil Zhenqiang Gong", "link": "https://arxiv.org/abs/1912.09899", "summary": "It is well-known that classifiers are vulnerable to adversarial\nperturbations. To defend against adversarial perturbations, various certified\nrobustness results have been derived. However, existing certified robustnesses\nare limited to top-1 predictions. In many real-world applications, top-$k$\npredictions are more relevant. In this work, we aim to derive certified\nrobustness for top-$k$ predictions. In particular, our certified robustness is\nbased on randomized smoothing, which turns any classifier to a new classifier\nvia adding noise to an input example. We adopt randomized smoothing because it\nis scalable to large-scale neural networks and applicable to any classifier. We\nderive a tight robustness in $\\ell_2$ norm for top-$k$ predictions when using\nrandomized smoothing with Gaussian noise. We find that generalizing the\ncertified robustness from top-1 to top-$k$ predictions faces significant\ntechnical challenges. We also empirically evaluate our method on CIFAR10 and\nImageNet. For example, our method can obtain an ImageNet classifier with a\ncertified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial\nperturbations are less than 0.5 (=127/255). Our code is publicly available at:\n\\url{https://github.com/jjy1994/Certify_Topk}."}, {"title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction", "authors": "Taeuk Kim, Jihun Choi, Daniel Edmiston, Sang-goo Lee"}, {"title": "Reanalysis of Variance Reduced Temporal Difference Learning", "authors": "Tengyu Xu, Zhe Wang, Yi Zhou, Yingbin Liang", "link": "https://arxiv.org/abs/2001.01898", "summary": "Temporal difference (TD) learning is a popular algorithm for policy\nevaluation in reinforcement learning, but the vanilla TD can substantially\nsuffer from the inherent optimization variance. A variance reduced TD (VRTD)\nalgorithm was proposed by Korda and La (2015), which applies the variance\nreduction technique directly to the online TD learning with Markovian samples.\nIn this work, we first point out the technical errors in the analysis of VRTD\nin Korda and La (2015), and then provide a mathematically solid analysis of the\nnon-asymptotic convergence of VRTD and its variance reduction performance. We\nshow that VRTD is guaranteed to converge to a neighborhood of the fixed-point\nsolution of TD at a linear convergence rate. Furthermore, the variance error\n(for both i.i.d.\\ and Markovian sampling) and the bias error (for Markovian\nsampling) of VRTD are significantly reduced by the batch size of variance\nreduction in comparison to those of vanilla TD. As a result, the overall\ncomputational complexity of VRTD to attain a given accurate solution\noutperforms that of TD under Markov sampling and outperforms that of TD under\ni.i.d.\\ sampling for a sufficiently small conditional number."}, {"title": "DeepV2D: Video to Depth with Differentiable Structure from Motion", "authors": "Zachary Teed, Jia Deng", "link": "https://arxiv.org/abs/1812.04605", "summary": "We propose DeepV2D, an end-to-end deep learning architecture for predicting\ndepth from video. DeepV2D combines the representation ability of neural\nnetworks with the geometric principles governing image formation. We compose a\ncollection of classical geometric algorithms, which are converted into\ntrainable modules and combined into an end-to-end differentiable architecture.\nDeepV2D interleaves two stages: motion estimation and depth estimation. During\ninference, motion and depth estimation are alternated and converge to accurate\ndepth. Code is available https://github.com/princeton-vl/DeepV2D."}, {"title": "On the Global Convergence  of Training Deep Linear ResNets", "authors": "Difan Zou, Philip M. Long, Quanquan Gu"}, {"title": "Iterative energy-based projection on a normal data manifold for anomaly localization", "authors": "David Dehaene, Oriel Frigo, S\u00e9bastien Combrexelle, Pierre Eline"}, {"title": "On Mutual Information Maximization for Representation Learning", "authors": "Michael Tschannen, Josip Djolonga, Paul K. Rubenstein, Sylvain Gelly, Mario Lucic", "link": "https://arxiv.org/abs/1907.13625", "summary": "Many recent methods for unsupervised or self-supervised representation\nlearning train feature extractors by maximizing an estimate of the mutual\ninformation (MI) between different views of the data. This comes with several\nimmediate problems: For example, MI is notoriously hard to estimate, and using\nit as an objective for representation learning may lead to highly entangled\nrepresentations due to its invariance under arbitrary invertible\ntransformations. Nevertheless, these methods have been repeatedly shown to\nexcel in practice. In this paper we argue, and provide empirical evidence, that\nthe success of these methods cannot be attributed to the properties of MI\nalone, and that they strongly depend on the inductive bias in both the choice\nof feature extractor architectures and the parametrization of the employed MI\nestimators. Finally, we establish a connection to deep metric learning and\nargue that this interpretation may be a plausible explanation for the success\nof the recently introduced methods."}, {"title": "Automated curriculum generation through setter-solver interactions", "authors": "Sebastien Racaniere, Andrew Lampinen, Adam Santoro, David Reichert, Vlad Firoiu, Timothy Lillicrap", "link": "https://arxiv.org/abs/1909.12892", "summary": "Reinforcement learning algorithms use correlations between policies and\nrewards to improve agent performance. But in dynamic or sparsely rewarding\nenvironments these correlations are often too small, or rewarding events are\ntoo infrequent to make learning feasible. Human education instead relies on\ncurricula--the breakdown of tasks into simpler, static challenges with dense\nrewards--to build up to complex behaviors. While curricula are also useful for\nartificial agents, hand-crafting them is time consuming. This has lead\nresearchers to explore automatic curriculum generation. Here we explore\nautomatic curriculum generation in rich, dynamic environments. Using a\nsetter-solver paradigm we show the importance of considering goal validity,\ngoal feasibility, and goal coverage to construct useful curricula. We\ndemonstrate the success of our approach in rich but sparsely rewarding 2D and\n3D environments, where an agent is tasked to achieve a single goal selected\nfrom a set of possible goals that varies between episodes, and identify\nchallenges for future work. Finally, we demonstrate the value of a novel\ntechnique that guides agents towards a desired goal distribution. Altogether,\nthese results represent a substantial step towards applying automatic task\ncurricula to learn complex, otherwise unlearnable goals, and to our knowledge\nare the first to demonstrate automated curriculum generation for\ngoal-conditioned agents in environments where the possible goals vary between\nepisodes."}, {"title": "Hypermodels for Exploration", "authors": "Vikranth Dwaracherla, Xiuyuan Lu, Morteza Ibrahimi, Ian Osband, Zheng Wen, Benjamin Van Roy"}, {"title": "Tensor Decompositions for Temporal Knowledge Base Completion", "authors": "Timoth\u00e9e Lacroix, Guillaume Obozinski, Nicolas Usunier"}, {"title": "Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds", "authors": "Jordan T. Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, Alekh Agarwal", "link": "https://arxiv.org/abs/1906.03671", "summary": "We design a new algorithm for batch active learning with deep neural network\nmodels. Our algorithm, Batch Active learning by Diverse Gradient Embeddings\n(BADGE), samples groups of points that are disparate and high-magnitude when\nrepresented in a hallucinated gradient space, a strategy designed to\nincorporate both predictive uncertainty and sample diversity into every\nselected batch. Crucially, BADGE trades off between diversity and uncertainty\nwithout requiring any hand-tuned hyperparameters. We show that while other\napproaches sometimes succeed for particular batch sizes or architectures, BADGE\nconsistently performs as well or better, making it a versatile option for\npractical active learning problems."}, {"title": "VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation", "authors": "Manoj Kumar, Mohammad Babaeizadeh, Dumitru Erhan, Chelsea Finn, Sergey Levine, Laurent Dinh, Durk Kingma", "link": "https://arxiv.org/abs/1903.01434", "summary": "Generative models that can model and predict sequences of future events can,\nin principle, learn to capture complex real-world phenomena, such as physical\ninteractions. However, a central challenge in video prediction is that the\nfuture is highly uncertain: a sequence of past observations of events can imply\nmany possible futures. Although a number of recent works have studied\nprobabilistic models that can represent uncertain futures, such models are\neither extremely expensive computationally as in the case of pixel-level\nautoregressive models, or do not directly optimize the likelihood of the data.\nTo our knowledge, our work is the first to propose multi-frame video prediction\nwith normalizing flows, which allows for direct optimization of the data\nlikelihood, and produces high-quality stochastic predictions. We describe an\napproach for modeling the latent space dynamics, and demonstrate that\nflow-based generative models offer a viable and competitive approach to\ngenerative modelling of video."}, {"title": "Toward Evaluating Robustness of Deep Reinforcement Learning with Continuous Control", "authors": "Tsui-Wei Weng, Krishnamurthy (Dj) Dvijotham, Jonathan Uesato, Kai Xiao, Sven Gowal, Robert Stanforth, Pushmeet Kohli"}, {"title": "A closer look at the approximation capabilities of neural networks", "authors": "Kai Fong Ernest Chong", "link": "https://arxiv.org/abs/2002.06505", "summary": "The universal approximation theorem, in one of its most general versions,\nsays that if we consider only continuous activation functions $\\sigma$, then a\nstandard feedforward neural network with one hidden layer is able to\napproximate any continuous multivariate function $f$ to any given approximation\nthreshold $\\varepsilon$, if and only if $\\sigma$ is non-polynomial. In this\npaper, we give a direct algebraic proof of the theorem. Furthermore we shall\nexplicitly quantify the number of hidden units required for approximation.\nSpecifically, if $X\\subseteq \\mathbb{R}^n$ is compact, then a neural network\nwith $n$ input units, $m$ output units, and a single hidden layer with\n$\\binom{n+d}{d}$ hidden units (independent of $m$ and $\\varepsilon$), can\nuniformly approximate any polynomial function $f:X \\to \\mathbb{R}^m$ whose\ntotal degree is at most $d$ for each of its $m$ coordinate functions. In the\ngeneral case that $f$ is any continuous function, we show there exists some\n$N\\in \\mathcal{O}(\\varepsilon^{-n})$ (independent of $m$), such that $N$ hidden\nunits would suffice to approximate $f$. We also show that this uniform\napproximation property (UAP) still holds even under seemingly strong conditions\nimposed on the weights. We highlight several consequences: (i) For any $\\delta\n> 0$, the UAP still holds if we restrict all non-bias weights $w$ in the last\nlayer to satisfy $|w| < \\delta$. (ii) There exists some $\\lambda>0$ (depending\nonly on $f$ and $\\sigma$), such that the UAP still holds if we restrict all\nnon-bias weights $w$ in the first layer to satisfy $|w|>\\lambda$. (iii) If the\nnon-bias weights in the first layer are \\emph{fixed} and randomly chosen from a\nsuitable range, then the UAP holds with probability $1$."}, {"title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning", "authors": "Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng"}, {"title": "Discriminative Particle Filter Reinforcement Learning for Complex Partial observations", "authors": "Xiao Ma, Peter Karkus, David Hsu, Wee Sun Lee, Nan Ye"}, {"title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation", "authors": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, Rosanne Liu", "link": "https://arxiv.org/abs/1912.02164", "summary": "Large transformer-based language models (LMs) trained on huge text corpora\nhave shown unparalleled generation capabilities. However, controlling\nattributes of the generated language (e.g. switching topic or sentiment) is\ndifficult without modifying the model architecture or fine-tuning on\nattribute-specific data and entailing the significant cost of retraining. We\npropose a simple alternative: the Plug and Play Language Model (PPLM) for\ncontrollable language generation, which combines a pretrained LM with one or\nmore simple attribute classifiers that guide text generation without any\nfurther training of the LM. In the canonical scenario we present, the attribute\nmodels are simple classifiers consisting of a user-specified bag of words or a\nsingle learned layer with 100,000 times fewer parameters than the LM. Sampling\nentails a forward and backward pass in which gradients from the attribute model\npush the LM's hidden activations and thus guide the generation. Model samples\ndemonstrate control over a range of topics and sentiment styles, and extensive\nautomated and human annotated evaluations show attribute alignment and fluency.\nPPLMs are flexible in that any combination of differentiable attribute models\nmay be used to steer text generation, which will allow for diverse and creative\napplications beyond the examples given in this paper."}, {"title": "Automated Relational Meta-learning", "authors": "Huaxiu Yao, Xian Wu, Zhiqiang Tao, Yaliang Li, Bolin Ding, Ruirui Li, Zhenhui Li"}, {"title": "Improved memory in recurrent neural networks with sequential non-normal dynamics", "authors": "Emin Orhan, Xaq Pitkow", "link": "https://arxiv.org/abs/1905.13715", "summary": "Training recurrent neural networks (RNNs) is a hard problem due to\ndegeneracies in the optimization landscape, a problem also known as\nvanishing/exploding gradients. Short of designing new RNN architectures,\nprevious methods for dealing with this problem usually boil down to\northogonalization of the recurrent dynamics, either at initialization or during\nthe entire training period. The basic motivation behind these methods is that\northogonal transformations are isometries of the Euclidean space, hence they\npreserve (Euclidean) norms and effectively deal with vanishing/exploding\ngradients. However, this ignores the crucial effects of non-linearity and\nnoise. In the presence of a non-linearity, orthogonal transformations no longer\npreserve norms, suggesting that alternative transformations might be better\nsuited to non-linear networks. Moreover, in the presence of noise, norm\npreservation itself ceases to be the ideal objective. A more sensible objective\nis maximizing the signal-to-noise ratio (SNR) of the propagated signal instead.\nPrevious work has shown that in the linear case, recurrent networks that\nmaximize the SNR display strongly non-normal, sequential dynamics and\northogonal networks are highly suboptimal by this measure. Motivated by this\nfinding, here we investigate the potential of non-normal RNNs, i.e. RNNs with a\nnon-normal recurrent connectivity matrix, in sequential processing tasks. Our\nexperimental results show that non-normal RNNs outperform their orthogonal\ncounterparts in a diverse range of benchmarks. We also find evidence for\nincreased non-normality and hidden chain-like feedforward motifs in trained\nRNNs initialized with orthogonal recurrent connectivity matrices."}, {"title": "Generalization through Memorization: Nearest Neighbor Language Models", "authors": "Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, Mike Lewis"}, {"title": "Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation", "authors": "Suraj Nair, Chelsea Finn", "link": "https://arxiv.org/abs/1909.05829", "summary": "Video prediction models combined with planning algorithms have shown promise\nin enabling robots to learn to perform many vision-based tasks through only\nself-supervision, reaching novel goals in cluttered scenes with unseen objects.\nHowever, due to the compounding uncertainty in long horizon video prediction\nand poor scalability of sampling-based planning optimizers, one significant\nlimitation of these approaches is the ability to plan over long horizons to\nreach distant goals. To that end, we propose a framework for subgoal generation\nand planning, hierarchical visual foresight (HVF), which generates subgoal\nimages conditioned on a goal image, and uses them for planning. The subgoal\nimages are directly optimized to decompose the task into easy to plan segments,\nand as a result, we observe that the method naturally identifies semantically\nmeaningful states as subgoals. Across three out of four simulated vision-based\nmanipulation tasks, we find that our method achieves nearly a 200% performance\nimprovement over planning without subgoals and model-free RL approaches.\nFurther, our experiments illustrate that our approach extends to real,\ncluttered visual scenes. Project page:\nhttps://sites.google.com/stanford.edu/hvf"}, {"title": "Projection-Based Constrained Policy Optimization", "authors": "Tsung-Yen Yang, Justinian Rosca, Karthik Narasimhan, Peter J. Ramadge"}, {"title": "Combining Q-Learning and Search with Amortized Value Estimates", "authors": "Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Tobias Pfaff, Theophane Weber, Lars Buesing, Peter W. Battaglia", "link": "https://arxiv.org/abs/1912.02807", "summary": "We introduce \"Search with Amortized Value Estimates\" (SAVE), an approach for\ncombining model-free Q-learning with model-based Monte-Carlo Tree Search\n(MCTS). In SAVE, a learned prior over state-action values is used to guide\nMCTS, which estimates an improved set of state-action values. The new\nQ-estimates are then used in combination with real experience to update the\nprior. This effectively amortizes the value computation performed by MCTS,\nresulting in a cooperative relationship between model-free learning and\nmodel-based search. SAVE can be implemented on top of any Q-learning agent with\naccess to a model, which we demonstrate by incorporating it into agents that\nperform challenging physical reasoning tasks and Atari. SAVE consistently\nachieves higher rewards with fewer training steps, and---in contrast to typical\nmodel-based search approaches---yields strong performance with very small\nsearch budgets. By combining real experience with information computed during\nsearch, SAVE demonstrates that it is possible to improve on both the\nperformance of model-free learning and the computational cost of planning."}, {"title": "Novelty Detection Via Blurring", "authors": "Sungik Choi, Sae-Young Chung", "link": "https://arxiv.org/abs/1911.11943", "summary": "Conventional out-of-distribution (OOD) detection schemes based on variational\nautoencoder or Random Network Distillation (RND) have been observed to assign\nlower uncertainty to the OOD than the target distribution. In this work, we\ndiscover that such conventional novelty detection schemes are also vulnerable\nto the blurred images. Based on the observation, we construct a novel RND-based\nOOD detector, SVD-RND, that utilizes blurred images during training. Our\ndetector is simple, efficient at test time, and outperforms baseline OOD\ndetectors in various domains. Further results show that SVD-RND learns better\ntarget distribution representation than the baseline RND algorithm. Finally,\nSVD-RND combined with geometric transform achieves near-perfect detection\naccuracy on the CelebA dataset."}, {"title": "Input Complexity and Out-of-distribution Detection with Likelihood-based Generative Models", "authors": "Joan Serr\u00e0, David \u00c1lvarez, Vicen\u00e7 G\u00f3mez, Olga Slizovskaia, Jos\u00e9 F. N\u00fa\u00f1ez, Jordi Luque", "link": "https://arxiv.org/abs/1909.11480", "summary": "Likelihood-based generative models are a promising resource to detect\nout-of-distribution (OOD) inputs which could compromise the robustness or\nreliability of a machine learning system. However, likelihoods derived from\nsuch models have been shown to be problematic for detecting certain types of\ninputs that significantly differ from training data. In this paper, we pose\nthat this problem is due to the excessive influence that input complexity has\nin generative models' likelihoods. We report a set of experiments supporting\nthis hypothesis, and use an estimate of input complexity to derive an efficient\nand parameter-free OOD score, which can be seen as a likelihood-ratio, akin to\nBayesian model comparison. We find such score to perform comparably to, or even\nbetter than, existing OOD detection approaches under a wide range of data sets,\nmodels, model sizes, and complexity estimates."}, {"title": "Learning to Control PDEs with Differentiable Physics", "authors": "Philipp Holl, Nils Thuerey, Vladlen Koltun", "link": "https://arxiv.org/abs/2001.07457", "summary": "Predicting outcomes and planning interactions with the physical world are\nlong-standing goals for machine learning. A variety of such tasks involves\ncontinuous physical systems, which can be described by partial differential\nequations (PDEs) with many degrees of freedom. Existing methods that aim to\ncontrol the dynamics of such systems are typically limited to relatively short\ntime frames or a small number of interaction parameters. We present a novel\nhierarchical predictor-corrector scheme which enables neural networks to learn\nto understand and control complex nonlinear physical systems over long time\nframes. We propose to split the problem into two distinct tasks: planning and\ncontrol. To this end, we introduce a predictor network that plans optimal\ntrajectories and a control network that infers the corresponding control\nparameters. Both stages are trained end-to-end using a differentiable PDE\nsolver. We demonstrate that our method successfully develops an understanding\nof complex physical systems and learns to control them for tasks involving PDEs\nsuch as the incompressible Navier-Stokes equations."}, {"title": "Learning-Augmented Data Stream Algorithms", "authors": "Tanqiu Jiang, Yi Li, Honghao Lin, Yisong Ruan, David P. Woodruff"}, {"title": "Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks", "authors": "Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz"}, {"title": "Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension", "authors": "Xinyun Chen, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, Quoc V. Le"}, {"title": "Learning transport cost from subset correspondence", "authors": "Ruishan Liu, Akshay Balsubramani, James Zou"}, {"title": "Provable Filter Pruning for Efficient Neural Networks", "authors": "Lucas Liebenwein, Cenk Baykal, Harry Lang, Dan Feldman, Daniela Rus", "link": "https://arxiv.org/abs/1911.07412", "summary": "We present a provable, sampling-based approach for generating compact\nConvolutional Neural Networks (CNNs) by identifying and removing redundant\nfilters from an over-parameterized network. Our algorithm uses a small batch of\ninput data points to assign a saliency score to each filter and constructs an\nimportance sampling distribution where filters that highly affect the output\nare sampled with correspondingly high probability. In contrast to existing\nfilter pruning approaches, our method is simultaneously data-informed, exhibits\nprovable guarantees on the size and performance of the pruned network, and is\nwidely applicable to varying network architectures and data sets. Our\nanalytical bounds bridge the notions of compressibility and importance of\nnetwork structures, which gives rise to a fully-automated procedure for\nidentifying and preserving filters in layers that are essential to the\nnetwork's performance. Our experimental evaluations on popular architectures\nand data sets show that our algorithm consistently generates sparser and more\nefficient models than those constructed by existing filter pruning approaches."}, {"title": "Towards Better Understanding of Adaptive Gradient Algorithms in Generative Adversarial Nets", "authors": "Mingrui Liu, Youssef Mroueh, Jerret Ross, Wei Zhang, Xiaodong Cui, Payel Das, Tianbao Yang"}, {"title": "Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin", "authors": "Colin Wei, Tengyu Ma", "link": "https://arxiv.org/abs/1910.04284", "summary": "For linear classifiers, the relationship between (normalized) output margin\nand generalization is captured in a clear and simple bound -- a large output\nmargin implies good generalization. Unfortunately, for deep models, this\nrelationship is less clear: existing analyses of the output margin give\ncomplicated bounds which sometimes depend exponentially on depth. In this work,\nwe propose to instead analyze a new notion of margin, which we call the\n\"all-layer margin.\" Our analysis reveals that the all-layer margin has a clear\nand direct relationship with generalization for deep models. This enables the\nfollowing concrete applications of the all-layer margin: 1) by analyzing the\nall-layer margin, we obtain tighter generalization bounds for neural nets which\ndepend on Jacobian and hidden layer norms and remove the exponential dependency\non depth 2) our neural net results easily translate to the adversarially robust\nsetting, giving the first direct analysis of robust test error for deep\nnetworks, and 3) we present a theoretically inspired training algorithm for\nincreasing the all-layer margin. Our algorithm improves both clean and\nadversarially robust test performance over strong baselines in practice."}, {"title": "Four Things Everyone Should Know to Improve Batch Normalization", "authors": "Cecilia Summers, Michael J. Dinneen", "link": "https://arxiv.org/abs/1906.03548", "summary": "A key component of most neural network architectures is the use of\nnormalization layers, such as Batch Normalization. Despite its common use and\nlarge utility in optimizing deep architectures, it has been challenging both to\ngenerically improve upon Batch Normalization and to understand the\ncircumstances that lend themselves to other enhancements. In this paper, we\nidentify four improvements to the generic form of Batch Normalization and the\ncircumstances under which they work, yielding performance gains across all\nbatch sizes while requiring no additional computation during training. These\ncontributions include proposing a method for reasoning about the current\nexample in inference normalization statistics, fixing a training vs. inference\ndiscrepancy; recognizing and validating the powerful regularization effect of\nGhost Batch Normalization for small and medium batch sizes; examining the\neffect of weight decay regularization on the scaling and shifting parameters\ngamma and beta; and identifying a new normalization algorithm for very small\nbatch sizes by combining the strengths of Batch and Group Normalization. We\nvalidate our results empirically on six datasets: CIFAR-100, SVHN, Caltech-256,\nOxford Flowers-102, CUB-2011, and ImageNet."}, {"title": "Building Deep Equivariant Capsule Networks", "authors": "Sai Raam Venkataraman, S. Balasubramanian, R. Raghunatha Sarma", "link": "https://arxiv.org/abs/1908.01300", "summary": "Capsule networks are constrained by the parameter-expensive nature of their\nlayers, and the general lack of provable equivariance guarantees. We present a\nvariation of capsule networks that aims to remedy this. We identify that\nlearning all pair-wise part-whole relationships between capsules of successive\nlayers is inefficient. Further, we also realise that the choice of prediction\nnetworks and the routing mechanism are both key to equivariance. Based on\nthese, we propose an alternative framework for capsule networks that learns to\nprojectively encode the manifold of pose-variations, termed the\nspace-of-variation (SOV), for every capsule-type of each layer. This is done\nusing a trainable, equivariant function defined over a grid of\ngroup-transformations. Thus, the prediction-phase of routing involves\nprojection into the SOV of a deeper capsule using the corresponding function.\nAs a specific instantiation of this idea, and also in order to reap the\nbenefits of increased parameter-sharing, we use type-homogeneous\ngroup-equivariant convolutions of shallower capsules in this phase. We also\nintroduce an equivariant routing mechanism based on degree-centrality. We show\nthat this particular instance of our general model is equivariant, and hence\npreserves the compositional representation of an input under transformations.\nWe conduct several experiments on standard object-classification datasets that\nshowcase the increased transformation-robustness, as well as general\nperformance, of our model to several capsule baselines."}, {"title": "Graph Neural Networks Exponentially Lose Expressive Power for Node Classification", "authors": "Kenta Oono, Taiji Suzuki", "link": "https://arxiv.org/abs/1905.10947", "summary": "Graph Neural Networks (graph NNs) are a promising deep learning approach for\nanalyzing graph-structured data. However, it is known that they do not improve\n(or sometimes worsen) their predictive performance as we pile up many layers\nand add non-lineality. To tackle this problem, we investigate the expressive\npower of graph NNs via their asymptotic behaviors as the layer size tends to\ninfinity. Our strategy is to generalize the forward propagation of a Graph\nConvolutional Network (GCN), which is a popular graph NN variant, as a specific\ndynamical system. In the case of a GCN, we show that when its weights satisfy\nthe conditions determined by the spectra of the (augmented) normalized\nLaplacian, its output exponentially approaches the set of signals that carry\ninformation of the connected components and node degrees only for\ndistinguishing nodes. Our theory enables us to relate the expressive power of\nGCNs with the topological information of the underlying graphs inherent in the\ngraph spectra. To demonstrate this, we characterize the asymptotic behavior of\nGCNs on the Erd\\H{o}s -- R\\'{e}nyi graph. We show that when the Erd\\H{o}s --\nR\\'{e}nyi graph is sufficiently dense and large, a broad range of GCNs on it\nsuffers from the \"information loss\" in the limit of infinite layers with high\nprobability. Based on the theory, we provide a principled guideline for weight\nnormalization of graph NNs. We experimentally confirm that the proposed weight\nscaling enhances the predictive performance of GCNs in real data. Code is\navailable at https://github.com/delta2323/gnn-asymptotics."}, {"title": "Query-efficient Meta Attack to Deep Neural Networks", "authors": "Jiawei Du, Hu Zhang, Joey Tianyi Zhou, Yi Yang, Jiashi Feng"}, {"title": "Intriguing Properties of Adversarial Training at Scale", "authors": "Cihang Xie, Alan Yuille", "link": "https://arxiv.org/abs/1906.03787", "summary": "Adversarial training is one of the main defenses against adversarial attacks.\nIn this paper, we provide the first rigorous study on diagnosing elements of\nadversarial training, which reveals two intriguing properties.\n  First, we study the role of normalization. Batch normalization (BN) is a\ncrucial element for achieving state-of-the-art performance on many vision\ntasks, but we show it may prevent networks from obtaining strong robustness in\nadversarial training. One unexpected observation is that, for models trained\nwith BN, simply removing clean images from training data largely boosts\nadversarial robustness, i.e., 18.3%. We relate this phenomenon to the\nhypothesis that clean images and adversarial images are drawn from two\ndifferent domains. This two-domain hypothesis may explain the issue of BN when\ntraining with a mixture of clean and adversarial images, as estimating\nnormalization statistics of this mixture distribution is challenging. Guided by\nthis two-domain hypothesis, we show disentangling the mixture distribution for\nnormalization, i.e., applying separate BNs to clean and adversarial images for\nstatistics estimation, achieves much stronger robustness. Additionally, we find\nthat enforcing BNs to behave consistently at training and testing can further\nenhance robustness.\n  Second, we study the role of network capacity. We find our so-called \"deep\"\nnetworks are still shallow for the task of adversarial learning. Unlike\ntraditional classification tasks where accuracy is only marginally improved by\nadding more layers to \"deep\" networks (e.g., ResNet-152), adversarial training\nexhibits a much stronger demand on deeper networks to achieve higher\nadversarial robustness. This robustness improvement can be observed\nsubstantially and consistently even by pushing the network capacity to an\nunprecedented scale, i.e., ResNet-638."}, {"title": "Pad\u00e9 Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks", "authors": "Alejandro Molina, Patrick Schramowski, Kristian Kersting"}, {"title": "Dynamically Pruned Message Passing Networks for Large-scale Knowledge Graph Reasoning", "authors": "Xiaoran Xu, Wei Feng, Yunsheng Jiang, Xiaohui Xie, Zhiqing Sun, Zhi-Hong Deng", "link": "https://arxiv.org/abs/1909.11334", "summary": "We propose Dynamically Pruned Message Passing Networks (DPMPN) for\nlarge-scale knowledge graph reasoning. In contrast to existing models,\nembedding-based or path-based, we learn an input-dependent subgraph to\nexplicitly model reasoning process. Subgraphs are dynamically constructed and\nexpanded by applying graphical attention mechanism conditioned on input\nqueries. In this way, we not only construct graph-structured explanations but\nalso enable message passing designed in Graph Neural Networks (GNNs) to scale\nwith graph sizes. We take the inspiration from the consciousness prior proposed\nby and develop a two-GNN framework to simultaneously encode input-agnostic full\ngraph representation and learn input-dependent local one coordinated by an\nattention module. Experiments demonstrate the reasoning capability of our model\nthat is to provide clear graphical explanations as well as deliver accurate\npredictions, outperforming most state-of-the-art methods in knowledge base\ncompletion tasks."}, {"title": "What Can Neural Networks Reason About?", "authors": "Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S. Du, Ken-ichi Kawarabayashi, Stefanie Jegelka", "link": "https://arxiv.org/abs/1905.13211", "summary": "Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results."}, {"title": "Structured Object-Aware Physics Prediction for Video Modeling and Planning", "authors": "Jannik Kossen, Karl Stelzner, Marcel Hussing, Claas Voelcker, Kristian Kersting", "link": "https://arxiv.org/abs/1910.02425", "summary": "When humans observe a physical system, they can easily locate objects,\nunderstand their interactions, and anticipate future behavior, even in settings\nwith complicated and previously unseen interactions. For computers, however,\nlearning such models from videos in an unsupervised fashion is an unsolved\nresearch problem. In this paper, we present STOVE, a novel state-space model\nfor videos, which explicitly reasons about objects and their positions,\nvelocities, and interactions. It is constructed by combining an image model and\na dynamics model in compositional manner and improves on previous work by\nreusing the dynamics model for inference, accelerating and regularizing\ntraining. STOVE predicts videos with convincing physical behavior over hundreds\nof timesteps, outperforms previous unsupervised models, and even approaches the\nperformance of supervised baselines. We further demonstrate the strength of our\nmodel as a simulator for sample efficient model-based control in a task with\nheavily interacting objects."}, {"title": "Learning Expensive Coordination: An Event-Based Deep RL Approach", "authors": "Zhenyu Shi, Runsheng Yu, Xinrun Wang, Rundong Wang, Youzhi Zhang, Hanjiang Lai, Bo An"}, {"title": "Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference", "authors": "Ting-Kuei Hu, Tianlong Chen, Haotao Wang, Zhangyang Wang", "link": "https://arxiv.org/abs/2002.10025", "summary": "Deep networks were recently suggested to face the odds between accuracy (on\nclean natural images) and robustness (on adversarially perturbed images)\n(Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently\nhigher sample complexity (Schmidt et al., 2018) and/or model capacity\n(Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view\nof that, give a classification task, growing the model capacity appears to help\ndraw a win-win between accuracy and robustness, yet at the expense of model\nsize and latency, therefore posing challenges for resource-constrained\napplications. Is it possible to co-design model accuracy, robustness and\nefficiency to achieve their triple wins? This paper studies multi-exit networks\nassociated with input-adaptive efficient inference, showing their strong\npromise in achieving a \"sweet point\" in cooptimizing model accuracy, robustness\nand efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks\n(RDI-Nets), allows for each input (either clean or adversarial) to adaptively\nchoose one of the multiple output layers (early branches or the final one) to\noutput its prediction. That multi-loss adaptivity adds new variations and\nflexibility to adversarial attacks and defenses, on which we present a\nsystematical investigation. We show experimentally that by equipping existing\nbackbones with such robust adaptive inference, the resulting RDI-Nets can\nachieve better accuracy and robustness, yet with over 30% computational\nsavings, compared to the defended original models."}, {"title": "Optimistic Exploration even with a Pessimistic Initialisation", "authors": "Tabish Rashid, Bei Peng, Wendelin Boehmer, Shimon Whiteson"}, {"title": "Generalization of Two-layer Neural Networks: An Asymptotic Viewpoint", "authors": "Jimmy Ba, Murat Erdogdu, Taiji Suzuki, Denny Wu, Tianzong Zhang"}, {"title": "Reinforced Genetic Algorithm Learning for Optimizing Computation Graphs", "authors": "Aditya Paliwal, Felix Gimeno, Vinod Nair, Yujia Li, Miles Lubin, Pushmeet Kohli, Oriol Vinyals", "link": "https://arxiv.org/abs/1905.02494", "summary": "We present a deep reinforcement learning approach to minimizing the execution\ncost of neural network computation graphs in an optimizing compiler. Unlike\nearlier learning-based works that require training the optimizer on the same\ngraph to be optimized, we propose a learning approach that trains an optimizer\noffline and then generalizes to previously unseen graphs without further\ntraining. This allows our approach to produce high-quality execution decisions\non real-world TensorFlow graphs in seconds instead of hours. We consider two\noptimization tasks for computation graphs: minimizing running time and peak\nmemory usage. In comparison to an extensive set of baselines, our approach\nachieves significant improvements over classical and other learning-based\nmethods on these two tasks."}, {"title": "PROGRESSIVE LEARNING AND DISENTANGLEMENT OF HIERARCHICAL REPRESENTATIONS", "authors": "Zhiyuan Li, Jaideep Vitthal Murkute, Prashnna Kumar Gyawali, Linwei Wang", "link": "", "summary": ""}, {"title": "Influence-Based Multi-Agent Exploration", "authors": "Tonghan Wang, Jianhao Wang, Yi Wu, Chongjie Zhang", "link": "https://arxiv.org/abs/1910.05512", "summary": "Intrinsically motivated reinforcement learning aims to address the\nexploration challenge for sparse-reward tasks. However, the study of\nexploration methods in transition-dependent multi-agent settings is largely\nabsent from the literature. We aim to take a step towards solving this problem.\nWe present two exploration methods: exploration via information-theoretic\ninfluence (EITI) and exploration via decision-theoretic influence (EDTI), by\nexploiting the role of interaction in coordinated behaviors of agents. EITI\nuses mutual information to capture influence transition dynamics. EDTI uses a\nnovel intrinsic reward, called Value of Interaction (VoI), to characterize and\nquantify the influence of one agent's behavior on expected returns of other\nagents. By optimizing EITI or EDTI objective as a regularizer, agents are\nencouraged to coordinate their exploration and learn policies to optimize team\nperformance. We show how to optimize these regularizers so that they can be\neasily integrated with policy gradient reinforcement learning. The resulting\nupdate rule draws a connection between coordinated exploration and intrinsic\nreward distribution. Finally, we empirically demonstrate the significant\nstrength of our method in a variety of multi-agent scenarios."}, {"title": "Hyper-SAGNN: a self-attention based graph neural network for hypergraphs", "authors": "Ruochi Zhang, Yuesong Zou, Jian Ma"}, {"title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing Systems", "authors": "Chris Reinke, Mayalen Etcheverry, Pierre-Yves Oudeyer", "link": "https://arxiv.org/abs/1908.06663", "summary": "In many complex dynamical systems, artificial or natural, one can observe\nself-organization of patterns emerging from local rules. Cellular automata,\nlike the Game of Life (GOL), have been widely used as abstract models enabling\nthe study of various aspects of self-organization and morphogenesis, such as\nthe emergence of spatially localized patterns. However, findings of\nself-organized patterns in such models have so far relied on manual tuning of\nparameters and initial states, and on the human eye to identify interesting\npatterns. In this paper, we formulate the problem of automated discovery of\ndiverse self-organized patterns in such high-dimensional complex dynamical\nsystems, as well as a framework for experimentation and evaluation. Using a\ncontinuous GOL as a testbed, we show that recent intrinsically-motivated\nmachine learning algorithms (POP-IMGEPs), initially developed for learning of\ninverse models in robotics, can be transposed and used in this novel\napplication area. These algorithms combine intrinsically-motivated goal\nexploration and unsupervised learning of goal space representations. Goal space\nrepresentations describe the interesting features of patterns for which diverse\nvariations should be discovered. In particular, we compare various approaches\nto define and learn goal space representations from the perspective of\ndiscovering diverse spatially localized patterns. Moreover, we introduce an\nextension of a state-of-the-art POP-IMGEP algorithm which incrementally learns\na goal representation using a deep auto-encoder, and the use of CPPN primitives\nfor generating initialization parameters. We show that it is more efficient\nthan several baselines and equally efficient as a system pre-trained on a\nhand-made database of patterns identified by human experts."}, {"title": "GAT: Generative Adversarial Training for Adversarial Example Detection and Classification", "authors": "Xuwang Yin, Soheil Kolouri, Gustavo K Rohde"}, {"title": "Theory and Evaluation Metrics for Learning Disentangled Representations", "authors": "Kien Do, Truyen Tran", "link": "https://arxiv.org/abs/1908.09961", "summary": "We make two theoretical contributions to disentanglement learning by (a)\ndefining precise semantics of disentangled representations, and (b)\nestablishing robust metrics for evaluation. First, we characterize the concept\n\"disentangled representations\" used in supervised and unsupervised methods\nalong three dimensions-informativeness, separability and interpretability -\nwhich can be expressed and quantified explicitly using information-theoretic\nconstructs. This helps explain the behaviors of several well-known\ndisentanglement learning models. We then propose robust metrics for measuring\ninformativeness, separability and interpretability. Through a comprehensive\nsuite of experiments, we show that our metrics correctly characterize the\nrepresentations learned by different methods and are consistent with\nqualitative (visual) results. Thus, the metrics allow disentanglement learning\nmethods to be compared on a fair ground. We also empirically uncovered new\ninteresting properties of VAE-based methods and interpreted them with our\nformulation. These findings are promising and hopefully will encourage the\ndesign of more theoretically driven models for learning disentangled\nrepresentations."}, {"title": "Monotonic Multihead Attention", "authors": "Xutai Ma, Juan Miguel Pino, James Cross, Liezl Puzon, Jiatao Gu", "link": "https://arxiv.org/abs/1909.12406", "summary": "Simultaneous machine translation models start generating a target sequence\nbefore they have encoded or read the source sequence. Recent approaches for\nthis task either apply a fixed policy on a state-of-the art Transformer model,\nor a learnable monotonic attention on a weaker recurrent neural network-based\nstructure. In this paper, we propose a new attention mechanism, Monotonic\nMultihead Attention (MMA), which extends the monotonic attention mechanism to\nmultihead attention. We also introduce two novel and interpretable approaches\nfor latency control that are specifically designed for multiple attentions\nheads. We apply MMA to the simultaneous machine translation task and\ndemonstrate better latency-quality tradeoffs compared to MILk, the previous\nstate-of-the-art approach. We also analyze how the latency controls affect the\nattention span and we motivate the introduction of our model by analyzing the\neffect of the number of decoder layers and heads on quality and latency."}, {"title": "CLEVRER: Collision Events for Video Representation and Reasoning", "authors": "Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, Joshua B. Tenenbaum", "link": "https://arxiv.org/abs/1910.01442", "summary": "The ability to reason about temporal and causal events from videos lies at\nthe core of human intelligence. Most video reasoning benchmarks, however, focus\non pattern recognition from complex visual and language input, instead of on\ncausal structure. We study the complementary problem, exploring the temporal\nand causal structures behind videos of objects with simple visual appearance.\nTo this end, we introduce the CoLlision Events for Video REpresentation and\nReasoning (CLEVRER), a diagnostic video dataset for systematic evaluation of\ncomputational models on a wide range of reasoning tasks. Motivated by the\ntheory of human casual judgment, CLEVRER includes four types of questions:\ndescriptive (e.g., \"what color\"), explanatory (\"what is responsible for\"),\npredictive (\"what will happen next\"), and counterfactual (\"what if\"). We\nevaluate various state-of-the-art models for visual reasoning on our benchmark.\nWhile these models thrive on the perception-based task (descriptive), they\nperform poorly on the causal tasks (explanatory, predictive and\ncounterfactual), suggesting that a principled approach for causal reasoning\nshould incorporate the capability of both perceiving complex visual and\nlanguage inputs, and understanding the underlying dynamics and causal\nrelations. We also study an oracle model that explicitly combines these\ncomponents via symbolic representations."}, {"title": "Understanding and Improving Information Transfer in Multi-Task Learning", "authors": "Sen Wu, Hongyang Zhang, Christopher R\u00e9"}, {"title": "Multi-agent Reinforcement Learning for Networked System Control", "authors": "Tianshu Chu, Sandeep Chinchali, Sachin Katti"}, {"title": "Distributionally Robust Neural Networks", "authors": "Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, Percy Liang"}, {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": "Baichuan Yuan, Xiaowei Wang, Jianxin Ma, Chang Zhou, Andrea L. Bertozzi, Hongxia Yang"}, {"title": "Once for All: Train One Network and Specialize it for Efficient Deployment", "authors": "Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, Song Han", "link": "https://arxiv.org/abs/1908.09791", "summary": "We address the challenging problem of efficient inference across many devices\nand resource constraints, especially on edge devices. Conventional approaches\neither manually design or use neural architecture search (NAS) to find a\nspecialized neural network and train it from scratch for each case, which is\ncomputationally prohibitive (causing $CO_2$ emission as much as 5 cars'\nlifetime) thus unscalable. In this work, we propose to train a once-for-all\n(OFA) network that supports diverse architectural settings by decoupling\ntraining and search, to reduce the cost. We can quickly get a specialized\nsub-network by selecting from the OFA network without additional training. To\nefficiently train OFA networks, we also propose a novel progressive shrinking\nalgorithm, a generalized pruning method that reduces the model size across many\nmore dimensions than pruning (depth, width, kernel size, and resolution). It\ncan obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can\nfit different hardware platforms and latency constraints while maintaining the\nsame level of accuracy as training independently. On diverse edge devices, OFA\nconsistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0%\nImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x\nfaster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency)\nwhile reducing many orders of magnitude GPU hours and $CO_2$ emission. In\nparticular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the\nmobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low\nPower Computer Vision Challenge (LPCVC), DSP classification track and the 4th\nLPCVC, both classification track and detection track. Code and 50 pre-trained\nmodels (for many devices & many latency constraints) are released at\nhttps://github.com/mit-han-lab/once-for-all."}, {"title": "BayesOpt Adversarial Attack", "authors": "Binxin Ru, Adam Cobb, Arno Blaas, Yarin Gal"}, {"title": "Demystifying Inter-Class Disentanglement", "authors": "Aviv Gabbay, Yedid Hoshen", "link": "https://arxiv.org/abs/1906.11796", "summary": "Learning to disentangle the hidden factors of variations within a set of\nobservations is a key task for artificial intelligence. We present a unified\nformulation for class and content disentanglement and use it to illustrate the\nlimitations of current methods. We therefore introduce LORD, a novel method\nbased on Latent Optimization for Representation Disentanglement. We find that\nlatent optimization, along with an asymmetric noise regularization, is superior\nto amortized inference for achieving disentangled representations. In extensive\nexperiments, our method is shown to achieve better disentanglement performance\nthan both adversarial and non-adversarial methods that use the same level of\nsupervision. We further introduce a clustering-based approach for extending our\nmethod for settings that exhibit in-class variation with promising results on\nthe task of domain translation."}, {"title": "A Learning-based Iterative Method for Solving Vehicle Routing Problems", "authors": "Hao Lu, Xingwen Zhang, Shuang Yang"}, {"title": "Progressive Memory Banks for Incremental Domain Adaptation", "authors": "Nabiha Asghar, Lili Mou, Kira A. Selby, Kevin D. Pantasdo, Pascal Poupart, Xin Jiang", "link": "https://arxiv.org/abs/1811.00239", "summary": "This paper addresses the problem of incremental domain adaptation (IDA) in\nnatural language processing (NLP). We assume each domain comes one after\nanother, and that we could only access data in the current domain. The goal of\nIDA is to build a unified model performing well on all the domains that we have\nencountered. We adopt the recurrent neural network (RNN) widely used in NLP,\nbut augment it with a directly parameterized memory bank, which is retrieved by\nan attention mechanism at each step of RNN transition. The memory bank provides\na natural way of IDA: when adapting our model to a new domain, we progressively\nadd new slots to the memory bank, which increases the number of parameters, and\nthus the model capacity. We learn the new memory slots and fine-tune existing\nparameters by back-propagation. Experimental results show that our approach\nachieves significantly better performance than fine-tuning alone. Compared with\nexpanding hidden states, our approach is more robust for old domains, shown by\nboth empirical and theoretical results. Our model also outperforms previous\nwork of IDA including elastic weight consolidation and progressive neural\nnetworks in the experiments."}, {"title": "Quantifying the Cost of Reliable Photo Authentication via High-Performance Learned Lossy Representations", "authors": "Pawel Korus, Nasir Memon"}, {"title": "On Computation and Generalization of Generative Adversarial Imitation Learning", "authors": "Minshuo Chen, Yizhou Wang, Tianyi Liu, Zhuoran Yang, Xingguo Li, Zhaoran Wang, Tuo Zhao", "link": "https://arxiv.org/abs/2001.02792", "summary": "Generative Adversarial Imitation Learning (GAIL) is a powerful and practical\napproach for learning sequential decision-making policies. Different from\nReinforcement Learning (RL), GAIL takes advantage of demonstration data by\nexperts (e.g., human), and learns both the policy and reward function of the\nunknown environment. Despite the significant empirical progresses, the theory\nbehind GAIL is still largely unknown. The major difficulty comes from the\nunderlying temporal dependency of the demonstration data and the minimax\ncomputational formulation of GAIL without convex-concave structure. To bridge\nsuch a gap between theory and practice, this paper investigates the theoretical\nproperties of GAIL. Specifically, we show: (1) For GAIL with general reward\nparameterization, the generalization can be guaranteed as long as the class of\nthe reward functions is properly controlled; (2) For GAIL, where the reward is\nparameterized as a reproducing kernel function, GAIL can be efficiently solved\nby stochastic first order optimization algorithms, which attain sublinear\nconvergence to a stationary solution. To the best of our knowledge, these are\nthe first results on statistical and computational guarantees of imitation\nlearning with reward/policy function approximation. Numerical experiments are\nprovided to support our analysis."}, {"title": "Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model", "authors": "Wenhan Xiong, Jingfei Du, William Yang Wang, Veselin Stoyanov", "link": "https://arxiv.org/abs/1912.09637", "summary": "Recent breakthroughs of pretrained language models have shown the\neffectiveness of self-supervised learning for a wide range of natural language\nprocessing (NLP) tasks. In addition to standard syntactic and semantic NLP\ntasks, pretrained models achieve strong improvements on tasks that involve\nreal-world knowledge, suggesting that large-scale language modeling could be an\nimplicit method to capture knowledge. In this work, we further investigate the\nextent to which pretrained models such as BERT capture knowledge using a\nzero-shot fact completion task. Moreover, we propose a simple yet effective\nweakly supervised pretraining objective, which explicitly forces the model to\nincorporate knowledge about real-world entities. Models trained with our new\nobjective yield significant improvements on the fact completion task. When\napplied to downstream tasks, our model consistently outperforms BERT on four\nentity-related question answering datasets (i.e., WebQuestions, TriviaQA,\nSearchQA and Quasar-T) with an average 2.7 F1 improvements and a standard\nfine-grained entity typing dataset (i.e., FIGER) with 5.7 accuracy gains."}, {"title": "Non-Autoregressive Dialog State Tracking", "authors": "Hung Le, Richard Socher, Steven C.H. Hoi", "link": "https://arxiv.org/abs/2002.08024", "summary": "Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues\nhave progressed toward open-vocabulary or generation-based approaches where the\nmodels can generate slot value candidates from the dialogue history itself.\nThese approaches have shown good performance gain, especially in complicated\ndialogue domains with dynamic slot values. However, they fall short in two\naspects: (1) they do not allow models to explicitly learn signals across\ndomains and slots to detect potential dependencies among (domain, slot) pairs;\nand (2) existing models follow auto-regressive approaches which incur high time\ncost when the dialogue evolves over multiple domains and multiple turns. In\nthis paper, we propose a novel framework of Non-Autoregressive Dialog State\nTracking (NADST) which can factor in potential dependencies among domains and\nslots to optimize the models towards better prediction of dialogue states as a\ncomplete set rather than separate slots. In particular, the non-autoregressive\nnature of our method not only enables decoding in parallel to significantly\nreduce the latency of DST for real-time dialogue response generation, but also\ndetect dependencies among slots at token level in addition to slot and domain\nlevel. Our empirical results show that our model achieves the state-of-the-art\njoint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency\nof our model is an order of magnitude lower than the previous state of the art\nas the dialogue history extends over time."}, {"title": "Adversarial AutoAugment", "authors": "Xinyu Zhang, Qiang Wang, Jian Zhang, Zhao Zhong", "link": "https://arxiv.org/abs/1912.11188", "summary": "Data augmentation (DA) has been widely utilized to improve generalization in\ntraining deep neural networks. Recently, human-designed data augmentation has\nbeen gradually replaced by automatically learned augmentation policy. Through\nfinding the best policy in well-designed search space of data augmentation,\nAutoAugment can significantly improve validation accuracy on image\nclassification tasks. However, this approach is not computationally practical\nfor large-scale problems. In this paper, we develop an adversarial method to\narrive at a computationally-affordable solution called Adversarial AutoAugment,\nwhich can simultaneously optimize target related object and augmentation policy\nsearch loss. The augmentation policy network attempts to increase the training\nloss of a target network through generating adversarial augmentation policies,\nwhile the target network can learn more robust features from harder examples to\nimprove the generalization. In contrast to prior work, we reuse the computation\nin target network training for policy evaluation, and dispense with the\nretraining of the target network. Compared to AutoAugment, this leads to about\n12x reduction in computing cost and 11x shortening in time overhead on\nImageNet. We show experimental results of our approach on CIFAR-10/CIFAR-100,\nImageNet, and demonstrate significant performance improvements over\nstate-of-the-art. On CIFAR-10, we achieve a top-1 test error of 1.36%, which is\nthe currently best performing single model. On ImageNet, we achieve a leading\nperformance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D\nwithout extra data."}, {"title": "Towards Fast Adaptation of Neural Architectures with Meta Learning", "authors": "Dongze Lian, Yin Zheng, Yintao Xu, Yanxiong Lu, Leyu Lin, Peilin Zhao, Junzhou Huang, Shenghua Gao"}, {"title": "Double Neural Counterfactual Regret Minimization", "authors": "Hui Li, Kailiang Hu, Shaohua Zhang, Yuan Qi, Le Song", "link": "https://arxiv.org/abs/1812.10607", "summary": "Counterfactual Regret Minimization (CRF) is a fundamental and effective\ntechnique for solving Imperfect Information Games (IIG). However, the original\nCRF algorithm only works for discrete state and action spaces, and the\nresulting strategy is maintained as a tabular representation. Such tabular\nrepresentation limits the method from being directly applied to large games and\ncontinuing to improve from a poor strategy profile. In this paper, we propose a\ndouble neural representation for the imperfect information games, where one\nneural network represents the cumulative regret, and the other represents the\naverage strategy. Furthermore, we adopt the counterfactual regret minimization\nalgorithm to optimize this double neural representation. To make neural\nlearning efficient, we also developed several novel techniques including a\nrobust sampling method, mini-batch Monte Carlo Counterfactual Regret\nMinimization (MCCFR) and Monte Carlo Counterfactual Regret Minimization Plus\n(MCCFR+) which may be of independent interests. Experimentally, we demonstrate\nthat the proposed double neural algorithm converges significantly better than\nthe reinforcement learning counterpart."}, {"title": "MetaPix: Few-Shot Video Retargeting", "authors": "Jessica Lee, Deva Ramanan, Rohit Girdhar", "link": "https://arxiv.org/abs/1910.04742", "summary": "We address the task of unsupervised retargeting of human actions from one\nvideo to another. We consider the challenging setting where only a few frames\nof the target is available. The core of our approach is a conditional\ngenerative model that can transcode input skeletal poses (automatically\nextracted with an off-the-shelf pose estimator) to output target frames.\nHowever, it is challenging to build a universal transcoder because humans can\nappear wildly different due to clothing and background scene geometry. Instead,\nwe learn to adapt - or personalize - a universal generator to the particular\nhuman and background in the target. To do so, we make use of meta-learning to\ndiscover effective strategies for on-the-fly personalization. One significant\nbenefit of meta-learning is that the personalized transcoder naturally enforces\ntemporal coherence across its generated frames; all frames contain consistent\nclothing and background geometry of the target. We experiment on in-the-wild\ninternet videos and images and show our approach improves over widely-used\nbaselines for the task."}, {"title": "SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes", "authors": "Johannes C. Thiele, Olivier Bichler, Antoine Dupret", "link": "https://arxiv.org/abs/1906.00851", "summary": "Event-based neuromorphic systems promise to reduce the energy consumption of\ndeep learning tasks by replacing expensive floating point operations on dense\nmatrices by low power sparse and asynchronous operations on spike events. While\nthese systems can be trained increasingly well using approximations of the\nback-propagation algorithm, these implementations usually require high\nprecision errors for training and are therefore incompatible with the typical\ncommunication infrastructure of neuromorphic circuits. In this work, we analyze\nhow the gradient can be discretized into spike events when training a spiking\nneural network. To accelerate our simulation, we show that using a special\nimplementation of the integrate-and-fire neuron allows us to describe the\naccumulated activations and errors of the spiking neural network in terms of an\nequivalent artificial neural network, allowing us to largely speed up training\ncompared to an explicit simulation of all spike events. This way we are able to\ndemonstrate that even for deep networks, the gradients can be discretized\nsufficiently well with spikes if the gradient is properly rescaled. This form\nof spike-based backpropagation enables us to achieve equivalent or better\naccuracies on the MNIST and CIFAR10 dataset than comparable state-of-the-art\nspiking neural networks trained with full precision gradients. The algorithm,\nwhich we call SpikeGrad, is based on accumulation and comparison operations and\ncan naturally exploit sparsity in the gradient computation, which makes it an\ninteresting choice for a spiking neuromorphic systems with on-chip learning\ncapacities."}, {"title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": "Lasse Espeholt, Rapha\u00ebl Marinier, Piotr Stanczyk, Ke Wang, Marcin Michalski\u200e", "link": "https://arxiv.org/abs/1910.06591", "summary": "We present a modern scalable reinforcement learning agent called SEED\n(Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we\nshow that it is not only possible to train on millions of frames per second but\nalso to lower the cost of experiments compared to current methods. We achieve\nthis with a simple architecture that features centralized inference and an\noptimized communication layer. SEED adopts two state of the art distributed\nalgorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is\nevaluated on Atari-57, DeepMind Lab and Google Research Football. We improve\nthe state of the art on Football and are able to reach state of the art on\nAtari-57 three times faster in wall-time. For the scenarios we consider, a 40%\nto 80% cost reduction for running experiments is achieved. The implementation\nalong with experiments is open-sourced so results can be reproduced and novel\nideas tried out."}, {"title": "Duration-of-Stay Storage Assignment under Uncertainty", "authors": "Michael Lingzhi Li, Elliott Wolf, Daniel Wintz", "link": "https://arxiv.org/abs/1903.05063", "summary": "Optimizing storage assignment is a central problem in warehousing. Past\nliterature has shown the superiority of the Duration-of-Stay (DoS) method in\nassigning pallets, but the methodology requires perfect prior knowledge of DoS\nfor each pallet, which is unknown and uncertain under realistic conditions. The\ndynamic nature of a warehouse further complicates the validity of synthetic\ndata testing that is often conducted for algorithms. In this paper, in\ncollaboration with a large cold storage company, we release the first publicly\navailable set of warehousing records to facilitate research into this central\nproblem. We introduce a new framework for storage assignment that accounts for\nuncertainty in warehouses. Then, by utilizing a combination of convolutional\nand recurrent neural network models, ParallelNet, we show that it is able to\npredict future shipments well: it achieves up to 29% decrease in MAPE compared\nto CNN-LSTM on unseen future shipments, and suffers less performance decay over\ntime. The framework is then integrated into a first-of-its-kind Storage\nAssignment system, which is being piloted in warehouses across the country,\nwith initial results showing up to 19% in labor savings."}, {"title": "SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition", "authors": "Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam Singh, Fei Deng, Jindong Jiang, Sungjin Ahn", "link": "https://arxiv.org/abs/2001.02407", "summary": "The ability to decompose complex multi-object scenes into meaningful\nabstractions like objects is fundamental to achieve higher-level cognition.\nPrevious approaches for unsupervised object-oriented scene representation\nlearning are either based on spatial-attention or scene-mixture approaches and\nlimited in scalability which is a main obstacle towards modeling real-world\nscenes. In this paper, we propose a generative latent variable model, called\nSPACE, that provides a unified probabilistic modeling framework that combines\nthe best of spatial-attention and scene-mixture approaches. SPACE can\nexplicitly provide factorized object representations for foreground objects\nwhile also decomposing background segments of complex morphology. Previous\nmodels are good at either of these, but not both. SPACE also resolves the\nscalability problems of previous methods by incorporating parallel\nspatial-attention and thus is applicable to scenes with a large number of\nobjects without performance degradations. We show through experiments on Atari\nand 3D-Rooms that SPACE achieves the above properties consistently in\ncomparison to SPAIR, IODINE, and GENESIS. Results of our experiments can be\nfound on our project website: https://sites.google.com/view/space-project-page"}, {"title": "Recurrent neural circuits for contour detection", "authors": "Drew Linsley, Junkyung Kim, Alekh Ashok, Thomas Serre"}, {"title": "Implementation Matters in Deep RL: A Case Study on PPO and TRPO", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Firdaus Janoos, Larry Rudolph, Aleksander Madry"}, {"title": "BERTScore: Evaluating Text Generation with BERT", "authors": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, Yoav Artzi", "link": "", "summary": ""}, {"title": "Learning to Move with Affordance Maps", "authors": "William Qi, Ravi Teja Mullapudi, Saurabh Gupta, Deva Ramanan", "link": "https://arxiv.org/abs/2001.02364", "summary": "The ability to autonomously explore and navigate a physical space is a\nfundamental requirement for virtually any mobile autonomous agent, from\nhousehold robotic vacuums to autonomous vehicles. Traditional SLAM-based\napproaches for exploration and navigation largely focus on leveraging scene\ngeometry, but fail to model dynamic objects (such as other agents) or semantic\nconstraints (such as wet floors or doorways). Learning-based RL agents are an\nattractive alternative because they can incorporate both semantic and geometric\ninformation, but are notoriously sample inefficient, difficult to generalize to\nnovel settings, and are difficult to interpret. In this paper, we combine the\nbest of both worlds with a modular approach that learns a spatial\nrepresentation of a scene that is trained to be effective when coupled with\ntraditional geometric planners. Specifically, we design an agent that learns to\npredict a spatial affordance map that elucidates what parts of a scene are\nnavigable through active self-supervised experience gathering. In contrast to\nmost simulation environments that assume a static world, we evaluate our\napproach in the VizDoom simulator, using large-scale randomly-generated maps\ncontaining a variety of dynamic actors and hazards. We show that learned\naffordance maps can be used to augment traditional approaches for both\nexploration and navigation, providing significant improvements in performance."}, {"title": "Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?", "authors": "Simon S. Du, Sham M. Kakade, Ruosong Wang, Lin F. Yang", "link": "https://arxiv.org/abs/1910.03016", "summary": "Modern deep learning methods provide effective means to learn good\nrepresentations. However, is a good representation itself sufficient for sample\nefficient reinforcement learning? This question has largely been studied only\nwith respect to (worst-case) approximation error, in the more classical\napproximate dynamic programming literature. With regards to the statistical\nviewpoint, this question is largely unexplored, and the extant body of\nliterature mainly focuses on conditions which permit sample efficient\nreinforcement learning with little understanding of what are necessary\nconditions for efficient reinforcement learning.\n  This work shows that, from the statistical viewpoint, the situation is far\nsubtler than suggested by the more traditional approximation viewpoint, where\nthe requirements on the representation that suffice for sample efficient RL are\neven more stringent. Our main results provide sharp thresholds for\nreinforcement learning methods, showing that there are hard limitations on what\nconstitutes good function approximation (in terms of the dimensionality of the\nrepresentation), where we focus on natural representational conditions relevant\nto value-based, model-based, and policy-based learning. These lower bounds\nhighlight that having a good (value-based, model-based, or policy-based)\nrepresentation in and of itself is insufficient for efficient reinforcement\nlearning, unless the quality of this approximation passes certain hard\nthresholds. Furthermore, our lower bounds also imply exponential separations on\nthe sample complexity between 1) value-based learning with perfect\nrepresentation and value-based learning with a good-but-not-perfect\nrepresentation, 2) value-based learning and policy-based learning, 3)\npolicy-based learning and supervised learning and 4) reinforcement learning and\nimitation learning."}, {"title": "Network Deconvolution", "authors": "Chengxi Ye, Matthew Evanusa, Hua He, Anton Mitrokhin, Tom Goldstein, James A. Yorke, Cornelia Fermuller, Yiannis Aloimonos", "link": "https://arxiv.org/abs/1905.11926", "summary": "Convolution is a central operation in Convolutional Neural Networks (CNNs),\nwhich applies a kernel to overlapping regions shifted across the image.\nHowever, because of the strong correlations in real-world image data,\nconvolutional kernels are in effect re-learning redundant data. In this work,\nwe show that this redundancy has made neural network training challenging, and\npropose network deconvolution, a procedure which optimally removes pixel-wise\nand channel-wise correlations before the data is fed into each layer. Network\ndeconvolution can be efficiently calculated at a fraction of the computational\ncost of a convolution layer. We also show that the deconvolution filters in the\nfirst layer of the network resemble the center-surround structure found in\nbiological neurons in the visual regions of the brain. Filtering with such\nkernels results in a sparse representation, a desired property that has been\nmissing in the training of neural networks. Learning from the sparse\nrepresentation promotes faster convergence and superior results without the use\nof batch normalization. We apply our network deconvolution operation to 10\nmodern neural network models by replacing batch normalization within each.\nExtensive experiments show that the network deconvolution operation is able to\ndeliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST,\nFashion-MNIST, Cityscapes, and ImageNet datasets."}, {"title": "Reinforcement Learning with Competitive  Ensembles of Information-Constrained Primitives", "authors": "Anirudh Goyal, Shagun Sodhani, Jonathan Binas, Xue Bin Peng, Sergey Levine, Yoshua Bengio", "link": "https://arxiv.org/abs/1906.10667", "summary": "Reinforcement learning agents that operate in diverse and complex\nenvironments can benefit from the structured decomposition of their behavior.\nOften, this is addressed in the context of hierarchical reinforcement learning,\nwhere the aim is to decompose a policy into lower-level primitives or options,\nand a higher-level meta-policy that triggers the appropriate behaviors for a\ngiven situation. However, the meta-policy must still produce appropriate\ndecisions in all states. In this work, we propose a policy design that\ndecomposes into primitives, similarly to hierarchical reinforcement learning,\nbut without a high-level meta-policy. Instead, each primitive can decide for\nthemselves whether they wish to act in the current state. We use an\ninformation-theoretic mechanism for enabling this decentralized decision: each\nprimitive chooses how much information it needs about the current state to make\na decision and the primitive that requests the most information about the\ncurrent state acts in the world. The primitives are regularized to use as\nlittle information as possible, which leads to natural competition and\nspecialization. We experimentally demonstrate that this policy architecture\nimproves over both flat and hierarchical policies in terms of generalization."}, {"title": "DiffTaichi: Differentiable Programming for Physical Simulation", "authors": "Yuanming Hu, Luke Anderson, Tzu-Mao Li, Qi Sun, Nathan Carr, Jonathan Ragan-Kelley, Fredo Durand", "link": "https://arxiv.org/abs/1910.00935", "summary": "We present DiffTaichi, a new differentiable programming language tailored for\nbuilding high-performance differentiable physical simulators. Based on an\nimperative programming language, DiffTaichi generates gradients of simulation\nsteps using source code transformations that preserve arithmetic intensity and\nparallelism. A light-weight tape is used to record the whole simulation program\nstructure and replay the gradient kernels in a reversed order, for end-to-end\nbackpropagation. We demonstrate the performance and productivity of our\nlanguage in gradient-based learning and optimization tasks on 10 different\nphysical simulators. For example, a differentiable elastic object simulator\nwritten in our language is 4.2x shorter than the hand-engineered CUDA version\nyet runs as fast, and is 188x faster than the TensorFlow implementation. Using\nour differentiable programs, neural network controllers are typically optimized\nwithin only tens of iterations."}, {"title": "A Mutual Information Maximization Perspective of Language Representation Learning", "authors": "Lingpeng Kong, Cyprien de Masson d'Autume, Lei Yu, Wang Ling, Zihang Dai, Dani Yogatama", "link": "https://arxiv.org/abs/1910.08350", "summary": "We show state-of-the-art word representation learning methods maximize an\nobjective function that is a lower bound on the mutual information between\ndifferent parts of a word sequence (i.e., a sentence). Our formulation provides\nan alternative perspective that unifies classical word embedding models (e.g.,\nSkip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to\nenhancing our theoretical understanding of these methods, our derivation leads\nto a principled framework that can be used to construct new self-supervised\ntasks. We provide an example by drawing inspirations from related methods based\non mutual information maximization that have been successful in computer\nvision, and introduce a simple self-supervised objective that maximizes the\nmutual information between a global sentence representation and n-grams in the\nsentence. Our analysis offers a holistic view of representation learning\nmethods to transfer knowledge and translate progress across multiple domains\n(e.g., natural language processing, computer vision, audio processing)."}, {"title": "Multi-Agent Interactions Modeling with Correlated Policies", "authors": "Minghuan Liu, Ming Zhou, Weinan Zhang, Yuzheng Zhuang, Jun Wang, Wulong Liu, Yong Yu"}, {"title": "State Alignment-based Imitation Learning", "authors": "Fangchen Liu, Zhan Ling, Tongzhou Mu, Hao Su", "link": "https://arxiv.org/abs/1911.10947", "summary": "Consider an imitation learning problem that the imitator and the expert have\ndifferent dynamics models. Most of the current imitation learning methods fail\nbecause they focus on imitating actions. We propose a novel state\nalignment-based imitation learning method to train the imitator to follow the\nstate sequences in expert demonstrations as much as possible. The state\nalignment comes from both local and global perspectives and we combine them\ninto a reinforcement learning framework by a regularized policy update\nobjective. We show the superiority of our method on standard imitation learning\nsettings and imitation learning settings where the expert and imitator have\ndifferent dynamics models."}, {"title": "Adversarial Training and Provable Defenses: Bridging the Gap", "authors": "Mislav Balunovic, Martin Vechev"}, {"title": "Measuring Compositional Generalization: A Comprehensive Method on Realistic Data", "authors": "Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang, Marc van Zee, Olivier Bousquet"}, {"title": "Robust training with ensemble consensus", "authors": "Jisoo Lee, Sae-Young Chung", "link": "https://arxiv.org/abs/1910.09792", "summary": "Since deep neural networks are over-parameterized, they can memorize noisy\nexamples. We address such memorizing issue in the presence of annotation noise.\nFrom the fact that deep neural networks cannot generalize neighborhoods of the\nfeatures acquired via memorization, we hypothesize that noisy examples do not\nconsistently incur small losses on the network under a certain perturbation.\nBased on this, we propose a novel training method called Learning with Ensemble\nConsensus (LEC) that prevents overfitting noisy examples by eliminating them\nusing the consensus of an ensemble of perturbed networks. One of the proposed\nLECs, LTEC outperforms the current state-of-the-art methods on noisy MNIST,\nCIFAR-10, and CIFAR-100 in an efficient manner."}, {"title": "Uncertainty-guided Continual Learning with Bayesian Neural Networks", "authors": "Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, Marcus Rohrbach", "link": "https://arxiv.org/abs/1906.02425", "summary": "Continual learning aims to learn new tasks without forgetting previously\nlearned ones. This is especially challenging when one cannot access data from\nprevious tasks and when the model has a fixed capacity. Current\nregularization-based continual learning algorithms need an external\nrepresentation and extra computation to measure the parameters'\n\\textit{importance}. In contrast, we propose Uncertainty-guided Continual\nBayesian Neural Networks (UCB), where the learning rate adapts according to the\nuncertainty defined in the probability distribution of the weights in networks.\nUncertainty is a natural way to identify \\textit{what to remember} and\n\\textit{what to change} as we continually learn, and thus mitigate catastrophic\nforgetting. We also show a variant of our model, which uses uncertainty for\nweight pruning and retains task performance after pruning by saving binary\nmasks per tasks. We evaluate our UCB approach extensively on diverse object\nclassification datasets with short and long sequences of tasks and report\nsuperior or on-par performance compared to existing approaches. Additionally,\nwe show that our model does not necessarily need task information at test time,\ni.e. it does not presume knowledge of which task a sample belongs to."}, {"title": "Fooling Detection Alone is Not Enough: Adversarial Attack against Multiple Object Tracking", "authors": "Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Hao Chen, Zhenyu Zhong, Tao Wei", "link": "https://arxiv.org/abs/1905.11026", "summary": "Recent work in adversarial machine learning started to focus on the visual\nperception in autonomous driving and studied Adversarial Examples (AEs) for\nobject detection models. However, in such visual perception pipeline the\ndetected objects must also be tracked, in a process called Multiple Object\nTracking (MOT), to build the moving trajectories of surrounding obstacles.\nSince MOT is designed to be robust against errors in object detection, it poses\na general challenge to existing attack techniques that blindly target objection\ndetection: we find that a success rate of over 98% is needed for them to\nactually affect the tracking results, a requirement that no existing attack\ntechnique can satisfy. In this paper, we are the first to study adversarial\nmachine learning attacks against the complete visual perception pipeline in\nautonomous driving, and discover a novel attack technique, tracker hijacking,\nthat can effectively fool MOT using AEs on object detection. Using our\ntechnique, successful AEs on as few as one single frame can move an existing\nobject in to or out of the headway of an autonomous vehicle to cause potential\nsafety hazards. We perform evaluation using the Berkeley Deep Drive dataset and\nfind that on average when 3 frames are attacked, our attack can have a nearly\n100% success rate while attacks that blindly target object detection only have\nup to 25%."}, {"title": "Tree-Structured Attention with Hierarchical Accumulation", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Steven Hoi, Richard Socher", "link": "https://arxiv.org/abs/2002.08046", "summary": "Incorporating hierarchical structures like constituency trees has been shown\nto be effective for various natural language processing (NLP) tasks. However,\nit is evident that state-of-the-art (SOTA) sequence-based models like the\nTransformer struggle to encode such structures inherently. On the other hand,\ndedicated models like the Tree-LSTM, while explicitly modeling hierarchical\nstructures, do not perform as efficiently as the Transformer. In this paper, we\nattempt to bridge this gap with \"Hierarchical Accumulation\" to encode parse\ntree structures into self-attention at constant time complexity. Our approach\noutperforms SOTA methods in four IWSLT translation tasks and the WMT'14\nEnglish-German translation task. It also yields improvements over Transformer\nand Tree-LSTM on three text classification tasks. We further demonstrate that\nusing hierarchical priors can compensate for data shortage, and that our model\nprefers phrase-level attentions over token-level attentions."}, {"title": "Dynamics-Aware Unsupervised Skill Discovery", "authors": "Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, Karol Hausman", "link": "", "summary": ""}, {"title": "Making Sense of Reinforcement Learning and Probabilistic Inference", "authors": "Brendan O'Donoghue, Ian Osband, Catalin Ionescu", "link": "https://arxiv.org/abs/2001.00805", "summary": "Reinforcement learning (RL) combines a control problem with statistical\nestimation: The system dynamics are not known to the agent, but can be learned\nthrough experience. A recent line of research casts 'RL as inference' and\nsuggests a particular framework to generalize the RL problem as probabilistic\ninference. Our paper surfaces a key shortcoming in that approach, and clarifies\nthe sense in which RL can be coherently cast as an inference problem. In\nparticular, an RL agent must consider the effects of its actions upon future\nrewards and observations: The exploration-exploitation tradeoff. In all but the\nmost simple settings, the resulting inference is computationally intractable so\nthat practical RL algorithms must resort to approximation. We demonstrate that\nthe popular 'RL as inference' approximation can perform poorly in even very\nbasic problems. However, we show that with a small modification the framework\ndoes yield algorithms that can provably perform well, and we show that the\nresulting algorithm is equivalent to the recently proposed K-learning, which we\nfurther connect with Thompson sampling."}, {"title": "Understanding the Limitations of Variational Mutual Information Estimators", "authors": "Jiaming Song, Stefano Ermon", "link": "https://arxiv.org/abs/1910.06222", "summary": "Variational approaches based on neural networks are showing promise for\nestimating mutual information (MI) between high dimensional variables. However,\nthey can be difficult to use in practice due to poorly understood bias/variance\ntradeoffs. We theoretically show that, under some conditions, estimators such\nas MINE exhibit variance that could grow exponentially with the true amount of\nunderlying MI. We also empirically demonstrate that existing estimators fail to\nsatisfy basic self-consistency properties of MI, such as data processing and\nadditivity under independence. Based on a unified perspective of variational\napproaches, we develop a new estimator that focuses on variance reduction.\nEmpirical results on standard benchmark tasks demonstrate that our proposed\nestimator exhibits improved bias-variance trade-offs on standard benchmark\ntasks."}, {"title": "Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness", "authors": "Pu Zhao, Pin-Yu Chen, Payel Das, Karthikeyan Natesan Ramamurthy, Xue Lin", "link": "https://arxiv.org/abs/2005.00060", "summary": "Mode connectivity provides novel geometric insights on analyzing loss\nlandscapes and enables building high-accuracy pathways between well-trained\nneural networks. In this work, we propose to employ mode connectivity in loss\nlandscapes to study the adversarial robustness of deep neural networks, and\nprovide novel methods for improving this robustness. Our experiments cover\nvarious types of adversarial attacks applied to different network architectures\nand datasets. When network models are tampered with backdoor or error-injection\nattacks, our results demonstrate that the path connection learned using limited\namount of bonafide data can effectively mitigate adversarial effects while\nmaintaining the original accuracy on clean data. Therefore, mode connectivity\nprovides users with the power to repair backdoored or error-injected models. We\nalso use mode connectivity to investigate the loss landscapes of regular and\nrobust models against evasion attacks. Experiments show that there exists a\nbarrier in adversarial robustness loss on the path connecting regular and\nadversarially-trained models. A high correlation is observed between the\nadversarial robustness loss and the largest eigenvalue of the input Hessian\nmatrix, for which theoretical justifications are provided. Our results suggest\nthat mode connectivity offers a holistic tool and practical means for\nevaluating and improving adversarial robustness."}, {"title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments", "authors": "Roberta Raileanu, Tim Rockt\u00e4schel", "link": "https://arxiv.org/abs/2002.12292", "summary": "Exploration in sparse reward environments remains one of the key challenges\nof model-free reinforcement learning. Instead of solely relying on extrinsic\nrewards provided by the environment, many state-of-the-art methods use\nintrinsic rewards to encourage exploration. However, we show that existing\nmethods fall short in procedurally-generated environments where an agent is\nunlikely to visit a state more than once. We propose a novel type of intrinsic\nreward which encourages the agent to take actions that lead to significant\nchanges in its learned state representation. We evaluate our method on multiple\nchallenging procedurally-generated tasks in MiniGrid, as well as on tasks with\nhigh-dimensional observations used in prior work. Our experiments demonstrate\nthat this approach is more sample efficient than existing exploration methods,\nparticularly for procedurally-generated MiniGrid environments. Furthermore, we\nanalyze the learned behavior as well as the intrinsic reward received by our\nagent. In contrast to previous approaches, our intrinsic reward does not\ndiminish during the course of training and it rewards the agent substantially\nmore for interacting with objects that it can control."}, {"title": "Intrinsic Motivation for Encouraging Synergistic Behavior", "authors": "Rohan Chitnis, Shubham Tulsiani, Saurabh Gupta, Abhinav Gupta"}, {"title": "Augmenting Non-Collaborative Dialog Systems with Explicit Semantic and Strategic Dialog History", "authors": "Yiheng Zhou, Yulia Tsvetkov, Alan W Black, Zhou Yu"}, {"title": "Phase Transitions for the Information Bottleneck in Representation Learning", "authors": "Tailin Wu, Ian Fischer"}, {"title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively", "authors": "Haotao Wang, Tianlong Chen, Zhangyang Wang, Kede Ma"}, {"title": "On Solving Minimax Optimization Locally: A Follow-the-Ridge Approach", "authors": "Yuanhao Wang, Guodong Zhang, Jimmy Ba", "link": "https://arxiv.org/abs/1910.07512", "summary": "Many tasks in modern machine learning can be formulated as finding equilibria\nin \\emph{sequential} games. In particular, two-player zero-sum sequential\ngames, also known as minimax optimization, have received growing interest. It\nis tempting to apply gradient descent to solve minimax optimization given its\npopularity and success in supervised learning. However, it has been noted that\nnaive application of gradient descent fails to find some local minimax and can\nconverge to non-local-minimax points. In this paper, we propose\n\\emph{Follow-the-Ridge} (FR), a novel algorithm that provably converges to and\nonly converges to local minimax. We show theoretically that the algorithm\naddresses the notorious rotational behaviour of gradient dynamics, and is\ncompatible with preconditioning and \\emph{positive} momentum. Empirically, FR\nsolves toy minimax problems and improves the convergence of GAN training\ncompared to the recent minimax optimization algorithms."}, {"title": "Disentangling Factors of Variations Using Few Labels", "authors": "Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar R\u00e4tsch, Bernhard Sch\u00f6lkopf, Olivier Bachem", "link": "https://arxiv.org/abs/1905.01258", "summary": "Learning disentangled representations is considered a cornerstone problem in\nrepresentation learning. Recently, Locatello et al. (2019) demonstrated that\nunsupervised disentanglement learning without inductive biases is theoretically\nimpossible and that existing inductive biases and unsupervised methods do not\nallow to consistently learn disentangled representations. However, in many\npractical settings, one might have access to a limited amount of supervision,\nfor example through manual labeling of (some) factors of variation in a few\ntraining examples. In this paper, we investigate the impact of such supervision\non state-of-the-art disentanglement methods and perform a large scale study,\ntraining over 52000 models under well-defined and reproducible experimental\nconditions. We observe that a small number of labeled examples (0.01--0.5\\% of\nthe data set), with potentially imprecise and incomplete labels, is sufficient\nto perform model selection on state-of-the-art unsupervised models. Further, we\ninvestigate the benefit of incorporating supervision into the training process.\nOverall, we empirically validate that with little and imprecise supervision it\nis possible to reliably learn disentangled representations."}, {"title": "Defending Against Physically Realizable Attacks on Image Classification", "authors": "Tong Wu, Liang Tong, Yevgeniy Vorobeychik"}, {"title": "Image-guided Neural Object Rendering", "authors": "Justus Thies, Michael Zollh\u00f6fer, Christian Theobalt, Marc Stamminger, Matthias Nie\u00dfner", "link": "https://arxiv.org/abs/1811.10720", "summary": "We propose a learned image-guided rendering technique that combines the\nbenefits of image-based rendering and GAN-based image synthesis. The goal of\nour method is to generate photo-realistic re-renderings of reconstructed\nobjects for virtual and augmented reality applications (e.g., virtual\nshowrooms, virtual tours \\& sightseeing, the digital inspection of historical\nartifacts). A core component of our work is the handling of view-dependent\neffects. Specifically, we directly train an object-specific deep neural network\nto synthesize the view-dependent appearance of an object. As input data we are\nusing an RGB video of the object. This video is used to reconstruct a proxy\ngeometry of the object via multi-view stereo. Based on this 3D proxy, the\nappearance of a captured view can be warped into a new target view as in\nclassical image-based rendering. This warping assumes diffuse surfaces, in case\nof view-dependent effects, such as specular highlights, it leads to artifacts.\nTo this end, we propose EffectsNet, a deep neural network that predicts\nview-dependent effects. Based on these estimations, we are able to convert\nobserved images to diffuse images. These diffuse images can be projected into\nother views. In the target view, our pipeline reinserts the new view-dependent\neffects. To composite multiple reprojected images to a final output, we learn a\ncomposition network that outputs photo-realistic results. Using this\nimage-guided approach, the network does not have to allocate capacity on\n``remembering'' object appearance, instead it learns how to combine the\nappearance of captured images. We demonstrate the effectiveness of our approach\nboth qualitatively and quantitatively on synthetic as well as on real data."}, {"title": "Disagreement-Regularized Imitation Learning", "authors": "Kiante Brantley, Wen Sun, Mikael Henaff"}, {"title": "Deep Orientation Uncertainty Learning based on a Bingham Loss", "authors": "Igor Gilitschenski, Roshni Sahoo, Wilko Schwarting, Alexander Amini, Sertac Karaman, Daniela Rus"}, {"title": "AdvectiveNet: An Eulerian-Lagrangian Fluidic Reservoir for Point Cloud Processing     ", "authors": "Xingzhe He, Helen Lu Cao, Bo Zhu", "link": "https://arxiv.org/abs/2002.00118", "summary": "This paper presents a novel physics-inspired deep learning approach for point\ncloud processing motivated by the natural flow phenomena in fluid mechanics.\nOur learning architecture jointly defines data in an Eulerian world space,\nusing a static background grid, and a Lagrangian material space, using moving\nparticles. By introducing this Eulerian-Lagrangian representation, we are able\nto naturally evolve and accumulate particle features using flow velocities\ngenerated from a generalized, high-dimensional force field. We demonstrate the\nefficacy of this system by solving various point cloud classification and\nsegmentation problems with state-of-the-art performance. The entire geometric\nreservoir and data flow mimics the pipeline of the classic PIC/FLIP scheme in\nmodeling natural flow, bridging the disciplines of geometric machine learning\nand physical simulation."}, {"title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": "John Zarka, Louis Thiry, Tomas Angles, Stephane Mallat", "link": "https://arxiv.org/abs/1910.03561", "summary": "We introduce a sparse scattering deep convolutional neural network, which\nprovides a simple model to analyze properties of deep representation learning\nfor classification. Learning a single dictionary matrix with a classifier\nyields a higher classification accuracy than AlexNet over the ImageNet 2012\ndataset. The network first applies a scattering transform that linearizes\nvariabilities due to geometric transformations such as translations and small\ndeformations. A sparse $\\ell^1$ dictionary coding reduces intra-class\nvariability while preserving class separation through projections over unions\nof linear spaces. It is implemented in a deep convolutional network with a\nhomotopy algorithm having an exponential convergence. A convergence proof is\ngiven in a general framework that includes ALISTA. Classification results are\nanalyzed on ImageNet."}, {"title": "Semantically-Guided Representation Learning for Self-Supervised Monocular Depth", "authors": "Vitor Guizilini, Rui Hou, Jie Li, Rares Ambrus, Adrien Gaidon", "link": "https://arxiv.org/abs/2002.12319", "summary": "Self-supervised learning is showing great promise for monocular depth\nestimation, using geometry as the only source of supervision. Depth networks\nare indeed capable of learning representations that relate visual appearance to\n3D properties by implicitly leveraging category-level patterns. In this work we\ninvestigate how to leverage more directly this semantic structure to guide\ngeometric representation learning, while remaining in the self-supervised\nregime. Instead of using semantic labels and proxy losses in a multi-task\napproach, we propose a new architecture leveraging fixed pretrained semantic\nsegmentation networks to guide self-supervised representation learning via\npixel-adaptive convolutions. Furthermore, we propose a two-stage training\nprocess to overcome a common semantic bias on dynamic objects via resampling.\nOur method improves upon the state of the art for self-supervised monocular\ndepth prediction over all pixels, fine-grained details, and per semantic\ncategories."}, {"title": "Pure and Spurious Critical Points: a Geometric Study of Linear Networks", "authors": "Matthew Trager, Kathl\u00e9n Kohn, Joan Bruna", "link": "https://arxiv.org/abs/1910.01671", "summary": "The critical locus of the loss function of a neural network is determined by\nthe geometry of the functional space and by the parameterization of this space\nby the network's weights. We introduce a natural distinction between pure\ncritical points, which only depend on the functional space, and spurious\ncritical points, which arise from the parameterization. We apply this\nperspective to revisit and extend the literature on the loss function of linear\nneural networks. For this type of network, the functional space is either the\nset of all linear maps from input to output space, or a determinantal variety,\ni.e., a set of linear maps with bounded rank. We use geometric properties of\ndeterminantal varieties to derive new results on the landscape of linear\nnetworks with different loss functions and different parameterizations. Our\nanalysis clearly illustrates that the absence of \"bad\" local minima in the loss\nlandscape of linear networks is due to two distinct phenomena that apply in\ndifferent settings: it is true for arbitrary smooth convex losses in the case\nof architectures that can express all linear maps (\"filling architectures\") but\nit holds only for the quadratic loss when the functional space is a\ndeterminantal variety (\"non-filling architectures\"). Without any assumption on\nthe architecture, smooth convex losses may lead to landscapes with many bad\nminima."}, {"title": "Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem", "authors": "Vaggos Chatziafratis, Sai Ganesh Nagarajan, Ioannis Panageas, Xiao Wang", "link": "https://arxiv.org/abs/1912.04378", "summary": "Understanding the representational power of Deep Neural Networks (DNNs) and\nhow their structural properties (e.g., depth, width, type of activation unit)\naffect the functions they can compute, has been an important yet challenging\nquestion in deep learning and approximation theory. In a seminal paper,\nTelgarsky highlighted the benefits of depth by presenting a family of functions\n(based on simple triangular waves) for which DNNs achieve zero classification\nerror, whereas shallow networks with fewer than exponentially many nodes incur\nconstant error. Even though Telgarsky's work reveals the limitations of shallow\nneural networks, it does not inform us on why these functions are difficult to\nrepresent and in fact he states it as a tantalizing open question to\ncharacterize those functions that cannot be well-approximated by smaller\ndepths.\n  In this work, we point to a new connection between DNNs expressivity and\nSharkovsky's Theorem from dynamical systems, that enables us to characterize\nthe depth-width trade-offs of ReLU networks for representing functions based on\nthe presence of generalized notion of fixed points, called periodic points (a\nfixed point is a point of period 1). Motivated by our observation that the\ntriangle waves used in Telgarsky's work contain points of period 3 - a period\nthat is special in that it implies chaotic behavior based on the celebrated\nresult by Li-Yorke - we proceed to give general lower bounds for the width\nneeded to represent periodic functions as a function of the depth. Technically,\nthe crux of our approach is based on an eigenvalue analysis of the dynamical\nsystem associated with such functions."}, {"title": "Efficient Probabilistic Logic Reasoning with Graph Neural Networks", "authors": "Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi, Le Song", "link": "https://arxiv.org/abs/2001.11850", "summary": "Markov Logic Networks (MLNs), which elegantly combine logic rules and\nprobabilistic graphical models, can be used to address many knowledge graph\nproblems. However, inference in MLN is computationally intensive, making the\nindustrial-scale application of MLN very difficult. In recent years, graph\nneural networks (GNNs) have emerged as efficient and effective tools for\nlarge-scale graph problems. Nevertheless, GNNs do not explicitly incorporate\nprior logic rules into the models, and may require many labeled examples for a\ntarget task. In this paper, we explore the combination of MLNs and GNNs, and\nuse graph neural networks for variational inference in MLN. We propose a GNN\nvariant, named ExpressGNN, which strikes a nice balance between the\nrepresentation power and the simplicity of the model. Our extensive experiments\non several benchmark datasets demonstrate that ExpressGNN leads to effective\nand efficient probabilistic logic reasoning."}, {"title": "HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS", "authors": "Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, Ke Wang"}, {"title": "Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation", "authors": "Hung-Yu Tseng, Hsin-Ying Lee, Jia-Bin Huang, Ming-Hsuan Yang", "link": "https://arxiv.org/abs/2001.08735", "summary": "Few-shot classification aims to recognize novel categories with only few\nlabeled images in each class. Existing metric-based few-shot classification\nalgorithms predict categories by comparing the feature embeddings of query\nimages with those from a few labeled images (support examples) using a learned\nmetric function. While promising performance has been demonstrated, these\nmethods often fail to generalize to unseen domains due to large discrepancy of\nthe feature distribution across domains. In this work, we address the problem\nof few-shot classification under domain shifts for metric-based methods. Our\ncore idea is to use feature-wise transformation layers for augmenting the image\nfeatures using affine transforms to simulate various feature distributions\nunder different domains in the training stage. To capture variations of the\nfeature distributions under different domains, we further apply a\nlearning-to-learn approach to search for the hyper-parameters of the\nfeature-wise transformation layers. We conduct extensive experiments and\nablation studies under the domain generalization setting using five few-shot\nclassification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae.\nExperimental results demonstrate that the proposed feature-wise transformation\nlayer is applicable to various metric-based models, and provides consistent\nimprovements on the few-shot classification performance under domain shift."}, {"title": "Domain Adaptive Multibranch Networks", "authors": "R\u00f3ger Berm\u00fadez-Chac\u00f3n, Mathieu Salzmann, Pascal Fua"}, {"title": "Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network", "authors": "Taiji Suzuki, Hiroshi Abe, Tomoaki Nishimura", "link": "https://arxiv.org/abs/1909.11274", "summary": "One of biggest issues in deep learning theory is its generalization ability\ndespite the huge model size. The classical learning theory suggests that\noverparameterized models cause overfitting. However, practically used large\ndeep models avoid overfitting, which is not well explained by the classical\napproaches. To resolve this issue, several attempts have been made. Among them,\nthe compression based bound is one of the promising approaches. However, the\ncompression based bound can be applied only to a compressed network, and it is\nnot applicable to the non-compressed original network. In this paper, we give a\nunified frame-work that can convert compression based bounds to those for\nnon-compressed original networks. The bound gives even better rate than the one\nfor the compressed network by improving the bias term. By establishing the\nunified frame-work, we can obtain a data dependent generalization error bound\nwhich gives a tighter evaluation than the data independent ones."}, {"title": "Smoothness and Stability in GANs", "authors": "Casey Chu, Kentaro Minami, Kenji Fukumizu", "link": "https://arxiv.org/abs/2002.04185", "summary": "Generative adversarial networks, or GANs, commonly display unstable behavior\nduring training. In this work, we develop a principled theoretical framework\nfor understanding the stability of various types of GANs. In particular, we\nderive conditions that guarantee eventual stationarity of the generator when it\nis trained with gradient descent, conditions that must be satisfied by the\ndivergence that is minimized by the GAN and the generator's architecture. We\nfind that existing GAN variants satisfy some, but not all, of these conditions.\nUsing tools from convex analysis, optimal transport, and reproducing kernels,\nwe construct a GAN that fulfills these conditions simultaneously. In the\nprocess, we explain and clarify the need for various existing GAN stabilization\ntechniques, including Lipschitz constraints, gradient penalties, and smooth\nactivation functions."}, {"title": "Inductive and Unsupervised Representation Learning on Graph Structured Objects", "authors": "Lichen Wang, Bo Zong, Qianqian Ma, Wei Cheng, Jingchao Ni, Wenchao Yu, Yanchi Liu, Dongjin Song, Haifeng Chen, Yun Fu"}, {"title": "Massively Multilingual Sparse Word Representations", "authors": "G\u00e1bor Berend"}, {"title": "GraphZoom: A Multi-level Spectral Approach for Accurate and Scalable Graph Embedding", "authors": "Chenhui Deng, Zhiqiang Zhao, Yongyu Wang, Zhiru Zhang, Zhuo Feng", "link": "https://arxiv.org/abs/1910.02370", "summary": "Graph embedding techniques have been increasingly deployed in a multitude of\ndifferent applications that involve learning on non-Euclidean data. However,\nexisting graph embedding models either fail to incorporate node attribute\ninformation during training or suffer from node attribute noise, which\ncompromises the accuracy. Moreover, very few of them scale to large graphs due\nto their high computational complexity and memory usage. In this paper we\npropose GraphZoom, a multi-level framework for improving both accuracy and\nscalability of unsupervised graph embedding algorithms. GraphZoom first\nperforms graph fusion to generate a new graph that effectively encodes the\ntopology of the original graph and the node attribute information. This fused\ngraph is then repeatedly coarsened into much smaller graphs by merging nodes\nwith high spectral similarities. GraphZoom allows any existing embedding\nmethods to be applied to the coarsened graph, before it progressively refine\nthe embeddings obtained at the coarsest level to increasingly finer graphs. We\nhave evaluated our approach on a number of popular graph datasets for both\ntransductive and inductive tasks. Our experiments show that GraphZoom can\nsubstantially increase the classification accuracy and significantly accelerate\nthe entire graph embedding process by up to 40.8x, when compared to the\nstate-of-the-art unsupervised embedding methods."}, {"title": "Neural Tangents: Fast and Easy Infinite Neural Networks in Python", "authors": "Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander A. Alemi, Jascha Sohl-Dickstein, Samuel S. Schoenholz", "link": "https://arxiv.org/abs/1912.02803", "summary": "Neural Tangents is a library designed to enable research into infinite-width\nneural networks. It provides a high-level API for specifying complex and\nhierarchical neural network architectures. These networks can then be trained\nand evaluated either at finite-width as usual or in their infinite-width limit.\nInfinite-width networks can be trained analytically using exact Bayesian\ninference or using gradient descent via the Neural Tangent Kernel.\nAdditionally, Neural Tangents provides tools to study gradient descent training\ndynamics of wide but finite networks in either function space or weight space.\n  The entire library runs out-of-the-box on CPU, GPU, or TPU. All computations\ncan be automatically distributed over multiple accelerators with near-linear\nscaling in the number of devices. Neural Tangents is available at\nwww.github.com/google/neural-tangents. We also provide an accompanying\ninteractive Colab notebook."}, {"title": "Learning to Guide Random Search", "authors": "Ozan Sener, Vladlen Koltun"}, {"title": "Understanding Why Neural Networks Generalize Well Through GSNR of Parameters", "authors": "Jinlong Liu, Yunzhi Bai, Guoqing Jiang, Ting Chen, Huayan Wang", "link": "https://arxiv.org/abs/2001.07384", "summary": "As deep neural networks (DNNs) achieve tremendous success across many\napplication domains, researchers tried to explore in many aspects on why they\ngeneralize well. In this paper, we provide a novel perspective on these issues\nusing the gradient signal to noise ratio (GSNR) of parameters during training\nprocess of DNNs. The GSNR of a parameter is defined as the ratio between its\ngradient's squared mean and variance, over the data distribution. Based on\nseveral approximations, we establish a quantitative relationship between model\nparameters' GSNR and the generalization gap. This relationship indicates that\nlarger GSNR during training process leads to better generalization performance.\nMoreover, we show that, different from that of shallow models (e.g. logistic\nregression, support vector machines), the gradient descent optimization\ndynamics of DNNs naturally produces large GSNR during training, which is\nprobably the key to DNNs' remarkable generalization ability."}, {"title": "Capsules with Inverted Dot-Product Attention Routing", "authors": "Yao-Hung Hubert Tsai, Nitish Srivastava, Hanlin Goh, Ruslan Salakhutdinov"}, {"title": "Towards a Deep Network Architecture for Structured Smoothness", "authors": "Haroun Habeeb, Oluwasanmi Koyejo"}, {"title": "BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by Coupling Binary Activations", "authors": "Hyungjun Kim, Kyungsu Kim, Jinseok Kim, Jae-Joon Kim"}, {"title": "A FRAMEWORK  FOR ROBUSTNESS CERTIFICATION  OF SMOOTHED CLASSIFIERS USING  F-DIVERGENCES", "authors": "Krishnamurthy (Dj) Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gyorgy, Kai Xiao, Sven Gowal, Pushmeet Kohli"}, {"title": "Towards Stable and Efficient Training of Verifiably Robust Neural Networks", "authors": "Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, Cho-Jui Hsieh", "link": "https://arxiv.org/abs/1906.06316", "summary": "Training neural networks with verifiable robustness guarantees is\nchallenging. Several existing approaches utilize linear relaxation based neural\nnetwork output bounds under perturbation, but they can slow down training by a\nfactor of hundreds depending on the underlying network architectures.\nMeanwhile, interval bound propagation (IBP) based training is efficient and\nsignificantly outperforms linear relaxation based methods on many tasks, yet it\nmay suffer from stability issues since the bounds are much looser especially at\nthe beginning of training. In this paper, we propose a new certified\nadversarial training method, CROWN-IBP, by combining the fast IBP bounds in a\nforward bounding pass and a tight linear relaxation based bound, CROWN, in a\nbackward bounding pass. CROWN-IBP is computationally efficient and consistently\noutperforms IBP baselines on training verifiably robust neural networks. We\nconduct large scale experiments on MNIST and CIFAR datasets, and outperform all\nprevious linear relaxation and bound propagation based certified defenses in\n$\\ell_\\infty$ robustness. Notably, we achieve 7.02% verified test error on\nMNIST at $\\epsilon=0.3$, and 66.94% on CIFAR-10 with $\\epsilon=8/255$. Code is\navailable at https://github.com/deepmind/interval-bound-propagation\n(TensorFlow) and https://github.com/huanzhang12/CROWN-IBP (PyTorch)."}, {"title": "Variational Template Machine for Data-to-Text Generation", "authors": "Rong Ye, Wenxian Shi, Hao Zhou, Zhongyu Wei, Lei Li"}, {"title": "Asymptotics of Wide Networks from Feynman Diagrams", "authors": "Ethan Dyer, Guy Gur-Ari", "link": "https://arxiv.org/abs/1909.11304", "summary": "Understanding the asymptotic behavior of wide networks is of considerable\ninterest. In this work, we present a general method for analyzing this large\nwidth behavior. The method is an adaptation of Feynman diagrams, a standard\ntool for computing multivariate Gaussian integrals. We apply our method to\nstudy training dynamics, improving existing bounds and deriving new results on\nwide network evolution during stochastic gradient descent. Going beyond the\nstrict large width limit, we present closed-form expressions for higher-order\nterms governing wide network training, and test these predictions empirically."}, {"title": "Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks", "authors": "Haoran You, Chaojian Li, Pengfei Xu, Yonggan Fu, Yue Wang, Xiaohan Chen, Richard G. Baraniuk, Zhangyang Wang, Yingyan Lin", "link": "https://arxiv.org/abs/1909.11957", "summary": "(Frankle & Carbin, 2019) shows that there exist winning tickets (small but\ncritical subnetworks) for dense, randomly initialized networks, that can be\ntrained alone to achieve comparable accuracies to the latter in a similar\nnumber of iterations. However, the identification of these winning tickets\nstill requires the costly train-prune-retrain process, limiting their practical\nbenefits. In this paper, we discover for the first time that the winning\ntickets can be identified at the very early training stage, which we term as\nearly-bird (EB) tickets, via low-cost training schemes (e.g., early stopping\nand low-precision training) at large learning rates. Our finding of EB tickets\nis consistent with recently reported observations that the key connectivity\npatterns of neural networks emerge early. Furthermore, we propose a mask\ndistance metric that can be used to identify EB tickets with low computational\noverhead, without needing to know the true winning tickets that emerge after\nthe full training. Finally, we leverage the existence of EB tickets and the\nproposed mask distance to develop efficient training methods, which are\nachieved by first identifying EB tickets via low-cost schemes, and then\ncontinuing to train merely the EB tickets towards the target accuracy.\nExperiments based on various deep networks and datasets validate: 1) the\nexistence of EB tickets, and the effectiveness of mask distance in efficiently\nidentifying them; and 2) that the proposed efficient training via EB tickets\ncan achieve up to 4.7x energy savings while maintaining comparable or even\nbetter accuracy, demonstrating a promising and easily adopted method for\ntackling cost-prohibitive deep network training. Code available at\nhttps://github.com/RICE-EIC/Early-Bird-Tickets."}, {"title": "Meta-Learning without Memorization", "authors": "Mingzhang Yin, George Tucker, Mingyuan Zhou, Sergey Levine, Chelsea Finn", "link": "https://arxiv.org/abs/1912.03820", "summary": "The ability to learn new concepts with small amounts of data is a critical\naspect of intelligence that has proven challenging for deep learning methods.\nMeta-learning has emerged as a promising technique for leveraging data from\nprevious tasks to enable efficient learning of new tasks. However, most\nmeta-learning algorithms implicitly require that the meta-training tasks be\nmutually-exclusive, such that no single model can solve all of the tasks at\nonce. For example, when creating tasks for few-shot image classification, prior\nwork uses a per-task random assignment of image classes to N-way classification\nlabels. If this is not done, the meta-learner can ignore the task training data\nand learn a single model that performs all of the meta-training tasks\nzero-shot, but does not adapt effectively to new image classes. This\nrequirement means that the user must take great care in designing the tasks,\nfor example by shuffling labels or removing task identifying information from\nthe inputs. In some domains, this makes meta-learning entirely inapplicable. In\nthis paper, we address this challenge by designing a meta-regularization\nobjective using information theory that places precedence on data-driven\nadaptation. This causes the meta-learner to decide what must be learned from\nthe task training data and what should be inferred from the task testing input.\nBy doing so, our algorithm can successfully use data from\nnon-mutually-exclusive tasks to efficiently adapt to novel tasks. We\ndemonstrate its applicability to both contextual and gradient-based\nmeta-learning algorithms, and apply it in practical settings where applying\nstandard meta-learning has been difficult. Our approach substantially\noutperforms standard meta-learning algorithms in these settings."}, {"title": "Revisiting Self-Training for Neural Sequence Generation", "authors": "Junxian He, Jiatao Gu, Jiajun Shen, Marc'Aurelio Ranzato", "link": "https://arxiv.org/abs/1909.13788", "summary": "Self-training is one of the earliest and simplest semi-supervised methods.\nThe key idea is to augment the original labeled dataset with unlabeled data\npaired with the model's prediction (i.e. the pseudo-parallel data). While\nself-training has been extensively studied on classification problems, in\ncomplex sequence generation tasks (e.g. machine translation) it is still\nunclear how self-training works due to the compositionality of the target\nspace. In this work, we first empirically show that self-training is able to\ndecently improve the supervised baseline on neural sequence generation tasks.\nThrough careful examination of the performance gains, we find that the\nperturbation on the hidden states (i.e. dropout) is critical for self-training\nto benefit from the pseudo-parallel data, which acts as a regularizer and\nforces the model to yield close predictions for similar unlabeled inputs. Such\neffect helps the model correct some incorrect predictions on unlabeled data. To\nfurther encourage this mechanism, we propose to inject noise to the input\nspace, resulting in a \"noisy\" version of self-training. Empirical study on\nstandard machine translation and text summarization benchmarks shows that noisy\nself-training is able to effectively utilize unlabeled data and improve the\nperformance of the supervised baseline by a large margin."}, {"title": "Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video", "authors": "Miguel Jaques, Michael Burke, Timothy Hospedales", "link": "https://arxiv.org/abs/1905.11169", "summary": "We propose a model that is able to perform unsupervised physical parameter\nestimation of systems from video, where the differential equations governing\nthe scene dynamics are known, but labeled states or objects are not available.\nExisting physical scene understanding methods require either object state\nsupervision, or do not integrate with differentiable physics to learn\ninterpretable system parameters and states. We address this problem through a\nphysics-as-inverse-graphics approach that brings together\nvision-as-inverse-graphics and differentiable physics engines, enabling objects\nand explicit state and velocity representations to be discovered. This\nframework allows us to perform long term extrapolative video prediction, as\nwell as vision-based model-predictive control. Our approach significantly\noutperforms related unsupervised methods in long-term future frame prediction\nof systems with interacting objects (such as ball-spring or 3-body\ngravitational systems), due to its ability to build dynamics into the model as\nan inductive bias. We further show the value of this tight vision-physics\nintegration by demonstrating data-efficient learning of vision-actuated\nmodel-based control for a pendulum system. We also show that the controller's\ninterpretability provides unique capabilities in goal-driven control and\nphysical reasoning for zero-data adaptation."}, {"title": "Masked Based Unsupervised Content Transfer", "authors": "Ron Mokady, Sagie Benaim, Lior Wolf, Amit Bermano"}, {"title": "Fast is better than free: Revisiting adversarial training", "authors": "Eric Wong, Leslie Rice, J. Zico Kolter", "link": "https://arxiv.org/abs/2001.03994", "summary": "Adversarial training, a method for learning robust deep networks, is\ntypically assumed to be more expensive than traditional training due to the\nnecessity of constructing adversarial examples via a first-order method like\nprojected gradient decent (PGD). In this paper, we make the surprising\ndiscovery that it is possible to train empirically robust models using a much\nweaker and cheaper adversary, an approach that was previously believed to be\nineffective, rendering the method no more costly than standard training in\npractice. Specifically, we show that adversarial training with the fast\ngradient sign method (FGSM), when combined with random initialization, is as\neffective as PGD-based training but has significantly lower cost. Furthermore\nwe show that FGSM adversarial training can be further accelerated by using\nstandard techniques for efficient training of deep networks, allowing us to\nlearn a robust CIFAR10 classifier with 45% robust accuracy to PGD attacks with\n$\\epsilon=8/255$ in 6 minutes, and a robust ImageNet classifier with 43% robust\naccuracy at $\\epsilon=2/255$ in 12 hours, in comparison to past work based on\n\"free\" adversarial training which took 10 and 50 hours to reach the same\nrespective thresholds. Finally, we identify a failure mode referred to as\n\"catastrophic overfitting\" which may have caused previous attempts to use FGSM\nadversarial training to fail. All code for reproducing the experiments in this\npaper as well as pretrained model weights are at\nhttps://github.com/locuslab/fast_adversarial."}, {"title": "GLAD: Learning Sparse Graph Recovery", "authors": "Harsh Shrivastava, Xinshi Chen, Binghong Chen, Guanghui Lan, Srinivas Aluru, Han Liu, Le Song"}, {"title": "word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement", "authors": "Aliakbar Panahi, Seyran Saeedi, Tom Arodz", "link": "https://arxiv.org/abs/1911.04975", "summary": "Deep learning natural language processing models often use vector word\nembeddings, such as word2vec or GloVe, to represent words. A discrete sequence\nof words can be much more easily integrated with downstream neural layers if it\nis represented as a sequence of continuous vectors. Also, semantic\nrelationships between words, learned from a text corpus, can be encoded in the\nrelative configurations of the embedding vectors. However, storing and\naccessing embedding vectors for all words in a dictionary requires large amount\nof space, and may stain systems with limited GPU memory. Here, we used\napproaches inspired by quantum computing to propose two related methods, {\\em\nword2ket} and {\\em word2ketXS}, for storing word embedding matrix during\ntraining and inference in a highly efficient way. Our approach achieves a\nhundred-fold or more reduction in the space required to store the embeddings\nwith almost no relative drop in accuracy in practical natural language\nprocessing tasks."}, {"title": "Adversarially robust transfer learning", "authors": "Ali Shafahi, Parsa Saadatpanah, Chen Zhu, Amin Ghiasi, Christoph Studer, David Jacobs, Tom Goldstein", "link": "https://arxiv.org/abs/1905.08232", "summary": "Transfer learning, in which a network is trained on one task and re-purposed\non another, is often used to produce neural network classifiers when data is\nscarce or full-scale training is too costly. When the goal is to produce a\nmodel that is not only accurate but also adversarially robust, data scarcity\nand computational limitations become even more cumbersome. We consider robust\ntransfer learning, in which we transfer not only performance but also\nrobustness from a source model to a target domain. We start by observing that\nrobust networks contain robust feature extractors. By training classifiers on\ntop of these feature extractors, we produce new models that inherit the\nrobustness of their parent networks. We then consider the case of fine tuning a\nnetwork by re-training end-to-end in the target domain. When using lifelong\nlearning strategies, this process preserves the robustness of the source\nnetwork while achieving high accuracy. By using such strategies, it is possible\nto produce accurate and robust models with little data, and without the cost of\nadversarial training. Additionally, we can improve the generalization of\nadversarially trained models, while maintaining their robustness."}, {"title": "Explanation  by Progressive  Exaggeration", "authors": "Sumedha Singla, Brian Pollack, Junxiang Chen, Kayhan Batmanghelich", "link": "https://arxiv.org/abs/1911.00483", "summary": "As machine learning methods see greater adoption and implementation in high\nstakes applications such as medical image diagnosis, the need for model\ninterpretability and explanation has become more critical. Classical approaches\nthat assess feature importance (e.g. saliency maps) do not explain how and why\na particular region of an image is relevant to the prediction. We propose a\nmethod that explains the outcome of a classification black-box by gradually\nexaggerating the semantic effect of a given class. Given a query input to a\nclassifier, our method produces a progressive set of plausible variations of\nthat query, which gradually changes the posterior probability from its original\nclass to its negation. These counter-factually generated samples preserve\nfeatures unrelated to the classification decision, such that a user can employ\nour method as a \"tuning knob\" to traverse a data manifold while crossing the\ndecision boundary. Our method is model agnostic and only requires the output\nvalue and gradient of the predictor with respect to its input."}, {"title": "Mixed-curvature Variational Autoencoders", "authors": "Ondrej Skopek, Octavian-Eugen Ganea, Gary B\u00e9cigneul", "link": "https://arxiv.org/abs/1911.08411", "summary": "Euclidean geometry has historically been the typical \"workhorse\" for machine\nlearning applications due to its power and simplicity. However, it has recently\nbeen shown that geometric spaces with constant non-zero curvature improve\nrepresentations and performance on a variety of data types and downstream\ntasks. Consequently, generative models like Variational Autoencoders (VAEs)\nhave been successfully generalized to elliptical and hyperbolic latent spaces.\nWhile these approaches work well on data with particular kinds of biases e.g.\ntree-like data for a hyperbolic VAE, there exists no generic approach unifying\nand leveraging all three models. We develop a Mixed-curvature Variational\nAutoencoder, an efficient way to train a VAE whose latent space is a product of\nconstant curvature Riemannian manifolds, where the per-component curvature is\nfixed or learnable. This generalizes the Euclidean VAE to curved latent spaces\nand recovers it when curvatures of all latent space components go to 0."}, {"title": "NAS evaluation is frustratingly hard", "authors": "Antoine Yang, Pedro M. Esperan\u00e7a, Fabio M. Carlucci", "link": "https://arxiv.org/abs/1912.12522", "summary": "Neural Architecture Search (NAS) is an exciting new field which promises to\nbe as much as a game-changer as Convolutional Neural Networks were in 2012.\nDespite many great works leading to substantial improvements on a variety of\ntasks, comparison between different methods is still very much an open issue.\nWhile most algorithms are tested on the same datasets, there is no shared\nexperimental protocol followed by all. As such, and due to the under-use of\nablation studies, there is a lack of clarity regarding why certain methods are\nmore effective than others. Our first contribution is a benchmark of $8$ NAS\nmethods on $5$ datasets. To overcome the hurdle of comparing methods with\ndifferent search spaces, we propose using a method's relative improvement over\nthe randomly sampled average architecture, which effectively removes advantages\narising from expertly engineered search spaces or training protocols.\nSurprisingly, we find that many NAS techniques struggle to significantly beat\nthe average architecture baseline. We perform further experiments with the\ncommonly used DARTS search space in order to understand the contribution of\neach component in the NAS pipeline. These experiments highlight that: (i) the\nuse of tricks in the evaluation protocol has a predominant impact on the\nreported performance of architectures; (ii) the cell-based search space has a\nvery narrow accuracy range, such that the seed has a considerable impact on\narchitecture rankings; (iii) the hand-designed macro-structure (cells) is more\nimportant than the searched micro-structure (operations); and (iv) the\ndepth-gap is a real phenomenon, evidenced by the change in rankings between $8$\nand $20$ cell architectures. To conclude, we suggest best practices, that we\nhope will prove useful for the community and help mitigate current NAS\npitfalls. The code used is available at\nhttps://github.com/antoyang/NAS-Benchmark."}, {"title": "Mixed Precision DNNs: All you need is a good parametrization", "authors": "Stefan Uhlich, Lukas Mauch, Fabien Cardinaux, Kazuki Yoshiyama, Javier Alonso Garcia, Stephen Tiedemann, Thomas Kemp, Akira Nakamura", "link": "https://arxiv.org/abs/1905.11452", "summary": "Efficient deep neural network (DNN) inference on mobile or embedded devices\ntypically involves quantization of the network parameters and activations. In\nparticular, mixed precision networks achieve better performance than networks\nwith homogeneous bitwidth for the same size constraint. Since choosing the\noptimal bitwidths is not straight forward, training methods, which can learn\nthem, are desirable. Differentiable quantization with straight-through\ngradients allows to learn the quantizer's parameters using gradient methods. We\nshow that a suited parametrization of the quantizer is the key to achieve a\nstable training and a good final performance. Specifically, we propose to\nparametrize the quantizer with the step size and dynamic range. The bitwidth\ncan then be inferred from them. Other parametrizations, which explicitly use\nthe bitwidth, consistently perform worse. We confirm our findings with\nexperiments on CIFAR-10 and ImageNet and we obtain mixed precision DNNs with\nlearned quantization parameters, achieving state-of-the-art performance."}, {"title": "Fast Task Inference with Variational Intrinsic Successor Features", "authors": "Steven Hansen, Will Dabney, Andre Barreto, David Warde-Farley, Tom Van de Wiele, Volodymyr Mnih", "link": "https://arxiv.org/abs/1906.05030", "summary": "It has been established that diverse behaviors spanning the controllable\nsubspace of an Markov decision process can be trained by rewarding a policy for\nbeing distinguishable from other policies \\citep{gregor2016variational,\neysenbach2018diversity, warde2018unsupervised}. However, one limitation of this\nformulation is generalizing behaviors beyond the finite set being explicitly\nlearned, as is needed for use on subsequent tasks. Successor features\n\\citep{dayan93improving, barreto2017successor} provide an appealing solution to\nthis generalization problem, but require defining the reward function as linear\nin some grounded feature space. In this paper, we show that these two\ntechniques can be combined, and that each method solves the other's primary\nlimitation. To do so we introduce Variational Intrinsic Successor FeatuRes\n(VISR), a novel algorithm which learns controllable features that can be\nleveraged to provide enhanced generalization and fast task inference through\nthe successor feature framework. We empirically validate VISR on the full Atari\nsuite, in a novel setup wherein the rewards are only exposed briefly after a\nlong unsupervised phase. Achieving human-level performance on 14 games and\nbeating all baselines, we believe VISR represents a step towards agents that\nrapidly learn from limited feedback."}, {"title": "Thinking While Moving: Deep Reinforcement Learning with Concurrent Control", "authors": "Ted Xiao, Eric Jang, Dmitry Kalashnikov, Sergey Levine, Julian Ibarz, Karol Hausman, Alexander Herzog", "link": "https://arxiv.org/abs/2004.06089", "summary": "We study reinforcement learning in settings where sampling an action from the\npolicy must be done concurrently with the time evolution of the controlled\nsystem, such as when a robot must decide on the next action while still\nperforming the previous action. Much like a person or an animal, the robot must\nthink and move at the same time, deciding on its next action before the\nprevious one has completed. In order to develop an algorithmic framework for\nsuch concurrent control problems, we start with a continuous-time formulation\nof the Bellman equations, and then discretize them in a way that is aware of\nsystem delays. We instantiate this new class of approximate dynamic programming\nmethods via a simple architectural extension to existing value-based deep\nreinforcement learning algorithms. We evaluate our methods on simulated\nbenchmark tasks and a large-scale robotic grasping task where the robot must\n\"think while moving\"."}, {"title": "Selection via Proxy: Efficient Data Selection for Deep Learning", "authors": "Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter Bailis, Percy Liang, Jure Leskovec, Matei Zaharia", "link": "https://arxiv.org/abs/1906.11829", "summary": "Data selection methods, such as active learning and core-set selection, are\nuseful tools for machine learning on large datasets. However, they can be\nprohibitively expensive to apply in deep learning because they depend on\nfeature representations that need to be learned. In this work, we show that we\ncan greatly improve the computational efficiency by using a small proxy model\nto perform data selection (e.g., selecting data points to label for active\nlearning). By removing hidden layers from the target model, using smaller\narchitectures, and training for fewer epochs, we create proxies that are an\norder of magnitude faster to train. Although these small proxy models have\nhigher error rates, we find that they empirically provide useful signals for\ndata selection. We evaluate this \"selection via proxy\" (SVP) approach on\nseveral data selection tasks across five datasets: CIFAR10, CIFAR100, ImageNet,\nAmazon Review Polarity, and Amazon Review Full. For active learning, applying\nSVP can give an order of magnitude improvement in data selection runtime (i.e.,\nthe time it takes to repeatedly train and select points) without significantly\nincreasing the final error (often within 0.1%). For core-set selection on\nCIFAR10, proxies that are over 10x faster to train than their larger, more\naccurate targets can remove up to 50% of the data without harming the final\naccuracy of the target, leading to a 1.6x end-to-end training time improvement."}, {"title": "The asymptotic spectrum of the Hessian of DNN throughout training", "authors": "Arthur Jacot, Franck Gabriel, Clement Hongler"}, {"title": "IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks", "authors": "Michael Luo, Jiahao Yao, Richard Liaw, Eric Liang, Ion Stoica"}, {"title": "An Inductive Bias for Distances: Neural Nets that Respect the Triangle Inequality", "authors": "Silviu Pitis, Harris Chan, Kiarash Jamali, Jimmy Ba", "link": "https://arxiv.org/abs/2002.05825", "summary": "Distances are pervasive in machine learning. They serve as similarity\nmeasures, loss functions, and learning targets; it is said that a good distance\nmeasure solves a task. When defining distances, the triangle inequality has\nproven to be a useful constraint, both theoretically--to prove convergence and\noptimality guarantees--and empirically--as an inductive bias. Deep metric\nlearning architectures that respect the triangle inequality rely, almost\nexclusively, on Euclidean distance in the latent space. Though effective, this\nfails to model two broad classes of subadditive distances, common in graphs and\nreinforcement learning: asymmetric metrics, and metrics that cannot be embedded\ninto Euclidean space. To address these problems, we introduce novel\narchitectures that are guaranteed to satisfy the triangle inequality. We prove\nour architectures universally approximate norm-induced metrics on\n$\\mathbb{R}^n$, and present a similar result for modified Input Convex Neural\nNetworks. We show that our architectures outperform existing metric approaches\nwhen modeling graph distances and have a better inductive bias than non-metric\napproaches when training data is limited in the multi-goal reinforcement\nlearning setting."}, {"title": "Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering", "authors": "Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, Caiming Xiong", "link": "https://arxiv.org/abs/1911.10470", "summary": "Answering questions that require multi-hop reasoning at web-scale\nnecessitates retrieving multiple evidence documents, one of which often has\nlittle lexical or semantic relationship to the question. This paper introduces\na new graph-based recurrent retrieval approach that learns to retrieve\nreasoning paths over the Wikipedia graph to answer multi-hop open-domain\nquestions. Our retriever model trains a recurrent neural network that learns to\nsequentially retrieve evidence paragraphs in the reasoning path by conditioning\non the previously retrieved documents. Our reader model ranks the reasoning\npaths and extracts the answer span included in the best reasoning path.\nExperimental results show state-of-the-art results in three open-domain QA\ndatasets, showcasing the effectiveness and robustness of our method. Notably,\nour method achieves significant improvement in HotpotQA, outperforming the\nprevious best model by more than 14 points."}, {"title": "Span Recovery for Deep Neural Networks with Applications to Input Obfuscation", "authors": "Rajesh Jayaram, David P. Woodruff, Qiuyi Zhang"}, {"title": "DeFINE: Deep Factorized Input Token Embeddings for Neural Sequence Modeling", "authors": "Sachin Mehta, Rik Koncel-Kedziorski, Mohammad Rastegari, Hannaneh Hajishirzi", "link": "https://arxiv.org/abs/1911.12385", "summary": "For sequence models with large vocabularies, a majority of network parameters\nlie in the input and output layers. In this work, we describe a new method,\nDeFINE, for learning deep token representations efficiently. Our architecture\nuses a hierarchical structure with novel skip-connections which allows for the\nuse of low dimensional input and output layers, reducing total parameters and\ntraining time while delivering similar or better performance versus existing\nmethods. DeFINE can be incorporated easily in new or existing sequence models.\nCompared to state-of-the-art methods including adaptive input representations,\nthis technique results in a 6% to 20% drop in perplexity. On WikiText-103,\nDeFINE reduces the total parameters of Transformer-XL by half with minimal\nimpact on performance. On the Penn Treebank, DeFINE improves AWD-LSTM by 4\npoints with a 17% reduction in parameters, achieving comparable performance to\nstate-of-the-art methods with fewer parameters. For machine translation, DeFINE\nimproves the efficiency of the Transformer model by about 1.4 times while\ndelivering similar performance."}, {"title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural Architecture Search", "authors": "Arber Zela, Julien Siems, Frank Hutter", "link": "https://arxiv.org/abs/2001.10422", "summary": "One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still\na lack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS\nmethods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101."}, {"title": "StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding", "authors": "Wei Wang, Bin Bi, Ming Yan, Chen Wu, Jiangnan Xia, Zuyi Bao, Liwei Peng, Luo Si", "link": "https://arxiv.org/abs/1908.04577", "summary": "Recently, the pre-trained language model, BERT (and its robustly optimized\nversion RoBERTa), has attracted a lot of attention in natural language\nunderstanding (NLU), and achieved state-of-the-art accuracy in various NLU\ntasks, such as sentiment classification, natural language inference, semantic\ntextual similarity and question answering. Inspired by the linearization\nexploration work of Elman [8], we extend BERT to a new model, StructBERT, by\nincorporating language structures into pre-training. Specifically, we pre-train\nStructBERT with two auxiliary tasks to make the most of the sequential order of\nwords and sentences, which leverage language structures at the word and\nsentence levels, respectively. As a result, the new model is adapted to\ndifferent levels of language understanding required by downstream tasks. The\nStructBERT with structural pre-training gives surprisingly good empirical\nresults on a variety of downstream tasks, including pushing the\nstate-of-the-art on the GLUE benchmark to 89.0 (outperforming all published\nmodels), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on\nSNLI to 91.7."}, {"title": "Abductive Commonsense Reasoning", "authors": "Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen-tau Yih, Yejin Choi", "link": "https://arxiv.org/abs/1908.05739", "summary": "Abductive reasoning is inference to the most plausible explanation. For\nexample, if Jenny finds her house in a mess when she returns from work, and\nremembers that she left a window open, she can hypothesize that a thief broke\ninto her house and caused the mess, as the most plausible explanation. While\nabduction has long been considered to be at the core of how people interpret\nand read between the lines in natural language (Hobbs et al., 1988), there has\nbeen relatively little research in support of abductive natural language\ninference and generation. We present the first study that investigates the\nviability of language-based abductive reasoning. We introduce a challenge\ndataset, ART, that consists of over 20k commonsense narrative contexts and 200k\nexplanations. Based on this dataset, we conceptualize two new tasks -- (i)\nAbductive NLI: a multiple-choice question answering task for choosing the more\nlikely explanation, and (ii) Abductive NLG: a conditional generation task for\nexplaining given observations in natural language. On Abductive NLI, the best\nmodel achieves 68.9% accuracy, well below human performance of 91.4%. On\nAbductive NLG, the current best language generators struggle even more, as they\nlack reasoning capabilities that are trivial for humans. Our analysis leads to\nnew insights into the types of reasoning that deep pre-trained language models\nfail to perform--despite their strong performance on the related but more\nnarrowly defined task of entailment NLI--pointing to interesting avenues for\nfuture research."}, {"title": "On Universal Equivariant Set Networks", "authors": "Nimrod Segol, Yaron Lipman", "link": "https://arxiv.org/abs/1910.02421", "summary": "Using deep neural networks that are either invariant or equivariant to\npermutations in order to learn functions on unordered sets has become\nprevalent. The most popular, basic models are DeepSets [Zaheer et al. 2017] and\nPointNet [Qi et al. 2017]. While known to be universal for approximating\ninvariant functions, DeepSets and PointNet are not known to be universal when\napproximating \\emph{equivariant} set functions. On the other hand, several\nrecent equivariant set architectures have been proven equivariant universal\n[Sannai et al. 2019], [Keriven et al. 2019], however these models either use\nlayers that are not permutation equivariant (in the standard sense) and/or use\nhigher order tensor variables which are less practical.\n  There is, therefore, a gap in understanding the universality of popular\nequivariant set models versus theoretical ones.\n  In this paper we close this gap by proving that: (i) PointNet is not\nequivariant universal; and (ii) adding a single linear transmission layer makes\nPointNet universal. We call this architecture PointNetST and argue it is the\nsimplest permutation equivariant universal model known to date. Another\nconsequence is that DeepSets is universal, and also PointNetSeg, a popular\npoint cloud segmentation network (used eg, in [Qi et al. 2017]) is universal.\n  The key theoretical tool used to prove the above results is an explicit\ncharacterization of all permutation equivariant polynomial layers. Lastly, we\nprovide numerical experiments validating the theoretical results and comparing\ndifferent permutation equivariant models."}, {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": "Lukas Prantl, Nuttapong Chentanez, Stefan Jeschke, Nils Thuerey", "link": "https://arxiv.org/abs/1907.05279", "summary": "Point clouds, as a form of Lagrangian representation, allow for powerful and\nflexible applications in a large number of computational disciplines. We\npropose a novel deep-learning method to learn stable and temporally coherent\nfeature spaces for points clouds that change over time. We identify a set of\ninherent problems with these approaches: without knowledge of the time\ndimension, the inferred solutions can exhibit strong flickering, and easy\nsolutions to suppress this flickering can result in undesirable local minima\nthat manifest themselves as halo structures. We propose a novel temporal loss\nfunction that takes into account higher time derivatives of the point\npositions, and encourages mingling, i.e., to prevent the aforementioned halos.\nWe combine these techniques in a super-resolution method with a truncation\napproach to flexibly adapt the size of the generated positions. We show that\nour method works for large, deforming point sets from different sources to\ndemonstrate the flexibility of our approach."}, {"title": "PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search", "authors": "Yuhui Xu, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Guo-Jun Qi, Qi Tian, Hongkai Xiong", "link": "https://arxiv.org/abs/1907.05737", "summary": "Differentiable architecture search (DARTS) provided a fast solution in\nfinding effective network architectures, but suffered from large memory and\ncomputing overheads in jointly training a super-network and searching for an\noptimal architecture. In this paper, we present a novel approach, namely,\nPartially-Connected DARTS, by sampling a small part of super-network to reduce\nthe redundancy in exploring the network space, thereby performing a more\nefficient search without comprising the performance. In particular, we perform\noperation search in a subset of channels while bypassing the held out part in a\nshortcut. This strategy may suffer from an undesired inconsistency on selecting\nthe edges of super-net caused by sampling different channels. We alleviate it\nusing edge normalization, which adds a new set of edge-level parameters to\nreduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can\nbe trained with a larger batch size and, consequently, enjoys both faster speed\nand higher training stability. Experimental results demonstrate the\neffectiveness of the proposed method. Specifically, we achieve an error rate of\n2.57% on CIFAR10 with merely 0.1 GPU-days for architecture search, and a\nstate-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile\nsetting) using 3.8 GPU-days for search. Our code has been made available at:\nhttps://github.com/yuhuixu1993/PC-DARTS."}, {"title": "Mirror-Generative Neural Machine Translation", "authors": "Zaixiang Zheng, Hao Zhou, Shujian Huang, Lei Li, Xin-Yu Dai, Jiajun Chen"}, {"title": "Training individually fair ML models with sensitive subspace robustness", "authors": "Mikhail Yurochkin, Amanda Bower, Yuekai Sun"}, {"title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "authors": "Hang Gao, Xizhou Zhu, Stephen Lin, Jifeng Dai", "link": "https://arxiv.org/abs/1910.02940", "summary": "Convolutional networks are not aware of an object's geometric variations,\nwhich leads to inefficient utilization of model and data capacity. To overcome\nthis issue, recent works on deformation modeling seek to spatially reconfigure\nthe data towards a common arrangement such that semantic recognition suffers\nless from deformation. This is typically done by augmenting static operators\nwith learned free-form sampling grids in the image space, dynamically tuned to\nthe data and task for adapting the receptive field. Yet adapting the receptive\nfield does not quite reach the actual goal -- what really matters to the\nnetwork is the \"effective\" receptive field (ERF), which reflects how much each\npixel contributes. It is thus natural to design other approaches to adapt the\nERF directly during runtime.\n  In this work, we instantiate one possible solution as Deformable Kernels\n(DKs), a family of novel and generic convolutional operators for handling\nobject deformations by directly adapting the ERF while leaving the receptive\nfield untouched. At the heart of our method is the ability to resample the\noriginal kernel space towards recovering the deformation of objects. This\napproach is justified with theoretical insights that the ERF is strictly\ndetermined by data sampling locations and kernel values. We implement DKs as\ngeneric drop-in replacements of rigid kernels and conduct a series of empirical\nstudies whose results conform with our theories. Over several tasks and\nstandard base models, our approach compares favorably against prior works that\nadapt during runtime. In addition, further experiments suggest a working\nmechanism orthogonal and complementary to previous works."}, {"title": "Reconstructing continuous distributions of 3D protein structure from cryo-EM images", "authors": "Ellen D. Zhong, Tristan Bepler, Joseph H. Davis, Bonnie Berger", "link": "https://arxiv.org/abs/1909.05215", "summary": "Cryo-electron microscopy (cryo-EM) is a powerful technique for determining\nthe structure of proteins and other macromolecular complexes at near-atomic\nresolution. In single particle cryo-EM, the central problem is to reconstruct\nthe three-dimensional structure of a macromolecule from $10^{4-7}$ noisy and\nrandomly oriented two-dimensional projections. However, the imaged protein\ncomplexes may exhibit structural variability, which complicates reconstruction\nand is typically addressed using discrete clustering approaches that fail to\ncapture the full range of protein dynamics. Here, we introduce a novel method\nfor cryo-EM reconstruction that extends naturally to modeling continuous\ngenerative factors of structural heterogeneity. This method encodes structures\nin Fourier space using coordinate-based deep neural networks, and trains these\nnetworks from unlabeled 2D cryo-EM images by combining exact inference over\nimage orientation with variational inference for structural heterogeneity. We\ndemonstrate that the proposed method, termed cryoDRGN, can perform ab initio\nreconstruction of 3D protein complexes from simulated and real 2D cryo-EM image\ndata. To our knowledge, cryoDRGN is the first neural network-based approach for\ncryo-EM reconstruction and the first end-to-end method for directly\nreconstructing continuous ensembles of protein structures from cryo-EM images."}, {"title": "A Target-Agnostic Attack on Deep Models: Exploiting Security Vulnerabilities of Transfer Learning", "authors": "Shahbaz Rezaei, Xin Liu", "link": "https://arxiv.org/abs/1904.04334", "summary": "Due to insufficient training data and the high computational cost to train a\ndeep neural network from scratch, transfer learning has been extensively used\nin many deep-neural-network-based applications. A commonly used transfer\nlearning approach involves taking a part of a pre-trained model, adding a few\nlayers at the end, and re-training the new layers with a small dataset. This\napproach, while efficient and widely used, imposes a security vulnerability\nbecause the pre-trained model used in transfer learning is usually publicly\navailable, including to potential attackers. In this paper, we show that\nwithout any additional knowledge other than the pre-trained model, an attacker\ncan launch an effective and efficient brute force attack that can craft\ninstances of input to trigger each target class with high confidence. We assume\nthat the attacker has no access to any target-specific information, including\nsamples from target classes, re-trained model, and probabilities assigned by\nSoftmax to each class, and thus making the attack target-agnostic. These\nassumptions render all previous attack models inapplicable, to the best of our\nknowledge. To evaluate the proposed attack, we perform a set of experiments on\nface recognition and speech recognition tasks and show the effectiveness of the\nattack. Our work reveals a fundamental security weakness of the Softmax layer\nwhen used in transfer learning settings."}, {"title": "Functional Regularisation for  Continual Learning with Gaussian Processes", "authors": "Michalis K. Titsias, Jonathan Schwarz, Alexander G. de G. Matthews, Razvan Pascanu, Yee Whye Teh", "link": "https://arxiv.org/abs/1901.11356", "summary": "We introduce a framework for Continual Learning (CL) based on Bayesian\ninference over the function space rather than the parameters of a deep neural\nnetwork. This method, referred to as functional regularisation for Continual\nLearning, avoids forgetting a previous task by constructing and memorising an\napproximate posterior belief over the underlying task-specific function. To\nachieve this we rely on a Gaussian process obtained by treating the weights of\nthe last layer of a neural network as random and Gaussian distributed. Then,\nthe training algorithm sequentially encounters tasks and constructs posterior\nbeliefs over the task-specific functions by using inducing point sparse\nGaussian process methods. At each step a new task is first learnt and then a\nsummary is constructed consisting of (i) inducing inputs -- a fixed-size subset\nof the task inputs selected such that it optimally represents the task -- and\n(ii) a posterior distribution over the function values at these inputs. This\nsummary then regularises learning of future tasks, through Kullback-Leibler\nregularisation terms. Our method thus unites approaches focused on\n(pseudo-)rehearsal with those derived from a sequential Bayesian inference\nperspective in a principled way, leading to strong results on accepted\nbenchmarks."}, {"title": "Minimizing FLOPs to Learn Efficient Sparse Representations", "authors": "Biswajit Paria, Chih-Kuan Yeh, Ian E.H. Yen, Ning Xu, Pradeep Ravikumar, Barnab\u00e1s P\u00f3czos"}, {"title": "Lagrangian Fluid Simulation with Continuous Convolutions", "authors": "Benjamin Ummenhofer, Lukas Prantl, Nils Thuerey, Vladlen Koltun"}, {"title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations", "authors": "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut", "link": "", "summary": ""}, {"title": "Estimating counterfactual treatment outcomes over time through adversarially balanced representations", "authors": "Ioana Bica, Ahmed M Alaa, James Jordon, Mihaela van der Schaar"}, {"title": "Graph inference learning for semi-supervised classification", "authors": "Chunyan Xu, Zhen Cui, Xiaobin Hong, Tong Zhang, Jian Yang, Wei Liu", "link": "https://arxiv.org/abs/2001.06137", "summary": "In this work, we address semi-supervised classification of graph data, where\nthe categories of those unlabeled nodes are inferred from labeled nodes as well\nas graph structures. Recent works often solve this problem via advanced graph\nconvolution in a conventionally supervised manner, but the performance could\ndegrade significantly when labeled data is scarce. To this end, we propose a\nGraph Inference Learning (GIL) framework to boost the performance of\nsemi-supervised node classification by learning the inference of node labels on\ngraph topology. To bridge the connection between two nodes, we formally define\na structure relation by encapsulating node attributes, between-node paths, and\nlocal topological structures together, which can make the inference\nconveniently deduced from one node to another node. For learning the inference\nprocess, we further introduce meta-optimization on structure relations from\ntraining nodes to validation nodes, such that the learnt graph inference\ncapability can be better self-adapted to testing nodes. Comprehensive\nevaluations on four benchmark datasets (including Cora, Citeseer, Pubmed, and\nNELL) demonstrate the superiority of our proposed GIL when compared against\nstate-of-the-art methods on the semi-supervised node classification task."}, {"title": "Learning To Explore Using Active Neural SLAM", "authors": "Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov"}, {"title": "Federated Learning with Matched Averaging", "authors": "Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, Yasaman Khazaeni", "link": "https://arxiv.org/abs/2002.06440", "summary": "Federated learning allows edge devices to collaboratively learn a shared\nmodel while keeping the training data on device, decoupling the ability to do\nmodel training from the need to store the data in the cloud. We propose\nFederated matched averaging (FedMA) algorithm designed for federated learning\nof modern neural network architectures e.g. convolutional neural networks\n(CNNs) and LSTMs. FedMA constructs the shared global model in a layer-wise\nmanner by matching and averaging hidden elements (i.e. channels for convolution\nlayers; hidden states for LSTM; neurons for fully connected layers) with\nsimilar feature extraction signatures. Our experiments indicate that FedMA not\nonly outperforms popular state-of-the-art federated learning algorithms on deep\nCNN and LSTM architectures trained on real world datasets, but also reduces the\noverall communication burden."}, {"title": "Learning The Difference That Makes A Difference With Counterfactually-Augmented Data", "authors": "Divyansh Kaushik, Eduard Hovy, Zachary Lipton", "link": "https://arxiv.org/abs/1909.12434", "summary": "Despite alarm over the reliance of machine learning systems on so-called\nspurious patterns, the term lacks coherent meaning in standard statistical\nframeworks. However, the language of causality offers clarity: spurious\nassociations are due to confounding (e.g., a common cause), but not direct or\nindirect causal effects. In this paper, we focus on natural language\nprocessing, introducing methods and resources for training models less\nsensitive to spurious patterns. Given documents and their initial labels, we\ntask humans with revising each document so that it (i) accords with a\ncounterfactual target label; (ii) retains internal coherence; and (iii) avoids\nunnecessary changes. Interestingly, on sentiment analysis and natural language\ninference tasks, classifiers trained on original data fail on their\ncounterfactually-revised counterparts and vice versa. Classifiers trained on\ncombined datasets perform remarkably well, just shy of those specialized to\neither domain. While classifiers trained on either original or manipulated data\nalone are sensitive to spurious features (e.g., mentions of genre), models\ntrained on the combined data are less sensitive to this signal. Both datasets\nare publicly available."}, {"title": "Conditional Learning of Fair Representations", "authors": "Han Zhao, Amanda Coston, Tameem Adel, Geoffrey J. Gordon", "link": "https://arxiv.org/abs/1910.07162", "summary": "We propose a novel algorithm for learning fair representations that can\nsimultaneously mitigate two notions of disparity among different demographic\nsubgroups in the classification setting. Two key components underpinning the\ndesign of our algorithm are balanced error rate and conditional alignment of\nrepresentations. We show how these two components contribute to ensuring\naccuracy parity and equalized false-positive and false-negative rates across\ngroups without impacting demographic parity. Furthermore, we also demonstrate\nboth in theory and on two real-world experiments that the proposed algorithm\nleads to a better utility-fairness trade-off on balanced datasets compared with\nexisting algorithms on learning fair representations for classification."}, {"title": "Mogrifier LSTM", "authors": "G\u00e1bor Melis, Tom\u00e1\u0161 Ko\u010disk\u00fd, Phil Blunsom", "link": "", "summary": ""}, {"title": "PCMC-Net: Feature-based Pairwise Choice Markov Chains", "authors": "Alix Lh\u00e9ritier", "link": "https://arxiv.org/abs/1909.11553", "summary": "Pairwise Choice Markov Chains (PCMC) have been recently introduced to\novercome limitations of choice models based on traditional axioms unable to\nexpress empirical observations from modern behavior economics like context\neffects occurring when a choice between two options is altered by adding a\nthird alternative. The inference approach that estimates the transition rates\nbetween each possible pair of alternatives via maximum likelihood suffers when\nthe examples of each alternative are scarce and is inappropriate when new\nalternatives can be observed at test time. In this work, we propose an\namortized inference approach for PCMC by embedding its definition into a neural\nnetwork that represents transition rates as a function of the alternatives' and\nindividual's features. We apply our construction to the complex case of airline\nitinerary booking where singletons are common (due to varying prices and\nindividual-specific itineraries), and context effects and behaviors strongly\ndependent on market segments are observed. Experiments show our network\nsignificantly outperforming, in terms of prediction accuracy and logarithmic\nloss, feature engineered standard and latent class Multinomial Logit models as\nwell as recent machine learning approaches."}, {"title": "Meta-Learning Acquisition Functions for Transfer Learning in Bayesian Optimization", "authors": "Michael Volpp, Lukas P. Fr\u00f6hlich, Kirsten Fischer, Andreas Doerr, Stefan Falkner, Frank Hutter, Christian Daniel", "link": "https://arxiv.org/abs/1904.02642", "summary": "Transferring knowledge across tasks to improve data-efficiency is one of the\nopen key challenges in the field of global black-box optimization. Readily\navailable algorithms are typically designed to be universal optimizers and,\ntherefore, often suboptimal for specific tasks. We propose a novel transfer\nlearning method to obtain customized optimizers within the well-established\nframework of Bayesian optimization, allowing our algorithm to utilize the\nproven generalization capabilities of Gaussian processes. Using reinforcement\nlearning to meta-train an acquisition function (AF) on a set of related tasks,\nthe proposed method learns to extract implicit structural information and to\nexploit it for improved data-efficiency. We present experiments on a\nsimulation-to-real transfer task as well as on several synthetic functions and\non two hyperparameter search problems. The results show that our algorithm (1)\nautomatically identifies structural properties of objective functions from\navailable source tasks or simulations, (2) performs favourably in settings with\nboth scarse and abundant source data, and (3) falls back to the performance\nlevel of general AFs if no particular structure is present."}, {"title": "DropEdge: Towards Deep Graph Convolutional Networks on Node Classification", "authors": "Yu Rong, Wenbing Huang, Tingyang Xu, Junzhou Huang"}, {"title": "Enhancing Transformation-Based Defenses Against Adversarial Attacks with a Distribution Classifier", "authors": "Connie Kou, Hwee Kuan Lee, Ee-Chien Chang, Teck Khim Ng"}, {"title": "Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information", "authors": "Yichi Zhou, Jialian Li, Jun Zhu"}, {"title": "Sparse Coding with Gated Learned ISTA", "authors": "Kailun Wu, Yiwen Guo, Ziang Li, Changshui Zhang"}, {"title": "To Relieve Your Headache of Training an MRF, Take AdVIL", "authors": "Chongxuan Li, Chao Du, Kun Xu, Max Welling, Jun Zhu, Bo Zhang", "link": "", "summary": ""}, {"title": "Bayesian Meta Sampling for Fast Uncertainty Adaptation", "authors": "Zhenyi Wang, Yang Zhao, Ping Yu, Ruiyi Zhang, Changyou Chen"}, {"title": "Strategies for Pre-training Graph Neural Networks", "authors": "Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec", "link": "https://arxiv.org/abs/1905.12265", "summary": "Many applications of machine learning require a model to make accurate\npre-dictions on test examples that are distributionally different from training\nones, while task-specific labels are scarce during training. An effective\napproach to this challenge is to pre-train a model on related tasks where data\nis abundant, and then fine-tune it on a downstream task of interest. While\npre-training has been effective in many language and vision domains, it remains\nan open question how to effectively use pre-training on graph datasets. In this\npaper, we develop a new strategy and self-supervised methods for pre-training\nGraph Neural Networks (GNNs). The key to the success of our strategy is to\npre-train an expressive GNN at the level of individual nodes as well as entire\ngraphs so that the GNN can learn useful local and global representations\nsimultaneously. We systematically study pre-training on multiple graph\nclassification datasets. We find that naive strategies, which pre-train GNNs at\nthe level of either entire graphs or individual nodes, give limited improvement\nand can even lead to negative transfer on many downstream tasks. In contrast,\nour strategy avoids negative transfer and improves generalization significantly\nacross downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC\nover non-pre-trained models and achieving state-of-the-art performance for\nmolecular property prediction and protein function prediction."}, {"title": "HiLLoC: lossless image compression with hierarchical latent variable models", "authors": "James Townsend, Thomas Bird, Julius Kunze, David Barber"}, {"title": "Learning to Link", "authors": "Maria-Florina Balcan, Travis Dick, Manuel Lang", "link": "https://arxiv.org/abs/1907.00533", "summary": "Clustering is an important part of many modern data analysis pipelines,\nincluding network analysis and data retrieval. There are many different\nclustering algorithms developed by various communities, and it is often not\nclear which algorithm will give the best performance on a specific clustering\ntask. Similarly, we often have multiple ways to measure distances between data\npoints, and the best clustering performance might require a non-trivial\ncombination of those metrics. In this work, we study data-driven algorithm\nselection and metric learning for clustering problems, where the goal is to\nsimultaneously learn the best algorithm and metric for a specific application.\nThe family of clustering algorithms we consider is parameterized linkage based\nprocedures that includes single and complete linkage. The family of distance\nfunctions we learn over are convex combinations of base distance functions. We\ndesign efficient learning algorithms which receive samples from an\napplication-specific distribution over clustering instances and simultaneously\nlearn both a near-optimal distance and clustering algorithm from these classes.\nWe also carry out a comprehensive empirical evaluation of our techniques\nshowing that they can lead to significantly improved clustering performance."}, {"title": "State-only Imitation with Transition Dynamics Mismatch", "authors": "Tanmay Gangwani, Jian Peng", "link": "http://arxiv.org/abs/2002.11879", "summary": "Imitation Learning (IL) is a popular paradigm for training agents to achieve\ncomplicated goals by leveraging expert behavior, rather than dealing with the\nhardships of designing a correct reward function. With the environment modeled\nas a Markov Decision Process (MDP), most of the existing IL algorithms are\ncontingent on the availability of expert demonstrations in the same MDP as the\none in which a new imitator policy is to be learned. This is uncharacteristic\nof many real-life scenarios where discrepancies between the expert and the\nimitator MDPs are common, especially in the transition dynamics function.\nFurthermore, obtaining expert actions may be costly or infeasible, making the\nrecent trend towards state-only IL (where expert demonstrations constitute only\nstates or observations) ever so promising. Building on recent adversarial\nimitation approaches that are motivated by the idea of divergence minimization,\nwe present a new state-only IL algorithm in this paper. It divides the overall\noptimization objective into two subproblems by introducing an indirection step\nand solves the subproblems iteratively. We show that our algorithm is\nparticularly effective when there is a transition dynamics mismatch between the\nexpert and imitator MDPs, while the baseline IL methods suffer from performance\ndegradation. To analyze this, we construct several interesting MDPs by\nmodifying the configuration parameters for the MuJoCo locomotion tasks from\nOpenAI Gym."}, {"title": "Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards", "authors": "Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari, Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn", "link": "https://arxiv.org/abs/1906.03352", "summary": "Imitation learning allows agents to learn complex behaviors from\ndemonstrations. However, learning a complex vision-based task may require an\nimpractical number of demonstrations. Meta-imitation learning is a promising\napproach towards enabling agents to learn a new task from one or a few\ndemonstrations by leveraging experience from learning similar tasks. In the\npresence of task ambiguity or unobserved dynamics, demonstrations alone may not\nprovide enough information; an agent must also try the task to successfully\ninfer a policy. In this work, we propose a method that can learn to learn from\nboth demonstrations and trial-and-error experience with sparse reward feedback.\nIn comparison to meta-imitation, this approach enables the agent to effectively\nand efficiently improve itself autonomously beyond the demonstration data. In\ncomparison to meta-reinforcement learning, we can scale to substantially\nbroader distributions of tasks, as the demonstration reduces the burden of\nexploration. Our experiments show that our method significantly outperforms\nprior approaches on a set of challenging, vision-based control tasks."}, {"title": "Model-Augmented Actor-Critic: Backpropagating through Paths", "authors": "Ignasi Clavera, Yao Fu, Pieter Abbeel"}, {"title": "Variance Reduction With Sparse Gradients", "authors": "Melih Elibol, Lihua Lei, Michael I. Jordan", "link": "https://arxiv.org/abs/2001.09623", "summary": "Variance reduction methods such as SVRG and SpiderBoost use a mixture of\nlarge and small batch gradients to reduce the variance of stochastic gradients.\nCompared to SGD, these methods require at least double the number of operations\nper update to model parameters. To reduce the computational cost of these\nmethods, we introduce a new sparsity operator: The random-top-k operator. Our\noperator reduces computational complexity by estimating gradient sparsity\nexhibited in a variety of applications by combining the top-k operator and the\nrandomized coordinate descent operator. With this operator, large batch\ngradients offer an extra benefit beyond variance reduction: A reliable estimate\nof gradient sparsity. Theoretically, our algorithm is at least as good as the\nbest algorithm (SpiderBoost), and further excels in performance whenever the\nrandom-top-k operator captures gradient sparsity. Empirically, our algorithm\nconsistently outperforms SpiderBoost using various models on various tasks\nincluding image classification, natural language processing, and sparse matrix\nfactorization. We also provide empirical evidence to support the intuition\nbehind our algorithm via a simple gradient entropy computation, which serves to\nquantify gradient sparsity at every iteration."}, {"title": "Understanding l4-based Dictionary Learning: Interpretation, Stability, and Robustness", "authors": "Yuexiang Zhai, Hermish Mehta, Zhengyuan Zhou, Yi Ma"}, {"title": "Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets", "authors": "Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma", "link": "https://arxiv.org/abs/2002.05990", "summary": "Skip connections are an essential component of current state-of-the-art deep\nneural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt.\nDespite their huge success in building deeper and more powerful DNNs, we\nidentify a surprising security weakness of skip connections in this paper. Use\nof skip connections allows easier generation of highly transferable adversarial\nexamples. Specifically, in ResNet-like (with skip connections) neural networks,\ngradients can backpropagate through either skip connections or residual\nmodules. We find that using more gradients from the skip connections rather\nthan the residual modules according to a decay factor, allows one to craft\nadversarial examples with high transferability. Our method is termed Skip\nGradient Method(SGM). We conduct comprehensive transfer attacks against\nstate-of-the-art DNNs including ResNets, DenseNets, Inceptions,\nInception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained\nDNNs. We show that employing SGM on the gradient flow can greatly improve the\ntransferability of crafted attacks in almost all cases. Furthermore, SGM can be\neasily combined with existing black-box attack techniques, and obtain high\nimprovements over state-of-the-art transferability methods. Our findings not\nonly motivate new research into the architectural vulnerability of DNNs, but\nalso open up further challenges for the design of secure DNN architectures."}, {"title": "MMA Training: Direct Input Space Margin Maximization through Adversarial Training", "authors": "Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, Ruitong Huang", "link": "https://arxiv.org/abs/1812.02637", "summary": "We study adversarial robustness of neural networks from a margin maximization\nperspective, where margins are defined as the distances from inputs to a\nclassifier's decision boundary. Our study shows that maximizing margins can be\nachieved by minimizing the adversarial loss on the decision boundary at the\n\"shortest successful perturbation\", demonstrating a close connection between\nadversarial losses and the margins. We propose Max-Margin Adversarial (MMA)\ntraining to directly maximize the margins to achieve adversarial robustness.\nInstead of adversarial training with a fixed $\\epsilon$, MMA offers an\nimprovement by enabling adaptive selection of the \"correct\" $\\epsilon$ as the\nmargin individually for each datapoint. In addition, we rigorously analyze\nadversarial training with the perspective of margin maximization, and provide\nan alternative interpretation for adversarial training, maximizing either a\nlower or an upper bound of the margins. Our experiments empirically confirm our\ntheory and demonstrate MMA training's efficacy on the MNIST and CIFAR10\ndatasets w.r.t. $\\ell_\\infty$ and $\\ell_2$ robustness. Code and models are\navailable at https://github.com/BorealisAI/mma_training."}, {"title": "Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers", "authors": "Junjie LIU, Zhe XU, Runbin SHI, Ray C. C. Cheung, Hayden K.H. So"}, {"title": "Automatically Discovering and Learning New Visual Categories with Ranking Statistics", "authors": "Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, Andrea Vedaldi, Andrew Zisserman"}, {"title": "Learning representations for binary-classification without backpropagation", "authors": "Mathias Lechner"}, {"title": "Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning", "authors": "Kimin Lee, Kibok Lee, Jinwoo Shin, Honglak Lee", "link": "https://arxiv.org/abs/1910.05396", "summary": "Deep reinforcement learning (RL) agents often fail to generalize to unseen\nenvironments (yet semantically similar to trained agents), particularly when\nthey are trained on high-dimensional state spaces, such as images. In this\npaper, we propose a simple technique to improve a generalization ability of\ndeep RL agents by introducing a randomized (convolutional) neural network that\nrandomly perturbs input observations. It enables trained agents to adapt to new\ndomains by learning robust features invariant across varied and randomized\nenvironments. Furthermore, we consider an inference method based on the Monte\nCarlo approximation to reduce the variance induced by this randomization. We\ndemonstrate the superiority of our method across 2D CoinRun, 3D DeepMind Lab\nexploration and 3D robotics control tasks: it significantly outperforms various\nregularization and data augmentation methods for the same purpose."}, {"title": "Neural Epitome Search for Architecture-Agnostic Network Compression", "authors": "Daquan Zhou, Xiaojie Jin, Qibin Hou, Kaixin Wang, Jianchao Yang, Jiashi Feng"}, {"title": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting", "authors": "Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio", "link": "https://arxiv.org/abs/1905.10437", "summary": "We focus on solving the univariate times series point forecasting problem\nusing deep learning. We propose a deep neural architecture based on backward\nand forward residual links and a very deep stack of fully-connected layers. The\narchitecture has a number of desirable properties, being interpretable,\napplicable without modification to a wide array of target domains, and fast to\ntrain. We test the proposed architecture on several well-known datasets,\nincluding M3, M4 and TOURISM competition datasets containing time series from\ndiverse domains. We demonstrate state-of-the-art performance for two\nconfigurations of N-BEATS for all the datasets, improving forecast accuracy by\n11% over a statistical benchmark and by 3% over last year's winner of the M4\ncompetition, a domain-adjusted hand-crafted hybrid between neural network and\nstatistical time series models. The first configuration of our model does not\nemploy any time-series-specific components and its performance on heterogeneous\ndatasets strongly suggests that, contrarily to received wisdom, deep learning\nprimitives such as residual blocks are by themselves sufficient to solve a wide\nrange of forecasting problems. Finally, we demonstrate how the proposed\narchitecture can be augmented to provide outputs that are interpretable without\nconsiderable loss in accuracy."}, {"title": "Generalization bounds for deep convolutional neural networks", "authors": "Philip M. Long, Hanie Sedghi", "link": "https://arxiv.org/abs/1905.12600", "summary": "We prove bounds on the generalization error of convolutional networks. The\nbounds are in terms of the training loss, the number of parameters, the\nLipschitz constant of the loss and the distance from the weights to the initial\nweights. They are independent of the number of pixels in the input, and the\nheight and width of hidden feature maps. We present experiments using CIFAR-10\nwith varying hyperparameters of a deep convolutional network, comparing our\nbounds with practical generalization gaps."}, {"title": "Rethinking the Hyperparameters for Fine-tuning", "authors": "Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto"}, {"title": "Decentralized Deep Learning with Arbitrary Communication Compression", "authors": "Anastasia Koloskova, Tao Lin, Sebastian U Stich, Martin Jaggi", "link": "https://arxiv.org/abs/1907.09356", "summary": "Decentralized training of deep learning models is a key element for enabling\ndata privacy and on-device learning over networks, as well as for efficient\nscaling to large compute clusters. As current approaches suffer from limited\nbandwidth of the network, we propose the use of communication compression in\nthe decentralized training context. We show that Choco-SGD $-$ recently\nintroduced and analyzed for strongly-convex objectives only $-$ converges under\narbitrary high compression ratio on general non-convex functions at the rate\n$O\\bigl(1/\\sqrt{nT}\\bigr)$ where $T$ denotes the number of iterations and $n$\nthe number of workers. The algorithm achieves linear speedup in the number of\nworkers and supports higher compression than previous state-of-the art methods.\nWe demonstrate the practical performance of the algorithm in two key scenarios:\nthe training of deep learning models (i) over distributed user devices,\nconnected by a social network and (ii) in a datacenter (outperforming\nall-reduce time-wise)."}, {"title": "Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness", "authors": "Tianyu Pang, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu", "link": "https://arxiv.org/abs/1905.10626", "summary": "Previous work shows that adversarially robust generalization requires larger\nsample complexity, and the same dataset, e.g., CIFAR-10, which enables good\nstandard accuracy may not suffice to train robust models. Since collecting new\ntraining data could be costly, we focus on better utilizing the given data by\ninducing the regions with high sample density in the feature space, which could\nlead to locally sufficient samples for robust learning. We first formally show\nthat the softmax cross-entropy (SCE) loss and its variants convey inappropriate\nsupervisory signals, which encourage the learned feature points to spread over\nthe space sparsely in training. This inspires us to propose the Max-Mahalanobis\ncenter (MMC) loss to explicitly induce dense feature regions in order to\nbenefit robustness. Namely, the MMC loss encourages the model to concentrate on\nlearning ordered and compact representations, which gather around the preset\noptimal centers for different classes. We empirically demonstrate that applying\nthe MMC loss can significantly improve robustness even under strong adaptive\nattacks, while keeping state-of-the-art accuracy on clean inputs with little\nextra computation compared to the SCE loss."}, {"title": "Permutation Equivariant Models for Compositional Generalization in Language", "authors": "Jonathan Gordon, David Lopez-Paz, Marco Baroni, Diane Bouchacourt"}, {"title": "Poly-encoders: Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring", "authors": "Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston", "link": "https://arxiv.org/abs/1905.01969", "summary": "The use of deep pre-trained bidirectional transformers has led to remarkable\nprogress in a number of applications (Devlin et al., 2018). For tasks that make\npairwise comparisons between sequences, matching a given input with a\ncorresponding label, two approaches are common: Cross-encoders performing full\nself-attention over the pair and Bi-encoders encoding the pair separately. The\nformer often performs better, but is too slow for practical use. In this work,\nwe develop a new transformer architecture, the Poly-encoder, that learns global\nrather than token level self-attention features. We perform a detailed\ncomparison of all three approaches, including what pre-training and fine-tuning\nstrategies work best. We show our models achieve state-of-the-art results on\nthree existing tasks; that Poly-encoders are faster than Cross-encoders and\nmore accurate than Bi-encoders; and that the best results are obtained by\npre-training on large datasets similar to the downstream tasks."}, {"title": "How much Position Information Do Convolutional Neural Networks Encode?", "authors": "Md Amirul Islam, Sen Jia, Neil D. B. Bruce", "link": "http://arxiv.org/abs/2001.08248", "summary": "In contrast to fully connected networks, Convolutional Neural Networks (CNNs)\nachieve efficiency by learning weights associated with local filters with a\nfinite spatial extent. An implication of this is that a filter may know what it\nis looking at, but not where it is positioned in the image. Information\nconcerning absolute position is inherently useful, and it is reasonable to\nassume that deep CNNs may implicitly learn to encode this information if there\nis a means to do so. In this paper, we test this hypothesis revealing the\nsurprising degree of absolute position information that is encoded in commonly\nused neural networks. A comprehensive set of experiments show the validity of\nthis hypothesis and shed light on how and where this information is represented\nwhile offering clues to where positional information is derived from in deep\nCNNs."}, {"title": "Jelly Bean World: A Testbed for Never-Ending Learning", "authors": "Emmanouil Antonios Platanios, Abulhair Saparov, Tom Mitchell", "link": "https://arxiv.org/abs/2002.06306", "summary": "Machine learning has shown growing success in recent years. However, current\nmachine learning systems are highly specialized, trained for particular\nproblems or domains, and typically on a single narrow dataset. Human learning,\non the other hand, is highly general and adaptable. Never-ending learning is a\nmachine learning paradigm that aims to bridge this gap, with the goal of\nencouraging researchers to design machine learning systems that can learn to\nperform a wider variety of inter-related tasks in more complex environments. To\ndate, there is no environment or testbed to facilitate the development and\nevaluation of never-ending learning systems. To this end, we propose the Jelly\nBean World testbed. The Jelly Bean World allows experimentation over\ntwo-dimensional grid worlds which are filled with items and in which agents can\nnavigate. This testbed provides environments that are sufficiently complex and\nwhere more generally intelligent algorithms ought to perform better than\ncurrent state-of-the-art reinforcement learning approaches. It does so by\nproducing non-stationary environments and facilitating experimentation with\nmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hope\nthat this new freely-available software will prompt new research and interest\nin the development and evaluation of never-ending learning systems and more\nbroadly, general intelligence systems."}, {"title": "Lite Transformer with Long-Short Range Attention", "authors": "Zhanghao Wu, Zhijian Liu, Ji Lin, Yujun Lin, Song Han", "link": "https://arxiv.org/abs/2004.11886", "summary": "Transformer has become ubiquitous in natural language processing (e.g.,\nmachine translation, question answering); however, it requires enormous amount\nof computations to achieve high performance, which makes it not suitable for\nmobile applications that are tightly constrained by the hardware resources and\nbattery. In this paper, we present an efficient mobile NLP architecture, Lite\nTransformer to facilitate deploying mobile NLP applications on edge devices.\nThe key primitive is the Long-Short Range Attention (LSRA), where one group of\nheads specializes in the local context modeling (by convolution) while another\ngroup specializes in the long-distance relationship modeling (by attention).\nSuch specialization brings consistent improvement over the vanilla transformer\non three well-established language tasks: machine translation, abstractive\nsummarization, and language modeling. Under constrained resources (500M/100M\nMACs), Lite Transformer outperforms transformer on WMT'14 English-French by\n1.2/1.7 BLEU, respectively. Lite Transformer reduces the computation of\ntransformer base model by 2.5x with 0.3 BLEU score degradation. Combining with\npruning and quantization, we further compressed the model size of Lite\nTransformer by 18.2x. For language modeling, Lite Transformer achieves 1.8\nlower perplexity than the transformer at around 500M MACs. Notably, Lite\nTransformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU\nfor the mobile NLP setting without the costly architecture search that requires\nmore than 250 GPU years. Code has been made available at\nhttps://github.com/mit-han-lab/lite-transformer."}, {"title": "Provable robustness against all adversarial $l_p$-perturbations for $p\\geq 1$", "authors": "Francesco Croce, Matthias Hein", "link": "https://arxiv.org/abs/1905.11213", "summary": "In recent years several adversarial attacks and defenses have been proposed.\nOften seemingly robust models turn out to be non-robust when more sophisticated\nattacks are used. One way out of this dilemma are provable robustness\nguarantees. While provably robust models for specific $l_p$-perturbation models\nhave been developed, we show that they do not come with any guarantee against\nother $l_q$-perturbations. We propose a new regularization scheme,\nMMR-Universal, for ReLU networks which enforces robustness wrt $l_1$- and\n$l_\\infty$-perturbations and show how that leads to the first provably robust\nmodels wrt any $l_p$-norm for $p\\geq 1$."}, {"title": "Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform", "authors": "Jun Li, Fuxin Li, Sinisa Todorovic", "link": "https://arxiv.org/abs/2002.01113", "summary": "Strictly enforcing orthonormality constraints on parameter matrices has been\nshown advantageous in deep learning. This amounts to Riemannian optimization on\nthe Stiefel manifold, which, however, is computationally expensive. To address\nthis challenge, we present two main contributions: (1) A new efficient\nretraction map based on an iterative Cayley transform for optimization updates,\nand (2) An implicit vector transport mechanism based on the combination of a\nprojection of the momentum and the Cayley transform on the Stiefel manifold. We\nspecify two new optimization algorithms: Cayley SGD with momentum, and Cayley\nADAM on the Stiefel manifold. Convergence of Cayley SGD is theoretically\nanalyzed. Our experiments for CNN training demonstrate that both algorithms:\n(a) Use less running time per iteration relative to existing approaches that\nenforce orthonormality of CNN parameters; and (b) Achieve faster convergence\nrates than the baseline SGD and ADAM algorithms without compromising the\nperformance of the CNN. Cayley SGD and Cayley ADAM are also shown to reduce the\ntraining time for optimizing the unitary transition matrices in RNNs."}, {"title": "How to 0wn the NAS in Your Spare Time", "authors": "Sanghyun Hong, Michael Davinroy, Yi\u01e7itcan Kaya, Dana Dachman-Soled, Tudor Dumitra\u015f"}, {"title": "Short and Sparse Deconvolution --- A Geometric Approach", "authors": "Yenson Lau, Qing Qu, Han-Wen Kuo, Pengcheng Zhou, Yuqian Zhang, John Wright", "link": "https://arxiv.org/abs/1908.10959", "summary": "Short-and-sparse deconvolution (SaSD) is the problem of extracting localized,\nrecurring motifs in signals with spatial or temporal structure. Variants of\nthis problem arise in applications such as image deblurring, microscopy, neural\nspike sorting, and more. The problem is challenging in both theory and\npractice, as natural optimization formulations are nonconvex. Moreover,\npractical deconvolution problems involve smooth motifs (kernels) whose spectra\ndecay rapidly, resulting in poor conditioning and numerical challenges. This\npaper is motivated by recent theoretical advances, which characterize the\noptimization landscape of a particular nonconvex formulation of SaSD. This is\nused to derive a $provable$ algorithm which exactly solves certain\nnon-practical instances of the SaSD problem. We leverage the key ideas from\nthis theory (sphere constraints, data-driven initialization) to develop a\n$practical$ algorithm, which performs well on data arising from a range of\napplication areas. We highlight key additional challenges posed by the\nill-conditioning of real SaSD problems, and suggest heuristics (acceleration,\ncontinuation, reweighting) to mitigate them. Experiments demonstrate both the\nperformance and generality of the proposed method."}, {"title": "SVQN: Sequential Variational Soft Q-Learning Networks", "authors": "Shiyu Huang, Hang Su, Jun Zhu, Ting Chen"}, {"title": "ProxSGD: Training Structured Neural Networks under Regularization and Constraints", "authors": "Yang Yang, Yaxiong Yuan, Avraam Chatzimichailidis, Ruud JG van Sloun, Lei Lei, Symeon Chatzinotas"}, {"title": "Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach", "authors": "Kimon Antonakopoulos, E. Veronica Belmega, Panayotis Mertikopoulos"}, {"title": "A critical analysis of self-supervision, or what we can learn from a single image", "authors": "Asano YM., Rupprecht C., Vedaldi A.", "link": "https://arxiv.org/abs/1904.13132", "summary": "We look critically at popular self-supervision techniques for learning deep\nconvolutional neural networks without manual labels. We show that three\ndifferent and representative methods, BiGAN, RotNet and DeepCluster, can learn\nthe first few layers of a convolutional network from a single image as well as\nusing millions of images and manual labels, provided that strong data\naugmentation is used. However, for deeper layers the gap with manual\nsupervision cannot be closed even if millions of unlabelled images are used for\ntraining. We conclude that: (1) the weights of the early layers of deep\nnetworks contain limited information about the statistics of natural images,\nthat (2) such low-level statistics can be learned through self-supervision just\nas well as through strong supervision, and that (3) the low-level statistics\ncan be captured via synthetic transformations instead of using a large image\ndataset."}, {"title": "Augmenting Genetic Algorithms with Deep Neural Networks for Exploring the Chemical Space", "authors": "AkshatKumar Nigam, Pascal Friederich, Mario Krenn, Alan Aspuru-Guzik", "link": "https://arxiv.org/abs/1909.11655", "summary": "Challenges in natural sciences can often be phrased as optimization problems.\nMachine learning techniques have recently been applied to solve such problems.\nOne example in chemistry is the design of tailor-made organic materials and\nmolecules, which requires efficient methods to explore the chemical space. We\npresent a genetic algorithm (GA) that is enhanced with a neural network (DNN)\nbased discriminator model to improve the diversity of generated molecules and\nat the same time steer the GA. We show that our algorithm outperforms other\ngenerative models in optimization tasks. We furthermore present a way to\nincrease interpretability of genetic algorithms, which helped us to derive\ndesign principles."}, {"title": "Neural Arithmetic Units", "authors": "Andreas Madsen, Alexander Rosenberg Johansen", "link": "https://arxiv.org/abs/2001.05016", "summary": "Neural networks can approximate complex functions, but they struggle to\nperform exact arithmetic operations over real numbers. The lack of inductive\nbias for arithmetic operations leaves neural networks without the underlying\nlogic necessary to extrapolate on tasks such as addition, subtraction, and\nmultiplication. We present two new neural network components: the Neural\nAddition Unit (NAU), which can learn exact addition and subtraction; and the\nNeural Multiplication Unit (NMU) that can multiply subsets of a vector. The NMU\nis, to our knowledge, the first arithmetic neural network component that can\nlearn to multiply elements from a vector, when the hidden size is large. The\ntwo new components draw inspiration from a theoretical analysis of recently\nproposed arithmetic components. We find that careful initialization,\nrestricting parameter space, and regularizing for sparsity is important when\noptimizing the NAU and NMU. Our proposed units NAU and NMU, compared with\nprevious neural units, converge more consistently, have fewer parameters, learn\nfaster, can converge for larger hidden sizes, obtain sparse and meaningful\nweights, and can extrapolate to negative and small values."}, {"title": "DeepSphere: a graph-based spherical CNN", "authors": "Micha\u00ebl Defferrard, Martino Milani, Fr\u00e9d\u00e9rick Gusset, Nathana\u00ebl Perraudin"}, {"title": "Vid2Game: Controllable Characters Extracted from Real-World Videos", "authors": "Oran Gafni, Lior Wolf, Yaniv Taigman", "link": "https://arxiv.org/abs/1904.08379", "summary": "We are given a video of a person performing a certain activity, from which we\nextract a controllable model. The model generates novel image sequences of that\nperson, according to arbitrary user-defined control signals, typically marking\nthe displacement of the moving body. The generated video can have an arbitrary\nbackground, and effectively capture both the dynamics and appearance of the\nperson.\n  The method is based on two networks. The first network maps a current pose,\nand a single-instance control signal to the next pose. The second network maps\nthe current pose, the new pose, and a given background, to an output frame.\nBoth networks include multiple novelties that enable high-quality performance.\nThis is demonstrated on multiple characters extracted from various videos of\ndancers and athletes."}, {"title": "Piecewise linear activations substantially shape the loss surfaces of neural networks", "authors": "Fengxiang He, Bohan Wang, Dacheng Tao"}, {"title": "SELF: Learning to Filter Noisy Labels with Self-Ensembling", "authors": "Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi Phuong Nhung Ngo, Thi Hoai Phuong Nguyen, Laura Beggel, Thomas Brox", "link": "https://arxiv.org/abs/1910.01842", "summary": "Deep neural networks (DNNs) have been shown to over-fit a dataset when being\ntrained with noisy labels for a long enough time. To overcome this problem, we\npresent a simple and effective method self-ensemble label filtering (SELF) to\nprogressively filter out the wrong labels during training. Our method improves\nthe task performance by gradually allowing supervision only from the\npotentially non-noisy (clean) labels and stops learning on the filtered noisy\nlabels. For the filtering, we form running averages of predictions over the\nentire training dataset using the network output at different training epochs.\nWe show that these ensemble estimates yield more accurate identification of\ninconsistent predictions throughout training than the single estimates of the\nnetwork at the most recent training epoch. While filtered samples are removed\nentirely from the supervised training loss, we dynamically leverage them via\nsemi-supervised learning in the unsupervised loss. We demonstrate the positive\neffect of such an approach on various image classification tasks under both\nsymmetric and asymmetric label noise and at different noise ratios. It\nsubstantially outperforms all previous works on noise-aware learning across\ndifferent datasets and can be applied to a broad set of network architectures."}, {"title": "Weakly Supervised Clustering by Exploiting Unique Class Count", "authors": "Mustafa Umit Oner, Hwee Kuan Lee, Wing-Kin Sung", "link": "https://arxiv.org/abs/1906.07647", "summary": "A weakly supervised learning based clustering framework is proposed in this\npaper. As the core of this framework, we introduce a novel multiple instance\nlearning task based on a bag level label called unique class count ($ucc$),\nwhich is the number of unique classes among all instances inside the bag. In\nthis task, no annotations on individual instances inside the bag are needed\nduring training of the models. We mathematically prove that with a perfect\n$ucc$ classifier, perfect clustering of individual instances inside the bags is\npossible even when no annotations on individual instances are given during\ntraining. We have constructed a neural network based $ucc$ classifier and\nexperimentally shown that the clustering performance of our framework with our\nweakly supervised $ucc$ classifier is comparable to that of fully supervised\nlearning models where labels for all instances are known. Furthermore, we have\ntested the applicability of our framework to a real world task of semantic\nsegmentation of breast cancer metastases in histological lymph node sections\nand shown that the performance of our weakly supervised framework is comparable\nto the performance of a fully supervised Unet model."}, {"title": "Differentiation of Blackbox Combinatorial Solvers", "authors": "Marin Vlastelica Pogan\u010di\u0107, Anselm Paulus, Vit Musil, Georg Martius, Michal Rolinek", "link": "https://arxiv.org/abs/1912.02175", "summary": "Achieving fusion of deep learning with combinatorial algorithms promises\ntransformative changes to artificial intelligence. One possible approach is to\nintroduce combinatorial building blocks into neural networks. Such end-to-end\narchitectures have the potential to tackle combinatorial problems on raw input\ndata such as ensuring global consistency in multi-object tracking or route\nplanning on maps in robotics. In this work, we present a method that implements\nan efficient backward pass through blackbox implementations of combinatorial\nsolvers with linear objective functions. We provide both theoretical and\nexperimental backing. In particular, we incorporate the Gurobi MIP solver,\nBlossom V algorithm, and Dijkstra's algorithm into architectures that extract\nsuitable features from raw inputs for the traveling salesman problem, the\nmin-cost perfect matching problem and the shortest path problem. The code is\navailable at https://github.com/martius-lab/blackbox-backprop."}, {"title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations", "authors": "Martin Engelcke, Adam R. Kosiorek, Oiwi Parker Jones, Ingmar Posner", "link": "https://arxiv.org/abs/1907.13052", "summary": "Generative latent-variable models are emerging as promising tools in robotics\nand reinforcement learning. Yet, even though tasks in these domains typically\ninvolve distinct objects, most state-of-the-art generative models do not\nexplicitly capture the compositional nature of visual scenes. Two recent\nexceptions, MONet and IODINE, decompose scenes into objects in an unsupervised\nfashion. Their underlying generative processes, however, do not account for\ncomponent interactions. Hence, neither of them allows for principled sampling\nof novel scenes. Here we present GENESIS, the first object-centric generative\nmodel of 3D visual scenes capable of both decomposing and generating scenes by\ncapturing relationships between scene components. GENESIS parameterises a\nspatial GMM over images which is decoded from a set of object-centric latent\nvariables that are either inferred sequentially in an amortised fashion or\nsampled from an autoregressive prior. We train GENESIS on several publicly\navailable datasets and evaluate its performance on scene generation,\ndecomposition, and semi-supervised learning."}, {"title": "Exploring Model-based Planning with Policy Networks", "authors": "Tingwu Wang, Jimmy Ba", "link": "https://arxiv.org/abs/1906.08649", "summary": "Model-based reinforcement learning (MBRL) with model-predictive control or\nonline planning has shown great potential for locomotion control tasks in terms\nof both sample efficiency and asymptotic performance. Despite their initial\nsuccesses, the existing planning methods search from candidate sequences\nrandomly generated in the action space, which is inefficient in complex\nhigh-dimensional environments. In this paper, we propose a novel MBRL\nalgorithm, model-based policy planning (POPLIN), that combines policy networks\nwith online planning. More specifically, we formulate action planning at each\ntime-step as an optimization problem using neural networks. We experiment with\nboth optimization w.r.t. the action sequences initialized from the policy\nnetwork, and also online optimization directly w.r.t. the parameters of the\npolicy network. We show that POPLIN obtains state-of-the-art performance in the\nMuJoCo benchmarking environments, being about 3x more sample efficient than the\nstate-of-the-art algorithms, such as PETS, TD3 and SAC. To explain the\neffectiveness of our algorithm, we show that the optimization surface in\nparameter space is smoother than in action space. Further more, we found the\ndistilled policy network can be effectively applied without the expansive model\npredictive control during test time for some environments such as Cheetah. Code\nis released in https://github.com/WilsonWangTHU/POPLIN."}, {"title": "Graph Convolutional Reinforcement Learning", "authors": "Jiechuan Jiang, Chen Dun, Tiejun Huang, Zongqing Lu"}, {"title": "Rotation-invariant clustering of neuronal responses in primary visual cortex", "authors": "Ivan Ustyuzhaninov, Santiago A. Cadena, Emmanouil Froudarakis, Paul G. Fahey, Edgar Y. Walker, Erick Cobos, Jacob Reimer, Fabian H. Sinz, Andreas S. Tolias, Matthias Bethge, Alexander S. Ecker"}, {"title": "Regularizing activations in neural networks via distribution matching with the Wasserstein metric", "authors": "Taejong Joo, Donggu Kang, Byunghoon Kim"}, {"title": "Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP", "authors": "Haonan Yu, Sergey Edunov, Yuandong Tian, Ari S. Morcos", "link": "https://arxiv.org/abs/1906.02768", "summary": "The lottery ticket hypothesis proposes that over-parameterization of deep\nneural networks (DNNs) aids training by increasing the probability of a \"lucky\"\nsub-network initialization being present rather than by helping the\noptimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon\nsuggests that initialization strategies for DNNs can be improved substantially,\nbut the lottery ticket hypothesis has only previously been tested in the\ncontext of supervised learning for natural image tasks. Here, we evaluate\nwhether \"winning ticket\" initializations exist in two different domains:\nnatural language processing (NLP) and reinforcement learning (RL).For NLP, we\nexamined both recurrent LSTM models and large-scale Transformer models (Vaswani\net al., 2017). For RL, we analyzed a number of discrete-action space tasks,\nincluding both classic control and pixel control. Consistent with workin\nsupervised image classification, we confirm that winning ticket initializations\ngenerally outperform parameter-matched random initializations, even at extreme\npruning rates for both NLP and RL. Notably, we are able to find winning ticket\ninitializations for Transformers which enable models one-third the size to\nachieve nearly equivalent performance. Together, these results suggest that the\nlottery ticket hypothesis is not restricted to supervised learning of natural\nimages, but rather represents a broader phenomenon in DNNs."}, {"title": "On Bonus Based Exploration Methods In The Arcade Learning Environment", "authors": "Adrien Ali Taiga, William Fedus, Marlos C. Machado, Aaron Courville, Marc G. Bellemare"}, {"title": "Reformer: The Efficient Transformer", "authors": "Nikita Kitaev, Lukasz Kaiser, Anselm Levskaya", "link": "https://arxiv.org/abs/2001.04451", "summary": "Large Transformer models routinely achieve state-of-the-art results on a\nnumber of tasks but training these models can be prohibitively costly,\nespecially on long sequences. We introduce two techniques to improve the\nefficiency of Transformers. For one, we replace dot-product attention by one\nthat uses locality-sensitive hashing, changing its complexity from O($L^2$) to\nO($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use\nreversible residual layers instead of the standard residuals, which allows\nstoring activations only once in the training process instead of $N$ times,\nwhere $N$ is the number of layers. The resulting model, the Reformer, performs\non par with Transformer models while being much more memory-efficient and much\nfaster on long sequences."}, {"title": "Sign Bits Are All You Need for Black-Box Attacks", "authors": "Abdullah Al-Dujaili, Una-May O'Reilly"}, {"title": "Gradient-Based Neural DAG Learning", "authors": "S\u00e9bastien Lachapelle, Philippe Brouillard, Tristan Deleu, Simon Lacoste-Julien", "link": "", "summary": ""}, {"title": "Don't Use Large Mini-batches, Use Local SGD", "authors": "Tao Lin, Sebastian U. Stich, Kumar Kshitij Patel, Martin Jaggi", "link": "", "summary": ""}, {"title": "Deep neuroethology of a virtual rodent", "authors": "Josh Merel, Diego Aldarondo, Jesse Marshall, Yuval Tassa, Greg Wayne, Bence Olveczky", "link": "https://arxiv.org/abs/1911.09451", "summary": "Parallel developments in neuroscience and deep learning have led to mutually\nproductive exchanges, pushing our understanding of real and artificial neural\nnetworks in sensory and cognitive systems. However, this interaction between\nfields is less developed in the study of motor control. In this work, we\ndevelop a virtual rodent as a platform for the grounded study of motor activity\nin artificial models of embodied control. We then use this platform to study\nmotor activity across contexts by training a model to solve four complex tasks.\nUsing methods familiar to neuroscientists, we describe the behavioral\nrepresentations and algorithms employed by different layers of the network\nusing a neuroethological approach to characterize motor activity relative to\nthe rodent's behavior and goals. We find that the model uses two classes of\nrepresentations which respectively encode the task-specific behavioral\nstrategies and task-invariant behavioral kinematics. These representations are\nreflected in the sequential activity and population dynamics of neural\nsubpopulations. Overall, the virtual rodent facilitates grounded collaborations\nbetween deep reinforcement learning and motor neuroscience."}, {"title": "Geom-GCN: Geometric Graph Convolutional Networks", "authors": "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang", "link": "https://arxiv.org/abs/2002.05287", "summary": "Message-passing neural networks (MPNNs) have been successfully applied to\nrepresentation learning on graphs in a variety of real-world applications.\nHowever, two fundamental weaknesses of MPNNs' aggregators limit their ability\nto represent graph-structured data: losing the structural information of nodes\nin neighborhoods and lacking the ability to capture long-range dependencies in\ndisassortative graphs. Few studies have noticed the weaknesses from different\nperspectives. From the observations on classical neural network and network\ngeometry, we propose a novel geometric aggregation scheme for graph neural\nnetworks to overcome the two weaknesses. The behind basic idea is the\naggregation on a graph can benefit from a continuous space underlying the\ngraph. The proposed aggregation scheme is permutation-invariant and consists of\nthree modules, node embedding, structural neighborhood, and bi-level\naggregation. We also present an implementation of the scheme in graph\nconvolutional networks, termed Geom-GCN (Geometric Graph Convolutional\nNetworks), to perform transductive learning on graphs. Experimental results\nshow the proposed Geom-GCN achieved state-of-the-art performance on a wide\nrange of open datasets of graphs. Code is available at\nhttps://github.com/graphdml-uiuc-jlu/geom-gcn."}, {"title": "An Exponential Learning Rate Schedule for Deep Learning", "authors": "Zhiyuan Li, Sanjeev Arora", "link": "https://arxiv.org/abs/1910.07454", "summary": "Intriguing empirical evidence exists that deep learning can work well with\nexoticschedules for varying the learning rate. This paper suggests that the\nphenomenon may be due to Batch Normalization or BN, which is ubiquitous and\nprovides benefits in optimization and generalization across all standard\narchitectures. The following new results are shown about BN with weight decay\nand momentum (in other words, the typical use case which was not considered in\nearlier theoretical analyses of stand-alone BN.\n  1. Training can be done using SGD with momentum and an exponentially\nincreasing learning rate schedule, i.e., learning rate increases by some $(1\n+\\alpha)$ factor in every epoch for some $\\alpha >0$. (Precise statement in the\npaper.) To the best of our knowledge this is the first time such a rate\nschedule has been successfully used, let alone for highly successful\narchitectures. As expected, such training rapidly blows up network weights, but\nthe net stays well-behaved due to normalization.\n  2. Mathematical explanation of the success of the above rate schedule: a\nrigorous proof that it is equivalent to the standard setting of BN + SGD +\nStandardRate Tuning + Weight Decay + Momentum. This equivalence holds for other\nnormalization layers as well, Group Normalization, LayerNormalization, Instance\nNorm, etc.\n  3. A worked-out toy example illustrating the above linkage of\nhyper-parameters. Using either weight decay or BN alone reaches global minimum,\nbut convergence fails when both are used."}, {"title": "Implicit Bias of Gradient Descent based Adversarial Training on Separable Data", "authors": "Yan Li, Ethan X.Fang, Huan Xu, Tuo Zhao"}, {"title": "Unrestricted Adversarial Examples via Semantic Manipulation", "authors": "Anand Bhattad, Min Jin Chong, Kaizhao Liang, Bo Li, D. A. Forsyth"}, {"title": "Robust anomaly detection and backdoor attack detection via differential privacy", "authors": "Min Du, Ruoxi Jia, Dawn Song", "link": "https://arxiv.org/abs/1911.07116", "summary": "Outlier detection and novelty detection are two important topics for anomaly\ndetection. Suppose the majority of a dataset are drawn from a certain\ndistribution, outlier detection and novelty detection both aim to detect data\nsamples that do not fit the distribution. Outliers refer to data samples within\nthis dataset, while novelties refer to new samples. In the meantime, backdoor\npoisoning attacks for machine learning models are achieved through injecting\npoisoning samples into the training dataset, which could be regarded as\n\"outliers\" that are intentionally added by attackers. Differential privacy has\nbeen proposed to avoid leaking any individual's information, when aggregated\nanalysis is performed on a given dataset. It is typically achieved by adding\nrandom noise, either directly to the input dataset, or to intermediate results\nof the aggregation mechanism. In this paper, we demonstrate that applying\ndifferential privacy can improve the utility of outlier detection and novelty\ndetection, with an extension to detect poisoning samples in backdoor attacks.\nWe first present a theoretical analysis on how differential privacy helps with\nthe detection, and then conduct extensive experiments to validate the\neffectiveness of differential privacy in improving outlier detection, novelty\ndetection, and backdoor attack detection."}, {"title": "You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings", "authors": "Daniel Ruffinelli, Samuel Broscheit, Rainer Gemulla"}, {"title": "Reducing Transformer Depth on Demand with Structured Dropout", "authors": "Angela Fan, Edouard Grave, Armand Joulin", "link": "https://arxiv.org/abs/1909.11556", "summary": "Overparameterized transformer networks have obtained state of the art results\nin various natural language processing tasks, such as machine translation,\nlanguage modeling, and question answering. These models contain hundreds of\nmillions of parameters, necessitating a large amount of computation and making\nthem prone to overfitting. In this work, we explore LayerDrop, a form of\nstructured dropout, which has a regularization effect during training and\nallows for efficient pruning at inference time. In particular, we show that it\nis possible to select sub-networks of any depth from one large network without\nhaving to finetune them and with limited impact on performance. We demonstrate\nthe effectiveness of our approach by improving the state of the art on machine\ntranslation, language modeling, summarization, question answering, and language\nunderstanding benchmarks. Moreover, we show that our approach leads to small\nBERT-like models of higher quality compared to training from scratch or using\ndistillation."}, {"title": "Jacobian Adversarially Regularized Networks for Robustness", "authors": "Alvin Chan, Yi Tay, Yew Soon Ong, Jie Fu", "link": "https://arxiv.org/abs/1912.10185", "summary": "Adversarial examples are crafted with imperceptible perturbations with the\nintent to fool neural networks. Against such attacks, adversarial training and\nits variants stand as the strongest defense to date. Previous studies have\npointed out that robust models that have undergone adversarial training tend to\nproduce more salient and interpretable Jacobian matrices than their non-robust\ncounterparts. A natural question is whether a model trained with an objective\nto produce salient Jacobian can result in better robustness. This paper answers\nthis question with affirmative empirical results. We propose Jacobian\nAdversarially Regularized Networks (JARN) as a method to optimize the saliency\nof a classifier's Jacobian by adversarially regularizing the model's Jacobian\nto resemble natural training images. Image classifiers trained with JARN show\nimproved robust accuracy compared to standard models on the MNIST, SVHN and\nCIFAR-10 datasets, uncovering a new angle to boost robustness without using\nadversarial training examples."}, {"title": "Certified Defenses for Adversarial Patches", "authors": "Ping-yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph Studor, Tom Goldstein"}, {"title": "Unbiased Contrastive Divergence Algorithm for Training Energy-Based Latent Variable Models", "authors": "Yixuan Qiu, Lingsong Zhang, Xiao Wang"}, {"title": "RaCT: Toward Amortized Ranking-Critical Training For Collaborative Filtering ", "authors": "Sam Lobel, Chunyuan Li, Jianfeng Gao, Lawrence Carin"}, {"title": "Identity Crisis: Memorization and Generalization Under Extreme Overparameterization", "authors": "Chiyuan Zhang, Samy Bengio, Moritz Hardt, Michael C. Mozer, Yoram Singer", "link": "https://arxiv.org/abs/1902.04698", "summary": "We study the interplay between memorization and generalization of\noverparameterized networks in the extreme case of a single training example and\nan identity-mapping task. We examine fully-connected and convolutional networks\n(FCN and CNN), both linear and nonlinear, initialized randomly and then trained\nto minimize the reconstruction error. The trained networks stereotypically take\none of two forms: the constant function (memorization) and the identity\nfunction (generalization). We formally characterize generalization in\nsingle-layer FCNs and CNNs. We show empirically that different architectures\nexhibit strikingly different inductive biases. For example, CNNs of up to 10\nlayers are able to generalize from a single example, whereas FCNs cannot learn\nthe identity function reliably from 60k examples. Deeper CNNs often fail, but\nnonetheless do astonishing work to memorize the training output: because CNN\nbiases are location invariant, the model must progressively grow an output\npattern from the image boundaries via the coordination of many layers. Our work\nhelps to quantify and visualize the sensitivity of inductive biases to\narchitectural choices such as depth, kernel width, and number of channels."}, {"title": "Robust Subspace Recovery Layer for Unsupervised Anomaly Detection", "authors": "Chieh-Hsin Lai, Dongmian Zou, Gilad Lerman", "link": "https://arxiv.org/abs/1904.00152", "summary": "We propose a neural network for unsupervised anomaly detection with a novel\nrobust subspace recovery layer (RSR layer). This layer seeks to extract the\nunderlying subspace from a latent representation of the given data and removes\noutliers that lie away from this subspace. It is used within an autoencoder.\nThe encoder maps the data into a latent space, from which the RSR layer\nextracts the subspace. The decoder then smoothly maps back the underlying\nsubspace to a \"manifold\" close to the original inliers. Inliers and outliers\nare distinguished according to the distances between the original and mapped\npositions (small for inliers and large for outliers). Extensive numerical\nexperiments with both image and document datasets demonstrate state-of-the-art\nprecision and recall."}, {"title": "Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks", "authors": "Sreyas Mohan, Zahra Kadkhodaie, Eero P. Simoncelli, Carlos Fernandez-Granda", "link": "https://arxiv.org/abs/1906.05478", "summary": "Deep convolutional networks often append additive constant (\"bias\") terms to\ntheir convolution operations, enabling a richer repertoire of functional\nmappings. Biases are also used to facilitate training, by subtracting mean\nresponse over batches of training images (a component of \"batch\nnormalization\"). Recent state-of-the-art blind denoising methods (e.g., DnCNN)\nseem to require these terms for their success. Here, however, we show that\nthese networks systematically overfit the noise levels for which they are\ntrained: when deployed at noise levels outside the training range, performance\ndegrades dramatically. In contrast, a bias-free architecture -- obtained by\nremoving the constant terms in every layer of the network, including those used\nfor batch normalization-- generalizes robustly across noise levels, while\npreserving state-of-the-art performance within the training range. Locally, the\nbias-free network acts linearly on the noisy image, enabling direct analysis of\nnetwork behavior via standard linear-algebraic tools. These analyses provide\ninterpretations of network functionality in terms of nonlinear adaptive\nfiltering, and projection onto a union of low-dimensional subspaces, connecting\nthe learning-based method to more traditional denoising methodology."}, {"title": "A Closer Look at Deep Policy Gradients", "authors": "Andrew Ilyas, Logan Engstrom, Shibani Santurkar, Dimitris Tsipras, Firdaus Janoos, Larry Rudolph, Aleksander Madry"}, {"title": "High Fidelity Speech Synthesis with Adversarial Networks", "authors": "Miko\u0142aj Bi\u0144kowski, Jeff Donahue, Sander Dieleman, Aidan Clark, Erich Elsen, Norman Casagrande, Luis C. Cobo, Karen Simonyan", "link": "https://arxiv.org/abs/1909.11646", "summary": "Generative adversarial networks have seen rapid development in recent years\nand have led to remarkable improvements in generative modelling of images.\nHowever, their application in the audio domain has received limited attention,\nand autoregressive models, such as WaveNet, remain the state of the art in\ngenerative modelling of audio signals such as human speech. To address this\npaucity, we introduce GAN-TTS, a Generative Adversarial Network for\nText-to-Speech. Our architecture is composed of a conditional feed-forward\ngenerator producing raw speech audio, and an ensemble of discriminators which\noperate on random windows of different sizes. The discriminators analyse the\naudio both in terms of general realism, as well as how well the audio\ncorresponds to the utterance that should be pronounced. To measure the\nperformance of GAN-TTS, we employ both subjective human evaluation (MOS - Mean\nOpinion Score), as well as novel quantitative metrics (Fr\\'echet DeepSpeech\nDistance and Kernel DeepSpeech Distance), which we find to be well correlated\nwith MOS. We show that GAN-TTS is capable of generating high-fidelity speech\nwith naturalness comparable to the state-of-the-art models, and unlike\nautoregressive models, it is highly parallelisable thanks to an efficient\nfeed-forward generator. Listen to GAN-TTS reading this abstract at\nhttps://storage.googleapis.com/deepmind-media/research/abstract.wav."}, {"title": "ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring", "authors": "David Berthelot, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, Colin Raffel", "link": "https://arxiv.org/abs/1911.09785", "summary": "We improve the recently-proposed \"MixMatch\" semi-supervised learning\nalgorithm by introducing two new techniques: distribution alignment and\naugmentation anchoring. Distribution alignment encourages the marginal\ndistribution of predictions on unlabeled data to be close to the marginal\ndistribution of ground-truth labels. Augmentation anchoring feeds multiple\nstrongly augmented versions of an input into the model and encourages each\noutput to be close to the prediction for a weakly-augmented version of the same\ninput. To produce strong augmentations, we propose a variant of AutoAugment\nwhich learns the augmentation policy while the model is being trained. Our new\nalgorithm, dubbed ReMixMatch, is significantly more data-efficient than prior\nwork, requiring between $5\\times$ and $16\\times$ less data to reach the same\naccuracy. For example, on CIFAR-10 with 250 labeled examples we reach $93.73\\%$\naccuracy (compared to MixMatch's accuracy of $93.58\\%$ with $4{,}000$ examples)\nand a median accuracy of $84.92\\%$ with just four labels per class. We make our\ncode and data open-source at https://github.com/google-research/remixmatch."}, {"title": "Decoupling Representation and Classifier for Long-Tailed Recognition", "authors": "Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, Yannis Kalantidis", "link": "https://arxiv.org/abs/1910.09217", "summary": "The long-tail distribution of the visual world poses great challenges for\ndeep learning based classification models on how to handle the class imbalance\nproblem. Existing solutions usually involve class-balancing strategies, e.g.,\nby loss re-weighting, data re-sampling, or transfer learning from head- to\ntail-classes, but most of them adhere to the scheme of jointly learning\nrepresentations and classifiers. In this work, we decouple the learning\nprocedure into representation learning and classification, and systematically\nexplore how different balancing strategies affect them for long-tailed\nrecognition. The findings are surprising: (1) data imbalance might not be an\nissue in learning high-quality representations; (2) with representations\nlearned with the simplest instance-balanced (natural) sampling, it is also\npossible to achieve strong long-tailed recognition ability by adjusting only\nthe classifier. We conduct extensive experiments and set new state-of-the-art\nperformance on common long-tailed benchmarks like ImageNet-LT, Places-LT and\niNaturalist, showing that it is possible to outperform carefully designed\nlosses, sampling strategies, even complex modules with memory, by using a\nstraightforward approach that decouples representation and classification. Our\ncode is available at https://github.com/facebookresearch/classifier-balancing."}, {"title": "In Search for a SAT-friendly Binarized Neural Network Architecture", "authors": "Nina Narodytska, Hongce Zhang, Aarti Gupta, Toby Walsh"}, {"title": "Continual learning with hypernetworks", "authors": "Johannes von Oswald, Christian Henning, Jo\u00e3o Sacramento, Benjamin F. Grewe", "link": "https://arxiv.org/abs/1906.00695", "summary": "Artificial neural networks suffer from catastrophic forgetting when they are\nsequentially trained on multiple tasks. To overcome this problem, we present a\nnovel approach based on task-conditioned hypernetworks, i.e., networks that\ngenerate the weights of a target model based on task identity. Continual\nlearning (CL) is less difficult for this class of models thanks to a simple key\nfeature: instead of recalling the input-output relations of all previously seen\ndata, task-conditioned hypernetworks only require rehearsing task-specific\nweight realizations, which can be maintained in memory using a simple\nregularizer. Besides achieving state-of-the-art performance on standard CL\nbenchmarks, additional experiments on long task sequences reveal that\ntask-conditioned hypernetworks display a very large capacity to retain previous\nmemories. Notably, such long memory lifetimes are achieved in a compressive\nregime, when the number of trainable hypernetwork weights is comparable or\nsmaller than target network size. We provide insight into the structure of\nlow-dimensional task embedding spaces (the input space of the hypernetwork) and\nshow that task-conditioned hypernetworks demonstrate transfer learning.\nFinally, forward information transfer is further supported by empirical results\non a challenging CL benchmark based on the CIFAR-10/100 image datasets."}, {"title": "Self-Adversarial Learning with Comparative Discrimination for Text Generation", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, Ming Zhou", "link": "https://arxiv.org/abs/2001.11691", "summary": "Conventional Generative Adversarial Networks (GANs) for text generation tend\nto have issues of reward sparsity and mode collapse that affect the quality and\ndiversity of generated samples. To address the issues, we propose a novel\nself-adversarial learning (SAL) paradigm for improving GANs' performance in\ntext generation. In contrast to standard GANs that use a binary classifier as\nits discriminator to predict whether a sample is real or generated, SAL employs\na comparative discriminator which is a pairwise classifier for comparing the\ntext quality between a pair of samples. During training, SAL rewards the\ngenerator when its currently generated sentence is found to be better than its\npreviously generated samples. This self-improvement reward mechanism allows the\nmodel to receive credits more easily and avoid collapsing towards the limited\nnumber of real samples, which not only helps alleviate the reward sparsity\nissue but also reduces the risk of mode collapse. Experiments on text\ngeneration benchmark datasets show that our proposed approach substantially\nimproves both the quality and the diversity, and yields more stable performance\ncompared to the previous GANs for text generation."}, {"title": "FreeLB: Enhanced Adversarial Training for Natural Language Understanding", "authors": "Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu", "link": "https://arxiv.org/abs/1909.11764", "summary": "Adversarial training, which minimizes the maximal risk for label-preserving\ninput perturbations, has proved to be effective for improving the\ngeneralization of language models. In this work, we propose a novel adversarial\ntraining algorithm, FreeLB, that promotes higher invariance in the embedding\nspace, by adding adversarial perturbations to word embeddings and minimizing\nthe resultant adversarial risk inside different regions around input samples.\nTo validate the effectiveness of the proposed approach, we apply it to\nTransformer-based models for natural language understanding and commonsense\nreasoning tasks. Experiments on the GLUE benchmark show that when applied only\nto the finetuning stage, it is able to improve the overall test scores of\nBERT-base model from 78.3 to 79.4, and RoBERTa-large model from 88.5 to 88.8.\nIn addition, the proposed approach achieves state-of-the-art single-model test\naccuracies of 85.44\\% and 67.75\\% on ARC-Easy and ARC-Challenge. Experiments on\nCommonsenseQA benchmark further demonstrate that FreeLB can be generalized and\nboost the performance of RoBERTa-large model on other tasks as well. Code is\navailable at \\url{https://github.com/zhuchen03/FreeLB ."}, {"title": "V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control", "authors": "H. Francis Song, Abbas Abdolmaleki, Jost Tobias Springenberg, Aidan Clark, Hubert Soyer, Jack W. Rae, Seb Noury, Arun Ahuja, Siqi Liu, Dhruva Tirumala, Nicolas Heess, Dan Belov, Martin Riedmiller, Matthew M. Botvinick", "link": "https://arxiv.org/abs/1909.12238", "summary": "Some of the most successful applications of deep reinforcement learning to\nchallenging domains in discrete and continuous control have used policy\ngradient methods in the on-policy setting. However, policy gradients can suffer\nfrom large variance that may limit performance, and in practice require\ncarefully tuned entropy regularization to prevent policy collapse. As an\nalternative to policy gradient algorithms, we introduce V-MPO, an on-policy\nadaptation of Maximum a Posteriori Policy Optimization (MPO) that performs\npolicy iteration based on a learned state-value function. We show that V-MPO\nsurpasses previously reported scores for both the Atari-57 and DMLab-30\nbenchmark suites in the multi-task setting, and does so reliably without\nimportance weighting, entropy regularization, or population-based tuning of\nhyperparameters. On individual DMLab and Atari levels, the proposed algorithm\ncan achieve scores that are substantially higher than has previously been\nreported. V-MPO is also applicable to problems with high-dimensional,\ncontinuous action spaces, which we demonstrate in the context of learning to\ncontrol simulated humanoids with 22 degrees of freedom from full state\nobservations and 56 degrees of freedom from pixel observations, as well as\nexample OpenAI Gym tasks where V-MPO achieves substantially higher asymptotic\nscores than previously reported."}, {"title": "On the Weaknesses of Reinforcement Learning for Neural Machine Translation", "authors": "Leshem Choshen, Lior Fox, Zohar Aizenbud, Omri Abend"}, {"title": "Learning to Coordinate Manipulation Skills via Skill Behavior Diversification", "authors": "Youngwoon Lee, Jingyun Yang, Joseph J. Lim"}, {"title": "Global Relational Models of Source Code", "authors": "Vincent J. Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, David Bieber"}, {"title": "Quantum Algorithms for Deep Convolutional Neural Networks", "authors": "Iordanis Kerenidis, Jonas Landman, Anupam Prakash", "link": "https://arxiv.org/abs/1911.01117", "summary": "Quantum computing is a new computational paradigm that promises applications\nin several fields, including machine learning. In the last decade, deep\nlearning, and in particular Convolutional neural networks (CNN), have become\nessential for applications in signal processing and image recognition. Quantum\ndeep learning, however remains a challenging problem, as it is difficult to\nimplement non linearities with quantum unitaries. In this paper we propose a\nquantum algorithm for applying and training deep convolutional neural networks\nwith a potential speedup. The quantum CNN (QCNN) is a shallow circuit,\nreproducing completely the classical CNN, by allowing non linearities and\npooling operations. The QCNN is particularly interesting for deep networks and\ncould allow new frontiers in image recognition, by using more or larger\nconvolution kernels, larger or deeper inputs. We introduce a new quantum\ntomography algorithm with $\\ell_{\\infty}$ norm guarantees, and new applications\nof probabilistic sampling in the context of information processing. We also\npresent numerical simulations for the classification of the MNIST dataset to\nprovide practical evidence for the efficiency of the QCNN."}, {"title": "Cross-Lingual Ability of Multilingual BERT: An Empirical Study", "authors": "Karthikeyan K, Zihan Wang, Stephen Mayhew, Dan Roth", "link": "https://arxiv.org/abs/1912.07840", "summary": "Recent work has exhibited the surprising cross-lingual abilities of\nmultilingual BERT (M-BERT) -- surprising since it is trained without any\ncross-lingual objective and with no aligned data. In this work, we provide a\ncomprehensive study of the contribution of different components in M-BERT to\nits cross-lingual ability. We study the impact of linguistic properties of the\nlanguages, the architecture of the model, and the learning objectives. The\nexperimental study is done in the context of three typologically different\nlanguages -- Spanish, Hindi, and Russian -- and using two conceptually\ndifferent NLP tasks, textual entailment and named entity recognition. Among our\nkey conclusions is the fact that the lexical overlap between languages plays a\nnegligible role in the cross-lingual success, while the depth of the network is\nan integral part of it. All our models and implementations can be found on our\nproject page: http://cogcomp.org/page/publication_view/900 ."}, {"title": "A Constructive Prediction of the Generalization Error Across Scales", "authors": "Jonathan S. Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, Nir Shavit", "link": "https://arxiv.org/abs/1909.12673", "summary": "The dependency of the generalization error of neural networks on model and\ndataset size is of critical importance both in practice and for understanding\nthe theory of neural networks. Nevertheless, the functional form of this\ndependency remains elusive. In this work, we present a functional form which\napproximates well the generalization error in practice. Capitalizing on the\nsuccessful concept of model scaling (e.g., width, depth), we are able to\nsimultaneously construct such a form and specify the exact models which can\nattain it across model/data scales. Our construction follows insights obtained\nfrom observations conducted over a range of model/data scales, in various model\ntypes and datasets, in vision and language tasks. We show that the form both\nfits the observations well across scales, and provides accurate predictions\nfrom small- to large-scale models and data."}, {"title": "Unsupervised Model Selection for Variational Disentangled Representation Learning", "authors": "Sunny Duan, Loic Matthey, Andre Saraiva, Nick Watters, Chris Burgess, Alexander Lerchner, Irina Higgins", "link": "https://arxiv.org/abs/1905.12614", "summary": "Disentangled representations have recently been shown to improve fairness,\ndata efficiency and generalisation in simple supervised and reinforcement\nlearning tasks. To extend the benefits of disentangled representations to more\ncomplex domains and practical applications, it is important to enable\nhyperparameter tuning and model selection of existing unsupervised approaches\nwithout requiring access to ground truth attribute labels, which are not\navailable for most datasets. This paper addresses this problem by introducing a\nsimple yet robust and reliable method for unsupervised disentangled model\nselection. Our approach, Unsupervised Disentanglement Ranking (UDR), leverages\nthe recent theoretical results that explain why variational autoencoders\ndisentangle (Rolinek et al, 2019), to quantify the quality of disentanglement\nby performing pairwise comparisons between trained model representations. We\nshow that our approach performs comparably to the existing supervised\nalternatives across 5,400 models from six state of the art unsupervised\ndisentangled representation learning model classes. Furthermore, we show that\nthe ranking produced by our approach correlates well with the final task\nperformance on two different domains."}, {"title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": "Alex Renda, Jonathan Frankle, Michael Carbin", "link": "https://arxiv.org/abs/2003.02389", "summary": "Many neural network pruning algorithms proceed in three steps: train the\nnetwork to completion, remove unwanted structure to compress the network, and\nretrain the remaining structure to recover lost accuracy. The standard\nretraining technique, fine-tuning, trains the unpruned weights from their final\ntrained values using a small fixed learning rate. In this paper, we compare\nfine-tuning to alternative retraining techniques. Weight rewinding (as proposed\nby Frankle et al., (2019)), rewinds unpruned weights to their values from\nearlier in training and retrains them from there using the original training\nschedule. Learning rate rewinding (which we propose) trains the unpruned\nweights from their final values using the same learning rate schedule as weight\nrewinding. Both rewinding techniques outperform fine-tuning, forming the basis\nof a network-agnostic pruning algorithm that matches the accuracy and\ncompression ratios of several more network-specific state-of-the-art\ntechniques."}, {"title": "Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks", "authors": "Wei Hu, Lechao Xiao, Jeffrey Pennington", "link": "https://arxiv.org/abs/2001.05992", "summary": "The selection of initial parameter values for gradient-based optimization of\ndeep neural networks is one of the most impactful hyperparameter choices in\ndeep learning systems, affecting both convergence times and model performance.\nYet despite significant empirical and theoretical analysis, relatively little\nhas been proved about the concrete effects of different initialization schemes.\nIn this work, we analyze the effect of initialization in deep linear networks,\nand provide for the first time a rigorous proof that drawing the initial\nweights from the orthogonal group speeds up convergence relative to the\nstandard Gaussian initialization with iid weights. We show that for deep\nnetworks, the width needed for efficient convergence to a global minimum with\northogonal initializations is independent of the depth, whereas the width\nneeded for efficient convergence with Gaussian initializations scales linearly\nin the depth. Our results demonstrate how the benefits of a good initialization\ncan persist throughout learning, suggesting an explanation for the recent\nempirical successes found by initializing very deep non-linear networks\naccording to the principle of dynamical isometry."}, {"title": "AutoQ: Automated Kernel-Wise Neural Network Quantization ", "authors": "Qian Lou, Feng Guo, Minje Kim, Lantao Liu, Lei Jiang.", "link": "https://arxiv.org/abs/1902.05690", "summary": "Network quantization is one of the most hardware friendly techniques to\nenable the deployment of convolutional neural networks (CNNs) on low-power\nmobile devices. Recent network quantization techniques quantize each weight\nkernel in a convolutional layer independently for higher inference accuracy,\nsince the weight kernels in a layer exhibit different variances and hence have\ndifferent amounts of redundancy. The quantization bitwidth or bit number (QBN)\ndirectly decides the inference accuracy, latency, energy and hardware overhead.\nTo effectively reduce the redundancy and accelerate CNN inferences, various\nweight kernels should be quantized with different QBNs. However, prior works\nuse only one QBN to quantize each convolutional layer or the entire CNN,\nbecause the design space of searching a QBN for each weight kernel is too\nlarge. The hand-crafted heuristic of the kernel-wise QBN search is so\nsophisticated that domain experts can obtain only sub-optimal results. It is\ndifficult for even deep reinforcement learning (DRL) Deep Deterministic Policy\nGradient (DDPG)-based agents to find a kernel-wise QBN configuration that can\nachieve reasonable inference accuracy. In this paper, we propose a\nhierarchical-DRL-based kernel-wise network quantization technique, AutoQ, to\nautomatically search a QBN for each weight kernel, and choose another QBN for\neach activation layer. Compared to the models quantized by the state-of-the-art\nDRL-based schemes, on average, the same models quantized by AutoQ reduce the\ninference latency by 54.06\\%, and decrease the inference energy consumption by\n50.69\\%, while achieving the same inference accuracy."}, {"title": "Learning Compositional Koopman Operators for Model-Based Control", "authors": "Yunzhu Li, Hao He, Jiajun Wu, Dina Katabi, Antonio Torralba", "link": "https://arxiv.org/abs/1910.08264", "summary": "Finding an embedding space for a linear approximation of a nonlinear\ndynamical system enables efficient system identification and control synthesis.\nThe Koopman operator theory lays the foundation for identifying the\nnonlinear-to-linear coordinate transformations with data-driven methods.\nRecently, researchers have proposed to use deep neural networks as a more\nexpressive class of basis functions for calculating the Koopman operators.\nThese approaches, however, assume a fixed dimensional state space; they are\ntherefore not applicable to scenarios with a variable number of objects. In\nthis paper, we propose to learn compositional Koopman operators, using graph\nneural networks to encode the state into object-centric embeddings and using a\nblock-wise linear transition matrix to regularize the shared structure across\nobjects. The learned dynamics can quickly adapt to new environments of unknown\nphysical parameters and produce control signals to achieve a specified goal.\nOur experiments on manipulating ropes and controlling soft robots show that the\nproposed method has better efficiency and generalization ability than existing\nbaselines."}, {"title": "Classification-Based Anomaly Detection for General Data", "authors": "Liron Bergman, Yedid Hoshen"}, {"title": "Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation", "authors": "Xinjie Fan, Yizhe Zhang, Zhendong Wang, Mingyuan Zhou"}, {"title": "Detecting Extrapolation with Local Ensembles", "authors": "David Madras, James Atwood, Alexander D'Amour", "link": "https://arxiv.org/abs/1910.09573", "summary": "We present local ensembles, a method for detecting extrapolation at test time\nin a pre-trained model. We focus on underdetermination as a key component of\nextrapolation: we aim to detect when many possible predictions are consistent\nwith the training data and model class. Our method uses local second-order\ninformation to approximate the variance of predictions across an ensemble of\nmodels from the same class. We compute this approximation by estimating the\nnorm of the component of a test point's gradient that aligns with the\nlow-curvature directions of the Hessian, and provide a tractable method for\nestimating this quantity. Experimentally, we show that our method is capable of\ndetecting when a pre-trained model is extrapolating on test data, with\napplications to out-of-distribution detection, detecting spurious correlates,\nand active learning."}, {"title": "Mathematical Reasoning in Latent Space", "authors": "Dennis Lee, Christian Szegedy, Markus Rabe, Sarah Loos, Kshitij Bansal", "link": "https://arxiv.org/abs/1909.11851", "summary": "We design and conduct a simple experiment to study whether neural networks\ncan perform several steps of approximate reasoning in a fixed dimensional\nlatent space. The set of rewrites (i.e. transformations) that can be\nsuccessfully performed on a statement represents essential semantic features of\nthe statement. We can compress this information by embedding the formula in a\nvector space, such that the vector associated with a statement can be used to\npredict whether a statement can be rewritten by other theorems. Predicting the\nembedding of a formula generated by some rewrite rule is naturally viewed as\napproximate reasoning in the latent space. In order to measure the\neffectiveness of this reasoning, we perform approximate deduction sequences in\nthe latent space and use the resulting embedding to inform the semantic\nfeatures of the corresponding formal statement (which is obtained by performing\nthe corresponding rewrite sequence using real formulas). Our experiments show\nthat graph neural networks can make non-trivial predictions about the\nrewrite-success of statements, even when they propagate predicted latent\nrepresentations for several steps. Since our corpus of mathematical formulas\nincludes a wide variety of mathematical disciplines, this experiment is a\nstrong indicator for the feasibility of deduction in latent space in general."}, {"title": "Learning Space Partitions for Nearest Neighbor Search", "authors": "Yihe Dong, Piotr Indyk, Ilya Razenshteyn, Tal Wagner", "link": "https://arxiv.org/abs/1901.08544", "summary": "Space partitions of $\\mathbb{R}^d$ underlie a vast and important class of\nfast nearest neighbor search (NNS) algorithms. Inspired by recent theoretical\nwork on NNS for general metric spaces [Andoni, Naor, Nikolov, Razenshteyn,\nWaingarten STOC 2018, FOCS 2018], we develop a new framework for building space\npartitions reducing the problem to \\emph{balanced graph partitioning} followed\nby \\emph{supervised classification.} We instantiate this general approach with\nthe KaHIP graph partitioner [Sanders, Schulz SEA 2013] and neural networks,\nrespectively, to obtain a new partitioning procedure called Neural\nLocality-Sensitive Hashing (Neural LSH). On several standard benchmarks for\nNNS, our experiments show that the partitions obtained by Neural LSH\nconsistently outperform partitions found by quantization-based and tree-based\nmethods."}, {"title": "Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification", "authors": "Yixiao Ge, Dapeng Chen, Hongsheng Li", "link": "https://arxiv.org/abs/2001.01526", "summary": "Person re-identification (re-ID) aims at identifying the same persons' images\nacross different cameras. However, domain diversities between different\ndatasets pose an evident challenge for adapting the re-ID model trained on one\ndataset to another one. State-of-the-art unsupervised domain adaptation methods\nfor person re-ID transferred the learned knowledge from the source domain by\noptimizing with pseudo labels created by clustering algorithms on the target\ndomain. Although they achieved state-of-the-art performances, the inevitable\nlabel noise caused by the clustering procedure was ignored. Such noisy pseudo\nlabels substantially hinders the model's capability on further improving\nfeature representations on the target domain. In order to mitigate the effects\nof noisy pseudo labels, we propose to softly refine the pseudo labels in the\ntarget domain by proposing an unsupervised framework, Mutual Mean-Teaching\n(MMT), to learn better features from the target domain via off-line refined\nhard pseudo labels and on-line refined soft pseudo labels in an alternative\ntraining manner. In addition, the common practice is to adopt both the\nclassification loss and the triplet loss jointly for achieving optimal\nperformances in person re-ID models. However, conventional triplet loss cannot\nwork with softly refined labels. To solve this problem, a novel soft\nsoftmax-triplet loss is proposed to support learning with soft pseudo triplet\nlabels for achieving the optimal domain adaptation performance. The proposed\nMMT framework achieves considerable improvements of 14.4%, 18.2%, 13.1% and\n16.4% mAP on Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT\nunsupervised domain adaptation tasks. Code is available at\nhttps://github.com/yxgeee/MMT."}, {"title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "authors": "Milad Alizadeh, Arash Behboodi, Mart van Baalen, Christos Louizos, Tijmen Blankevoort, Max Welling"}, {"title": "Co-Attentive Equivariant Neural Networks: Focusing Equivariance On Transformations Co-Occurring in Data", "authors": "David W. Romero, Mark Hoogendoorn", "link": "https://arxiv.org/abs/1911.07849", "summary": "Equivariance is a nice property to have as it produces much more parameter\nefficient neural architectures and preserves the structure of the input through\nthe feature mapping. Even though some combinations of transformations might\nnever appear (e.g. an upright face with a horizontal nose), current equivariant\narchitectures consider the set of all possible transformations in a\ntransformation group when learning feature representations. Contrarily, the\nhuman visual system is able to attend to the set of relevant transformations\noccurring in the environment and utilizes this information to assist and\nimprove object recognition. Based on this observation, we modify conventional\nequivariant feature mappings such that they are able to attend to the set of\nco-occurring transformations in data and generalize this notion to act on\ngroups consisting of multiple symmetries. We show that our proposed\nco-attentive equivariant neural networks consistently outperform conventional\nrotation equivariant and rotation & reflection equivariant neural networks on\nrotated MNIST and CIFAR-10."}, {"title": "Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel", "authors": "Xin Qiu, Elliot Meyerson, Risto Miikkulainen", "link": "https://arxiv.org/abs/1906.00588", "summary": "Neural Networks (NNs) have been extensively used for a wide spectrum of\nreal-world regression tasks, where the goal is to predict a numerical outcome\nsuch as revenue, effectiveness, or a quantitative result. In many such tasks,\nthe point prediction is not enough: the uncertainty (i.e. risk or confidence)\nof that prediction must also be estimated. Standard NNs, which are most often\nused in such tasks, do not provide uncertainty information. Existing approaches\naddress this issue by combining Bayesian models with NNs, but these models are\nhard to implement, more expensive to train, and usually do not predict as\naccurately as standard NNs. In this paper, a new framework (RIO) is developed\nthat makes it possible to estimate uncertainty in any pretrained standard NN.\nThe behavior of the NN is captured by modeling its prediction residuals with a\nGaussian Process, whose kernel includes both the NN's input and its output. The\nframework is evaluated in twelve real-world datasets, where it is found to (1)\nprovide reliable estimates of uncertainty, (2) reduce the error of the point\npredictions, and (3) scale well to large datasets. Given that RIO can be\napplied to any standard NN without modifications to model architecture or\ntraining pipeline, it provides an important ingredient for building real-world\nNN applications."}, {"title": "Causal Discovery with Reinforcement Learning", "authors": "Shengyu Zhu, Ignavier Ng, Zhitang Chen", "link": "https://arxiv.org/abs/1906.04477", "summary": "Discovering causal structure among a set of variables is a fundamental\nproblem in many empirical sciences. Traditional score-based casual discovery\nmethods rely on various local heuristics to search for a Directed Acyclic Graph\n(DAG) according to a predefined score function. While these methods, e.g.,\ngreedy equivalence search, may have attractive results with infinite samples\nand certain model assumptions, they are usually less satisfactory in practice\ndue to finite data and possible violation of assumptions. Motivated by recent\nadvances in neural combinatorial optimization, we propose to use Reinforcement\nLearning (RL) to search for the DAG with the best scoring. Our encoder-decoder\nmodel takes observable data as input and generates graph adjacency matrices\nthat are used to compute rewards. The reward incorporates both the predefined\nscore function and two penalty terms for enforcing acyclicity. In contrast with\ntypical RL applications where the goal is to learn a policy, we use RL as a\nsearch strategy and our final output would be the graph, among all graphs\ngenerated during training, that achieves the best reward. We conduct\nexperiments on both synthetic and real datasets, and show that the proposed\napproach not only has an improved search ability but also allows a flexible\nscore function under the acyclicity constraint."}, {"title": "Overlearning Reveals Sensitive Attributes", "authors": "Congzheng Song, Vitaly Shmatikov", "link": "https://arxiv.org/abs/1905.11742", "summary": "\"Overlearning\" means that a model trained for a seemingly simple objective\nimplicitly learns to recognize attributes and concepts that are (1) not part of\nthe learning objective, and (2) sensitive from a privacy or bias perspective.\nFor example, a binary gender classifier of facial images also learns to\nrecognize races\\textemdash even races that are not represented in the training\ndata\\textemdash and identities.\n  We demonstrate overlearning in several vision and NLP models and analyze its\nharmful consequences. First, inference-time representations of an overlearned\nmodel reveal sensitive attributes of the input, breaking privacy protections\nsuch as model partitioning. Second, an overlearned model can be \"re-purposed\"\nfor a different, privacy-violating task even in the absence of the original\ntraining data.\n  We show that overlearning is intrinsic for some tasks and cannot be prevented\nby censoring unwanted attributes. Finally, we investigate where, when, and why\noverlearning happens during model training."}, {"title": "Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks", "authors": "Yu Bai, Jason D. Lee", "link": "http://arxiv.org/abs/1910.01619", "summary": "Recent theoretical work has established connections between over-parametrized\nneural networks and linearized models governed by he Neural Tangent Kernels\n(NTKs). NTK theory leads to concrete convergence and generalization results,\nyet the empirical performance of neural networks are observed to exceed their\nlinearized models, suggesting insufficiency of this theory.\n  Towards closing this gap, we investigate the training of over-parametrized\nneural networks that are beyond the NTK regime yet still governed by the Taylor\nexpansion of the network. We bring forward the idea of \\emph{randomizing} the\nneural networks, which allows them to escape their NTK and couple with\nquadratic models. We show that the optimization landscape of randomized\ntwo-layer networks are nice and amenable to escaping-saddle algorithms. We\nprove concrete generalization and expressivity results on these randomized\nnetworks, which lead to sample complexity bounds (of learning certain simple\nfunctions) that match the NTK and can in addition be better by a dimension\nfactor when mild distributional assumptions are present. We demonstrate that\nour randomization technique can be generalized systematically beyond the\nquadratic case, by using it to find networks that are coupled with higher-order\nterms in their Taylor series."}, {"title": "Learning to Represent Programs with Property Signatures", "authors": "Augustus Odena, Charles Sutton"}, {"title": "Can gradient clipping mitigate label noise?", "authors": "Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar"}, {"title": "Dynamic Model Pruning with Feedback", "authors": "Tao Lin, Sebastian U. Stich, Luis Barba, Daniil Dmitriev, Martin Jaggi"}, {"title": "Deep Learning of Determinantal Point Processes via Proper Spectral Sub-gradient", "authors": "Tianshu Yu, Yikang Li, Baoxin Li"}, {"title": "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning", "authors": "Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin Gal, Katja Hofmann, Shimon Whiteson", "link": "", "summary": ""}, {"title": "Infinite-Horizon Differentiable Model Predictive Control", "authors": "Sebastian East, Marco Gallieri, Jonathan Masci, Jan Koutnik, Mark Cannon", "link": "https://arxiv.org/abs/2001.02244", "summary": "This paper proposes a differentiable linear quadratic Model Predictive\nControl (MPC) framework for safe imitation learning. The infinite-horizon cost\nis enforced using a terminal cost function obtained from the discrete-time\nalgebraic Riccati equation (DARE), so that the learned controller can be proven\nto be stabilizing in closed-loop. A central contribution is the derivation of\nthe analytical derivative of the solution of the DARE, thereby allowing the use\nof differentiation-based learning methods. A further contribution is the\nstructure of the MPC optimization problem: an augmented Lagrangian method\nensures that the MPC optimization is feasible throughout training whilst\nenforcing hard constraints on state and input, and a pre-stabilizing controller\nensures that the MPC solution and derivatives are accurate at each iteration.\nThe learning capabilities of the framework are demonstrated in a set of\nnumerical studies."}, {"title": "Continual Learning with Bayesian Neural Networks for Non-Stationary Data", "authors": "Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick van der Smagt, Stephan G\u00fcnnemann"}, {"title": "ES-MAML: Simple Hessian-Free Meta Learning", "authors": "Xingyou Song, Wenbo Gao, Yuxiang Yang, Krzysztof Choromanski, Aldo Pacchiano, Yunhao Tang", "link": "", "summary": ""}, {"title": "Training binary neural networks with real-to-binary convolutions", "authors": "Brais Martinez, Jing Yang, Adrian Bulat, Georgios Tzimiropoulos", "link": "https://arxiv.org/abs/2003.11535", "summary": "This paper shows how to train binary networks to within a few percent points\n($\\sim 3-5 \\%$) of the full precision counterpart. We first show how to build a\nstrong baseline, which already achieves state-of-the-art accuracy, by combining\nrecently proposed advances and carefully adjusting the optimization procedure.\nSecondly, we show that by attempting to minimize the discrepancy between the\noutput of the binary and the corresponding real-valued convolution, additional\nsignificant accuracy gains can be obtained. We materialize this idea in two\ncomplementary ways: (1) with a loss function, during training, by matching the\nspatial attention maps computed at the output of the binary and real-valued\nconvolutions, and (2) in a data-driven manner, by using the real-valued\nactivations, available during inference prior to the binarization process, for\nre-scaling the activations right after the binary convolution. Finally, we show\nthat, when putting all of our improvements together, the proposed model beats\nthe current state of the art by more than 5% top-1 accuracy on ImageNet and\nreduces the gap to its real-valued counterpart to less than 3% and 5% top-1\naccuracy on CIFAR-100 and ImageNet respectively when using a ResNet-18\narchitecture. Code available at https://github.com/brais-martinez/real2binary."}, {"title": "Economy Statistical Recurrent Units For Inferring Nonlinear Granger Causality", "authors": "Saurabh Khanna, Vincent Y. F. Tan", "link": "https://arxiv.org/abs/1911.09879", "summary": "Granger causality is a widely-used criterion for analyzing interactions in\nlarge-scale networks. As most physical interactions are inherently nonlinear,\nwe consider the problem of inferring the existence of pairwise Granger\ncausality between nonlinearly interacting stochastic processes from their time\nseries measurements. Our proposed approach relies on modeling the embedded\nnonlinearities in the measurements using a component-wise time series\nprediction model based on Statistical Recurrent Units (SRUs). We make a case\nthat the network topology of Granger causal relations is directly inferrable\nfrom a structured sparse estimate of the internal parameters of the SRU\nnetworks trained to predict the processes$'$ time series measurements. We\npropose a variant of SRU, called economy-SRU, which, by design has considerably\nfewer trainable parameters, and therefore less prone to overfitting. The\neconomy-SRU computes a low-dimensional sketch of its high-dimensional hidden\nstate in the form of random projections to generate the feedback for its\nrecurrent processing. Additionally, the internal weight parameters of the\neconomy-SRU are strategically regularized in a group-wise manner to facilitate\nthe proposed network in extracting meaningful predictive features that are\nhighly time-localized to mimic real-world causal events. Extensive experiments\nare carried out to demonstrate that the proposed economy-SRU based time series\nprediction model outperforms the MLP, LSTM and attention-gated CNN-based time\nseries models considered previously for inferring Granger causality."}, {"title": "Sliced Cramer Synaptic Consolidation for Preserving Deeply Learned Representations", "authors": "Soheil Kolouri, Nicholas A. Ketz, Andrea Soltoggio, Praveen K. Pilly"}, {"title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "authors": "Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas Papernot, Mohit Iyyer", "link": "https://arxiv.org/abs/1910.12366", "summary": "We study the problem of model extraction in natural language processing, in\nwhich an adversary with only query access to a victim model attempts to\nreconstruct a local copy of that model. Assuming that both the adversary and\nvictim model fine-tune a large pretrained language model such as BERT (Devlin\net al. 2019), we show that the adversary does not need any real training data\nto successfully mount the attack. In fact, the attacker need not even use\ngrammatical or semantically meaningful queries: we show that random sequences\nof words coupled with task-specific heuristics form effective queries for model\nextraction on a diverse set of NLP tasks, including natural language inference\nand question answering. Our work thus highlights an exploit only made feasible\nby the shift towards transfer learning methods within the NLP community: for a\nquery budget of a few hundred dollars, an attacker can extract a model that\nperforms only slightly worse than the victim model. Finally, we study two\ndefense strategies against model extraction---membership classification and API\nwatermarking---which while successful against naive adversaries, are\nineffective against more sophisticated ones."}, {"title": "Deep probabilistic subsampling for task-adaptive compressed sensing", "authors": "Iris A.M. Huijben, Bastiaan S. Veeling, Ruud J.G. van Sloun"}, {"title": "On the Need for Topology-Aware Generative Models for Manifold-Based Defenses", "authors": "Uyeong Jang, Susmit Jha, Somesh Jha", "link": "https://arxiv.org/abs/1909.03334", "summary": "Machine-learning (ML) algorithms or models, especially deep neural networks\n(DNNs), have shown significant promise in several areas. However, researchers\nhave recently demonstrated that ML algorithms, especially DNNs, are vulnerable\nto adversarial examples (slightly perturbed samples that cause\nmisclassification). The existence of adversarial examples has hindered the\ndeployment of ML algorithms in safety-critical sectors, such as security.\nSeveral defenses for adversarial examples exist in the literature. One of the\nimportant classes of defenses are manifold-based defenses, where a sample is\n``pulled back\" into the data manifold before classifying. These defenses rely\non the assumption that data lie in a manifold of a lower dimension than the\ninput space. These defenses use a generative model to approximate the input\ndistribution. In this paper, we investigate the following question: do the\ngenerative models used in manifold-based defenses need to be topology-aware? We\nsuggest the answer is yes, and we provide theoretical and empirical evidence to\nsupport our claim."}, {"title": "Coherent Gradients: An Approach to Understanding Generalization in Gradient Descent-based Optimization", "authors": "Satrajit Chatterjee", "link": "https://arxiv.org/abs/2002.10657", "summary": "An open question in the Deep Learning community is why neural networks\ntrained with Gradient Descent generalize well on real datasets even though they\nare capable of fitting random data. We propose an approach to answering this\nquestion based on a hypothesis about the dynamics of gradient descent that we\ncall Coherent Gradients: Gradients from similar examples are similar and so the\noverall gradient is stronger in certain directions where these reinforce each\nother. Thus changes to the network parameters during training are biased\ntowards those that (locally) simultaneously benefit many examples when such\nsimilarity exists. We support this hypothesis with heuristic arguments and\nperturbative experiments and outline how this can explain several common\nempirical observations about Deep Learning. Furthermore, our analysis is not\njust descriptive, but prescriptive. It suggests a natural modification to\ngradient descent that can greatly reduce overfitting."}, {"title": "Enhancing Adversarial Defense by k-Winners-Take-All", "authors": "Chang Xiao, Peilin Zhong, Changxi Zheng", "link": "https://arxiv.org/abs/1905.10510", "summary": "We propose a simple change to existing neural network structures for better\ndefending against gradient-based adversarial attacks. Instead of using popular\nactivation functions (such as ReLU), we advocate the use of k-Winners-Take-All\n(k-WTA) activation, a C0 discontinuous function that purposely invalidates the\nneural network model's gradient at densely distributed input data points. The\nproposed k-WTA activation can be readily used in nearly all existing networks\nand training methods with no significant overhead. Our proposal is\ntheoretically rationalized. We analyze why the discontinuities in k-WTA\nnetworks can largely prevent gradient-based search of adversarial examples and\nwhy they at the same time remain innocuous to the network training. This\nunderstanding is also empirically backed. We test k-WTA activation on various\nnetwork structures optimized by a training method, be it adversarial training\nor not. In all cases, the robustness of k-WTA networks outperforms that of\ntraditional networks under white-box attacks."}, {"title": "Extreme Tensoring for Low-Memory Preconditioning ", "authors": "Xinyi Chen, Naman Agarwal, Elad Hazan, Cyril Zhang, Yi Zhang", "link": "https://arxiv.org/abs/1902.04620", "summary": "State-of-the-art models are now trained with billions of parameters, reaching\nhardware limits in terms of memory consumption. This has created a recent\ndemand for memory-efficient optimizers. To this end, we investigate the limits\nand performance tradeoffs of memory-efficient adaptively preconditioned\ngradient methods. We propose extreme tensoring for high-dimensional stochastic\noptimization, showing that an optimizer needs very little memory to benefit\nfrom adaptive preconditioning. Our technique applies to arbitrary models (not\nnecessarily with tensor-shaped parameters), and is accompanied by regret and\nconvergence guarantees, which shed light on the tradeoffs between\npreconditioner quality and expressivity. On a large-scale NLP model, we reduce\nthe optimizer memory overhead by three orders of magnitude, without degrading\nperformance."}, {"title": "MEMO: A Deep Network for Flexible Combination of Episodic Memories", "authors": "Andrea Banino, Adri\u00e0 Puigdom\u00e8nech Badia, Raphael K\u00f6ster, Martin J. Chadwick, Vinicius Zambaldi, Demis Hassabis, Caswell Barry, Matthew Botvinick, Dharshan Kumaran, Charles Blundell", "link": "https://arxiv.org/abs/2001.10913", "summary": "Recent research developing neural network architectures with external memory\nhave often used the benchmark bAbI question and answering dataset which\nprovides a challenging number of tasks requiring reasoning. Here we employed a\nclassic associative inference task from the memory-based reasoning neuroscience\nliterature in order to more carefully probe the reasoning capacity of existing\nmemory-augmented architectures. This task is thought to capture the essence of\nreasoning -- the appreciation of distant relationships among elements\ndistributed across multiple facts or memories. Surprisingly, we found that\ncurrent architectures struggle to reason over long distance associations.\nSimilar results were obtained on a more complex task involving finding the\nshortest path between nodes in a path. We therefore developed MEMO, an\narchitecture endowed with the capacity to reason over longer distances. This\nwas accomplished with the addition of two novel components. First, it\nintroduces a separation between memories (facts) stored in external memory and\nthe items that comprise these facts in external memory. Second, it makes use of\nan adaptive retrieval mechanism, allowing a variable number of \"memory hops\"\nbefore the answer is produced. MEMO is capable of solving our novel reasoning\ntasks, as well as match state of the art results in bAbI."}, {"title": "Denoising and Regularization via Exploiting the Structural Bias of Convolutional Generators", "authors": "Reinhard Heckel and Mahdi Soltanolkotabi", "link": "https://arxiv.org/abs/1910.14634", "summary": "Convolutional Neural Networks (CNNs) have emerged as highly successful tools\nfor image generation, recovery, and restoration. A major contributing factor to\nthis success is that convolutional networks impose strong prior assumptions\nabout natural images. A surprising experiment that highlights this\narchitectural bias towards natural images is that one can remove noise and\ncorruptions from a natural image without using any training data, by simply\nfitting (via gradient descent) a randomly initialized, over-parameterized\nconvolutional generator to the corrupted image. While this over-parameterized\nnetwork can fit the corrupted image perfectly, surprisingly after a few\niterations of gradient descent it generates an almost uncorrupted image. This\nintriguing phenomenon enables state-of-the-art CNN-based denoising and\nregularization of other inverse problems. In this paper, we attribute this\neffect to a particular architectural choice of convolutional networks, namely\nconvolutions with fixed interpolating filters. We then formally characterize\nthe dynamics of fitting a two-layer convolutional generator to a noisy signal\nand prove that early-stopped gradient descent denoises/regularizes. Our proof\nrelies on showing that convolutional generators fit the structured part of an\nimage significantly faster than the corrupted portion."}, {"title": "Inductive Matrix Completion Based on Graph Neural Networks", "authors": "Muhan Zhang, Yixin Chen"}, {"title": "Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies", "authors": "Sungryull Sohn, Hyunjae Woo, Jongwook Choi, Honglak Lee", "link": "https://arxiv.org/abs/2001.00248", "summary": "We propose and address a novel few-shot RL problem, where a task is\ncharacterized by a subtask graph which describes a set of subtasks and their\ndependencies that are unknown to the agent. The agent needs to quickly adapt to\nthe task over few episodes during adaptation phase to maximize the return in\nthe test phase. Instead of directly learning a meta-policy, we develop a\nMeta-learner with Subtask Graph Inference(MSGI), which infers the latent\nparameter of the task by interacting with the environment and maximizes the\nreturn given the latent parameter. To facilitate learning, we adopt an\nintrinsic reward inspired by upper confidence bound (UCB) that encourages\nefficient exploration. Our experiment results on two grid-world domains and\nStarCraft II environments show that the proposed method is able to accurately\ninfer the latent task parameter, and to adapt more efficiently than existing\nmeta RL and hierarchical RL methods."}, {"title": "Accelerating SGD with momentum for over-parameterized learning", "authors": "Chaoyue Liu, Mikhail Belkin", "link": "https://arxiv.org/abs/1810.13395", "summary": "Nesterov SGD is widely used for training modern neural networks and other\nmachine learning models. Yet, its advantages over SGD have not been\ntheoretically clarified. Indeed, as we show in our paper, both theoretically\nand empirically, Nesterov SGD with any parameter selection does not in general\nprovide acceleration over ordinary SGD. Furthermore, Nesterov SGD may diverge\nfor step sizes that ensure convergence of ordinary SGD. This is in contrast to\nthe classical results in the deterministic scenario, where the same step size\nensures accelerated convergence of the Nesterov's method over optimal gradient\ndescent.\n  To address the non-acceleration issue, we introduce a compensation term to\nNesterov SGD. The resulting algorithm, which we call MaSS, converges for same\nstep sizes as SGD. We prove that MaSS obtains an accelerated convergence rates\nover SGD for any mini-batch size in the linear setting. For full batch, the\nconvergence rate of MaSS matches the well-known accelerated rate of the\nNesterov's method.\n  We also analyze the practically important question of the dependence of the\nconvergence rate and optimal hyper-parameters on the mini-batch size,\ndemonstrating three distinct regimes: linear scaling, diminishing returns and\nsaturation.\n  Experimental evaluation of MaSS for several standard architectures of deep\nnetworks, including ResNet and convolutional networks, shows improved\nperformance over SGD, Nesterov SGD and Adam."}, {"title": "Observational Overfitting in Reinforcement Learning", "authors": "Xingyou Song, Yiding Jiang, Stephen Tu, Yilun Du, Behnam Neyshabur", "link": "https://arxiv.org/abs/1912.02975", "summary": "A major component of overfitting in model-free reinforcement learning (RL)\ninvolves the case where the agent may mistakenly correlate reward with certain\nspurious features from the observations generated by the Markov Decision\nProcess (MDP). We provide a general framework for analyzing this scenario,\nwhich we use to design multiple synthetic benchmarks from only modifying the\nobservation space of an MDP. When an agent overfits to different observation\nspaces even if the underlying MDP dynamics is fixed, we term this observational\noverfitting. Our experiments expose intriguing properties especially with\nregards to implicit regularization, and also corroborate results from previous\nworks in RL generalization and supervised learning (SL)."}, {"title": "SAdam: A Variant of Adam for Strongly Convex Functions", "authors": "Guanghui Wang, Shiyin Lu, Quan Cheng, Wei-wei Tu, Lijun Zhang", "link": "https://arxiv.org/abs/1905.02957", "summary": "The Adam algorithm has become extremely popular for large-scale machine\nlearning. Under convexity condition, it has been proved to enjoy a\ndata-dependant $O(\\sqrt{T})$ regret bound where $T$ is the time horizon.\nHowever, whether strong convexity can be utilized to further improve the\nperformance remains an open problem. In this paper, we give an affirmative\nanswer by developing a variant of Adam (referred to as SAdam) which achieves a\ndata-dependant $O(\\log T)$ regret bound for strongly convex functions. The\nessential idea is to maintain a faster decaying yet under controlled step size\nfor exploiting strong convexity. In addition, under a special configuration of\nhyperparameters, our SAdam reduces to SC-RMSprop, a recently proposed variant\nof RMSprop for strongly convex functions, for which we provide the first\ndata-dependent logarithmic regret bound. Empirical results on optimizing\nstrongly convex functions and training deep networks demonstrate the\neffectiveness of our method."}, {"title": "Stochastic Conditional Generative Networks with Basis Decomposition", "authors": "Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, Qiang Qiu", "link": "https://arxiv.org/abs/1909.11286", "summary": "While generative adversarial networks (GANs) have revolutionized machine\nlearning, a number of open questions remain to fully understand them and\nexploit their power. One of these questions is how to efficiently achieve\nproper diversity and sampling of the multi-mode data space. To address this, we\nintroduce BasisGAN, a stochastic conditional multi-mode image generator. By\nexploiting the observation that a convolutional filter can be well approximated\nas a linear combination of a small set of basis elements, we learn a\nplug-and-played basis generator to stochastically generate basis elements, with\njust a few hundred of parameters, to fully embed stochasticity into\nconvolutional filters. By sampling basis elements instead of filters, we\ndramatically reduce the cost of modeling the parameter space with no sacrifice\non either image diversity or fidelity. To illustrate this proposed\nplug-and-play framework, we construct variants of BasisGAN based on\nstate-of-the-art conditional image generation networks, and train the networks\nby simply plugging in a basis generator, without additional auxiliary\ncomponents, hyperparameters, or training objectives. The experimental success\nis complemented with theoretical results indicating how the perturbations\nintroduced by the proposed sampling of basis elements can propagate to the\nappearance of generated images."}, {"title": "RaPP: Novelty Detection with Reconstruction along Projection Pathway", "authors": "Ki Hyun Kim, Sangwoo Shim, Yongsub Lim, Jongseob Jeon, Jeongwoo Choi, Byungchan Kim, Andre S. Yoon"}, {"title": "Logic and the 2-Simplicial Transformer", "authors": "James Clift, Dmitry Doryn, Daniel Murfet, James Wallbridge"}, {"title": "Learning Disentangled Representations for CounterFactual Regression", "authors": "Negar Hassanpour, Russell Greiner"}, {"title": "Training Generative Adversarial Networks from Incomplete Observations using Factorised Discriminators", "authors": "Daniel Stoller, Sebastian Ewert, Simon Dixon", "link": "https://arxiv.org/abs/1905.12660", "summary": "Generative adversarial networks (GANs) have shown great success in\napplications such as image generation and inpainting. However, they typically\nrequire large datasets, which are often not available, especially in the\ncontext of prediction tasks such as image segmentation that require labels.\nTherefore, methods such as the CycleGAN use more easily available unlabelled\ndata, but do not offer a way to leverage additional labelled data for improved\nperformance. To address this shortcoming, we show how to factorise the joint\ndata distribution into a set of lower-dimensional distributions along with\ntheir dependencies. This allows splitting the discriminator in a GAN into\nmultiple \"sub-discriminators\" that can be independently trained from incomplete\nobservations. Their outputs can be combined to estimate the density ratio\nbetween the joint real and the generator distribution, which enables training\ngenerators as in the original GAN framework. We apply our method to image\ngeneration, image segmentation and audio source separation, and obtain improved\nperformance over a standard GAN when additional incomplete training examples\nare available. For the Cityscapes segmentation task in particular, our method\nalso improves accuracy by an absolute 14.9% over CycleGAN while using only 25\nadditional paired examples."}, {"title": "Principled Weight Initialization for Hypernetworks", "authors": "Oscar Chang, Lampros Flokas, Hod Lipson"}, {"title": "LEARNED STEP SIZE QUANTIZATION", "authors": "Steven K. Esser, Jeffrey L. McKinstry, Deepika Bablani, Rathinakumar Appuswamy, Dharmendra S. Modha", "link": "", "summary": ""}, {"title": "A Probabilistic Formulation of Unsupervised Text Style Transfer", "authors": "Junxian He, Xinyi Wang, Graham Neubig, Taylor Berg-Kirkpatrick", "link": "https://arxiv.org/abs/2002.03912", "summary": "We present a deep generative model for unsupervised text style transfer that\nunifies previously proposed non-generative techniques. Our probabilistic\napproach models non-parallel data from two domains as a partially observed\nparallel corpus. By hypothesizing a parallel latent sequence that generates\neach observed sequence, our model learns to transform sequences from one domain\nto another in a completely unsupervised fashion. In contrast with traditional\ngenerative sequence models (e.g. the HMM), our model makes few assumptions\nabout the data it generates: it uses a recurrent language model as a prior and\nan encoder-decoder as a transduction distribution. While computation of\nmarginal data likelihood is intractable in this model class, we show that\namortized variational inference admits a practical surrogate. Further, by\ndrawing connections between our variational objective and other recent\nunsupervised style transfer and machine translation techniques, we show how our\nprobabilistic view can unify some known non-generative objectives such as\nbacktranslation and adversarial loss. Finally, we demonstrate the effectiveness\nof our method on a wide range of unsupervised style transfer tasks, including\nsentiment transfer, formality transfer, word decipherment, author imitation,\nand related language translation. Across all style transfer tasks, our approach\nyields substantial gains over state-of-the-art non-generative baselines,\nincluding the state-of-the-art unsupervised machine translation techniques that\nour approach generalizes. Further, we conduct experiments on a standard\nunsupervised machine translation task and find that our unified approach\nmatches the current state-of-the-art."}, {"title": "Real or Not Real, that is the Question", "authors": "Yuanbo Xiangli, Yubin Deng, Bo Dai, Chen Change Loy, Dahua Lin"}, {"title": "R\u00e9nyi Fair Inference", "authors": "Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, Meisam Razaviyayn", "link": "https://arxiv.org/abs/1906.12005", "summary": "Machine learning algorithms have been increasingly deployed in critical\nautomated decision-making systems that directly affect human lives. When these\nalgorithms are only trained to minimize the training/test error, they could\nsuffer from systematic discrimination against individuals based on their\nsensitive attributes such as gender or race. Recently, there has been a surge\nin machine learning society to develop algorithms for fair machine learning. In\nparticular, many adversarial learning procedures have been proposed to impose\nfairness. Unfortunately, these algorithms either can only impose fairness up to\nfirst-order dependence between the variables, or they lack computational\nconvergence guarantees. In this paper, we use R\\'enyi correlation as a measure\nof fairness of machine learning models and develop a general training framework\nto impose fairness. In particular, we propose a min-max formulation which\nbalances the accuracy and fairness when solved to optimality. For the case of\ndiscrete sensitive attributes, we suggest an iterative algorithm with\ntheoretical convergence guarantee for solving the proposed min-max problem. Our\nalgorithm and analysis are then specialized to fair classification and the fair\nclustering problem under disparate impact doctrine. Finally, the performance of\nthe proposed R\\'enyi fair inference framework is evaluated on Adult and Bank\ndatasets."}, {"title": "A Fair Comparison of Graph Neural Networks for Graph Classification", "authors": "Federico Errica, Marco Podda, Davide Bacciu, Alessio Micheli"}, {"title": "Learning the Arrow of Time for Problems in Reinforcement Learning", "authors": "Nasim Rahaman, Steffen Wolf, Anirudh Goyal, Roman Remme, Yoshua Bengio"}, {"title": "Multiplicative Interactions and Where to Find Them", "authors": "Siddhant M. Jayakumar, Wojciech M. Czarnecki, Jacob Menick, Jonathan Schwarz, Jack Rae, Simon Osindero, Yee Whye Teh, Tim Harley, Razvan Pascanu"}, {"title": "Deep Imitative Models for Flexible Inference, Planning, and Control", "authors": "Nicholas Rhinehart, Rowan McAllister, Sergey Levine", "link": "https://arxiv.org/abs/1810.06544", "summary": "Imitation Learning (IL) is an appealing approach to learn desirable\nautonomous behavior. However, directing IL to achieve arbitrary goals is\ndifficult. In contrast, planning-based algorithms use dynamics models and\nreward functions to achieve goals. Yet, reward functions that evoke desirable\nbehavior are often difficult to specify. In this paper, we propose Imitative\nModels to combine the benefits of IL and goal-directed planning. Imitative\nModels are probabilistic predictive models of desirable behavior able to plan\ninterpretable expert-like trajectories to achieve specified goals. We derive\nfamilies of flexible goal objectives, including constrained goal regions,\nunconstrained goal sets, and energy-based goals. We show that our method can\nuse these objectives to successfully direct behavior. Our method substantially\noutperforms six IL approaches and a planning-based approach in a dynamic\nsimulated autonomous driving task, and is efficiently learned from expert\ndemonstrations without online data collection. We also show our approach is\nrobust to poorly specified goals, such as goals on the wrong side of the road."}, {"title": "Model-based reinforcement learning for biological sequence design", "authors": "Christof Angermueller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, Lucy Colwell"}, {"title": "Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well", "authors": "Vipul Gupta, Santiago Akle Serrano, Dennis DeCoste", "link": "https://arxiv.org/abs/2001.02312", "summary": "We propose Stochastic Weight Averaging in Parallel (SWAP), an algorithm to\naccelerate DNN training. Our algorithm uses large mini-batches to compute an\napproximate solution quickly and then refines it by averaging the weights of\nmultiple models computed independently and in parallel. The resulting models\ngeneralize equally well as those trained with small mini-batches but are\nproduced in a substantially shorter time. We demonstrate the reduction in\ntraining time and the good generalization performance of the resulting models\non the computer vision datasets CIFAR10, CIFAR100, and ImageNet."}, {"title": "Critical initialisation in continuous approximations of binary neural networks", "authors": "George Stamatescu, Federica Gerace, Carlo Lucibello, Ian Fuss, Langford White"}, {"title": "On Robustness of Neural Ordinary Differential Equations", "authors": "Hanshu YAN, Jiawei DU, Vincent TAN, Jiashi FENG", "link": "https://arxiv.org/abs/1910.05513", "summary": "Neural ordinary differential equations (ODEs) have been attracting increasing\nattention in various research domains recently. There have been some works\nstudying optimization issues and approximation capabilities of neural ODEs, but\ntheir robustness is still yet unclear. In this work, we fill this important gap\nby exploring robustness properties of neural ODEs both empirically and\ntheoretically. We first present an empirical study on the robustness of the\nneural ODE-based networks (ODENets) by exposing them to inputs with various\ntypes of perturbations and subsequently investigating the changes of the\ncorresponding outputs. In contrast to conventional convolutional neural\nnetworks (CNNs), we find that the ODENets are more robust against both random\nGaussian perturbations and adversarial attack examples. We then provide an\ninsightful understanding of this phenomenon by exploiting a certain desirable\nproperty of the flow of a continuous-time ODE, namely that integral curves are\nnon-intersecting. Our work suggests that, due to their intrinsic robustness, it\nis promising to use neural ODEs as a basic block for building robust deep\nnetwork models. To further enhance the robustness of vanilla neural ODEs, we\npropose the time-invariant steady neural ODE (TisODE), which regularizes the\nflow on perturbed data via the time-invariant property and the imposition of a\nsteady-state constraint. We show that the TisODE method outperforms vanilla\nneural ODEs and also can work in conjunction with other state-of-the-art\narchitectural methods to build more robust deep networks."}, {"title": "Escaping Saddle Points Faster with Stochastic Momentum", "authors": "Jun-Kun Wang, Chi-Heng Lin, Jacob Abernethy"}, {"title": "Transferable Perturbations of Deep Feature Distributions", "authors": "Nathan Inkawhich, Kevin Liang, Lawrence Carin, Yiran Chen"}, {"title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces", "authors": "Prithviraj Ammanabrolu, Matthew Hausknecht", "link": "https://arxiv.org/abs/2001.08837", "summary": "Interactive Fiction games are text-based simulations in which an agent\ninteracts with the world purely through natural language. They are ideal\nenvironments for studying how to extend reinforcement learning agents to meet\nthe challenges of natural language understanding, partial observability, and\naction generation in combinatorially-large text-based action spaces. We present\nKG-A2C, an agent that builds a dynamic knowledge graph while exploring and\ngenerates actions using a template-based action space. We contend that the dual\nuses of the knowledge graph to reason about game state and to constrain natural\nlanguage generation are the keys to scalable exploration of combinatorially\nlarge natural language actions. Results across a wide variety of IF games show\nthat KG-A2C outperforms current IF agents despite the exponential increase in\naction space size."}, {"title": "Energy-based models for atomic-resolution protein conformations", "authors": "Yilun Du, Joshua Meier, Jerry Ma, Rob Fergus, Alexander Rives", "link": "https://arxiv.org/abs/2004.13167", "summary": "We propose an energy-based model (EBM) of protein conformations that operates\nat atomic scale. The model is trained solely on crystallized protein data. By\ncontrast, existing approaches for scoring conformations use energy functions\nthat incorporate knowledge of physical principles and features that are the\ncomplex product of several decades of research and tuning. To evaluate the\nmodel, we benchmark on the rotamer recovery task, the problem of predicting the\nconformation of a side chain from its context within a protein structure, which\nhas been used to evaluate energy functions for protein design. The model\nachieves performance close to that of the Rosetta energy function, a\nstate-of-the-art method widely used in protein structure prediction and design.\nAn investigation of the model's outputs and hidden representations finds that\nit captures physicochemical properties relevant to protein energy."}, {"title": "Interpretable Complex-Valued Neural Networks for Privacy Protection", "authors": "Liyao Xiang, Hao Zhang, Haotian Ma, Yifan Zhang, Jie Ren, Quanshi Zhang", "link": "https://arxiv.org/abs/1901.09546", "summary": "Previous studies have found that an adversary attacker can often infer\nunintended input information from intermediate-layer features. We study the\npossibility of preventing such adversarial inference, yet without too much\naccuracy degradation. We propose a generic method to revise the neural network\nto boost the challenge of inferring input attributes from features, while\nmaintaining highly accurate outputs. In particular, the method transforms\nreal-valued features into complex-valued ones, in which the input is hidden in\na randomized phase of the transformed features. The knowledge of the phase acts\nlike a key, with which any party can easily recover the output from the\nprocessing result, but without which the party can neither recover the output\nnor distinguish the original input. Preliminary experiments on various datasets\nand network structures have shown that our method significantly diminishes the\nadversary's ability in inferring about the input while largely preserves the\nresulting accuracy."}, {"title": "Neural Policy Gradient Methods: Global Optimality and Rates of Convergence", "authors": "Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang", "link": "https://arxiv.org/abs/1909.01150", "summary": "Policy gradient methods with actor-critic schemes demonstrate tremendous\nempirical successes, especially when the actors and critics are parameterized\nby neural networks. However, it remains less clear whether such \"neural\" policy\ngradient methods converge to globally optimal policies and whether they even\nconverge at all. We answer both the questions affirmatively in the\noverparameterized regime. In detail, we prove that neural natural policy\ngradient converges to a globally optimal policy at a sublinear rate. Also, we\nshow that neural vanilla policy gradient converges sublinearly to a stationary\npoint. Meanwhile, by relating the suboptimality of the stationary points to the\nrepresentation power of neural actor and critic classes, we prove the global\noptimality of all stationary points under mild regularity conditions.\nParticularly, we show that a key to the global optimality and convergence is\nthe \"compatibility\" between the actor and critic, which is ensured by sharing\nneural architectures and random initializations across the actor and critic. To\nthe best of our knowledge, our analysis establishes the first global optimality\nand convergence guarantees for neural policy gradient methods."}, {"title": "A Theoretical Analysis of the Number of Shots in Few-Shot Learning", "authors": "Tianshi Cao, Marc T Law, Sanja Fidler", "link": "https://arxiv.org/abs/1909.11722", "summary": "Few-shot classification is the task of predicting the category of an example\nfrom a set of few labeled examples. The number of labeled examples per category\nis called the number of shots (or shot number). Recent works tackle this task\nthrough meta-learning, where a meta-learner extracts information from observed\ntasks during meta-training to quickly adapt to new tasks during meta-testing.\nIn this formulation, the number of shots exploited during meta-training has an\nimpact on the recognition performance at meta-test time. Generally, the shot\nnumber used in meta-training should match the one used in meta-testing to\nobtain the best performance. We introduce a theoretical analysis of the impact\nof the shot number on Prototypical Networks, a state-of-the-art few-shot\nclassification method. From our analysis, we propose a simple method that is\nrobust to the choice of shot number used during meta-training, which is a\ncrucial hyperparameter. The performance of our model trained for an arbitrary\nmeta-training shot number shows great performance for different values of\nmeta-testing shot numbers. We experimentally demonstrate our approach on\ndifferent few-shot classification benchmarks."}, {"title": "Directional Message Passing for Molecular Graphs", "authors": "Johannes Klicpera, Janek Gro\u00df, Stephan G\u00fcnnemann", "link": "https://arxiv.org/abs/2003.03123", "summary": "Graph neural networks have recently achieved great successes in predicting\nquantum mechanical properties of molecules. These models represent a molecule\nas a graph using only the distance between atoms (nodes). They do not, however,\nconsider the spatial direction from one atom to another, despite directional\ninformation playing a central role in empirical potentials for molecules, e.g.\nin angular potentials. To alleviate this limitation we propose directional\nmessage passing, in which we embed the messages passed between atoms instead of\nthe atoms themselves. Each message is associated with a direction in coordinate\nspace. These directional message embeddings are rotationally equivariant since\nthe associated directions rotate with the molecule. We propose a message\npassing scheme analogous to belief propagation, which uses the directional\ninformation by transforming messages based on the angle between them.\nAdditionally, we use spherical Bessel functions and spherical harmonics to\nconstruct theoretically well-founded, orthogonal representations that achieve\nbetter performance than the currently prevalent Gaussian radial basis\nrepresentations while using fewer than 1/4 of the parameters. We leverage these\ninnovations to construct the directional message passing neural network\n(DimeNet). DimeNet outperforms previous GNNs on average by 76% on MD17 and by\n31% on QM9. Our implementation is available online."}, {"title": "Sub-policy Adaptation for Hierarchical Reinforcement Learning", "authors": "Alexander Li, Carlos Florensa, Ignasi Clavera, Pieter Abbeel", "link": "https://arxiv.org/abs/1906.05862", "summary": "Hierarchical reinforcement learning is a promising approach to tackle\nlong-horizon decision-making problems with sparse rewards. Unfortunately, most\nmethods still decouple the lower-level skill acquisition process and the\ntraining of a higher level that controls the skills in a new task. Leaving the\nskills fixed can lead to significant sub-optimality in the transfer setting. In\nthis work, we propose a novel algorithm to discover a set of skills, and\ncontinuously adapt them along with the higher level even when training on a new\ntask. Our main contributions are two-fold. First, we derive a new hierarchical\npolicy gradient with an unbiased latent-dependent baseline, and we introduce\nHierarchical Proximal Policy Optimization (HiPPO), an on-policy method to\nefficiently train all levels of the hierarchy jointly. Second, we propose a\nmethod for training time-abstractions that improves the robustness of the\nobtained skills to environment changes. Code and results are available at\nsites.google.com/view/hippo-rl"}, {"title": "StructPool: Structured Graph Pooling via Conditional Random Fields", "authors": "Hao Yuan, Shuiwang Ji"}, {"title": "Conservative Uncertainty Estimation By Fitting  Prior Networks", "authors": "Kamil Ciosek, Vincent Fortuin, Ryota Tomioka, Katja Hofmann, Richard Turner"}, {"title": "Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning", "authors": "Dexter R.R. Scobee, S. Shankar Sastry", "link": "https://arxiv.org/abs/1909.05477", "summary": "While most approaches to the problem of Inverse Reinforcement Learning (IRL)\nfocus on estimating a reward function that best explains an expert agent's\npolicy or demonstrated behavior on a control task, it is often the case that\nsuch behavior is more succinctly represented by a simple reward combined with a\nset of hard constraints. In this setting, the agent is attempting to maximize\ncumulative rewards subject to these given constraints on their behavior. We\nreformulate the problem of IRL on Markov Decision Processes (MDPs) such that,\ngiven a nominal model of the environment and a nominal reward function, we seek\nto estimate state, action, and feature constraints in the environment that\nmotivate an agent's behavior. Our approach is based on the Maximum Entropy IRL\nframework, which allows us to reason about the likelihood of an expert agent's\ndemonstrations given our knowledge of an MDP. Using our method, we can infer\nwhich constraints can be added to the MDP to most increase the likelihood of\nobserving these demonstrations. We present an algorithm which iteratively\ninfers the Maximum Likelihood Constraint to best explain observed behavior, and\nwe evaluate its efficacy using both simulated behavior and recorded data of\nhumans navigating around an obstacle."}, {"title": "Neural Stored-program Memory", "authors": "Hung Le, Truyen Tran, Svetha Venkatesh", "link": "https://arxiv.org/abs/1906.08862", "summary": "Neural networks powered with external memory simulate computer behaviors.\nThese models, which use the memory to store data for a neural controller, can\nlearn algorithms and other complex tasks. In this paper, we introduce a new\nmemory to store weights for the controller, analogous to the stored-program\nmemory in modern computer architectures. The proposed model, dubbed Neural\nStored-program Memory, augments current memory-augmented neural networks,\ncreating differentiable machines that can switch programs through time, adapt\nto variable contexts and thus resemble the Universal Turing Machine. A wide\nrange of experiments demonstrate that the resulting machines not only excel in\nclassical algorithmic problems, but also have potential for compositional,\ncontinual, few-shot learning and question-answering tasks."}, {"title": "Batch-shaping for learning conditional channel gated networks", "authors": "Babak Ehteshami Bejnordi, Tijmen Blankevoort, Max Welling"}, {"title": "The Shape of Data: Intrinsic Distance for Data Distributions", "authors": "Anton Tsitsulin, Marina Munkhoeva, Davide Mottin, Panagiotis Karras, Alex Bronstein, Ivan Oseledets, Emmanuel Mueller"}, {"title": "Environmental drivers of systematicity and generalization in a situated agent", "authors": "Felix Hill, Andrew Lampinen, Rosalia Schneider, Stephen Clark, Matthew Botvinick, James L. McClelland, Adam Santoro", "link": "https://arxiv.org/abs/1910.00571", "summary": "The question of whether deep neural networks are good at generalising beyond\ntheir immediate training experience is of critical importance for\nlearning-based approaches to AI. Here, we consider tests of out-of-sample\ngeneralisation that require an agent to respond to never-seen-before\ninstructions by manipulating and positioning objects in a 3D Unity simulated\nroom. We first describe a comparatively generic agent architecture that\nexhibits strong performance on these tests. We then identify three aspects of\nthe training regime and environment that make a significant difference to its\nperformance: (a) the number of object/word experiences in the training set; (b)\nthe visual invariances afforded by the agent's perspective, or frame of\nreference; and (c) the variety of visual input inherent in the perceptual\naspect of the agent's perception. Our findings indicate that the degree of\ngeneralisation that networks exhibit can depend critically on particulars of\nthe environment in which a given task is instantiated. They further suggest\nthat the propensity for neural networks to generalise in systematic ways may\nincrease if, like human children, those networks have access to many frames of\nrichly varying, multi-modal observations as they learn."}, {"title": "Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving", "authors": "Yurong You, Yan Wang, Wei-Lun Chao, Divyansh Garg, Geoff Pleiss, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger", "link": "", "summary": ""}, {"title": "The Early Phase of Neural Network Training", "authors": "Jonathan Frankle, David J. Schwab, Ari S. Morcos", "link": "https://arxiv.org/abs/2002.10365", "summary": "Recent studies have shown that many important aspects of neural network\nlearning take place within the very earliest iterations or epochs of training.\nFor example, sparse, trainable sub-networks emerge (Frankle et al., 2019),\ngradient descent moves into a small subspace (Gur-Ari et al., 2018), and the\nnetwork undergoes a critical period (Achille et al., 2019). Here, we examine\nthe changes that deep neural networks undergo during this early phase of\ntraining. We perform extensive measurements of the network state during these\nearly iterations of training and leverage the framework of Frankle et al.\n(2019) to quantitatively probe the weight distribution and its reliance on\nvarious aspects of the dataset. We find that, within this framework, deep\nnetworks are not robust to reinitializing with random weights while maintaining\nsigns, and that weight distributions are highly non-independent even after only\na few hundred iterations. Despite this behavior, pre-training with blurred\ninputs or an auxiliary self-supervised task can approximate the changes in\nsupervised networks, suggesting that these changes are not inherently\nlabel-dependent, though labels significantly accelerate this process. Together,\nthese results help to elucidate the network changes occurring during this\npivotal initial period of learning."}, {"title": "Pre-training Tasks for Embedding-based Large-scale Retrieval", "authors": "Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar", "link": "https://arxiv.org/abs/2002.03932", "summary": "We consider the large-scale query-document retrieval problem: given a query\n(e.g., a question), return the set of relevant documents (e.g., paragraphs\ncontaining the answer) from a large document corpus. This problem is often\nsolved in two steps. The retrieval phase first reduces the solution space,\nreturning a subset of candidate documents. The scoring phase then re-ranks the\ndocuments. Critically, the retrieval algorithm not only desires high recall but\nalso requires to be highly efficient, returning candidates in time sublinear to\nthe number of documents. Unlike the scoring phase witnessing significant\nadvances recently due to the BERT-style pre-training tasks on cross-attention\nmodels, the retrieval phase remains less well studied. Most previous works rely\non classic Information Retrieval (IR) methods such as BM-25 (token matching +\nTF-IDF weights). These models only accept sparse handcrafted features and can\nnot be optimized for different downstream tasks of interest. In this paper, we\nconduct a comprehensive study on the embedding-based retrieval models. We show\nthat the key ingredient of learning a strong embedding-based Transformer model\nis the set of pre-training tasks. With adequately designed paragraph-level\npre-training tasks, the Transformer models can remarkably improve over the\nwidely-used BM-25 as well as embedding models without Transformers. The\nparagraph-level pre-training tasks we studied are Inverse Cloze Task (ICT),\nBody First Selection (BFS), Wiki Link Prediction (WLP), and the combination of\nall three."}, {"title": "Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN)", "authors": "Peter Sorrenson, Carsten Rother, Ullrich K\u00f6the", "link": "https://arxiv.org/abs/2001.04872", "summary": "A central question of representation learning asks under which conditions it\nis possible to reconstruct the true latent variables of an arbitrarily complex\ngenerative process. Recent breakthrough work by Khemakhem et al. (2019) on\nnonlinear ICA has answered this question for a broad class of conditional\ngenerative processes. We extend this important result in a direction relevant\nfor application to real-world data. First, we generalize the theory to the case\nof unknown intrinsic problem dimension and prove that in some special (but not\nvery restrictive) cases, informative latent variables will be automatically\nseparated from noise by an estimating model. Furthermore, the recovered\ninformative latent variables will be in one-to-one correspondence with the true\nlatent variables of the generating process, up to a trivial component-wise\ntransformation. Second, we introduce a modification of the RealNVP invertible\nneural network architecture (Dinh et al. (2016)) which is particularly suitable\nfor this type of problem: the General Incompressible-flow Network (GIN).\nExperiments on artificial data and EMNIST demonstrate that theoretical\npredictions are indeed verified in practice. In particular, we provide a\ndetailed set of exactly 22 informative latent variables extracted from EMNIST."}, {"title": "Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "link": "https://arxiv.org/abs/1909.12077", "summary": "In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning\nframework which can infer the dynamics of a physical system, given by an\nordinary differential equation (ODE), from observed state trajectories. To\nachieve better generalization with fewer training samples, SymODEN incorporates\nappropriate inductive bias by designing the associated computation graph in a\nphysics-informed manner. In particular, we enforce Hamiltonian dynamics with\ncontrol to learn the underlying dynamics in a transparent way, which can then\nbe leveraged to draw insight about relevant physical aspects of the system,\nsuch as mass and potential energy. In addition, we propose a parametrization\nwhich can enforce this Hamiltonian formalism even when the generalized\ncoordinate data is embedded in a high-dimensional space or we can only access\nvelocity data instead of generalized momentum. This framework, by offering\ninterpretable, physically-consistent models for physical systems, opens up new\npossibilities for synthesizing model-based control strategies."}, {"title": "SNODE: Spectral Discretization of Neural ODEs for System Identification", "authors": "Alessio Quaglino, Marco Gallieri, Jonathan Masci, Jan Koutn\u00edk", "link": "https://arxiv.org/abs/1906.07038", "summary": "This paper proposes the use of spectral element methods\n\\citep{canuto_spectral_1988} for fast and accurate training of Neural Ordinary\nDifferential Equations (ODE-Nets; \\citealp{Chen2018NeuralOD}) for system\nidentification. This is achieved by expressing their dynamics as a truncated\nseries of Legendre polynomials. The series coefficients, as well as the network\nweights, are computed by minimizing the weighted sum of the loss function and\nthe violation of the ODE-Net dynamics. The problem is solved by coordinate\ndescent that alternately minimizes, with respect to the coefficients and the\nweights, two unconstrained sub-problems using standard backpropagation and\ngradient methods. The resulting optimization scheme is fully time-parallel and\nresults in a low memory footprint. Experimental comparison to standard methods,\nsuch as backpropagation through explicit solvers and the adjoint technique\n\\citep{Chen2018NeuralOD}, on training surrogate models of small and\nmedium-scale dynamical systems shows that it is at least one order of magnitude\nfaster at reaching a comparable value of the loss function. The corresponding\ntesting MSE is one order of magnitude smaller as well, suggesting\ngeneralization capabilities increase."}, {"title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning", "authors": "Akanksha Atrey, Kaleigh Clary, David Jensen"}, {"title": "Understanding the Limitations of Conditional Generative Models", "authors": "Ethan Fetaya, Joern-Henrik Jacobsen, Will Grathwohl, Richard Zemel", "link": "https://arxiv.org/abs/1906.01171", "summary": "Class-conditional generative models hold promise to overcome the shortcomings\nof their discriminative counterparts. They are a natural choice to solve\ndiscriminative tasks in a robust manner as they jointly optimize for predictive\nperformance and accurate modeling of the input distribution. In this work, we\ninvestigate robust classification with likelihood-based generative models from\na theoretical and practical perspective to investigate if they can deliver on\ntheir promises. Our analysis focuses on a spectrum of robustness properties:\n(1) Detection of worst-case outliers in the form of adversarial examples; (2)\nDetection of average-case outliers in the form of ambiguous inputs and (3)\nDetection of incorrectly labeled in-distribution inputs. Our theoretical result\nreveals that it is impossible to guarantee detectability of\nadversarially-perturbed inputs even for near-optimal generative classifiers.\nExperimentally, we find that while we are able to train robust models for\nMNIST, robustness completely breaks down on CIFAR10. We relate this failure to\nvarious undesirable model properties that can be traced to the maximum\nlikelihood training objective. Despite being a common choice in the literature,\nour results indicate that likelihood-based conditional generative models may\nare surprisingly ineffective for robust classification."}, {"title": "A Generalized Training Approach for Multiagent Learning", "authors": "Paul Muller, Shayegan Omidshafiei, Mark Rowland, Karl Tuyls, Julien Perolat, Siqi Liu, Daniel Hennes, Luke Marris, Marc Lanctot, Edward Hughes, Zhe Wang, Guy Lever, Nicolas Heess, Thore Graepel, Remi Munos", "link": "https://arxiv.org/abs/1909.12823", "summary": "This paper investigates a population-based training regime based on\ngame-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is\ngeneral in the sense that it (1) encompasses well-known algorithms such as\nfictitious play and double oracle as special cases, and (2) in principle\napplies to general-sum, many-player games. Despite this, prior studies of PSRO\nhave been focused on two-player zero-sum games, a regime wherein Nash\nequilibria are tractably computable. In moving from two-player zero-sum games\nto more general settings, computation of Nash equilibria quickly becomes\ninfeasible. Here, we extend the theoretical underpinnings of PSRO by\nconsidering an alternative solution concept, $\\alpha$-Rank, which is unique\n(thus faces no equilibrium selection issues, unlike Nash) and applies readily\nto general-sum, many-player settings. We establish convergence guarantees in\nseveral games classes, and identify links between Nash equilibria and\n$\\alpha$-Rank. We demonstrate the competitive performance of\n$\\alpha$-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player\nKuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by\nconsidering 3- to 5-player poker games, yielding instances where $\\alpha$-Rank\nachieves faster convergence than approximate Nash solvers, thus establishing it\nas a favorable general games solver. We also carry out an initial empirical\nvalidation in MuJoCo soccer, illustrating the feasibility of the proposed\napproach in another complex domain."}, {"title": "Adversarially Robust Representations with Smooth Encoders", "authors": "Taylan Cemgil, Sumedh Ghaisas, Krishnamurthy (Dj) Dvijotham, Pushmeet Kohli"}, {"title": "Maxmin Q-learning: Controlling the Estimation Bias of Q-learning", "authors": "Qingfeng Lan, Yangchen Pan, Alona Fyshe, Martha White"}, {"title": "Understanding Knowledge Distillation in Non-autoregressive Machine Translation", "authors": "Chunting Zhou, Jiatao Gu, Graham Neubig", "link": "https://arxiv.org/abs/1911.02727", "summary": "Non-autoregressive machine translation (NAT) systems predict a sequence of\noutput tokens in parallel, achieving substantial improvements in generation\nspeed compared to autoregressive models. Existing NAT models usually rely on\nthe technique of knowledge distillation, which creates the training data from a\npretrained autoregressive model for better performance. Knowledge distillation\nis empirically useful, leading to large gains in accuracy for NAT models, but\nthe reason for this success has, as of yet, been unclear. In this paper, we\nfirst design systematic experiments to investigate why knowledge distillation\nis crucial to NAT training. We find that knowledge distillation can reduce the\ncomplexity of data sets and help NAT to model the variations in the output\ndata. Furthermore, a strong correlation is observed between the capacity of an\nNAT model and the optimal complexity of the distilled data for the best\ntranslation quality. Based on these findings, we further propose several\napproaches that can alter the complexity of data sets to improve the\nperformance of NAT models. We achieve the state-of-the-art performance for the\nNAT-based models, and close the gap with the autoregressive baseline on WMT14\nEn-De benchmark."}, {"title": "Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations", "authors": "Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru Zhang"}, {"title": "Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation", "authors": "Yu Chen, Lingfei Wu, Mohammed J. Zaki", "link": "https://arxiv.org/abs/1908.04942", "summary": "Natural question generation (QG) aims to generate questions from a passage\nand an answer. Previous works on QG either (i) ignore the rich structure\ninformation hidden in text, (ii) solely rely on cross-entropy loss that leads\nto issues like exposure bias and inconsistency between train/test measurement,\nor (iii) fail to fully exploit the answer information. To address these\nlimitations, in this paper, we propose a reinforcement learning (RL) based\ngraph-to-sequence (Graph2Seq) model for QG. Our model consists of a Graph2Seq\ngenerator with a novel Bidirectional Gated Graph Neural Network based encoder\nto embed the passage, and a hybrid evaluator with a mixed objective combining\nboth cross-entropy and RL losses to ensure the generation of syntactically and\nsemantically valid text. We also introduce an effective Deep Alignment Network\nfor incorporating the answer information into the passage at both the word and\ncontextual levels. Our model is end-to-end trainable and achieves new\nstate-of-the-art scores, outperforming existing methods by a significant margin\non the standard SQuAD benchmark."}, {"title": "Emergent Tool Use From Multi-Agent Autocurricula", "authors": "Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew, Igor Mordatch", "link": "https://arxiv.org/abs/1909.07528", "summary": "Through multi-agent competition, the simple objective of hide-and-seek, and\nstandard reinforcement learning algorithms at scale, we find that agents create\na self-supervised autocurriculum inducing multiple distinct rounds of emergent\nstrategy, many of which require sophisticated tool use and coordination. We\nfind clear evidence of six emergent phases in agent strategy in our\nenvironment, each of which creates a new pressure for the opposing team to\nadapt; for instance, agents learn to build multi-object shelters using moveable\nboxes which in turn leads to agents discovering that they can overcome\nobstacles using ramps. We further provide evidence that multi-agent competition\nmay scale better with increasing environment complexity and leads to behavior\nthat centers around far more human-relevant skills than other self-supervised\nreinforcement learning methods such as intrinsic motivation. Finally, we\npropose transfer and fine-tuning as a way to quantitatively evaluate targeted\ncapabilities, and we compare hide-and-seek agents to both intrinsic motivation\nand random initialization baselines in a suite of domain-specific intelligence\ntests."}, {"title": "Continual Learning with Adaptive Weights (CLAW)", "authors": "Tameem Adel, Han Zhao, Richard E. Turner"}, {"title": "Learning to Balance: Bayesian Meta-Learning for Imbalanced and Out-of-distribution Tasks", "authors": "Hae Beom Lee, Hayeon Lee, Donghyun Na, Saehoon Kim, Minseop Park, Eunho Yang, Sung Ju Hwang", "link": "https://arxiv.org/abs/1905.12917", "summary": "While tasks could come with varying the number of instances and classes in\nrealistic settings, the existing meta-learning approaches for few-shot\nclassification assume that the number of instances per task and class is fixed.\nDue to such restriction, they learn to equally utilize the meta-knowledge\nacross all the tasks, even when the number of instances per task and class\nlargely varies. Moreover, they do not consider distributional difference in\nunseen tasks, on which the meta-knowledge may have less usefulness depending on\nthe task relatedness. To overcome these limitations, we propose a novel\nmeta-learning model that adaptively balances the effect of the meta-learning\nand task-specific learning within each task. Through the learning of the\nbalancing variables, we can decide whether to obtain a solution by relying on\nthe meta-knowledge or task-specific learning. We formulate this objective into\na Bayesian inference framework and tackle it using variational inference. We\nvalidate our Bayesian Task-Adaptive Meta-Learning (Bayesian TAML) on multiple\nrealistic task- and class-imbalanced datasets, on which it significantly\noutperforms existing meta-learning approaches. Further ablation study confirms\nthe effectiveness of each balancing component and the Bayesian learning\nframework."}, {"title": "A Latent Morphology Model for Open-Vocabulary Neural Machine Translation", "authors": "Duygu Ataman, Wilker Aziz, Alexandra Birch", "link": "https://arxiv.org/abs/1910.13890", "summary": "Translation into morphologically-rich languages challenges neural machine\ntranslation (NMT) models with extremely sparse vocabularies where atomic\ntreatment of surface forms is unrealistic. This problem is typically addressed\nby either pre-processing words into subword units or performing translation\ndirectly at the level of characters. The former is based on word segmentation\nalgorithms optimized using corpus-level statistics with no regard to the\ntranslation task. The latter learns directly from translation data but requires\nrather deep architectures. In this paper, we propose to translate words by\nmodeling word formation through a hierarchical latent variable model which\nmimics the process of morphological inflection. Our model generates words one\ncharacter at a time by composing two latent representations: a continuous one,\naimed at capturing the lexical semantics, and a set of (approximately) discrete\nfeatures, aimed at capturing the morphosyntactic function, which are shared\namong different surface forms. Our model achieves better accuracy in\ntranslation into three morphologically-rich languages than conventional\nopen-vocabulary NMT methods, while also demonstrating a better generalization\ncapacity under low to mid-resource settings."}, {"title": "Scalable Neural Methods for Reasoning With a Symbolic Knowledge   Base", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "link": "https://arxiv.org/abs/2002.06115", "summary": "We describe a novel way of representing a symbolic knowledge base (KB) called\na sparse-matrix reified KB. This representation enables neural modules that are\nfully differentiable, faithful to the original semantics of the KB, expressive\nenough to model multi-hop inferences, and scalable enough to use with\nrealistically large KBs. The sparse-matrix reified KB can be distributed across\nmultiple GPUs, can scale to tens of millions of entities and facts, and is\norders of magnitude faster than naive sparse-matrix implementations. The\nreified KB enables very simple end-to-end architectures to obtain competitive\nperformance on several benchmarks representing two families of tasks: KB\ncompletion, and learning semantic parsers from denotations."}, {"title": "Transferring Optimality Across Data Distributions via Homotopy Methods", "authors": "Matilde Gargiani, Andrea Zanelli, Quoc Tran Dinh, Moritz Diehl, Frank Hutter"}, {"title": "Infinite-horizon Off-Policy Policy Evaluation with Multiple Behavior Policies", "authors": "Xinyun Chen, Lu Wang, Yizhe Hang, Heng Ge, Hongyuan Zha", "link": "https://arxiv.org/abs/1910.04849", "summary": "We consider off-policy policy evaluation when the trajectory data are\ngenerated by multiple behavior policies. Recent work has shown the key role\nplayed by the state or state-action stationary distribution corrections in the\ninfinite horizon context for off-policy policy evaluation. We propose estimated\nmixture policy (EMP), a novel class of partially policy-agnostic methods to\naccurately estimate those quantities. With careful analysis, we show that EMP\ngives rise to estimates with reduced variance for estimating the state\nstationary distribution correction while it also offers a useful induction bias\nfor estimating the state-action stationary distribution correction. In\nextensive experiments with both continuous and discrete environments, we\ndemonstrate that our algorithm offers significantly improved accuracy compared\nto the state-of-the-art methods."}, {"title": "Discovering Motor Programs by Recomposing Demonstrations", "authors": "Tanmay Shankar, Shubham Tulsiani, Lerrel Pinto, Abhinav Gupta"}, {"title": "Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search", "authors": "Anji Liu, Jianshu Chen, Mingze Yu, Yu Zhai, Xuewen Zhou, Ji Liu", "link": "https://arxiv.org/abs/1810.11755", "summary": "Monte Carlo Tree Search (MCTS) algorithms have achieved great success on many\nchallenging benchmarks (e.g., Computer Go). However, they generally require a\nlarge number of rollouts, making their applications costly. Furthermore, it is\nalso extremely challenging to parallelize MCTS due to its inherent sequential\nnature: each rollout heavily relies on the statistics (e.g., node visitation\ncounts) estimated from previous simulations to achieve an effective\nexploration-exploitation tradeoff. In spite of these difficulties, we develop\nan algorithm, WU-UCT, to effectively parallelize MCTS, which achieves linear\nspeedup and exhibits only limited performance loss with an increasing number of\nworkers. The key idea in WU-UCT is a set of statistics that we introduce to\ntrack the number of on-going yet incomplete simulation queries (named as\nunobserved samples). These statistics are used to modify the UCT tree policy in\nthe selection steps in a principled manner to retain effective\nexploration-exploitation tradeoff when we parallelize the most time-consuming\nexpansion and simulation steps. Experiments on a proprietary benchmark and the\nAtari Game benchmark demonstrate the linear speedup and the superior\nperformance of WU-UCT comparing to existing techniques."}, {"title": "Sampling-Free Learning of Bayesian Quantized Neural Networks", "authors": "Jiahao Su, Milan Cvitkovic, Furong Huang", "link": "https://arxiv.org/abs/1912.02992", "summary": "Bayesian learning of model parameters in neural networks is important in\nscenarios where estimates with well-calibrated uncertainty are important. In\nthis paper, we propose Bayesian quantized networks (BQNs), quantized neural\nnetworks (QNNs) for which we learn a posterior distribution over their discrete\nparameters. We provide a set of efficient algorithms for learning and\nprediction in BQNs without the need to sample from their parameters or\nactivations, which not only allows for differentiable learning in QNNs, but\nalso reduces the variance in gradients. We evaluate BQNs on MNIST,\nFashion-MNIST, KMNIST and CIFAR10 image classification datasets, compared\nagainst bootstrap ensemble of QNNs (E-QNN). We demonstrate BQNs achieve both\nlower predictive errors and better-calibrated uncertainties than E-QNN (with\nless than 20% of the negative log-likelihood)."}, {"title": "Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning", "authors": "Arsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, Dmitry Vetrov"}, {"title": "The Break-Even Point on Optimization Trajectories of Deep Neural Networks", "authors": "Stanislaw Jastrzebski, Maciej Szymczak, Stanislav Fort, Devansh Arpit, Jacek Tabor, Kyunghyun Cho, Krzysztof Geras"}, {"title": "A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case", "authors": "Greg Ongie, Rebecca Willett, Daniel Soudry, Nathan Srebro", "link": "https://arxiv.org/abs/1910.01635", "summary": "A key element of understanding the efficacy of overparameterized neural\nnetworks is characterizing how they represent functions as the number of\nweights in the network approaches infinity. In this paper, we characterize the\nnorm required to realize a function $f:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ as a\nsingle hidden-layer ReLU network with an unbounded number of units (infinite\nwidth), but where the Euclidean norm of the weights is bounded, including\nprecisely characterizing which functions can be realized with finite norm. This\nwas settled for univariate univariate functions in Savarese et al. (2019),\nwhere it was shown that the required norm is determined by the L1-norm of the\nsecond derivative of the function. We extend the characterization to\nmultivariate functions (i.e., networks with d input units), relating the\nrequired norm to the L1-norm of the Radon transform of a (d+1)/2-power\nLaplacian of the function. This characterization allows us to show that all\nfunctions in Sobolev spaces $W^{s,1}(\\mathbb{R})$, $s\\geq d+1$, can be\nrepresented with bounded norm, to calculate the required norm for several\nspecific functions, and to obtain a depth separation result. These results have\nimportant implications for understanding generalization performance and the\ndistinction between neural networks and more traditional kernel learning."}, {"title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization", "authors": "Junjie Yan, Ruosi Wan, Xiangyu Zhang, Wei Zhang, Yichen Wei, Jian Sun", "link": "https://arxiv.org/abs/2001.06838", "summary": "Batch Normalization (BN) is one of the most widely used techniques in Deep\nLearning field. But its performance can awfully degrade with insufficient batch\nsize. This weakness limits the usage of BN on many computer vision tasks like\ndetection or segmentation, where batch size is usually small due to the\nconstraint of memory consumption. Therefore many modified normalization\ntechniques have been proposed, which either fail to restore the performance of\nBN completely, or have to introduce additional nonlinear operations in\ninference procedure and increase huge consumption. In this paper, we reveal\nthat there are two extra batch statistics involved in backward propagation of\nBN, on which has never been well discussed before. The extra batch statistics\nassociated with gradients also can severely affect the training of deep neural\nnetwork. Based on our analysis, we propose a novel normalization method, named\nMoving Average Batch Normalization (MABN). MABN can completely restore the\nperformance of vanilla BN in small batch cases, without introducing any\nadditional nonlinear operations in inference procedure. We prove the benefits\nof MABN by both theoretical analysis and experiments. Our experiments\ndemonstrate the effectiveness of MABN in multiple computer vision tasks\nincluding ImageNet and COCO. The code has been released in\nhttps://github.com/megvii-model/MABN."}, {"title": "Geometric Analysis of Nonconvex Optimization Landscapes for Overcomplete Learning", "authors": "Qing Qu, Yuexiang Zhai, Xiao Li, Yuqian Zhang, Zhihui Zhu"}, {"title": "Improving Adversarial Robustness Requires Revisiting Misclassified Examples", "authors": "Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, Quanquan Gu"}, {"title": "FSNet: Compression of Deep Convolutional Neural Networks by Filter Summary", "authors": "Yingzhen Yang, Jiahui Yu, Nebojsa Jojic, Jun Huan, Thomas S. Huang"}, {"title": "Never Give Up: Learning Directed Exploration Strategies", "authors": "Adri\u00e0 Puigdom\u00e8nech Badia, Pablo Sprechmann, Alex Vitvitskyi, Daniel Guo, Bilal Piot, Steven Kapturowski, Olivier Tieleman, Martin Arjovsky, Alexander Pritzel, Andrew Bolt, Charles Blundell", "link": "https://arxiv.org/abs/2002.06038", "summary": "We propose a reinforcement learning agent to solve hard exploration games by\nlearning a range of directed exploratory policies. We construct an episodic\nmemory-based intrinsic reward using k-nearest neighbors over the agent's recent\nexperience to train the directed exploratory policies, thereby encouraging the\nagent to repeatedly revisit all states in its environment. A self-supervised\ninverse dynamics model is used to train the embeddings of the nearest neighbour\nlookup, biasing the novelty signal towards what the agent can control. We\nemploy the framework of Universal Value Function Approximators (UVFA) to\nsimultaneously learn many directed exploration policies with the same neural\nnetwork, with different trade-offs between exploration and exploitation. By\nusing the same neural network for different degrees of\nexploration/exploitation, transfer is demonstrated from predominantly\nexploratory policies yielding effective exploitative policies. The proposed\nmethod can be incorporated to run with modern distributed RL agents that\ncollect large amounts of experience from many actors running in parallel on\nseparate environment instances. Our method doubles the performance of the base\nagent in all hard exploration in the Atari-57 suite while maintaining a very\nhigh score across the remaining games, obtaining a median human normalised\nscore of 1344.0%. Notably, the proposed method is the first algorithm to\nachieve non-zero rewards (with a mean score of 8,400) in the game of Pitfall!\nwithout using demonstrations or hand-crafted features."}, {"title": "Are Transformers universal approximators of sequence-to-sequence functions?", "authors": "Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank Reddi, Sanjiv Kumar"}, {"title": "BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES", "authors": "Amin Ghiasi, Ali Shafahi, Tom Goldstein"}, {"title": "Meta-Learning Deep Energy-Based Memory Models", "authors": "Sergey Bartunov, Jack Rae, Simon Osindero, Timothy Lillicrap", "link": "https://arxiv.org/abs/1910.02720", "summary": "We study the problem of learning associative memory -- a system which is able\nto retrieve a remembered pattern based on its distorted or incomplete version.\nAttractor networks provide a sound model of associative memory: patterns are\nstored as attractors of the network dynamics and associative retrieval is\nperformed by running the dynamics starting from a query pattern until it\nconverges to an attractor. In such models the dynamics are often implemented as\nan optimization procedure that minimizes an energy function, such as in the\nclassical Hopfield network. In general it is difficult to derive a writing rule\nfor a given dynamics and energy that is both compressive and fast. Thus, most\nresearch in energy-based memory has been limited either to tractable energy\nmodels not expressive enough to handle complex high-dimensional objects such as\nnatural images, or to models that do not offer fast writing. We present a novel\nmeta-learning approach to energy-based memory models (EBMM) that allows one to\nuse an arbitrary neural architecture as an energy model and quickly store\npatterns in its weights. We demonstrate experimentally that our EBMM approach\ncan build compressed memories for synthetic and natural data, and is capable of\nassociative retrieval that outperforms existing memory systems in terms of the\nreconstruction error and compression rate."}, {"title": "TabFact: A Large-scale Dataset for Table-based Fact Verification", "authors": "Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, William Yang Wang", "link": "https://arxiv.org/abs/1909.02164", "summary": "The problem of verifying whether a textual hypothesis holds based on the\ngiven evidence, also known as fact verification, plays an important role in the\nstudy of natural language understanding and semantic representation. However,\nexisting studies are mainly restricted to dealing with unstructured evidence\n(e.g., natural language sentences and documents, news, etc), while verification\nunder structured evidence, such as tables, graphs, and databases, remains\nunder-explored. This paper specifically aims to study the fact verification\ngiven semi-structured data as evidence. To this end, we construct a large-scale\ndataset called TabFact with 16k Wikipedia tables as the evidence for 118k\nhuman-annotated natural language statements, which are labeled as either\nENTAILED or REFUTED. TabFact is challenging since it involves both soft\nlinguistic reasoning and hard symbolic reasoning. To address these reasoning\nchallenges, we design two different models: Table-BERT and Latent Program\nAlgorithm (LPA). Table-BERT leverages the state-of-the-art pre-trained language\nmodel to encode the linearized tables and statements into continuous vectors\nfor verification. LPA parses statements into programs and executes them against\nthe tables to obtain the returned binary value for verification. Both methods\nachieve similar accuracy but still lag far behind human performance. We also\nperform a comprehensive analysis to demonstrate great future opportunities. The\ndata and code of the dataset are provided in\n\\url{https://github.com/wenhuchen/Table-Fact-Checking}."}, {"title": "FSPool: Learning Set Representations with Featurewise Sort Pooling", "authors": "Yan Zhang, Jonathon Hare, Adam Pr\u00fcgel-Bennett", "link": "https://arxiv.org/abs/1906.02795", "summary": "Traditional set prediction models can struggle with simple datasets due to an\nissue we call the responsibility problem. We introduce a pooling method for\nsets of feature vectors based on sorting features across elements of the set.\nThis can be used to construct a permutation-equivariant auto-encoder that\navoids this responsibility problem. On a toy dataset of polygons and a set\nversion of MNIST, we show that such an auto-encoder produces considerably\nbetter reconstructions and representations. Replacing the pooling function in\nexisting set encoders with FSPool improves accuracy and convergence speed on a\nvariety of datasets."}, {"title": "Reinforced active learning for image segmentation", "authors": "Arantxa Casanova, Pedro O. Pinheiro, Negar Rostamzadeh, Christopher J. Pal", "link": "https://arxiv.org/abs/2002.06583", "summary": "Learning-based approaches for semantic segmentation have two inherent\nchallenges. First, acquiring pixel-wise labels is expensive and time-consuming.\nSecond, realistic segmentation datasets are highly unbalanced: some categories\nare much more abundant than others, biasing the performance to the most\nrepresented ones. In this paper, we are interested in focusing human labelling\neffort on a small subset of a larger pool of data, minimizing this effort while\nmaximizing performance of a segmentation model on a hold-out set. We present a\nnew active learning strategy for semantic segmentation based on deep\nreinforcement learning (RL). An agent learns a policy to select a subset of\nsmall informative image regions -- opposed to entire images -- to be labeled,\nfrom a pool of unlabeled data. The region selection decision is made based on\npredictions and uncertainties of the segmentation model being trained. Our\nmethod proposes a new modification of the deep Q-network (DQN) formulation for\nactive learning, adapting it to the large-scale nature of semantic segmentation\nproblems. We test the proof of concept in CamVid and provide results in the\nlarge-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN\napproach requires roughly 30% less additional labeled data than our most\ncompetitive baseline to reach the same performance. Moreover, we find that our\nmethod asks for more labels of under-represented categories compared to the\nbaselines, improving their performance and helping to mitigate class imbalance."}, {"title": "A Stochastic Derivative Free Optimization Method with Momentum", "authors": "Eduard Gorbunov, Adel Bibi, Ozan Sener, El Houcine Bergou, Peter Richtarik", "link": "http://arxiv.org/abs/1905.13278", "summary": "We consider the problem of unconstrained minimization of a smooth objective\nfunction in $\\mathbb{R}^d$ in setting where only function evaluations are\npossible. We propose and analyze stochastic zeroth-order method with heavy ball\nmomentum. In particular, we propose, SMTP, a momentum version of the stochastic\nthree-point method (STP) \\cite{Bergou_2018}. We show new complexity results for\nnon-convex, convex and strongly convex functions. We test our method on a\ncollection of learning to continuous control tasks on several MuJoCo\n\\cite{Todorov_2012} environments with varying difficulty and compare against\nSTP, other state-of-the-art derivative-free optimization algorithms and against\npolicy gradient methods. SMTP significantly outperforms STP and all other\nmethods that we considered in our numerical experiments. Our second\ncontribution is SMTP with importance sampling which we call SMTP_IS. We provide\nconvergence analysis of this method for non-convex, convex and strongly convex\nobjectives."}, {"title": "FasterSeg: Searching for Faster Real-time Semantic Segmentation", "authors": "Wuyang Chen, Xinyu Gong, Xianming Liu, Qian Zhang, Yuan Li, Zhangyang Wang", "link": "https://arxiv.org/abs/1912.10917", "summary": "We present FasterSeg, an automatically designed semantic segmentation network\nwith not only state-of-the-art performance but also faster speed than current\nmethods. Utilizing neural architecture search (NAS), FasterSeg is discovered\nfrom a novel and broader search space integrating multi-resolution branches,\nthat has been recently found to be vital in manually designed segmentation\nmodels. To better calibrate the balance between the goals of high accuracy and\nlow latency, we propose a decoupled and fine-grained latency regularization,\nthat effectively overcomes our observed phenomenons that the searched networks\nare prone to \"collapsing\" to low-latency yet poor-accuracy models. Moreover, we\nseamlessly extend FasterSeg to a new collaborative search (co-searching)\nframework, simultaneously searching for a teacher and a student network in the\nsame single run. The teacher-student distillation further boosts the student\nmodel's accuracy. Experiments on popular segmentation benchmarks demonstrate\nthe competency of FasterSeg. For example, FasterSeg can run over 30% faster\nthan the closest manually designed competitor on Cityscapes, while maintaining\ncomparable accuracy."}, {"title": "Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks", "authors": "Tianyu Pang, Kun Xu, Jun Zhu", "link": "https://arxiv.org/abs/1909.11515", "summary": "It has been widely recognized that adversarial examples can be easily crafted\nto fool deep networks, which mainly root from the locally non-linear behavior\nnearby input examples. Applying mixup in training provides an effective\nmechanism to improve generalization performance and model robustness against\nadversarial perturbations, which introduces the globally linear behavior\nin-between training examples. However, in previous work, the mixup-trained\nmodels only passively defend adversarial attacks in inference by directly\nclassifying the inputs, where the induced global linearity is not well\nexploited. Namely, since the locality of the adversarial perturbations, it\nwould be more efficient to actively break the locality via the globality of the\nmodel predictions. Inspired by simple geometric intuition, we develop an\ninference principle, named mixup inference (MI), for mixup-trained models. MI\nmixups the input with other random clean samples, which can shrink and transfer\nthe equivalent perturbation if the input is adversarial. Our experiments on\nCIFAR-10 and CIFAR-100 demonstrate that MI can further improve the adversarial\nrobustness for the models trained by mixup and its variants."}, {"title": "Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees", "authors": "Binghong Chen, Bo Dai, Qinjie Lin, Guo Ye, Han Liu, Le Song"}, {"title": "Difference-Seeking Generative Adversarial Network--Unseen Sample Generation", "authors": "Yi Lin Sung, Sung-Hsien Hsieh, Soo-Chang Pei, Chun-Shien Lu"}, {"title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations", "authors": "Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai", "link": "https://arxiv.org/abs/1908.08530", "summary": "We introduce a new pre-trainable generic representation for visual-linguistic\ntasks, called Visual-Linguistic BERT (VL-BERT for short). VL-BERT adopts the\nsimple yet powerful Transformer model as the backbone, and extends it to take\nboth visual and linguistic embedded features as input. In it, each element of\nthe input is either of a word from the input sentence, or a region-of-interest\n(RoI) from the input image. It is designed to fit for most of the\nvisual-linguistic downstream tasks. To better exploit the generic\nrepresentation, we pre-train VL-BERT on the massive-scale Conceptual Captions\ndataset, together with text-only corpus. Extensive empirical analysis\ndemonstrates that the pre-training procedure can better align the\nvisual-linguistic clues and benefit the downstream tasks, such as visual\ncommonsense reasoning, visual question answering and referring expression\ncomprehension. It is worth noting that VL-BERT achieved the first place of\nsingle model on the leaderboard of the VCR benchmark. Code is released at\n\\url{https://github.com/jackroos/VL-BERT}."}, {"title": "Spectral  Embedding of Regularized Block Models", "authors": "Nathan De Lara, Thomas Bonald", "link": "https://arxiv.org/abs/1912.10903", "summary": "Spectral embedding is a popular technique for the representation of graph\ndata. Several regularization techniques have been proposed to improve the\nquality of the embedding with respect to downstream tasks like clustering. In\nthis paper, we explain on a simple block model the impact of the complete graph\nregularization, whereby a constant is added to all entries of the adjacency\nmatrix. Specifically, we show that the regularization forces the spectral\nembedding to focus on the largest blocks, making the representation less\nsensitive to noise or outliers. We illustrate these results on both on both\nsynthetic and real data, showing how regularization improves standard\nclustering scores."}, {"title": "Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning", "authors": "Gil Lederman, Markus Rabe, Sanjit Seshia, Edward A. Lee", "link": "https://arxiv.org/abs/1807.08058", "summary": "We demonstrate how to learn efficient heuristics for automated reasoning\nalgorithms for quantified Boolean formulas through deep reinforcement learning.\nWe focus on a backtracking search algorithm, which can already solve formulas\nof impressive size - up to hundreds of thousands of variables. The main\nchallenge is to find a representation of these formulas that lends itself to\nmaking predictions in a scalable way. For a family of challenging problems, we\nlearned a heuristic that solves significantly more formulas compared to the\nexisting handwritten heuristics."}, {"title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators", "authors": "Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning"}, {"title": "Knowledge Consistency between Neural Networks and Beyond", "authors": "Ruofan Liang, Tianlin Li, Longfei Li, Jing Wang, Quanshi Zhang", "link": "https://arxiv.org/abs/1908.01581", "summary": "This paper aims to analyze knowledge consistency between pre-trained deep\nneural networks. We propose a generic definition for knowledge consistency\nbetween neural networks at different fuzziness levels. A task-agnostic method\nis designed to disentangle feature components, which represent the consistent\nknowledge, from raw intermediate-layer features of each neural network. As a\ngeneric tool, our method can be broadly used for different applications. In\npreliminary experiments, we have used knowledge consistency as a tool to\ndiagnose representations of neural networks. Knowledge consistency provides new\ninsights to explain the success of existing deep-learning techniques, such as\nknowledge distillation and network compression. More crucially, knowledge\nconsistency can also be used to refine pre-trained networks and boost\nperformance."}, {"title": "Few-shot Text Classification with Distributional Signatures", "authors": "Yujia Bao, Menghua Wu, Shiyu Chang, Regina Barzilay", "link": "https://arxiv.org/abs/1908.06039", "summary": "In this paper, we explore meta-learning for few-shot text classification.\nMeta-learning has shown strong performance in computer vision, where low-level\npatterns are transferable across learning tasks. However, directly applying\nthis approach to text is challenging--lexical features highly informative for\none task may be insignificant for another. Thus, rather than learning solely\nfrom words, our model also leverages their distributional signatures, which\nencode pertinent word occurrence patterns. Our model is trained within a\nmeta-learning framework to map these signatures into attention scores, which\nare then used to weight the lexical representations of words. We demonstrate\nthat our model consistently outperforms prototypical networks learned on\nlexical knowledge (Snell et al., 2017) in both few-shot text classification and\nrelation classification by a significant margin across six benchmark datasets\n(20.0% on average in 1-shot classification)."}, {"title": "Deep Audio Priors Emerge From Harmonic Convolutional Networks", "authors": "Zhoutong Zhang, Yunyun Wang, Chuang Gan, Jiajun Wu, Joshua B. Tenenbaum, Antonio Torralba, William T. Freeman"}, {"title": "Adversarial Lipschitz Regularization", "authors": "D\u00e1vid Terj\u00e9k", "link": "https://arxiv.org/abs/1907.05681", "summary": "Generative adversarial networks (GANs) are one of the most popular approaches\nwhen it comes to training generative models, among which variants of\nWasserstein GANs are considered superior to the standard GAN formulation in\nterms of learning stability and sample quality. However, Wasserstein GANs\nrequire the critic to be 1-Lipschitz, which is often enforced implicitly by\npenalizing the norm of its gradient, or by globally restricting its Lipschitz\nconstant via weight normalization techniques. Training with a regularization\nterm penalizing the violation of the Lipschitz constraint explicitly, instead\nof through the norm of the gradient, was found to be practically infeasible in\nmost situations. Inspired by Virtual Adversarial Training, we propose a method\ncalled Adversarial Lipschitz Regularization, and show that using an explicit\nLipschitz penalty is indeed viable and leads to competitive performance when\napplied to Wasserstein GANs, highlighting an important connection between\nLipschitz regularization and adversarial training."}, {"title": "Variational Recurrent Models for Solving Partially Observable Control Tasks", "authors": "Dongqi Han, Kenji Doya, Jun Tani"}, {"title": "Stable Rank Normalization for Improved Generalization in Neural Networks and GANs", "authors": "Amartya Sanyal, Philip H. Torr, Puneet K. Dokania", "link": "https://arxiv.org/abs/1906.04659", "summary": "Exciting new work on the generalization bounds for neural networks (NN) given\nby Neyshabur et al. , Bartlett et al. closely depend on two\nparameter-depenedent quantities: the Lipschitz constant upper-bound and the\nstable rank (a softer version of the rank operator). This leads to an\ninteresting question of whether controlling these quantities might improve the\ngeneralization behaviour of NNs. To this end, we propose stable rank\nnormalization (SRN), a novel, optimal, and computationally efficient\nweight-normalization scheme which minimizes the stable rank of a linear\noperator. Surprisingly we find that SRN, inspite of being non-convex problem,\ncan be shown to have a unique optimal solution. Moreover, we show that SRN\nallows control of the data-dependent empirical Lipschitz constant, which in\ncontrast to the Lipschitz upper-bound, reflects the true behaviour of a model\non a given dataset. We provide thorough analyses to show that SRN, when applied\nto the linear layers of a NN for classification, provides striking\nimprovements-11.3% on the generalization gap compared to the standard NN along\nwith significant reduction in memorization. When applied to the discriminator\nof GANs (called SRN-GAN) it improves Inception, FID, and Neural divergence\nscores on the CIFAR 10/100 and CelebA datasets, while learning mappings with\nlow empirical Lipschitz constants."}, {"title": "Extreme Classification via Adversarial Softmax Approximation", "authors": "Robert Bamler, Stephan Mandt"}, {"title": "Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks", "authors": "Yuhang Li, Xin Dong, Wei Wang", "link": "http://arxiv.org/abs/1909.13144", "summary": "We propose Additive Powers-of-Two~(APoT) quantization, an efficient\nnon-uniform quantization scheme for the bell-shaped and long-tailed\ndistribution of weights and activations in neural networks. By constraining all\nquantization levels as the sum of Powers-of-Two terms, APoT quantization enjoys\nhigh computational efficiency and a good match with the distribution of\nweights. A simple reparameterization of the clipping function is applied to\ngenerate a better-defined gradient for learning the clipping threshold.\nMoreover, weight normalization is presented to refine the distribution of\nweights to make the training more stable and consistent. Experimental results\nshow that our proposed method outperforms state-of-the-art methods, and is even\ncompetitive with the full-precision models, demonstrating the effectiveness of\nour proposed APoT quantization. For example, our 4-bit quantized ResNet-50 on\nImageNet achieves 76.6% top-1 accuracy without bells and whistles; meanwhile,\nour model reduces 22% computational cost compared with the uniformly quantized\ncounterpart. The code is available at\nhttps://github.com/yhhhli/APoT_Quantization."}, {"title": "Identifying through Flows for Recovering Latent Representations", "authors": "Shen Li, Bryan Hooi, Gim Hee Lee", "link": "https://arxiv.org/abs/1909.12555", "summary": "Identifiability, or recovery of the true latent representations from which\nthe observed data originates, is de facto a fundamental goal of representation\nlearning. Yet, most deep generative models do not address the question of\nidentifiability, and thus fail to deliver on the promise of the recovery of the\ntrue latent sources that generate the observations. Recent work proposed\nidentifiable generative modelling using variational autoencoders (iVAE) with a\ntheory of identifiability. Due to the intractablity of KL divergence between\nvariational approximate posterior and the true posterior, however, iVAE has to\nmaximize the evidence lower bound (ELBO) of the marginal likelihood, leading to\nsuboptimal solutions in both theory and practice. In contrast, we propose an\nidentifiable framework for estimating latent representations using a flow-based\nmodel (iFlow). Our approach directly maximizes the marginal likelihood,\nallowing for theoretical guarantees on identifiability, thereby dispensing with\nvariational approximations. We derive its optimization objective in analytical\nform, making it possible to train iFlow in an end-to-end manner. Simulations on\nsynthetic data validate the correctness and effectiveness of our proposed\nmethod and demonstrate its practical advantages over other existing methods."}, {"title": "Frequency-based Search-control in Dyna", "authors": "Yangchen Pan, Jincheng Mei, Amir-massoud Farahmand"}, {"title": "Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games", "authors": "Zuyue Fu, Zhuoran Yang, Yongxin Chen, Zhaoran Wang", "link": "https://arxiv.org/abs/1910.07498", "summary": "We study discrete-time mean-field Markov games with infinite numbers of\nagents where each agent aims to minimize its ergodic cost. We consider the\nsetting where the agents have identical linear state transitions and quadratic\ncost functions, while the aggregated effect of the agents is captured by the\npopulation mean of their states, namely, the mean-field state. For such a game,\nbased on the Nash certainty equivalence principle, we provide sufficient\nconditions for the existence and uniqueness of its Nash equilibrium. Moreover,\nto find the Nash equilibrium, we propose a mean-field actor-critic algorithm\nwith linear function approximation, which does not require knowing the model of\ndynamics. Specifically, at each iteration of our algorithm, we use the\nsingle-agent actor-critic algorithm to approximately obtain the optimal policy\nof the each agent given the current mean-field state, and then update the\nmean-field state. In particular, we prove that our algorithm converges to the\nNash equilibrium at a linear rate. To the best of our knowledge, this is the\nfirst success of applying model-free reinforcement learning with function\napproximation to discrete-time mean-field Markov games with provable\nnon-asymptotic global convergence guarantees."}, {"title": "Decoding As Dynamic Programming For Recurrent Autoregressive Models", "authors": "Najam Zaidi, Trevor Cohn, Gholamreza Haffari"}, {"title": "Disentangling neural mechanisms for perceptual grouping", "authors": "Junkyung Kim, Drew Linsley, Kalpit Thakkar, Thomas Serre", "link": "https://arxiv.org/abs/1906.01558", "summary": "Forming perceptual groups and individuating objects in visual scenes is an\nessential step towards visual intelligence. This ability is thought to arise in\nthe brain from computations implemented by bottom-up, horizontal, and top-down\nconnections between neurons. However, the relative contributions of these\nconnections to perceptual grouping are poorly understood. We address this\nquestion by systematically evaluating neural network architectures featuring\ncombinations of these connections on two synthetic visual tasks, which stress\nlow-level `gestalt' vs. high-level object cues for perceptual grouping. We show\nthat increasing the difficulty of either task strains learning for networks\nthat rely solely on bottom-up processing. Horizontal connections resolve this\nlimitation on tasks with gestalt cues by supporting incremental spatial\npropagation of activities, whereas top-down connections rescue learning on\ntasks featuring object cues by propagating coarse predictions about the\nposition of the target object. Our findings disassociate the computational\nroles of bottom-up, horizontal and top-down connectivity, and demonstrate how a\nmodel featuring all of these interactions can more flexibly learn to form\nperceptual groups."}, {"title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": "Karl Schulz, Leon Sixt, Federico Tombari, Tim Landgraf"}, {"title": "Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks", "authors": "Ziwei Ji, Matus Telgarsky", "link": "https://arxiv.org/abs/1909.12292", "summary": "Recent theoretical work has guaranteed that overparameterized networks\ntrained by gradient descent achieve arbitrarily low training error, and\nsometimes even low test error. The required width, however, is always\npolynomial in at least one of the sample size $n$, the (inverse) target error\n$1/\\epsilon$, and the (inverse) failure probability $1/\\delta$. This work shows\nthat $\\widetilde{\\Theta}(1/\\epsilon)$ iterations of gradient descent with\n$\\widetilde{\\Omega}(1/\\epsilon^2)$ training examples on two-layer ReLU networks\nof any width exceeding $\\mathrm{polylog}(n,1/\\epsilon,1/\\delta)$ suffice to\nachieve a test misclassification error of $\\epsilon$. We also prove that\nstochastic gradient descent can achieve $\\epsilon$ test error with\npolylogarithmic width and $\\widetilde{\\Theta}(1/\\epsilon)$ samples. The\nanalysis relies upon the separation margin of the limiting kernel, which is\nguaranteed positive, can distinguish between true labels and random labels, and\ncan give a tight sample-complexity analysis in the infinite-width setting"}, {"title": "Controlling generative models with continuous factors of variations", "authors": "Antoine Plumerault, Herv\u00e9 Le Borgne, C\u00e9line Hudelot", "link": "https://arxiv.org/abs/2001.10238", "summary": "Recent deep generative models are able to provide photo-realistic images as\nwell as visual or textual content embeddings useful to address various tasks of\ncomputer vision and natural language processing. Their usefulness is\nnevertheless often limited by the lack of control over the generative process\nor the poor understanding of the learned representation. To overcome these\nmajor issues, very recent work has shown the interest of studying the semantics\nof the latent space of generative models. In this paper, we propose to advance\non the interpretability of the latent space of generative models by introducing\na new method to find meaningful directions in the latent space of any\ngenerative model along which we can move to control precisely specific\nproperties of the generated image like the position or scale of the object in\nthe image. Our method does not require human annotations and is particularly\nwell suited for the search of directions encoding simple transformations of the\ngenerated image, such as translation, zoom or color variations. We demonstrate\nthe effectiveness of our method qualitatively and quantitatively, both for GANs\nand variational auto-encoders."}, {"title": "Residual Energy-Based Models for Text Generation", "authors": "Yuntian Deng, Anton Bakhtin, Myle Ott, Arthur Szlam, Marc'Aurelio Ranzato"}, {"title": "The Curious Case of Neural Text Degeneration", "authors": "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi", "link": "https://arxiv.org/abs/1904.09751", "summary": "Despite considerable advancements with deep neural language models, the\nenigma of neural text degeneration persists when these models are tested as\ntext generators. The counter-intuitive empirical observation is that even\nthough the use of likelihood as training objective leads to high quality models\nfor a broad range of language understanding tasks, using likelihood as a\ndecoding objective leads to text that is bland and strangely repetitive.\n  In this paper, we reveal surprising distributional differences between human\ntext and machine text. In addition, we find that decoding strategies alone can\ndramatically effect the quality of machine text, even when generated from\nexactly the same neural language model. Our findings motivate Nucleus Sampling,\na simple but effective method to draw the best out of neural generation. By\nsampling text from the dynamic nucleus of the probability distribution, which\nallows for diversity while effectively truncating the less reliable tail of the\ndistribution, the resulting text better demonstrates the quality of human text,\nyielding enhanced diversity without sacrificing fluency and coherence."}, {"title": "Compressive Transformers for Long-Range Sequence Modelling", "authors": "Jack W. Rae, Anna Potapenko, Siddhant M. Jayakumar, Chloe Hillier, Timothy P. Lillicrap"}, {"title": "Learning from Explanations with Neural Execution Tree", "authors": "Ziqi Wang, Yujia Qin, Wenxuan Zhou, Jun Yan, Qinyuan Ye, Leonardo Neves, Zhiyuan Liu, Xiang Ren"}, {"title": "DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures", "authors": "Huanrui Yang, Wei Wen, Hai Li", "link": "https://arxiv.org/abs/1908.09979", "summary": "In seeking for sparse and efficient neural network models, many previous\nworks investigated on enforcing L1 or L0 regularizers to encourage weight\nsparsity during training. The L0 regularizer measures the parameter sparsity\ndirectly and is invariant to the scaling of parameter values, but it cannot\nprovide useful gradients, and therefore requires complex optimization\ntechniques. The L1 regularizer is almost everywhere differentiable and can be\neasily optimized with gradient descent. Yet it is not scale-invariant, causing\nthe same shrinking rate to all parameters, which is inefficient in increasing\nsparsity. Inspired by the Hoyer measure (the ratio between L1 and L2 norms)\nused in traditional compressed sensing problems, we present DeepHoyer, a set of\nsparsity-inducing regularizers that are both differentiable almost everywhere\nand scale-invariant. Our experiments show that enforcing DeepHoyer regularizers\ncan produce even sparser neural network models than previous works, under the\nsame accuracy level. We also show that DeepHoyer can be applied to both\nelement-wise and structural pruning."}, {"title": "On Generalization Error Bounds of Noisy Gradient Methods for Non-Convex Learning", "authors": "Jian Li, Xuanyuan Luo, Mingda Qiao", "link": "https://arxiv.org/abs/1902.00621", "summary": "Generalization error (also known as the out-of-sample error) measures how\nwell the hypothesis learned from training data generalizes to previously unseen\ndata. Proving tight generalization error bounds is a central question in\nstatistical learning theory. In this paper, we obtain generalization error\nbounds for learning general non-convex objectives, which has attracted\nsignificant attention in recent years. We develop a new framework, termed\nBayes-Stability, for proving algorithm-dependent generalization error bounds.\nThe new framework combines ideas from both the PAC-Bayesian theory and the\nnotion of algorithmic stability. Applying the Bayes-Stability method, we obtain\nnew data-dependent generalization bounds for stochastic gradient Langevin\ndynamics (SGLD) and several other noisy gradient methods (e.g., with momentum,\nmini-batch and acceleration, Entropy-SGD). Our result recovers (and is\ntypically tighter than) a recent result in Mou et al. (2018) and improves upon\nthe results in Pensia et al. (2018). Our experiments demonstrate that our\ndata-dependent bounds can distinguish randomly labelled data from normal data,\nwhich provides an explanation to the intriguing phenomena observed in Zhang et\nal. (2017a). We also study the setting where the total loss is the sum of a\nbounded loss and an additional \\ell_2 regularization term. We obtain new\ngeneralization bounds for the continuous Langevin dynamic in this setting by\ndeveloping a new Log-Sobolev inequality for the parameter distribution at any\ntime. Our new bounds are more desirable when the noisy level of the process is\nnot small, and do not become vacuous even when T tends to infinity."}, {"title": "Implementing Inductive bias for different navigation tasks through diverse RNN attrractors", "authors": "Tie XU, Omri Barak"}, {"title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples", "authors": "Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, Hugo Larochelle", "link": "https://arxiv.org/abs/1903.03096", "summary": "Few-shot classification refers to learning a classifier for new classes given\nonly a few examples. While a plethora of models have emerged to tackle it, we\nfind the procedure and datasets that are used to assess their progress lacking.\nTo address this limitation, we propose Meta-Dataset: a new benchmark for\ntraining and evaluating models that is large-scale, consists of diverse\ndatasets, and presents more realistic tasks. We experiment with popular\nbaselines and meta-learners on Meta-Dataset, along with a competitive method\nthat we propose. We analyze performance as a function of various\ncharacteristics of test tasks and examine the models' ability to leverage\ndiverse training sources for improving their generalization. We also propose a\nnew set of baselines for quantifying the benefit of meta-learning in\nMeta-Dataset. Our extensive experimentation has uncovered important research\nchallenges and we hope to inspire work in these directions."}, {"title": "Estimating Gradients for Discrete Random Variables by Sampling without Replacement", "authors": "Wouter Kool, Herke van Hoof, Max Welling", "link": "https://arxiv.org/abs/2002.06043", "summary": "We derive an unbiased estimator for expectations over discrete random\nvariables based on sampling without replacement, which reduces variance as it\navoids duplicate samples. We show that our estimator can be derived as the\nRao-Blackwellization of three different estimators. Combining our estimator\nwith REINFORCE, we obtain a policy gradient estimator and we reduce its\nvariance using a built-in control variate which is obtained without additional\nmodel evaluations. The resulting estimator is closely related to other gradient\nestimators. Experiments with a toy problem, a categorical Variational\nAuto-Encoder and a structured prediction problem show that our estimator is the\nonly estimator that is consistently among the best estimators in both high and\nlow entropy settings."}, {"title": "MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius", "authors": "Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh, Liwei Wang", "link": "https://arxiv.org/abs/2001.02378", "summary": "Adversarial training is one of the most popular ways to learn robust models\nbut is usually attack-dependent and time costly. In this paper, we propose the\nMACER algorithm, which learns robust models without using adversarial training\nbut performs better than all existing provable l2-defenses. Recent work shows\nthat randomized smoothing can be used to provide a certified l2 radius to\nsmoothed classifiers, and our algorithm trains provably robust smoothed\nclassifiers via MAximizing the CErtified Radius (MACER). The attack-free\ncharacteristic makes MACER faster to train and easier to optimize. In our\nexperiments, we show that our method can be applied to modern deep neural\nnetworks on a wide range of datasets, including Cifar-10, ImageNet, MNIST, and\nSVHN. For all tasks, MACER spends less training time than state-of-the-art\nadversarial training algorithms, and the learned models achieve larger average\ncertified radius."}, {"title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": "Fabien Baradel, Natalia Neverova, Julien Mille, Greg Mori, Christian Wolf", "link": "https://arxiv.org/abs/1909.12000", "summary": "Understanding causes and effects in mechanical systems is an essential\ncomponent of reasoning in the physical world. This work poses a new problem of\ncounterfactual learning of object mechanics from visual input. We develop the\nCoPhy benchmark to assess the capacity of the state-of-the-art models for\ncausal physical reasoning in a synthetic 3D environment and propose a model for\nlearning the physical dynamics in a counterfactual setting. Having observed a\nmechanical experiment that involves, for example, a falling tower of blocks, a\nset of bouncing balls or colliding objects, we learn to predict how its outcome\nis affected by an arbitrary intervention on its initial conditions, such as\ndisplacing one of the objects in the scene. The alternative future is predicted\ngiven the altered past and a latent representation of the confounders learned\nby the model in an end-to-end fashion with no supervision. We compare against\nfeedforward video prediction baselines and show how observing alternative\nexperiences allows the network to capture latent physical properties of the\nenvironment, which results in significantly more accurate predictions at the\nlevel of super human performance."}, {"title": "Neural Machine Translation with Universal Visual Representation", "authors": "Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao Li, Hai Zhao"}, {"title": "Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models", "authors": "Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang", "link": "https://arxiv.org/abs/1909.11299", "summary": "In natural language processing, it has been observed recently that\ngeneralization could be greatly improved by finetuning a large-scale language\nmodel pretrained on a large unlabeled corpus. Despite its recent success and\nwide adoption, finetuning a large pretrained language model on a downstream\ntask is prone to degenerate performance when there are only a small number of\ntraining instances available. In this paper, we introduce a new regularization\ntechnique, to which we refer as \"mixout\", motivated by dropout. Mixout\nstochastically mixes the parameters of two models. We show that our mixout\ntechnique regularizes learning to minimize the deviation from one of the two\nmodels and that the strength of regularization adapts along the optimization\ntrajectory. We empirically evaluate the proposed mixout and its variants on\nfinetuning a pretrained language model on downstream tasks. More specifically,\nwe demonstrate that the stability of finetuning and the average accuracy\ngreatly increase when we use the proposed approach to regularize finetuning of\nBERT on downstream tasks in GLUE."}, {"title": "AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures", "authors": "Michael S. Ryoo, AJ Piergiovanni, Mingxing Tan, Anelia Angelova", "link": "https://arxiv.org/abs/1905.13209", "summary": "Learning to represent videos is a very challenging task both algorithmically\nand computationally. Standard video CNN architectures have been designed by\ndirectly extending architectures devised for image understanding to include the\ntime dimension, using modules such as 3D convolutions, or by using two-stream\ndesign to capture both appearance and motion in videos. We interpret a video\nCNN as a collection of multi-stream convolutional blocks connected to each\nother, and propose the approach of automatically finding neural architectures\nwith better connectivity and spatio-temporal interactions for video\nunderstanding. This is done by evolving a population of overly-connected\narchitectures guided by connection weight learning. Architectures combining\nrepresentations that abstract different input types (i.e., RGB and optical\nflow) at multiple temporal resolutions are searched for, allowing different\ntypes or sources of information to interact with each other. Our method,\nreferred to as AssembleNet, outperforms prior approaches on public video\ndatasets, in some cases by a great margin. We obtain 58.6% mAP on Charades and\n34.27% accuracy on Moments-in-Time."}, {"title": "GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation", "authors": "Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, Jian Tang", "link": "https://arxiv.org/abs/2001.09382", "summary": "Molecular graph generation is a fundamental problem for drug discovery and\nhas been attracting growing attention. The problem is challenging since it\nrequires not only generating chemically valid molecular structures but also\noptimizing their chemical properties in the meantime. Inspired by the recent\nprogress in deep generative models, in this paper we propose a flow-based\nautoregressive model for graph generation called GraphAF. GraphAF combines the\nadvantages of both autoregressive and flow-based approaches and enjoys: (1)\nhigh model flexibility for data density estimation; (2) efficient parallel\ncomputation for training; (3) an iterative sampling process, which allows\nleveraging chemical domain knowledge for valency checking. Experimental results\nshow that GraphAF is able to generate 68% chemically valid molecules even\nwithout chemical knowledge rules and 100% valid molecules with chemical rules.\nThe training process of GraphAF is two times faster than the existing\nstate-of-the-art approach GCPN. After fine-tuning the model for goal-directed\nproperty optimization with reinforcement learning, GraphAF achieves\nstate-of-the-art performance on both chemical property optimization and\nconstrained property optimization."}, {"title": "Fair Resource Allocation in Federated Learning", "authors": "Tian Li, Maziar Sanjabi, Ahmad Beirami, Virginia Smith", "link": "http://arxiv.org/abs/1905.10497", "summary": "Federated learning involves training statistical models in massive,\nheterogeneous networks. Naively minimizing an aggregate loss function in such a\nnetwork may disproportionately advantage or disadvantage some of the devices.\nIn this work, we propose q-Fair Federated Learning (q-FFL), a novel\noptimization objective inspired by fair resource allocation in wireless\nnetworks that encourages a more fair (specifically, a more uniform) accuracy\ndistribution across devices in federated networks. To solve q-FFL, we devise a\ncommunication-efficient method, q-FedAvg, that is suited to federated networks.\nWe validate both the effectiveness of q-FFL and the efficiency of q-FedAvg on a\nsuite of federated datasets with both convex and non-convex models, and show\nthat q-FFL (along with q-FedAvg) outperforms existing baselines in terms of the\nresulting fairness, flexibility, and efficiency."}, {"title": "Simplified Action Decoder for Deep Multi-Agent Reinforcement Learning", "authors": "Hengyuan Hu, Jakob N Foerster", "link": "https://arxiv.org/abs/1912.02288", "summary": "In recent years we have seen fast progress on a number of benchmark problems\nin AI, with modern methods achieving near or super human performance in Go,\nPoker and Dota. One common aspect of all of these challenges is that they are\nby design adversarial or, technically speaking, zero-sum. In contrast to these\nsettings, success in the real world commonly requires humans to collaborate and\ncommunicate with others, in settings that are, at least partially, cooperative.\nIn the last year, the card game Hanabi has been established as a new benchmark\nenvironment for AI to fill this gap. In particular, Hanabi is interesting to\nhumans since it is entirely focused on theory of mind, i.e., the ability to\neffectively reason over the intentions, beliefs and point of view of other\nagents when observing their actions. Learning to be informative when observed\nby others is an interesting challenge for Reinforcement Learning (RL):\nFundamentally, RL requires agents to explore in order to discover good\npolicies. However, when done naively, this randomness will inherently make\ntheir actions less informative to others during training. We present a new deep\nmulti-agent RL method, the Simplified Action Decoder (SAD), which resolves this\ncontradiction exploiting the centralized training phase. During training SAD\nallows other agents to not only observe the (exploratory) action chosen, but\nagents instead also observe the greedy action of their team mates. By combining\nthis simple intuition with best practices for multi-agent learning, SAD\nestablishes a new SOTA for learning methods for 2-5 players on the self-play\npart of the Hanabi challenge. Our ablations show the contributions of SAD\ncompared with the best practice components. All of our code and trained agents\nare available at https://github.com/facebookresearch/Hanabi_SAD."}, {"title": "Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation", "authors": "Nitin Rathi, Gopalakrishnan Srinivasan, Priyadarshini Panda, Kaushik Roy"}, {"title": "Gradients as Features for Deep Representation Learning", "authors": "Fangzhou Mu, Yingyu Liang, Yin Li"}, {"title": "Hamiltonian Generative Networks", "authors": "Peter Toth, Danilo J. Rezende, Andrew Jaegle, S\u00e9bastien Racani\u00e8re, Aleksandar Botev, Irina Higgins", "link": "https://arxiv.org/abs/1909.13789", "summary": "The Hamiltonian formalism plays a central role in classical and quantum\nphysics. Hamiltonians are the main tool for modelling the continuous time\nevolution of systems with conserved quantities, and they come equipped with\nmany useful properties, like time reversibility and smooth interpolation in\ntime. These properties are important for many machine learning problems - from\nsequence prediction to reinforcement learning and density modelling - but are\nnot typically provided out of the box by standard tools such as recurrent\nneural networks. In this paper, we introduce the Hamiltonian Generative Network\n(HGN), the first approach capable of consistently learning Hamiltonian dynamics\nfrom high-dimensional observations (such as images) without restrictive domain\nassumptions. Once trained, we can use HGN to sample new trajectories, perform\nrollouts both forward and backward in time and even speed up or slow down the\nlearned dynamics. We demonstrate how a simple modification of the network\narchitecture turns HGN into a powerful normalising flow model, called Neural\nHamiltonian Flow (NHF), that uses Hamiltonian dynamics to model expressive\ndensities. We hope that our work serves as a first practical demonstration of\nthe value that the Hamiltonian formalism can bring to deep learning."}, {"title": "Compositional languages emerge in a neural iterated learning model", "authors": "Yi Ren, Shangmin Guo, Matthieu Labeau, Shay B. Cohen, Simon Kirby", "link": "https://arxiv.org/abs/2002.01365", "summary": "The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication."}, {"title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization", "authors": "Daniel Golovin, John Karro, Greg Kochanski, Chansoo Lee, Xingyou Song, Qiuyi Zhang", "link": "https://arxiv.org/abs/1911.06317", "summary": "Zeroth-order optimization is the process of minimizing an objective $f(x)$,\ngiven oracle access to evaluations at adaptively chosen inputs $x$. In this\npaper, we present two simple yet powerful GradientLess Descent (GLD) algorithms\nthat do not rely on an underlying gradient estimate and are numerically stable.\nWe analyze our algorithm from a novel geometric perspective and present a novel\nanalysis that shows convergence within an $\\epsilon$-ball of the optimum in\n$O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, for any monotone transform of a\nsmooth and strongly convex objective with latent dimension $k < n$, where the\ninput dimension is $n$, $R$ is the diameter of the input space and $Q$ is the\ncondition number. Our rates are the first of its kind to be both 1)\npoly-logarithmically dependent on dimensionality and 2) invariant under\nmonotone transformations. We further leverage our geometric perspective to show\nthat our analysis is optimal. Both monotone invariance and its ability to\nutilize a low latent dimensionality are key to the empirical success of our\nalgorithms, as demonstrated on BBOB and MuJoCo benchmarks."}, {"title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": "Hae Beom Lee, Taewook Nam, Eunho Yang, Sung Ju Hwang", "link": "https://arxiv.org/abs/1905.12914", "summary": "A machine learning model that generalizes well should obtain low errors on\nunseen test examples. Thus, if we know how to optimally perturb training\nexamples to account for test examples, we may achieve better generalization\nperformance. However, obtaining such perturbation is not possible in standard\nmachine learning frameworks as the distribution of the test data is unknown. To\ntackle this challenge, we propose a novel regularization method, meta-dropout,\nwhich learns to perturb the latent features of training examples for\ngeneralization in a meta-learning framework. Specifically, we meta-learn a\nnoise generator which outputs a multiplicative noise distribution for latent\nfeatures, to obtain low errors on the test instances in an input-dependent\nmanner. Then, the learned noise generator can perturb the training examples of\nunseen tasks at the meta-test time for improved generalization. We validate our\nmethod on few-shot classification datasets, whose results show that it\nsignificantly improves the generalization performance of the base model, and\nlargely outperforms existing regularization methods such as information\nbottleneck, manifold mixup, and information dropout."}, {"title": "Ranking Policy Gradient", "authors": "Kaixiang Lin, Jiayu Zhou", "link": "https://arxiv.org/abs/1906.09674", "summary": "Sample inefficiency is a long-lasting problem in reinforcement learning (RL).\nThe state-of-the-art estimates the optimal action values while it usually\ninvolves an extensive search over the state-action space and unstable\noptimization. Towards the sample-efficient RL, we propose ranking policy\ngradient (RPG), a policy gradient method that learns the optimal rank of a set\nof discrete actions. To accelerate the learning of policy gradient methods, we\nestablish the equivalence between maximizing the lower bound of return and\nimitating a near-optimal policy without accessing any oracles. These results\nlead to a general off-policy learning framework, which preserves the\noptimality, reduces variance, and improves the sample-efficiency. Furthermore,\nthe sample complexity of RPG does not depend on the dimension of state space,\nwhich enables RPG for large-scale problems. We conduct extensive experiments\nshowing that when consolidating with the off-policy learning framework, RPG\nsubstantially reduces the sample complexity, comparing to the state-of-the-art."}, {"title": "CATER: A diagnostic dataset for Compositional Actions & TEmporal Reasoning", "authors": "Rohit Girdhar, Deva Ramanan", "link": "https://arxiv.org/abs/1910.04744", "summary": "Computer vision has undergone a dramatic revolution in performance, driven in\nlarge part through deep features trained on large-scale supervised datasets.\nHowever, much of these improvements have focused on static image analysis;\nvideo understanding has seen rather modest improvements. Even though new\ndatasets and spatiotemporal models have been proposed, simple frame-by-frame\nclassification methods often still remain competitive. We posit that current\nvideo datasets are plagued with implicit biases over scene and object structure\nthat can dwarf variations in temporal structure. In this work, we build a video\ndataset with fully observable and controllable object and scene bias, and which\ntruly requires spatiotemporal understanding in order to be solved. Our dataset,\nnamed CATER, is rendered synthetically using a library of standard 3D objects,\nand tests the ability to recognize compositions of object movements that\nrequire long-term reasoning. In addition to being a challenging dataset, CATER\nalso provides a plethora of diagnostic tools to analyze modern spatiotemporal\nvideo architectures by being completely observable and controllable. Using\nCATER, we provide insights into some of the most recent state of the art deep\nvideo architectures."}, {"title": "On the Equivalence between Positional Node Embeddings and Structural Graph Representations", "authors": "Balasubramaniam Srinivasan, Bruno Ribeiro"}, {"title": "Ridge Regression: Structure, Cross-Validation, and Sketching", "authors": "Sifan Liu, Edgar Dobriban", "link": "https://arxiv.org/abs/1910.02373", "summary": "We study the following three fundamental problems about ridge regression: (1)\nwhat is the structure of the estimator? (2) how to correctly use\ncross-validation to choose the regularization parameter? and (3) how to\naccelerate computation without losing too much accuracy? We consider the three\nproblems in a unified large-data linear model. We give a precise representation\nof ridge regression as a covariance matrix-dependent linear combination of the\ntrue parameter and the noise. We study the bias of $K$-fold cross-validation\nfor choosing the regularization parameter, and propose a simple\nbias-correction. We analyze the accuracy of primal and dual sketching for ridge\nregression, showing they are surprisingly accurate. Our results are illustrated\nby simulations and by analyzing empirical data."}, {"title": "Differentiable learning of numerical rules in knowledge graphs", "authors": "Po-Wei Wang, Daria Stepanova, Csaba Domokos, J. Zico Kolter"}, {"title": "AMRL: Aggregated Memory For Reinforcement Learning", "authors": "Jacob Beck, Kamil Ciosek, Sam Devlin, Sebastian Tschiatschek, Cheng Zhang, Katja Hofmann"}, {"title": "Memory-Based Graph Networks", "authors": "Amir Hosein Khasahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Quaid Morris"}, {"title": "Understanding Generalization in Recurrent Neural Networks", "authors": "Zhuozhuo Tu, Fengxiang He, Dacheng Tao"}, {"title": "Locality and Compositionality in Zero-Shot Learning", "authors": "Tristan Sylvain, Linda Petrini, Devon Hjelm", "link": "https://arxiv.org/abs/1912.12179", "summary": "In this work we study locality and compositionality in the context of\nlearning representations for Zero Shot Learning (ZSL). In order to well-isolate\nthe importance of these properties in learned representations, we impose the\nadditional constraint that, differently from most recent work in ZSL, no\npre-training on different datasets (e.g. ImageNet) is performed. The results of\nour experiments show how locality, in terms of small parts of the input, and\ncompositionality, i.e. how well can the learned representations be expressed as\na function of a smaller vocabulary, are both deeply related to generalization\nand motivate the focus on more local-aware models in future research directions\nfor representation learning."}, {"title": "Ensemble Distribution Distillation", "authors": "Andrey Malinin, Bruno Mlodozeniec, Mark Gales", "link": "https://arxiv.org/abs/1905.00076", "summary": "Ensembles of models often yield improvements in system performance. These\nensemble approaches have also been empirically shown to yield robust measures\nof uncertainty, and are capable of distinguishing between different\n\\emph{forms} of uncertainty. However, ensembles come at a computational and\nmemory cost which may be prohibitive for many applications. There has been\nsignificant work done on the distillation of an ensemble into a single model.\nSuch approaches decrease computational cost and allow a single model to achieve\nan accuracy comparable to that of an ensemble. However, information about the\n\\emph{diversity} of the ensemble, which can yield estimates of different forms\nof uncertainty, is lost. This work considers the novel task of \\emph{Ensemble\nDistribution Distillation} (EnD$^2$) --- distilling the distribution of the\npredictions from an ensemble, rather than just the average prediction, into a\nsingle model. EnD$^2$ enables a single model to retain both the improved\nclassification performance of ensemble distillation as well as information\nabout the diversity of the ensemble, which is useful for uncertainty\nestimation. A solution for EnD$^2$ based on Prior Networks, a class of models\nwhich allow a single neural network to explicitly model a distribution over\noutput distributions, is proposed in this work. The properties of EnD$^2$ are\ninvestigated on both an artificial dataset, and on the CIFAR-10, CIFAR-100 and\nTinyImageNet datasets, where it is shown that EnD$^2$ can approach the\nclassification performance of an ensemble, and outperforms both standard DNNs\nand Ensemble Distillation on the tasks of misclassification and\nout-of-distribution input detection."}, {"title": "Unpaired Point Cloud Completion on Real Scans using Adversarial Training", "authors": "Xuelin Chen, Baoquan Chen, Niloy J. Mitra", "link": "https://arxiv.org/abs/1904.00069", "summary": "As 3D scanning solutions become increasingly popular, several deep learning\nsetups have been developed geared towards that task of scan completion, i.e.,\nplausibly filling in regions there were missed in the raw scans. These methods,\nhowever, largely rely on supervision in the form of paired training data, i.e.,\npartial scans with corresponding desired completed scans. While these methods\nhave been successfully demonstrated on synthetic data, the approaches cannot be\ndirectly used on real scans in absence of suitable paired training data. We\ndevelop a first approach that works directly on input point clouds, does not\nrequire paired training data, and hence can directly be applied to real scans\nfor scan completion. We evaluate the approach qualitatively on several\nreal-world datasets (ScanNet, Matterport, KITTI), quantitatively on 3D-EPN\nshape completion benchmark dataset, and demonstrate realistic completions under\nvarying levels of incompleteness."}, {"title": "NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search", "authors": "Xuanyi Dong, Yi Yang", "link": "https://arxiv.org/abs/2001.00326", "summary": "Neural architecture search (NAS) has achieved breakthrough success in a great\nnumber of applications in the past few years. It could be time to take a step\nback and analyze the good and bad aspects in the field of NAS. A variety of\nalgorithms search architectures under different search space. These searched\narchitectures are trained using different setups, e.g., hyper-parameters, data\naugmentation, regularization. This raises a comparability problem when\ncomparing the performance of various NAS algorithms. NAS-Bench-101 has shown\nsuccess to alleviate this problem. In this work, we propose an extension to\nNAS-Bench-101: NAS-Bench-201 with a different search space, results on multiple\ndatasets, and more diagnostic information. NAS-Bench-201 has a fixed search\nspace and provides a unified benchmark for almost any up-to-date NAS\nalgorithms. The design of our search space is inspired from the one used in the\nmost popular cell-based searching algorithms, where a cell is represented as a\nDAG. Each edge here is associated with an operation selected from a predefined\noperation set. For it to be applicable for all NAS algorithms, the search space\ndefined in NAS-Bench-201 includes all possible architectures generated by 4\nnodes and 5 associated operation options, which results in 15,625 candidates in\ntotal. The training log and the performance for each architecture candidate are\nprovided for three datasets. This allows researchers to avoid unnecessary\nrepetitive training for selected candidate and focus solely on the search\nalgorithm itself. The training time saved for every candidate also largely\nimproves the efficiency of many methods. We provide additional diagnostic\ninformation such as fine-grained loss and accuracy, which can give inspirations\nto new designs of NAS algorithms. In further support, we have analyzed it from\nmany aspects and benchmarked 10 recent NAS algorithms."}, {"title": "Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML", "authors": "Aniruddh Raghu, Maithra Raghu, Samy Bengio, Oriol Vinyals", "link": "https://arxiv.org/abs/1909.09157", "summary": "An important research direction in machine learning has centered around\ndeveloping meta-learning algorithms to tackle few-shot learning. An especially\nsuccessful algorithm has been Model Agnostic Meta-Learning (MAML), a method\nthat consists of two optimization loops, with the outer loop finding a\nmeta-initialization, from which the inner loop can efficiently learn new tasks.\nDespite MAML's popularity, a fundamental open question remains -- is the\neffectiveness of MAML due to the meta-initialization being primed for rapid\nlearning (large, efficient changes in the representations) or due to feature\nreuse, with the meta initialization already containing high quality features?\nWe investigate this question, via ablation studies and analysis of the latent\nrepresentations, finding that feature reuse is the dominant factor. This leads\nto the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we\nremove the inner loop for all but the (task-specific) head of a MAML-trained\nnetwork. ANIL matches MAML's performance on benchmark few-shot image\nclassification and RL and offers computational improvements over MAML. We\nfurther study the precise contributions of the head and body of the network,\nshowing that performance on the test tasks is entirely determined by the\nquality of the learned features, and we can remove even the head of the network\n(the NIL algorithm). We conclude with a discussion of the rapid learning vs\nfeature reuse question for meta-learning algorithms more broadly."}, {"title": "Dynamic Time Lag Regression: Predicting What & When", "authors": "Mandar Chandorkar, Cyril Furtlehner, Bala Poduval, Enrico Camporeale, Michele Sebag"}, {"title": "From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech", "authors": "Hyeong-Seok Choi, Changdae Park, Kyogu Lee"}, {"title": "Distributed Bandit Learning: Near-Optimal Regret with Efficient Communication", "authors": "Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, Liwei Wang", "link": "https://arxiv.org/abs/1904.06309", "summary": "We study the problem of regret minimization for distributed bandits learning,\nin which $M$ agents work collaboratively to minimize their total regret under\nthe coordination of a central server. Our goal is to design communication\nprotocols with near-optimal regret and little communication cost, which is\nmeasured by the total amount of transmitted data. For distributed multi-armed\nbandits, we propose a protocol with near-optimal regret and only $O(M\\log(MK))$\ncommunication cost, where $K$ is the number of arms. The communication cost is\nindependent of the time horizon $T$, has only logarithmic dependence on the\nnumber of arms, and matches the lower bound except for a logarithmic factor.\nFor distributed $d$-dimensional linear bandits, we propose a protocol that\nachieves near-optimal regret and has communication cost of order\n$\\tilde{O}(Md)$, which has only logarithmic dependence on $T$."}, {"title": "Smooth markets: A basic mechanism for organizing gradient-based learners", "authors": "David Balduzzi, Wojciech M. Czarnecki, Tom Anthony, Ian Gemp, Edward Hughes, Joel Leibo, Georgios Piliouras, Thore Graepel", "link": "https://arxiv.org/abs/2001.04678", "summary": "With the success of modern machine learning, it is becoming increasingly\nimportant to understand and control how learning algorithms interact.\nUnfortunately, negative results from game theory show there is little hope of\nunderstanding or controlling general n-player games. We therefore introduce\nsmooth markets (SM-games), a class of n-player games with pairwise zero sum\ninteractions. SM-games codify a common design pattern in machine learning that\nincludes (some) GANs, adversarial training, and other recent algorithms. We\nshow that SM-games are amenable to analysis and optimization using first-order\nmethods."}, {"title": "LambdaNet: Probabilistic Type Inference using Graph Neural Networks", "authors": "Jiayi Wei, Maruth Goyal, Greg Durrett, Isil Dillig"}, {"title": "Program Guided Agent", "authors": "Shao-Hua Sun, Te-Lin Wu, Joseph J. Lim"}, {"title": "AtomNAS: Fine-Grained End-to-End Neural Architecture Search", "authors": "Jieru Mei, Yingwei Li, Xiaochen Lian, Xiaojie Jin, Linjie Yang, Alan Yuille, Jianchao Yang", "link": "https://arxiv.org/abs/1912.09640", "summary": "Search space design is very critical to neural architecture search (NAS)\nalgorithms. We propose a fine-grained search space comprised of atomic blocks,\na minimal search unit that is much smaller than the ones used in recent NAS\nalgorithms. This search space allows a mix of operations by composing different\ntypes of atomic blocks, while the search space in previous methods only allows\nhomogeneous operations. Based on this search space, we propose a resource-aware\narchitecture search framework which automatically assigns the computational\nresources (e.g., output channel numbers) for each operation by jointly\nconsidering the performance and the computational cost. In addition, to\naccelerate the search process, we propose a dynamic network shrinkage technique\nwhich prunes the atomic blocks with negligible influence on outputs on the fly.\nInstead of a search-and-retrain two-stage paradigm, our method simultaneously\nsearches and trains the target architecture. Our method achieves\nstate-of-the-art performance under several FLOPs configurations on ImageNet\nwith a small searching cost. We open our entire codebase at:\nhttps://github.com/meijieru/AtomNAS."}, {"title": "SUMO: Unbiased Estimation of Log Marginal Probability for Latent Variable Models", "authors": "Yucen Luo, Alex Beatson, Mohammad Norouzi, Jun Zhu, David Duvenaud, Ryan P. Adams, Ricky T. Q. Chen"}, {"title": "Your classifier is secretly an energy based model and you should treat it like one", "authors": "Will Grathwohl, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, Kevin Swersky", "link": "https://arxiv.org/abs/1912.03263", "summary": "We propose to reinterpret a standard discriminative classifier of p(y|x) as\nan energy based model for the joint distribution p(x,y). In this setting, the\nstandard class probabilities can be easily computed as well as unnormalized\nvalues of p(x) and p(x|y). Within this framework, standard discriminative\narchitectures may beused and the model can also be trained on unlabeled data.\nWe demonstrate that energy based training of the joint distribution improves\ncalibration, robustness, andout-of-distribution detection while also enabling\nour models to generate samplesrivaling the quality of recent GAN approaches. We\nimprove upon recently proposed techniques for scaling up the training of energy\nbased models and presentan approach which adds little overhead compared to\nstandard classification training. Our approach is the first to achieve\nperformance rivaling the state-of-the-artin both generative and discriminative\nlearning within one hybrid model."}, {"title": "On the Convergence of FedAvg on Non-IID Data", "authors": "Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, Zhihua Zhang", "link": "", "summary": ""}, {"title": "White Noise Analysis of Neural Networks", "authors": "Ali Borji, Sikun Lin", "link": "https://arxiv.org/abs/1912.12106", "summary": "A white noise analysis of modern deep neural networks is presented to unveil\ntheir biases at the whole network level or the single neuron level. Our\nanalysis is based on two popular and related methods in psychophysics and\nneurophysiology namely classification images and spike triggered analysis.\nThese methods have been widely used to understand the underlying mechanisms of\nsensory systems in humans and monkeys. We leverage them to investigate the\ninherent biases of deep neural networks and to obtain a first-order\napproximation of their functionality. We emphasize on CNNs since they are\ncurrently the state of the art methods in computer vision and are a decent\nmodel of human visual processing. In addition, we study multi-layer\nperceptrons, logistic regression, and recurrent neural networks. Experiments\nover four classic datasets, MNIST, Fashion-MNIST, CIFAR-10, and ImageNet, show\nthat the computed bias maps resemble the target classes and when used for\nclassification lead to an over twofold performance than the chance level.\nFurther, we show that classification images can be used to attack a black-box\nclassifier and to detect adversarial patch attacks. Finally, we utilize spike\ntriggered averaging to derive the filters of CNNs and explore how the behavior\nof a network changes when neurons in different layers are modulated. Our effort\nillustrates a successful example of borrowing from neurosciences to study ANNs\nand highlights the importance of cross-fertilization and synergy across machine\nlearning, deep learning, and computational neuroscience."}, {"title": "Deep Symbolic Superoptimization Without Human Knowledge", "authors": "Hui Shi, Yang Zhang, Xinyun Chen, Yuandong Tian, Jishen Zhao"}, {"title": "Dream to Control: Learning Behaviors by Latent Imagination", "authors": "Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi", "link": "https://arxiv.org/abs/1912.01603", "summary": "Learned world models summarize an agent's experience to facilitate learning\ncomplex behaviors. While learning world models from high-dimensional sensory\ninputs is becoming feasible through deep learning, there are many potential\nways for deriving behaviors from them. We present Dreamer, a reinforcement\nlearning agent that solves long-horizon tasks from images purely by latent\nimagination. We efficiently learn behaviors by propagating analytic gradients\nof learned state values back through trajectories imagined in the compact state\nspace of a learned world model. On 20 challenging visual control tasks, Dreamer\nexceeds existing approaches in data-efficiency, computation time, and final\nperformance."}, {"title": "Weakly Supervised Disentanglement with Guarantees", "authors": "Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, Ben Poole", "link": "https://arxiv.org/abs/1910.09772", "summary": "Learning disentangled representations that correspond to factors of variation\nin real-world data is critical to interpretable and human-controllable machine\nlearning. Recently, concerns about the viability of learning disentangled\nrepresentations in a purely unsupervised manner has spurred a shift toward the\nincorporation of weak supervision. However, there is currently no formalism\nthat identifies when and how weak supervision will guarantee disentanglement.\nTo address this issue, we provide a theoretical framework to assist in\nanalyzing the disentanglement guarantees (or lack thereof) conferred by weak\nsupervision when coupled with learning algorithms based on distribution\nmatching. We empirically verify the guarantees and limitations of several weak\nsupervision methods (restricted labeling, match-pairing, and rank-pairing),\ndemonstrating the predictive power and usefulness of our theoretical framework."}, {"title": "Making Efficient Use of Demonstrations to Solve Hard Exploration Problems", "authors": "Caglar Gulcehre, Tom Le Paine, Bobak Shahriari, Misha Denil, Matt Hoffman, Hubert Soyer, Richard Tanburn, Steven Kapturowski, Neil Rabinowitz, Duncan Williams, Gabriel Barth-Maron, Ziyu Wang, Nando de Freitas, Worlds Team", "link": "https://arxiv.org/abs/1909.01387", "summary": "This paper introduces R2D3, an agent that makes efficient use of\ndemonstrations to solve hard exploration problems in partially observable\nenvironments with highly variable initial conditions. We also introduce a suite\nof eight tasks that combine these three properties, and show that R2D3 can\nsolve several of the tasks where other state of the art methods (both with and\nwithout demonstrations) fail to see even a single successful trajectory after\ntens of billions of steps of exploration."}, {"title": "Contrastive Learning of Structured World Models", "authors": "Thomas Kipf, Elise van der Pol, Max Welling", "link": "https://arxiv.org/abs/1911.12247", "summary": "A structured understanding of our world in terms of objects, relations, and\nhierarchies is an important component of human cognition. Learning such a\nstructured world model from raw sensory data remains a challenge. As a step\ntowards this goal, we introduce Contrastively-trained Structured World Models\n(C-SWMs). C-SWMs utilize a contrastive approach for representation learning in\nenvironments with compositional structure. We structure each state embedding as\na set of object representations and their relations, modeled by a graph neural\nnetwork. This allows objects to be discovered from raw pixel observations\nwithout direct supervision as part of the learning process. We evaluate C-SWMs\non compositional environments involving multiple interacting objects that can\nbe manipulated independently by an agent, simple Atari games, and a\nmulti-object physics simulation. Our experiments demonstrate that C-SWMs can\novercome limitations of models based on pixel reconstruction and outperform\ntypical representatives of this model class in highly structured environments,\nwhile learning interpretable object-based representations."}, {"title": "Adaptive Structural Fingerprints for Graph Attention Networks", "authors": "Kai Zhang, Yaokang Zhu, Jun Wang, Jie Zhang"}, {"title": "Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning", "authors": "Qian Long, Zihan Zhou, Abhinav Gupta, Fei Fang, Yi Wu\u2020, Xiaolong Wang\u2020", "link": "https://arxiv.org/abs/2003.10423", "summary": "In multi-agent games, the complexity of the environment can grow\nexponentially as the number of agents increases, so it is particularly\nchallenging to learn good policies when the agent population is large. In this\npaper, we introduce Evolutionary Population Curriculum (EPC), a curriculum\nlearning paradigm that scales up Multi-Agent Reinforcement Learning (MARL) by\nprogressively increasing the population of training agents in a stage-wise\nmanner. Furthermore, EPC uses an evolutionary approach to fix an objective\nmisalignment issue throughout the curriculum: agents successfully trained in an\nearly stage with a small population are not necessarily the best candidates for\nadapting to later stages with scaled populations. Concretely, EPC maintains\nmultiple sets of agents in each stage, performs mix-and-match and fine-tuning\nover these sets and promotes the sets of agents with the best adaptability to\nthe next stage. We implement EPC on a popular MARL algorithm, MADDPG, and\nempirically show that our approach consistently outperforms baselines by a\nlarge margin as the number of agents grows exponentially."}, {"title": "Efficient and Information-Preserving Future Frame Prediction and Beyond", "authors": "Wei Yu, Yichao Lu, Steve Easterbrook, Sanja Fidler"}, {"title": "Fantastic Generalization Measures and Where to Find Them", "authors": "Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, Samy Bengio", "link": "https://arxiv.org/abs/1912.02178", "summary": "Generalization of deep networks has been of great interest in recent years,\nresulting in a number of theoretically and empirically motivated complexity\nmeasures. However, most papers proposing such measures study only a small set\nof models, leaving open the question of whether the conclusion drawn from those\nexperiments would remain valid in other settings. We present the first large\nscale study of generalization in deep networks. We investigate more then 40\ncomplexity measures taken from both theoretical bounds and empirical studies.\nWe train over 10,000 convolutional networks by systematically varying commonly\nused hyperparameters. Hoping to uncover potentially causal relationships\nbetween each measure and generalization, we analyze carefully controlled\nexperiments and show surprising failures of some measures as well as promising\nmeasures for further research."}, {"title": "Data-Independent Neural Pruning via Coresets", "authors": "Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, Dan Feldman", "link": "https://arxiv.org/abs/1907.04018", "summary": "Previous work showed empirically that large neural networks can be\nsignificantly reduced in size while preserving their accuracy. Model\ncompression became a central research topic, as it is crucial for deployment of\nneural networks on devices with limited computational and memory resources. The\nmajority of the compression methods are based on heuristics and offer no\nworst-case guarantees on the trade-off between the compression rate and the\napproximation error for an arbitrarily new sample. We propose the first\nefficient, data-independent neural pruning algorithm with a provable trade-off\nbetween its compression rate and the approximation error for any future test\nsample. Our method is based on the coreset framework, which finds a small\nweighted subset of points that provably approximates the original inputs.\nSpecifically, we approximate the output of a layer of neurons by a coreset of\nneurons in the previous layer and discard the rest. We apply this framework in\na layer-by-layer fashion from the top to the bottom. Unlike previous works, our\ncoreset is data independent, meaning that it provably guarantees the accuracy\nof the function for any input $x\\in \\mathbb{R}^d$, including an adversarial\none. We demonstrate the effectiveness of our method on popular network\narchitectures. In particular, our coresets yield 90\\% compression of the\nLeNet-300-100 architecture on MNIST while improving the accuracy."}, {"title": "Abstract Diagrammatic Reasoning with Multiplex Graph Networks", "authors": "Duo Wang, Mateja Jamnik, Pietro Lio"}, {"title": "On the interaction between supervision and self-play in emergent communication", "authors": "Ryan Lowe, Abhinav Gupta, Jakob Foerster, Douwe Kiela, Joelle Pineau"}, {"title": "A Signal Propagation Perspective for Pruning Neural Networks at Initialization", "authors": "Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, Philip H. S. Torr", "link": "https://arxiv.org/abs/1906.06307", "summary": "Network pruning is a promising avenue for compressing deep neural networks. A\ntypical approach to pruning starts by training a model and then removing\nredundant parameters while minimizing the impact on what is learned.\nAlternatively, a recent approach shows that pruning can be done at\ninitialization prior to training, based on a saliency criterion called\nconnection sensitivity. However, it remains unclear exactly why pruning an\nuntrained, randomly initialized neural network is effective. In this work, by\nnoting connection sensitivity as a form of gradient, we formally characterize\ninitialization conditions to ensure reliable connection sensitivity\nmeasurements, which in turn yields effective pruning results. Moreover, we\nanalyze the signal propagation properties of the resulting pruned networks and\nintroduce a simple, data-free method to improve their trainability. Our\nmodifications to the existing pruning at initialization method lead to improved\nresults on all tested network models for image classification tasks.\nFurthermore, we empirically study the effect of supervision for pruning and\ndemonstrate that our signal propagation perspective, combined with unsupervised\npruning, can be useful in various scenarios where pruning is applied to\nnon-standard arbitrarily-designed architectures."}, {"title": "Doubly Robust Bias Reduction in Infinite Horizon Off-Policy Estimation", "authors": "Ziyang Tang, Yihao Feng, Lihong Li, Dengyong Zhou, Qiang Liu", "link": "https://arxiv.org/abs/1910.07186", "summary": "Infinite horizon off-policy policy evaluation is a highly challenging task\ndue to the excessively large variance of typical importance sampling (IS)\nestimators. Recently, Liu et al. (2018a) proposed an approach that\nsignificantly reduces the variance of infinite-horizon off-policy evaluation by\nestimating the stationary density ratio, but at the cost of introducing\npotentially high biases due to the error in density ratio estimation. In this\npaper, we develop a bias-reduced augmentation of their method, which can take\nadvantage of a learned value function to obtain higher accuracy. Our method is\ndoubly robust in that the bias vanishes when either the density ratio or the\nvalue function estimation is perfect. In general, when either of them is\naccurate, the bias can also be reduced. Both theoretical and empirical results\nshow that our method yields significant advantages over previous methods."}, {"title": "Understanding Architectures Learnt by Cell-based Neural Architecture Search", "authors": "Yao Shu, Wei Wang, Shaofeng Cai", "link": "https://arxiv.org/abs/1909.09569", "summary": "Neural architecture search (NAS) searches architectures automatically for\ngiven tasks, e.g., image classification and language modeling. Improving the\nsearch efficiency and effectiveness have attracted increasing attention in\nrecent years. However, few efforts have been devoted to understanding the\ngenerated architectures. In this paper, we first reveal that existing NAS\nalgorithms (e.g., DARTS, ENAS) tend to favor architectures with wide and\nshallow cell structures. These favorable architectures consistently achieve\nfast convergence and are consequently selected by NAS algorithms. Our empirical\nand theoretical study further confirms that their fast convergence derives from\ntheir smooth loss landscape and accurate gradient information. Nonetheless,\nthese architectures may not necessarily lead to better generalization\nperformance compared with other candidate architectures in the same search\nspace, and therefore further improvement is possible by revising existing NAS\nalgorithms."}, {"title": "Deep 3D Pan via Local adaptive \"t-shaped\" convolutions with global and local adaptive dilations", "authors": "Juan Luis Gonzalez Bello, Munchurl Kim", "link": "https://arxiv.org/abs/1910.01089", "summary": "Recent advances in deep learning have shown promising results in many\nlow-level vision tasks. However, solving the single-image-based view synthesis\nis still an open problem. In particular, the generation of new images at\nparallel camera views given a single input image is of great interest, as it\nenables 3D visualization of the 2D input scenery. We propose a novel network\narchitecture to perform stereoscopic view synthesis at arbitrary camera\npositions along the X-axis, or Deep 3D Pan, with \"t-shaped\" adaptive kernels\nequipped with globally and locally adaptive dilations. Our proposed network\narchitecture, the monster-net, is devised with a novel \"t-shaped\" adaptive\nkernel with globally and locally adaptive dilation, which can efficiently\nincorporate global camera shift into and handle local 3D geometries of the\ntarget image's pixels for the synthesis of naturally looking 3D panned views\nwhen a 2-D input image is given. Extensive experiments were performed on the\nKITTI, CityScapes and our VICLAB_STEREO indoors dataset to prove the efficacy\nof our method. Our monster-net significantly outperforms the state-of-the-art\nmethod, SOTA, by a large margin in all metrics of RMSE, PSNR, and SSIM. Our\nproposed monster-net is capable of reconstructing more reliable image\nstructures in synthesized images with coherent geometry. Moreover, the\ndisparity information that can be extracted from the \"t-shaped\" kernel is much\nmore reliable than that of the SOTA for the unsupervised monocular depth\nestimation task, confirming the effectiveness of our method."}, {"title": "RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?", "authors": "Anil Kag, Ziming Zhang, Venkatesh Saligrama"}, {"title": "Consistency Regularization for Generative Adversarial Networks", "authors": "Han Zhang, Zizhao Zhang, Augustus Odena, Honglak Lee", "link": "https://arxiv.org/abs/1910.12027", "summary": "Generative Adversarial Networks (GANs) are known to be difficult to train,\ndespite considerable research effort. Several regularization techniques for\nstabilizing training have been proposed, but they introduce non-trivial\ncomputational overheads and interact poorly with existing techniques like\nspectral normalization. In this work, we propose a simple, effective training\nstabilizer based on the notion of consistency regularization---a popular\ntechnique in the semi-supervised learning literature. In particular, we augment\ndata passing into the GAN discriminator and penalize the sensitivity of the\ndiscriminator to these augmentations. We conduct a series of experiments to\ndemonstrate that consistency regularization works effectively with spectral\nnormalization and various GAN architectures, loss functions and optimizer\nsettings. Our method achieves the best FID scores for unconditional image\ngeneration compared to other regularization methods on CIFAR-10 and CelebA.\nMoreover, Our consistency regularized GAN (CR-GAN) improves state-of-the-art\nFID scores for conditional generation from 14.73 to 11.48 on CIFAR-10 and from\n8.73 to 6.66 on ImageNet-2012."}, {"title": "Detecting and Diagnosing Adversarial Images with Class-Conditional Capsule Reconstructions", "authors": "Yao Qin, Nicholas Frosst, Sara Sabour, Colin Raffel, Garrison Cottrell, Geoffrey Hinton", "link": "https://arxiv.org/abs/1907.02957", "summary": "Adversarial examples raise questions about whether neural network models are\nsensitive to the same visual features as humans. In this paper, we first detect\nadversarial examples or otherwise corrupted images based on a class-conditional\nreconstruction of the input. To specifically attack our detection mechanism, we\npropose the Reconstructive Attack which seeks both to cause a misclassification\nand a low reconstruction error. This reconstructive attack produces undetected\nadversarial examples but with much smaller success rate. Among all these\nattacks, we find that CapsNets always perform better than convolutional\nnetworks. Then, we diagnose the adversarial examples for CapsNets and find that\nthe success of the reconstructive attack is highly related to the visual\nsimilarity between the source and target class. Additionally, the resulting\nperturbations can cause the input image to appear visually more like the target\nclass and hence become non-adversarial. This suggests that CapsNets use\nfeatures that are more aligned with human perception and have the potential to\naddress the central issue raised by adversarial examples."}, {"title": "V4D: 4D Convolutional Neural Networks for Video-level Representation Learning", "authors": "Shiwen Zhang, Sheng Guo, Weilin Huang, Matthew R. Scott, Limin Wang", "link": "https://arxiv.org/abs/2002.07442", "summary": "Most existing 3D CNNs for video representation learning are clip-based\nmethods, and thus do not consider video-level temporal evolution of\nspatio-temporal features. In this paper, we propose Video-level 4D\nConvolutional Neural Networks, referred as V4D, to model the evolution of\nlong-range spatio-temporal representation with 4D convolutions, and at the same\ntime, to preserve strong 3D spatio-temporal representation with residual\nconnections. Specifically, we design a new 4D residual block able to capture\ninter-clip interactions, which could enhance the representation power of the\noriginal clip-level 3D CNNs. The 4D residual blocks can be easily integrated\ninto the existing 3D CNNs to perform long-range modeling hierarchically. We\nfurther introduce the training and inference methods for the proposed V4D.\nExtensive experiments are conducted on three video recognition benchmarks,\nwhere V4D achieves excellent results, surpassing recent 3D CNNs by a large\nmargin."}, {"title": "Relational State-Space Model for Stochastic Multi-Object Systems", "authors": "Fan Yang, Ling Chen, Fan Zhou, Yusong Gao, Wei Cao"}, {"title": "Deep Learning For Symbolic Mathematics", "authors": "Guillaume Lample, Fran\u00e7ois Charton", "link": "https://arxiv.org/abs/1912.01412", "summary": "Neural networks have a reputation for being better at solving statistical or\napproximate problems than at performing calculations or working with symbolic\ndata. In this paper, we show that they can be surprisingly good at more\nelaborated tasks in mathematics, such as symbolic integration and solving\ndifferential equations. We propose a syntax for representing mathematical\nproblems, and methods for generating large datasets that can be used to train\nsequence-to-sequence models. We achieve results that outperform commercial\nComputer Algebra Systems such as Matlab or Mathematica."}, {"title": "On the Variance of the Adaptive Learning Rate and Beyond", "authors": "Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, Jiawei Han", "link": "https://arxiv.org/abs/1908.03265", "summary": "The learning rate warmup heuristic achieves remarkable success in stabilizing\ntraining, accelerating convergence and improving generalization for adaptive\nstochastic optimization algorithms like RMSprop and Adam. Here, we study its\nmechanism in details. Pursuing the theory behind warmup, we identify a problem\nof the adaptive learning rate (i.e., it has problematically large variance in\nthe early stage), suggest warmup works as a variance reduction technique, and\nprovide both empirical and theoretical evidence to verify our hypothesis. We\nfurther propose RAdam, a new variant of Adam, by introducing a term to rectify\nthe variance of the adaptive learning rate. Extensive experimental results on\nimage classification, language modeling, and neural machine translation verify\nour intuition and demonstrate the effectiveness and robustness of our proposed\nmethod. All implementations are available at:\nhttps://github.com/LiyuanLucasLiu/RAdam."}, {"title": "A Theory of Usable Information under Computational Constraints", "authors": "Yilun Xu, Shengjia Zhao, Jiaming Song, Russell Stewart, Stefano Ermon", "link": "https://arxiv.org/abs/2002.10689", "summary": "We propose a new framework for reasoning about information in complex\nsystems. Our foundation is based on a variational extension of Shannon's\ninformation theory that takes into account the modeling power and computational\nconstraints of the observer. The resulting \\emph{predictive\n$\\mathcal{V}$-information} encompasses mutual information and other notions of\ninformativeness such as the coefficient of determination. Unlike Shannon's\nmutual information and in violation of the data processing inequality,\n$\\mathcal{V}$-information can be created through computation. This is\nconsistent with deep neural networks extracting hierarchies of progressively\nmore informative features in representation learning. Additionally, we show\nthat by incorporating computational constraints, $\\mathcal{V}$-information can\nbe reliably estimated from data even in high dimensions with PAC-style\nguarantees. Empirically, we demonstrate predictive $\\mathcal{V}$-information is\nmore effective than mutual information for structure learning and fair\nrepresentation learning."}, {"title": "The intriguing role of module criticality in the generalization of deep networks", "authors": "Niladri Chatterji, Behnam Neyshabur, Hanie Sedghi", "link": "https://arxiv.org/abs/1912.00528", "summary": "We study the phenomenon that some modules of deep neural networks (DNNs) are\nmore critical than others. Meaning that rewinding their parameter values back\nto initialization, while keeping other modules fixed at the trained parameters,\nresults in a large drop in the network's performance. Our analysis reveals\ninteresting properties of the loss landscape which leads us to propose a\ncomplexity measure, called module criticality, based on the shape of the\nvalleys that connects the initial and final values of the module parameters. We\nformulate how generalization relates to the module criticality, and show that\nthis measure is able to explain the superior generalization performance of some\narchitectures over others, whereas earlier measures fail to do so."}, {"title": "Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents", "authors": "Christian Rupprecht, Cyril Ibrahim, Christopher J. Pal", "link": "https://arxiv.org/abs/1904.01318", "summary": "As deep reinforcement learning driven by visual perception becomes more\nwidely used there is a growing need to better understand and probe the learned\nagents. Understanding the decision making process and its relationship to\nvisual inputs can be very valuable to identify problems in learned behavior.\nHowever, this topic has been relatively under-explored in the research\ncommunity. In this work we present a method for synthesizing visual inputs of\ninterest for a trained agent. Such inputs or states could be situations in\nwhich specific actions are necessary. Further, critical states in which a very\nhigh or a very low reward can be achieved are often interesting to understand\nthe situational awareness of the system as they can correspond to risky states.\nTo this end, we learn a generative model over the state space of the\nenvironment and use its latent space to optimize a target function for the\nstate of interest. In our experiments we show that this method can generate\ninsights for a variety of environments and reinforcement learning methods. We\nexplore results in the standard Atari benchmark games as well as in an\nautonomous driving simulator. Based on the efficiency with which we have been\nable to identify behavioural weaknesses with this technique, we believe this\ngeneral approach could serve as an important tool for AI safety applications."}, {"title": "Generative Models for Effective ML on Private, Decentralized Datasets", "authors": "Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy, Peter Kairouz, Mingqing Chen, Rajiv Mathews, Blaise Aguera y Arcas", "link": "https://arxiv.org/abs/1911.06679", "summary": "To improve real-world applications of machine learning, experienced modelers\ndevelop intuition about their datasets, their models, and how the two interact.\nManual inspection of raw data - of representative samples, of outliers, of\nmisclassifications - is an essential tool in a) identifying and fixing problems\nin the data, b) generating new modeling hypotheses, and c) assigning or\nrefining human-provided labels. However, manual data inspection is problematic\nfor privacy sensitive datasets, such as those representing the behavior of\nreal-world individuals. Furthermore, manual data inspection is impossible in\nthe increasingly important setting of federated learning, where raw examples\nare stored at the edge and the modeler may only access aggregated outputs such\nas metrics or model parameters. This paper demonstrates that generative models\n- trained using federated methods and with formal differential privacy\nguarantees - can be used effectively to debug many commonly occurring data\nissues even when the data cannot be directly inspected. We explore these\nmethods in applications to text with differentially private federated RNNs and\nto images using a novel algorithm for differentially private federated GANs."}, {"title": "Training Recurrent Neural Networks Online by Learning Explicit State Variables", "authors": "Somjit Nath, Vincent Liu, Alan Chan, Xin Li, Adam White, Martha White"}, {"title": "Multilingual Alignment of Contextual Word Representations", "authors": "Steven Cao, Nikita Kitaev, Dan Klein", "link": "https://arxiv.org/abs/2002.03518", "summary": "We propose procedures for evaluating and strengthening contextual embedding\nalignment and show that they are useful in analyzing and improving multilingual\nBERT. In particular, after our proposed alignment procedure, BERT exhibits\nsignificantly improved zero-shot performance on XNLI compared to the base\nmodel, remarkably matching pseudo-fully-supervised translate-train models for\nBulgarian and Greek. Further, to measure the degree of alignment, we introduce\na contextual version of word retrieval and show that it correlates well with\ndownstream zero-shot transfer. Using this word retrieval task, we also analyze\nBERT and find that it exhibits systematic deficiencies, e.g. worse alignment\nfor open-class parts-of-speech and word pairs written in different scripts,\nthat are corrected by the alignment procedure. These results support contextual\nalignment as a useful concept for understanding large multilingual pre-trained\nmodels."}, {"title": "CAQL: Continuous Action Q-Learning", "authors": "Moonkyung Ryu, Yinlam Chow, Ross Anderson, Christian Tjandraatmadja, Craig Boutilier", "link": "", "summary": ""}, {"title": "The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget", "authors": "Anirudh Goyal, Yoshua Bengio, Matthew Botvinick, Sergey Levine", "link": "https://arxiv.org/abs/2004.11935", "summary": "In many applications, it is desirable to extract only the relevant\ninformation from complex input data, which involves making a decision about\nwhich input features are relevant. The information bottleneck method formalizes\nthis as an information-theoretic optimization problem by maintaining an optimal\ntradeoff between compression (throwing away irrelevant input information), and\npredicting the target. In many problem settings, including the reinforcement\nlearning problems we consider in this work, we might prefer to compress only\npart of the input. This is typically the case when we have a standard\nconditioning input, such as a state observation, and a \"privileged\" input,\nwhich might correspond to the goal of a task, the output of a costly planning\nalgorithm, or communication with another agent. In such cases, we might prefer\nto compress the privileged input, either to achieve better generalization\n(e.g., with respect to goals) or to minimize access to costly information\n(e.g., in the case of communication). Practical implementations of the\ninformation bottleneck based on variational inference require access to the\nprivileged input in order to compute the bottleneck variable, so although they\nperform compression, this compression operation itself needs unrestricted,\nlossless access. In this work, we propose the variational bandwidth bottleneck,\nwhich decides for each example on the estimated value of the privileged\ninformation before seeing it, i.e., only based on the standard input, and then\naccordingly chooses stochastically, whether to access the privileged input or\nnot. We formulate a tractable approximation to this framework and demonstrate\nin a series of reinforcement learning experiments that it can improve\ngeneralization and reduce access to computationally costly information."}, {"title": "Target-Embedding Autoencoders for Supervised Representation Learning", "authors": "Daniel Jarrett, Mihaela van der Schaar", "link": "https://arxiv.org/abs/2001.08345", "summary": "Autoencoder-based learning has emerged as a staple for disciplining\nrepresentations in unsupervised and semi-supervised settings. This paper\nanalyzes a framework for improving generalization in a purely supervised\nsetting, where the target space is high-dimensional. We motivate and formalize\nthe general framework of target-embedding autoencoders (TEA) for supervised\nprediction, learning intermediate latent representations jointly optimized to\nbe both predictable from features as well as predictive of targets---encoding\nthe prior that variations in targets are driven by a compact set of underlying\nfactors. As our theoretical contribution, we provide a guarantee of\ngeneralization for linear TEAs by demonstrating uniform stability, interpreting\nthe benefit of the auxiliary reconstruction task as a form of regularization.\nAs our empirical contribution, we extend validation of this approach beyond\nexisting static classification applications to multivariate sequence\nforecasting, verifying their advantage on both linear and nonlinear recurrent\narchitectures---thereby underscoring the further generality of this framework\nbeyond feedforward instantiations."}, {"title": "Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement Learning", "authors": "Noah Siegel, Jost Tobias Springenberg, Felix Berkenkamp, Abbas Abdolmaleki, Michael Neunert, Thomas Lampe, Roland Hafner, Nicolas Heess, Martin Riedmiller"}, {"title": "Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech", "authors": "David Harwath, Wei-Ning Hsu, James Glass", "link": "https://arxiv.org/abs/1911.09602", "summary": "In this paper, we present a method for learning discrete linguistic units by\nincorporating vector quantization layers into neural models of visually\ngrounded speech. We show that our method is capable of capturing both\nword-level and sub-word units, depending on how it is configured. What\ndifferentiates this paper from prior work on speech unit learning is the choice\nof training objective. Rather than using a reconstruction-based loss, we use a\ndiscriminative, multimodal grounding objective which forces the learned units\nto be useful for semantic image retrieval. We evaluate the sub-word units on\nthe ZeroSpeech 2019 challenge, achieving a 27.3\\% reduction in ABX error rate\nover the top-performing submission, while keeping the bitrate approximately the\nsame. We also present experiments demonstrating the noise robustness of these\nunits. Finally, we show that a model with multiple quantizers can\nsimultaneously learn phone-like detectors at a lower layer and word-like\ndetectors at a higher layer. We show that these detectors are highly accurate,\ndiscovering 279 words with an F1 score of greater than 0.5."}, {"title": "Order Learning and Its Application to Age Estimation", "authors": "Kyungsun Lim, Nyeong-Ho Shin, Young-Yoon Lee, Chang-Su Kim"}, {"title": "Understanding and Robustifying Differentiable Architecture Search", "authors": "Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas Brox, Frank Hutter", "link": "https://arxiv.org/abs/1909.09656", "summary": "Differentiable Architecture Search (DARTS) has attracted a lot of attention\ndue to its simplicity and small search costs achieved by a continuous\nrelaxation and an approximation of the resulting bi-level optimization problem.\nHowever, DARTS does not work robustly for new problems: we identify a wide\nrange of search spaces for which DARTS yields degenerate architectures with\nvery poor test performance. We study this failure mode and show that, while\nDARTS successfully minimizes validation loss, the found solutions generalize\npoorly when they coincide with high validation loss curvature in the\narchitecture space. We show that by adding one of various types of\nregularization we can robustify DARTS to find solutions with less curvature and\nbetter generalization properties. Based on these observations, we propose\nseveral simple variations of DARTS that perform substantially more robustly in\npractice. Our observations are robust across five search spaces on three image\nclassification tasks and also hold for the very different domains of disparity\nestimation (a dense regression task) and language modelling."}, {"title": "A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning", "authors": "Soochan Lee, Junsoo Ha, Dongsu Zhang, Gunhee Kim", "link": "http://arxiv.org/abs/2001.00689", "summary": "Despite the growing interest in continual learning, most of its contemporary\nworks have been studied in a rather restricted setting where tasks are clearly\ndistinguishable, and task boundaries are known during training. However, if our\ngoal is to develop an algorithm that learns as humans do, this setting is far\nfrom realistic, and it is essential to develop a methodology that works in a\ntask-free manner. Meanwhile, among several branches of continual learning,\nexpansion-based methods have the advantage of eliminating catastrophic\nforgetting by allocating new resources to learn new data. In this work, we\npropose an expansion-based approach for task-free continual learning. Our\nmodel, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a\nset of neural network experts that are in charge of a subset of the data.\nCN-DPM expands the number of experts in a principled way under the Bayesian\nnonparametric framework. With extensive experiments, we show that our model\nsuccessfully performs task-free continual learning for both discriminative and\ngenerative tasks such as image classification and image generation."}, {"title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": "Chen Xing, Sercan Arik, Zizhao Zhang, Tomas Pfister", "link": "https://arxiv.org/abs/1912.01730", "summary": "Deep neural networks (DNNs) are poorly calibrated when trained in\nconventional ways. To improve confidence calibration of DNNs, we propose a\nnovel training method, distance-based learning from errors (DBLE). DBLE bases\nits confidence estimation on distances in the representation space. In DBLE, we\nfirst adapt prototypical learning to train classification models. It yields a\nrepresentation space where the distance between a test sample and its ground\ntruth class center can calibrate the model's classification performance. At\ninference, however, these distances are not available due to the lack of ground\ntruth labels. To circumvent this by inferring the distance for every test\nsample, we propose to train a confidence model jointly with the classification\nmodel. We integrate this into training by merely learning from mis-classified\ntraining samples, which we show to be highly beneficial for effective learning.\nOn multiple datasets and DNN architectures, we demonstrate that DBLE\noutperforms alternative single-model confidence calibration approaches. DBLE\nalso achieves comparable performance with computationally-expensive ensemble\napproaches with lower computational cost and lower number of parameters."}, {"title": "Mutual Information Gradient Estimation for  Representation Learning", "authors": "Liangjian Wen, Yiji Zhou, Lirong He, Mingyuan Zhou, Zenglin Xu"}, {"title": "A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms", "authors": "Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Nan Rosemary Ke, Sebastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, Christopher Pal", "link": "https://arxiv.org/abs/1901.10912", "summary": "We propose to meta-learn causal structures based on how fast a learner adapts\nto new distributions arising from sparse distributional changes, e.g. due to\ninterventions, actions of agents and other sources of non-stationarities. We\nshow that under this assumption, the correct causal structural choices lead to\nfaster adaptation to modified distributions because the changes are\nconcentrated in one or just a few mechanisms when the learned knowledge is\nmodularized appropriately. This leads to sparse expected gradients and a lower\neffective number of degrees of freedom needing to be relearned while adapting\nto the change. It motivates using the speed of adaptation to a modified\ndistribution as a meta-learning objective. We demonstrate how this can be used\nto determine the cause-effect relationship between two observed variables. The\ndistributional changes do not need to correspond to standard interventions\n(clamping a variable), and the learner has no direct knowledge of these\ninterventions. We show that causal structures can be parameterized via\ncontinuous variables and learned end-to-end. We then explore how these ideas\ncould be used to also learn an encoder that would map low-level observed\nvariables to unobserved causal variables leading to faster adaptation\nout-of-distribution, learning a representation space where one can satisfy the\nassumptions of independent mechanisms and of small and sparse changes in these\nmechanisms due to actions and non-stationarities."}, {"title": "DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames", "authors": "Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, Dhruv Batra", "link": "https://arxiv.org/abs/1911.00357", "summary": "We present Decentralized Distributed Proximal Policy Optimization (DD-PPO), a\nmethod for distributed reinforcement learning in resource-intensive simulated\nenvironments. DD-PPO is distributed (uses multiple machines), decentralized\n(lacks a centralized server), and synchronous (no computation is ever stale),\nmaking it conceptually simple and easy to implement. In our experiments on\ntraining virtual robots to navigate in Habitat-Sim, DD-PPO exhibits near-linear\nscaling -- achieving a speedup of 107x on 128 GPUs over a serial\nimplementation. We leverage this scaling to train an agent for 2.5 Billion\nsteps of experience (the equivalent of 80 years of human experience) -- over 6\nmonths of GPU-time training in under 3 days of wall-clock time with 64 GPUs.\n  This massive-scale training not only sets the state of art on Habitat\nAutonomous Navigation Challenge 2019, but essentially solves the task\n--near-perfect autonomous navigation in an unseen environment without access to\na map, directly from an RGB-D camera and a GPS+Compass sensor. Fortuitously,\nerror vs computation exhibits a power-law-like distribution; thus, 90% of peak\nperformance is obtained relatively early (at 100 million steps) and relatively\ncheaply (under 1 day with 8 GPUs). Finally, we show that the scene\nunderstanding and navigation policies learned can be transferred to other\nnavigation tasks -- the analog of ImageNet pre-training + task-specific\nfine-tuning for embodied AI. Our model outperforms ImageNet pre-trained CNNs on\nthese transfer tasks and can serve as a universal resource (all models and code\nare publicly available)."}, {"title": "Counterfactuals uncover the modular structure of deep generative models", "authors": "Michel Besserve, Arash Mehrjou, R\u00e9my Sun, Bernhard Sch\u00f6lkopf", "link": "https://arxiv.org/abs/1812.03253", "summary": "Deep generative models can emulate the perceptual properties of complex image\ndatasets, providing a latent representation of the data. However, manipulating\nsuch representation to perform meaningful and controllable transformations in\nthe data space remains challenging without some form of supervision. While\nprevious work has focused on exploiting statistical independence to disentangle\nlatent factors, we argue that such requirement is too restrictive and propose\ninstead a non-statistical framework that relies on counterfactual manipulations\nto uncover a modular structure of the network composed of disentangled groups\nof internal variables. Experiments with a variety of generative models trained\non complex image datasets show the obtained modules can be used to design\ntargeted interventions. This opens the way to applications such as\ncomputationally efficient style transfer and the automated assessment of\nrobustness to contextual changes in pattern recognition systems."}, {"title": "Kernel of CycleGAN as a principal homogeneous space", "authors": "Nikita Moriakov, Jonas Adler, Jonas Teuwen", "link": "https://arxiv.org/abs/2001.09061", "summary": "Unpaired image-to-image translation has attracted significant interest due to\nthe invention of CycleGAN, a method which utilizes a combination of adversarial\nand cycle consistency losses to avoid the need for paired data. It is known\nthat the CycleGAN problem might admit multiple solutions, and our goal in this\npaper is to analyze the space of exact solutions and to give perturbation\nbounds for approximate solutions. We show theoretically that the exact solution\nspace is invariant with respect to automorphisms of the underlying probability\nspaces, and, furthermore, that the group of automorphisms acts freely and\ntransitively on the space of exact solutions. We examine the case of zero\n`pure' CycleGAN loss first in its generality, and, subsequently, expand our\nanalysis to approximate solutions for `extended' CycleGAN loss where identity\nloss term is included. In order to demonstrate that these results are\napplicable, we show that under mild conditions nontrivial smooth automorphisms\nexist. Furthermore, we provide empirical evidence that neural networks can\nlearn these automorphisms with unexpected and unwanted results. We conclude\nthat finding optimal solutions to the CycleGAN loss does not necessarily lead\nto the envisioned result in image-to-image translation tasks and that\nunderlying hidden symmetries can render the result utterly useless."}, {"title": "Inductive representation learning on temporal graphs", "authors": "da Xu, chuanwei ruan, evren korpeoglu, sushant kumar, kannan achan"}, {"title": "Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints", "authors": "Mengtian Li, Ersin Yumer, Deva Ramanan", "link": "https://arxiv.org/abs/1905.04753", "summary": "In most practical settings and theoretical analyses, one assumes that a model\ncan be trained until convergence. However, the growing complexity of machine\nlearning datasets and models may violate such assumptions. Indeed, current\napproaches for hyper-parameter tuning and neural architecture search tend to be\nlimited by practical resource constraints. Therefore, we introduce a formal\nsetting for studying training under the non-asymptotic, resource-constrained\nregime, i.e., budgeted training. We analyze the following problem: \"given a\ndataset, algorithm, and fixed resource budget, what is the best achievable\nperformance?\" We focus on the number of optimization iterations as the\nrepresentative resource. Under such a setting, we show that it is critical to\nadjust the learning rate schedule according to the given budget. Among\nbudget-aware learning schedules, we find simple linear decay to be both robust\nand high-performing. We support our claim through extensive experiments with\nstate-of-the-art models on ImageNet (image classification), Kinetics (video\nclassification), MS COCO (object detection and instance segmentation), and\nCityscapes (semantic segmentation). We also analyze our results and find that\nthe key to a good schedule is budgeted convergence, a phenomenon whereby the\ngradient vanishes at the end of each allowed budget. We also revisit existing\napproaches for fast convergence and show that budget-aware learning schedules\nreadily outperform such approaches under (the practical but under-explored)\nbudgeted training setting."}, {"title": "Differentiable Reasoning over a Virtual Knowledge Base", "authors": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William W. Cohen", "link": "https://arxiv.org/abs/2002.10640", "summary": "We consider the task of answering complex multi-hop questions using a corpus\nas a virtual knowledge base (KB). In particular, we describe a neural module,\nDrKIT, that traverses textual data like a KB, softly following paths of\nrelations between mentions of entities in the corpus. At each step the module\nuses a combination of sparse-matrix TFIDF indices and a maximum inner product\nsearch (MIPS) on a special index of contextual representations of the mentions.\nThis module is differentiable, so the full system can be trained end-to-end\nusing gradient based methods, starting from natural language inputs. We also\ndescribe a pretraining scheme for the contextual representation encoder by\ngenerating hard negative examples using existing knowledge bases. We show that\nDrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,\ncutting the gap between text-based and KB-based state-of-the-art by 70%. On\nHotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking\napproach to retrieving the relevant passages required to answer a question.\nDrKIT is also very efficient, processing 10-100x more queries per second than\nexisting multi-hop systems."}, {"title": "Scalable and Order-robust Continual Learning with Additive Parameter Decomposition", "authors": "Jaehong Yoon, Saehoon Kim, Eunho Yang, Sung Ju Hwang", "link": "http://arxiv.org/abs/1902.09432", "summary": "While recent continual learning methods largely alleviate the catastrophic\nproblem on toy-sized datasets, some issues remain to be tackled to apply them\nto real-world problem domains. First, a continual learning model should\neffectively handle catastrophic forgetting and be efficient to train even with\na large number of tasks. Secondly, it needs to tackle the problem of\norder-sensitivity, where the performance of the tasks largely varies based on\nthe order of the task arrival sequence, as it may cause serious problems where\nfairness plays a critical role (e.g. medical diagnosis). To tackle these\npractical challenges, we propose a novel continual learning method that is\nscalable as well as order-robust, which instead of learning a completely shared\nset of weights, represents the parameters for each task as a sum of task-shared\nand sparse task-adaptive parameters. With our Additive Parameter Decomposition\n(APD), the task-adaptive parameters for earlier tasks remain mostly unaffected,\nwhere we update them only to reflect the changes made to the task-shared\nparameters. This decomposition of parameters effectively prevents catastrophic\nforgetting and order-sensitivity, while being computation- and\nmemory-efficient. Further, we can achieve even better scalability with APD\nusing hierarchical knowledge consolidation, which clusters the task-adaptive\nparameters to obtain hierarchically shared parameters. We validate our network\nwith APD, APD-Net, on multiple benchmark datasets against state-of-the-art\ncontinual learning methods, which it largely outperforms in accuracy,\nscalability, and order-robustness."}, {"title": "Optimal Strategies Against Generative Attacks", "authors": "Roy Mor, Erez Peterfreund, Matan Gavish, Amir Globerson"}, {"title": "Neural Module Networks for Reasoning over Text", "authors": "Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, Matt Gardner", "link": "https://arxiv.org/abs/1912.04971", "summary": "Answering compositional questions that require multiple steps of reasoning\nagainst text is challenging, especially when they involve discrete, symbolic\noperations. Neural module networks (NMNs) learn to parse such questions as\nexecutable programs composed of learnable modules, performing well on synthetic\nvisual QA domains. However, we find that it is challenging to learn these\nmodels for non-synthetic questions on open-domain text, where a model needs to\ndeal with the diversity of natural language and perform a broader range of\nreasoning. We extend NMNs by: (a) introducing modules that reason over a\nparagraph of text, performing symbolic reasoning (such as arithmetic, sorting,\ncounting) over numbers and dates in a probabilistic and differentiable manner;\nand (b) proposing an unsupervised auxiliary loss to help extract arguments\nassociated with the events in text. Additionally, we show that a limited amount\nof heuristically-obtained question program and intermediate module output\nsupervision provides sufficient inductive bias for accurate learning. Our\nproposed model significantly outperforms state-of-the-art models on a subset of\nthe DROP dataset that poses a variety of reasoning challenges that are covered\nby our modules."}, {"title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction", "authors": "Sangdon Park, Osbert Bastani, Nikolai Matni, Insup Lee"}, {"title": "Sign-OPT: A Query-Efficient Hard-label Adversarial Attack", "authors": "Minhao Cheng, Simranjit Singh, Patrick H. Chen, Pin-Yu Chen, Sijia Liu, Cho-Jui Hsieh"}, {"title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased Robustness Against Adversarial Attacks", "authors": "Sanchari Sen, Balaraman Ravindran, Anand Raghunathan"}, {"title": "DDSP: Differentiable Digital Signal Processing", "authors": "Jesse Engel, Lamtharn (Hanoi) Hantrakul, Chenjie Gu, Adam Roberts"}, {"title": "The Gambler's Problem and Beyond", "authors": "Baoxiang Wang, Shuai Li, Jiajin Li, Siu On Chan"}, {"title": "The Logical Expressiveness of Graph Neural Networks", "authors": "Pablo Barcel\u00f3, Egor V. Kostylev, Mikael Monet, Jorge P\u00e9rez, Juan Reutter, Juan Pablo Silva"}, {"title": "Learning Robust Representations via Multi-View Information Bottleneck", "authors": "Marco Federici, Anjan Dutta, Patrick Forr\u00e9, Nate Kushman, Zeynep Akata", "link": "https://arxiv.org/abs/2002.07017", "summary": "The information bottleneck principle provides an information-theoretic method\nfor representation learning, by training an encoder to retain all information\nwhich is relevant for predicting the label while minimizing the amount of\nother, excess information in the representation. The original formulation,\nhowever, requires labeled data to identify the superfluous information. In this\nwork, we extend this ability to the multi-view unsupervised setting, where two\nviews of the same underlying entity are provided but the label is unknown. This\nenables us to identify superfluous information as that not shared by both\nviews. A theoretical analysis leads to the definition of a new multi-view model\nthat produces state-of-the-art results on the Sketchy dataset and label-limited\nversions of the MIR-Flickr dataset. We also extend our theory to the\nsingle-view setting by taking advantage of standard data augmentation\ntechniques, empirically showing better generalization capabilities when\ncompared to common unsupervised approaches for representation learning."}, {"title": "Empirical Studies on the Properties of Linear Regions in Deep Neural Networks", "authors": "Xiao Zhang, Dongrui Wu"}, {"title": "Compositional Language Continual Learning", "authors": "Yuanpeng Li, Liang Zhao, Kenneth Church, Mohamed Elhoseiny"}, {"title": "Self-labelling via simultaneous clustering and representation learning", "authors": "Asano YM., Rupprecht C., Vedaldi A.", "link": "https://arxiv.org/abs/1911.05371", "summary": "Combining clustering and representation learning is one of the most promising\napproaches for unsupervised learning of deep neural networks. However, doing so\nnaively leads to ill posed learning problems with degenerate solutions. In this\npaper, we propose a novel and principled learning formulation that addresses\nthese issues. The method is obtained by maximizing the information between\nlabels and input data indices. We show that this criterion extends standard\ncrossentropy minimization to an optimal transport problem, which we solve\nefficiently for millions of input images and thousands of labels using a fast\nvariant of the Sinkhorn-Knopp algorithm. The resulting method is able to\nself-label visual data so as to train highly competitive image representations\nwithout manual labels. Our method achieves state of the art representation\nlearning performance for AlexNet and ResNet-50 on SVHN, CIFAR-10, CIFAR-100 and\nImageNet and yields the first self-supervised AlexNet that outperforms the\nsupervised Pascal VOC detection baseline. Code and models are available."}, {"title": "GraphSAINT: Graph Sampling Based Inductive Learning Method", "authors": "Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, Viktor Prasanna", "link": "", "summary": ""}, {"title": "Explain Your Move: Understanding Agent Actions Using Focused Feature Saliency", "authors": "Piyush Gupta, Nikaash Puri, Sukriti Verma, Dhruv Kayastha, Shripad Deshmukh, Balaji Krishnamurthy, Sameer Singh"}, {"title": "Lipschitz constant estimation of Neural Networks via sparse polynomial optimization", "authors": "Fabian Latorre, Paul Rolland, Volkan Cevher", "link": "https://arxiv.org/abs/2004.08688", "summary": "We introduce LiPopt, a polynomial optimization framework for computing\nincreasingly tighter upper bounds on the Lipschitz constant of neural networks.\nThe underlying optimization problems boil down to either linear (LP) or\nsemidefinite (SDP) programming. We show how to use the sparse connectivity of a\nnetwork, to significantly reduce the complexity of computation. This is\nspecially useful for convolutional as well as pruned neural networks. We\nconduct experiments on networks with random weights as well as networks trained\non MNIST, showing that in the particular case of the $\\ell_\\infty$-Lipschitz\nconstant, our approach yields superior estimates, compared to baselines\navailable in the literature."}, {"title": "Action Semantics Network: Considering the Effects of Actions in Multiagent Systems", "authors": "Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing Hu, Yingfeng Chen, Changjie Fan, Yang Gao", "link": "https://arxiv.org/abs/1907.11461", "summary": "In multiagent systems (MASs), each agent makes individual decisions but all\nof them contribute globally to the system evolution. Learning in MASs is\ndifficult since each agent's selection of actions must take place in the\npresence of other co-learning agents. Moreover, the environmental stochasticity\nand uncertainties increase exponentially with the increase in the number of\nagents. Previous works borrow various multiagent coordination mechanisms into\ndeep learning architecture to facilitate multiagent coordination. However, none\nof them explicitly consider action semantics between agents that different\nactions have different influences on other agents. In this paper, we propose a\nnovel network architecture, named Action Semantics Network (ASN), that\nexplicitly represents such action semantics between agents. ASN characterizes\ndifferent actions' influence on other agents using neural networks based on the\naction semantics between them. ASN can be easily combined with existing deep\nreinforcement learning (DRL) algorithms to boost their performance.\nExperimental results on StarCraft II micromanagement and Neural MMO show ASN\nsignificantly improves the performance of state-of-the-art DRL approaches\ncompared with several network architectures."}, {"title": "Finite Depth and Width Corrections to the Neural Tangent Kernel", "authors": "Boris Hanin, Mihai Nica", "link": "https://arxiv.org/abs/1909.05989", "summary": "We prove the precise scaling, at finite depth and width, for the mean and\nvariance of the neural tangent kernel (NTK) in a randomly initialized ReLU\nnetwork. The standard deviation is exponential in the ratio of network depth to\nwidth. Thus, even in the limit of infinite overparameterization, the NTK is not\ndeterministic if depth and width simultaneously tend to infinity. Moreover, we\nprove that for such deep and wide networks, the NTK has a non-trivial evolution\nduring training by showing that the mean of its first SGD update is also\nexponential in the ratio of network depth to width. This is sharp contrast to\nthe regime where depth is fixed and network width is very large. Our results\nsuggest that, unlike relatively shallow and wide networks, deep and wide ReLU\nnetworks are capable of learning data-dependent features even in the so-called\nlazy training regime."}, {"title": "Measuring the Reliability of Reinforcement Learning Algorithms", "authors": "Stephanie C.Y. Chan, Samuel Fishman, Anoop Korattikara, John Canny, Sergio Guadarrama", "link": "https://arxiv.org/abs/1912.05663", "summary": "Lack of reliability is a well-known issue for reinforcement learning (RL)\nalgorithms. This problem has gained increasing attention in recent years, and\nefforts to improve it have grown substantially. To aid RL researchers and\nproduction users with the evaluation and improvement of reliability, we propose\na set of metrics that quantitatively measure different aspects of reliability.\nIn this work, we focus on variability and risk, both during training and after\nlearning (on a fixed policy). We designed these metrics to be general-purpose,\nand we also designed complementary statistical tests to enable rigorous\ncomparisons on these metrics. In this paper, we first describe the desired\nproperties of the metrics and their design, the aspects of reliability that\nthey measure, and their applicability to different scenarios. We then describe\nthe statistical tests and make additional practical recommendations for\nreporting results. The metrics and accompanying statistical tools have been\nmade available as an open-source library at\nhttps://github.com/google-research/rl-reliability-metrics. We apply our metrics\nto a set of common RL algorithms and environments, compare them, and analyze\nthe results."}, {"title": "Probability Calibration for Knowledge Graph Embedding Models", "authors": "Pedro Tabacof, Luca Costabello"}, {"title": "And the Bit Goes Down: Revisiting the Quantization of Neural Networks", "authors": "Pierre Stock, Armand Joulin, R\u00e9mi Gribonval, Benjamin Graham, Herv\u00e9 J\u00e9gou", "link": "https://arxiv.org/abs/1907.05686", "summary": "In this paper, we address the problem of reducing the memory footprint of\nconvolutional network architectures. We introduce a vector quantization method\nthat aims at preserving the quality of the reconstruction of the network\noutputs rather than its weights. The principle of our approach is that it\nminimizes the loss reconstruction error for in-domain inputs. Our method only\nrequires a set of unlabelled data at quantization time and allows for efficient\ninference on CPU by using byte-aligned codebooks to store the compressed\nweights. We validate our approach by quantizing a high performing ResNet-50\nmodel to a memory size of 5MB (20x compression factor) while preserving a top-1\naccuracy of 76.1% on ImageNet object classification and by compressing a Mask\nR-CNN with a 26x factor."}, {"title": "Biologically inspired sleep algorithm for increased generalization and adversarial robustness in deep neural networks", "authors": "Timothy Tadros, Giri Krishnan, Ramyaa Ramyaa, Maxim Bazhenov"}, {"title": "Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue", "authors": "Byeongchang Kim, Jaewoo Ahn, Gunhee Kim", "link": "https://arxiv.org/abs/2002.07510", "summary": "Knowledge-grounded dialogue is a task of generating an informative response\nbased on both discourse context and external knowledge. As we focus on better\nmodeling the knowledge selection in the multi-turn knowledge-grounded dialogue,\nwe propose a sequential latent variable model as the first approach to this\nmatter. The model named sequential knowledge transformer (SKT) can keep track\nof the prior and posterior distribution over knowledge; as a result, it can not\nonly reduce the ambiguity caused from the diversity in knowledge selection of\nconversation but also better leverage the response information for proper\nchoice of knowledge. Our experimental results show that the proposed model\nimproves the knowledge selection accuracy and subsequently the performance of\nutterance generation. We achieve the new state-of-the-art performance on Wizard\nof Wikipedia (Dinan et al., 2019) as one of the most large-scale and\nchallenging benchmarks. We further validate the effectiveness of our model over\nexisting conversation methods in another knowledge-based dialogue Holl-E\ndataset (Moghe et al., 2018)."}, {"title": "Adjustable Real-time Style Transfer", "authors": "Mohammad Babaeizadeh, Golnaz Ghiasi", "link": "https://arxiv.org/abs/1811.08560", "summary": "Artistic style transfer is the problem of synthesizing an image with content\nsimilar to a given image and style similar to another. Although recent\nfeed-forward neural networks can generate stylized images in real-time, these\nmodels produce a single stylization given a pair of style/content images, and\nthe user doesn't have control over the synthesized output. Moreover, the style\ntransfer depends on the hyper-parameters of the model with varying \"optimum\"\nfor different input images. Therefore, if the stylized output is not appealing\nto the user, she/he has to try multiple models or retrain one with different\nhyper-parameters to get a favorite stylization. In this paper, we address these\nissues by proposing a novel method which allows adjustment of crucial\nhyper-parameters, after the training and in real-time, through a set of\nmanually adjustable parameters. These parameters enable the user to modify the\nsynthesized outputs from the same pair of style/content images, in search of a\nfavorite stylized image. Our quantitative and qualitative experiments indicate\nhow adjusting these parameters is comparable to retraining the model with\ndifferent hyper-parameters. We also demonstrate how these parameters can be\nrandomized to generate results which are diverse but still very similar in\nstyle and content."}, {"title": "From Variational to Deterministic Autoencoders", "authors": "Partha Ghosh, Mehdi S. M. Sajjadi, Antonio Vergari, Michael Black, Bernhard Scholkopf", "link": "https://arxiv.org/abs/1903.12436", "summary": "Variational Autoencoders (VAEs) provide a theoretically-backed and popular\nframework for deep generative models. However, learning a VAE from data poses\nstill unanswered theoretical questions and considerable practical challenges.\nIn this work, we propose an alternative framework for generative modeling that\nis simpler, easier to train, and deterministic, yet has many of the advantages\nof VAEs. We observe that sampling a stochastic encoder in a Gaussian VAE can be\ninterpreted as simply injecting noise into the input of a deterministic\ndecoder. We investigate how substituting this kind of stochasticity, with other\nexplicit and implicit regularization schemes, can lead to an equally smooth and\nmeaningful latent space without forcing it to conform to an arbitrarily chosen\nprior. To retrieve a generative mechanism to sample new data, we introduce an\nex-post density estimation step that can be readily applied also to existing\nVAEs, improving their sample quality. We show, in a rigorous empirical study,\nthat the proposed regularized deterministic autoencoders are able to generate\nsamples that are comparable to, or better than, those of VAEs and more powerful\nalternatives when applied to images as well as to structured data such as\nmolecules. \\footnote{An implementation is available at:\n\\url{https://github.com/ParthaEth/Regularized_autoencoders-RAE-}}"}, {"title": "Kernelized Wasserstein Natural Gradient", "authors": "M Arbel, A Gretton, W Li, G Montufar", "link": "https://arxiv.org/abs/1910.09652", "summary": "Many machine learning problems can be expressed as the optimization of some\ncost functional over a parametric family of probability distributions. It is\noften beneficial to solve such optimization problems using natural gradient\nmethods. These methods are invariant to the parametrization of the family, and\nthus can yield more effective optimization. Unfortunately, computing the\nnatural gradient is challenging as it requires inverting a high dimensional\nmatrix at each iteration. We propose a general framework to approximate the\nnatural gradient for the Wasserstein metric, by leveraging a dual formulation\nof the metric restricted to a Reproducing Kernel Hilbert Space. Our approach\nleads to an estimator for gradient direction that can trade-off accuracy and\ncomputational cost, with theoretical guarantees. We verify its accuracy on\nsimple examples, and show the advantage of using such an estimator in\nclassification tasks on Cifar10 and Cifar100 empirically."}, {"title": "Probabilistic Connection Importance Inference and Lossless Compression of Deep Neural Networks", "authors": "Xin Xing, Long Sha, Pengyu Hong, Zuofeng Shang, Jun S. Liu"}, {"title": "Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen Categories", "authors": "Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang, Hao Su"}, {"title": "Symplectic Recurrent Neural Networks", "authors": "Zhengdao Chen, Jianyu Zhang, Martin Arjovsky, L\u00e9on Bottou", "link": "http://arxiv.org/abs/1909.13334", "summary": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards."}, {"title": "Robustness Verification for Transformers", "authors": "Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh"}, {"title": "Dynamics-Aware Embeddings", "authors": "William Whitney, Rajat Agarwal, Kyunghyun Cho, Abhinav Gupta", "link": "https://arxiv.org/abs/1908.09357", "summary": "In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps."}, {"title": "Functional vs. parametric equivalence of ReLU networks", "authors": "Mary Phuong, Christoph H. Lampert"}, {"title": "Expected Information Maximization: Using the I-Projection for Mixture Density Estimation", "authors": "Philipp Becker, Oleg Arenz, Gerhard Neumann"}, {"title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes", "authors": "Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, Cho-Jui Hsieh", "link": "https://arxiv.org/abs/1904.00962", "summary": "Training large deep neural networks on massive datasets is computationally\nvery challenging. There has been recent surge in interest in using large batch\nstochastic optimization methods to tackle this issue. The most prominent\nalgorithm in this line of research is LARS, which by employing layerwise\nadaptive learning rates trains ResNet on ImageNet in a few minutes. However,\nLARS performs poorly for attention models like BERT, indicating that its\nperformance gains are not consistent across tasks. In this paper, we first\nstudy a principled layerwise adaptation strategy to accelerate training of deep\nneural networks using large mini-batches. Using this strategy, we develop a new\nlayerwise adaptive large batch optimization technique called LAMB; we then\nprovide convergence analysis of LAMB as well as LARS, showing convergence to a\nstationary point in general nonconvex settings. Our empirical results\ndemonstrate the superior performance of LAMB across various tasks such as BERT\nand ResNet-50 training with very little hyperparameter tuning. In particular,\nfor BERT training, our optimizer enables use of very large batch sizes of 32868\nwithout any degradation of performance. By increasing the batch size to the\nmemory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to\njust 76 minutes (Table 1). The LAMB implementation is available at\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py"}, {"title": "Scalable Model Compression by Entropy Penalized Reparameterization", "authors": "Deniz Oktay, Johannes Ball\u00e9, Saurabh Singh, Abhinav Shrivastava", "link": "https://arxiv.org/abs/1906.06624", "summary": "We describe a simple and general neural network weight compression approach,\nin which the network parameters (weights and biases) are represented in a\n\"latent\" space, amounting to a reparameterization. This space is equipped with\na learned probability model, which is used to impose an entropy penalty on the\nparameter representation during training, and to compress the representation\nusing a simple arithmetic coder after training. Classification accuracy and\nmodel compressibility is maximized jointly, with the bitrate--accuracy\ntrade-off specified by a hyperparameter. We evaluate the method on the MNIST,\nCIFAR-10 and ImageNet classification benchmarks using six distinct model\narchitectures. Our results show that state-of-the-art model compression can be\nachieved in a scalable and general way without requiring complex procedures\nsuch as multi-stage training."}, {"title": "Effect of Activation Functions on the Training of Overparametrized Neural Nets", "authors": "Abhishek Panigrahi, Abhishek Shetty, Navin Goyal", "link": "https://arxiv.org/abs/1908.05660", "summary": "It is well-known that overparametrized neural networks trained using\ngradient-based methods quickly achieve small training error with appropriate\nhyperparameter settings. Recent papers have proved this statement theoretically\nfor highly overparametrized networks under reasonable assumptions. These\nresults either assume that the activation function is ReLU or they crucially\ndepend on the minimum eigenvalue of a certain Gram matrix depending on the\ndata, random initialization and the activation function. In the later case,\nexisting works only prove that this minimum eigenvalue is non-zero and do not\nprovide quantitative bounds. On the empirical side, a contemporary line of\ninvestigations has proposed a number of alternative activation functions which\ntend to perform better than ReLU at least in some settings but no clear\nunderstanding has emerged. This state of affairs underscores the importance of\ntheoretically understanding the impact of activation functions on training. In\nthe present paper, we provide theoretical results about the effect of\nactivation function on the training of highly overparametrized 2-layer neural\nnetworks. A crucial property that governs the performance of an activation is\nwhether or not it is smooth. For non-smooth activations such as ReLU, SELU and\nELU, all eigenvalues of the associated Gram matrix are large under minimal\nassumptions on the data. For smooth activations such as tanh, swish and\npolynomials, the situation is more complex. If the subspace spanned by the data\nhas small dimension then the minimum eigenvalue of the Gram matrix can be small\nleading to slow training. But if the dimension is large and the data satisfies\nanother mild condition, then the eigenvalues are large. If we allow deep\nnetworks, then the small data dimension is not a limitation provided that the\ndepth is sufficient. We discuss a number of extensions and applications of\nthese results."}, {"title": "One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation", "authors": "Shunshi Zhang, Bradly C. Stadie"}, {"title": "Option Discovery using Deep Skill Chaining", "authors": "Akhil Bagaria, George Konidaris"}, {"title": "Generalized Convolutional Forest Networks for Domain Generalization and Visual Recognition", "authors": "Jongbin Ryu, Gitaek Kwon, Ming-Hsuan Yang, Jongwoo Lim"}, {"title": "Guiding Program Synthesis by Learning to Generate Examples", "authors": "Larissa Laich, Pavol Bielik, Martin Vechev"}, {"title": "Encoding word order in complex embeddings", "authors": "Benyou Wang, Donghao Zhao, Christina Lioma, Qiuchi Li, Peng Zhang, Jakob Grue Simonsen", "link": "https://arxiv.org/abs/1912.12333", "summary": "Sequential word order is important when processing text. Currently, neural\nnetworks (NNs) address this by modeling word position using position\nembeddings. The problem is that position embeddings capture the position of\nindividual words, but not the ordered relationship (e.g., adjacency or\nprecedence) between individual word positions. We present a novel and\nprincipled solution for modeling both the global absolute positions of words\nand their order relationships. Our solution generalizes word embeddings,\npreviously defined as independent vectors, to continuous word functions over a\nvariable (position). The benefit of continuous functions over variable\npositions is that word representations shift smoothly with increasing\npositions. Hence, word representations in different positions can correlate\nwith each other in a continuous function. The general solution of these\nfunctions is extended to complex-valued domain due to richer representations.\nWe extend CNN, RNN and Transformer NNs to complex-valued versions to\nincorporate our complex embedding (we make all code available). Experiments on\ntext classification, machine translation and language modeling show gains over\nboth classical word embeddings and position-enriched word embeddings. To our\nknowledge, this is the first work in NLP to link imaginary numbers in\ncomplex-valued representations to concrete meanings (i.e., word order)."}, {"title": "SCALOR: Generative World Models with Scalable Object Representations", "authors": "Jindong Jiang, Sepehr Janghorbani, Gerard De Melo, Sungjin Ahn", "link": "https://arxiv.org/abs/1910.02384", "summary": "Scalability in terms of object density in a scene is a primary challenge in\nunsupervised sequential object-oriented representation learning. Most of the\nprevious models have been shown to work only on scenes with a few objects. In\nthis paper, we propose SCALOR, a probabilistic generative world model for\nlearning SCALable Object-oriented Representation of a video. With the proposed\nspatially-parallel attention and proposal-rejection mechanisms, SCALOR can deal\nwith orders of magnitude larger numbers of objects compared to the previous\nstate-of-the-art models. Additionally, we introduce a background module that\nallows SCALOR to model complex dynamic backgrounds as well as many foreground\nobjects in the scene. We demonstrate that SCALOR can deal with crowded scenes\ncontaining up to a hundred objects while jointly modeling complex dynamic\nbackgrounds. Importantly, SCALOR is the first unsupervised object\nrepresentation model shown to work for natural scenes containing several tens\nof moving objects."}, {"title": "Neural Execution of Graph Algorithms", "authors": "Petar Veli\u010dkovi\u0107, Rex Ying, Matilde Padovano, Raia Hadsell, Charles Blundell", "link": "https://arxiv.org/abs/1910.10593", "summary": "Graph Neural Networks (GNNs) are a powerful representational tool for solving\nproblems on graph-structured inputs. In almost all cases so far, however, they\nhave been applied to directly recovering a final solution from raw inputs,\nwithout explicit guidance on how to structure their problem-solving. Here,\ninstead, we focus on learning in the space of algorithms: we train several\nstate-of-the-art GNN architectures to imitate individual steps of classical\ngraph algorithms, parallel (breadth-first search, Bellman-Ford) as well as\nsequential (Prim's algorithm). As graph algorithms usually rely on making\ndiscrete decisions within neighbourhoods, we hypothesise that\nmaximisation-based message passing neural networks are best-suited for such\nobjectives, and validate this claim empirically. We also demonstrate how\nlearning in the space of algorithms can yield new opportunities for positive\ntransfer between tasks---showing how learning a shortest-path algorithm can be\nsubstantially improved when simultaneously learning a reachability algorithm."}, {"title": "Towards Verified Robustness under Text Deletion Interventions", "authors": "Johannes Welbl, Po-Sen Huang, Robert Stanforth, Sven Gowal, Krishnamurthy (Dj) Dvijotham, Martin Szummer, Pushmeet Kohli"}, {"title": "Curvature Graph Network", "authors": "Ze Ye, Kin Sum Liu, Tengfei Ma, Jie Gao, Chao Chen"}, {"title": "Physics-aware Difference Graph Networks for Sparsely-Observed Dynamics", "authors": "Sungyong Seo, Chuizheng Meng, Yan Liu"}, {"title": "Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks", "authors": "Sanjeev Arora, Simon S. Du, Zhiyuan Li, Ruslan Salakhutdinov, Ruosong Wang, Dingli Yu", "link": "https://arxiv.org/abs/1910.01663", "summary": "Recent research shows that the following two models are equivalent: (a)\ninfinitely wide neural networks (NNs) trained under l2 loss by gradient descent\nwith infinitesimally small learning rate (b) kernel regression with respect to\nso-called Neural Tangent Kernels (NTKs) (Jacot et al., 2018). An efficient\nalgorithm to compute the NTK, as well as its convolutional counterparts,\nappears in Arora et al. (2019a), which allowed studying performance of\ninfinitely wide nets on datasets like CIFAR-10. However, super-quadratic\nrunning time of kernel methods makes them best suited for small-data tasks. We\nreport results suggesting neural tangent kernels perform strongly on low-data\ntasks.\n  1. On a standard testbed of classification/regression tasks from the UCI\ndatabase, NTK SVM beats the previous gold standard, Random Forests (RF), and\nalso the corresponding finite nets.\n  2. On CIFAR-10 with 10 - 640 training samples, Convolutional NTK consistently\nbeats ResNet-34 by 1% - 3%.\n  3. On VOC07 testbed for few-shot image classification tasks on ImageNet with\ntransfer learning (Goyal et al., 2019), replacing the linear SVM currently used\nwith a Convolutional NTK SVM consistently improves performance.\n  4. Comparing the performance of NTK with the finite-width net it was derived\nfrom, NTK behavior starts at lower net widths than suggested by theoretical\nanalysis(Arora et al., 2019a). NTK's efficacy may trace to lower variance of\noutput."}, {"title": "Population-Guided Parallel Policy Search for Reinforcement Learning", "authors": "Whiyoung Jung, Giseung Park, Youngchul Sung"}, {"title": "Deep Double Descent: Where Bigger Models and More Data Hurt", "authors": "Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, Ilya Sutskever"}, {"title": "At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks?", "authors": "Niv Giladi, Mor Shpigel Nacson, Elad Hoffer, Daniel Soudry", "link": "https://arxiv.org/abs/1909.12340", "summary": "Background: Recent developments have made it possible to accelerate neural\nnetworks training significantly using large batch sizes and data parallelism.\nTraining in an asynchronous fashion, where delay occurs, can make training even\nmore scalable. However, asynchronous training has its pitfalls, mainly a\ndegradation in generalization, even after convergence of the algorithm. This\ngap remains not well understood, as theoretical analysis so far mainly focused\non the convergence rate of asynchronous methods. Contributions: We examine\nasynchronous training from the perspective of dynamical stability. We find that\nthe degree of delay interacts with the learning rate, to change the set of\nminima accessible by an asynchronous stochastic gradient descent algorithm. We\nderive closed-form rules on how the learning rate could be changed, while\nkeeping the accessible set the same. Specifically, for high delay values, we\nfind that the learning rate should be kept inversely proportional to the delay.\nWe then extend this analysis to include momentum. We find momentum should be\neither turned off, or modified to improve training stability. We provide\nempirical experiments to validate our theoretical findings."}, {"title": "Discrepancy Ratio: Evaluating Model Performance When Even Experts Disagree on the Truth", "authors": "Igor Lovchinsky, Alon Daks, Israel Malkin, Pouya Samangouei, Ardavan Saeedi, Yang Liu, Swami Sankaranarayanan, Tomer Gafner, Ben Sternlieb, Patrick Maher, Nathan Silberman"}, {"title": "Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks", "authors": "Leopold Cambier, Anahita Bhiwandiwalla, Ting Gong, Oguz H. Elibol, Mehran Nekuii, Hanlin Tang"}, {"title": "Learning Efficient Parameter Server Synchronization Policies for Distributed SGD", "authors": "Rong Zhu, Sheng Yang, Andreas Pfadler, Zhengping Qian, Jingren Zhou"}, {"title": "Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks", "authors": "Christopher J. Cueva, Peter Y. Wang, Matthew Chin, Xue-Xin Wei", "link": "https://arxiv.org/abs/1912.10189", "summary": "Recent work suggests goal-driven training of neural networks can be used to\nmodel neural activity in the brain. While response properties of neurons in\nartificial neural networks bear similarities to those in the brain, the network\narchitectures are often constrained to be different. Here we ask if a neural\nnetwork can recover both neural representations and, if the architecture is\nunconstrained and optimized, the anatomical properties of neural circuits. We\ndemonstrate this in a system where the connectivity and the functional\norganization have been characterized, namely, the head direction circuits of\nthe rodent and fruit fly. We trained recurrent neural networks (RNNs) to\nestimate head direction through integration of angular velocity. We found that\nthe two distinct classes of neurons observed in the head direction system, the\nCompass neurons and the Shifter neurons, emerged naturally in artificial neural\nnetworks as a result of training. Furthermore, connectivity analysis and\nin-silico neurophysiology revealed structural and mechanistic similarities\nbetween artificial networks and the head direction system. Overall, our results\nshow that optimization of RNNs in a goal-driven task can recapitulate the\nstructure and function of biological circuits, suggesting that artificial\nneural networks can be used to study the brain at the level of both neural\nactivity and anatomical organization."}, {"title": "Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation", "authors": "Byung Hoon Ahn, Prannoy Pilligundla, Amir Yazdanbakhsh, Hadi Esmaeilzadeh"}, {"title": "Multi-Scale Representation Learning  for Spatial Feature Distributions using Grid Cells", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "link": "https://arxiv.org/abs/2003.00824", "summary": "Unsupervised text encoding models have recently fueled substantial progress\nin NLP. The key idea is to use neural networks to convert words in texts to\nvector space representations based on word positions in a sentence and their\ncontexts, which are suitable for end-to-end training of downstream tasks. We\nsee a strikingly similar situation in spatial analysis, which focuses on\nincorporating both absolute positions and spatial contexts of geographic\nobjects such as POIs into models. A general-purpose representation model for\nspace is valuable for a multitude of tasks. However, no such general model\nexists to date beyond simply applying discretization or feed-forward nets to\ncoordinates, and little effort has been put into jointly modeling distributions\nwith vastly different characteristics, which commonly emerges from GIS data.\nMeanwhile, Nobel Prize-winning Neuroscience research shows that grid cells in\nmammals provide a multi-scale periodic representation that functions as a\nmetric for location encoding and is critical for recognizing places and for\npath-integration. Therefore, we propose a representation learning model called\nSpace2Vec to encode the absolute positions and spatial relationships of places.\nWe conduct experiments on two real-world geographic data for two different\ntasks: 1) predicting types of POIs given their positions and context, 2) image\nclassification leveraging their geo-locations. Results show that because of its\nmulti-scale representations, Space2Vec outperforms well-established ML\napproaches such as RBF kernels, multi-layer feed-forward nets, and tile\nembedding approaches for location modeling and image classification tasks.\nDetailed analysis shows that all baselines can at most well handle distribution\nat one scale but show poor performances in other scales. In contrast,\nSpace2Vec's multi-scale representation can handle distributions at different\nscales."}, {"title": "U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation", "authors": "Junho Kim, Minjae Kim, Hyeonwoo Kang, Kwang Hee Lee", "link": "https://arxiv.org/abs/1907.10830", "summary": "We propose a novel method for unsupervised image-to-image translation, which\nincorporates a new attention module and a new learnable normalization function\nin an end-to-end manner. The attention module guides our model to focus on more\nimportant regions distinguishing between source and target domains based on the\nattention map obtained by the auxiliary classifier. Unlike previous\nattention-based method which cannot handle the geometric changes between\ndomains, our model can translate both images requiring holistic changes and\nimages requiring large shape changes. Moreover, our new AdaLIN (Adaptive\nLayer-Instance Normalization) function helps our attention-guided model to\nflexibly control the amount of change in shape and texture by learned\nparameters depending on datasets. Experimental results show the superiority of\nthe proposed method compared to the existing state-of-the-art models with a\nfixed network architecture and hyper-parameters. Our code and datasets are\navailable at https://github.com/taki0112/UGATIT or\nhttps://github.com/znxlwm/UGATIT-pytorch."}, {"title": "Model Based Reinforcement Learning for Atari", "authors": "\u0141ukasz Kaiser, Mohammad Babaeizadeh, Piotr Mi\u0142os, B\u0142a\u017cej Osi\u0144ski, Roy H Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski, Sergey Levine, Afroz Mohiuddin, Ryan Sepassi, George Tucker, Henryk Michalewski", "link": "https://arxiv.org/abs/1903.00374", "summary": "Model-free reinforcement learning (RL) can be used to learn effective\npolicies for complex tasks, such as Atari games, even from image observations.\nHowever, this typically requires very large amounts of interaction --\nsubstantially more, in fact, than a human would need to learn the same games.\nHow can people learn so quickly? Part of the answer may be that people can\nlearn how the game works and predict which actions will lead to desirable\noutcomes. In this paper, we explore how video prediction models can similarly\nenable agents to solve Atari games with fewer interactions than model-free\nmethods. We describe Simulated Policy Learning (SimPLe), a complete model-based\ndeep RL algorithm based on video prediction models and present a comparison of\nseveral model architectures, including a novel architecture that yields the\nbest results in our setting. Our experiments evaluate SimPLe on a range of\nAtari games in low data regime of 100k interactions between the agent and the\nenvironment, which corresponds to two hours of real-time play. In most games\nSimPLe outperforms state-of-the-art model-free algorithms, in some games by\nover an order of magnitude."}, {"title": "Learning to Learn by Zeroth-Order Oracle", "authors": "Yangjun Ruan, Yuanhao Xiong, Sashank Reddi, Sanjiv Kumar, Cho-Jui Hsieh", "link": "https://arxiv.org/abs/1910.09464", "summary": "In the learning to learn (L2L) framework, we cast the design of optimization\nalgorithms as a machine learning problem and use deep neural networks to learn\nthe update rules. In this paper, we extend the L2L framework to zeroth-order\n(ZO) optimization setting, where no explicit gradient information is available.\nOur learned optimizer, modeled as recurrent neural network (RNN), first\napproximates gradient by ZO gradient estimator and then produces parameter\nupdate utilizing the knowledge of previous iterations. To reduce high variance\neffect due to ZO gradient estimator, we further introduce another RNN to learn\nthe Gaussian sampling rule and dynamically guide the query direction sampling.\nOur learned optimizer outperforms hand-designed algorithms in terms of\nconvergence rate and final solution on both synthetic and practical ZO\noptimization tasks (in particular, the black-box adversarial attack task, which\nis one of the most widely used tasks of ZO optimization). We finally conduct\nextensive analytical experiments to demonstrate the effectiveness of our\nproposed optimizer."}, {"title": "Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings", "authors": "Shweta Mahajan, Iryna Gurevych, Stefan Roth"}, {"title": "Low-dimensional statistical manifold embedding of directed graphs", "authors": "Thorben Funke, Tian Guo, Alen Lancic, Nino Antulov-Fantulin", "link": "https://arxiv.org/abs/1905.10227", "summary": "We propose a novel node embedding of directed graphs to statistical\nmanifolds, which is based on a global minimization of pairwise relative entropy\nand graph geodesics in a non-linear way. Each node is encoded with a\nprobability density function over a measurable space. Furthermore, we analyze\nthe connection between the geometrical properties of such embedding and their\nefficient learning procedure. Extensive experiments show that our proposed\nembedding is better in preserving the global geodesic information of graphs, as\nwell as outperforming existing embedding models on directed graphs in a variety\nof evaluation metrics, in an unsupervised setting."}, {"title": "Robust Reinforcement Learning for Continuous Control with Model Misspecification", "authors": "Daniel J. Mankowitz, Nir Levine, Rae Jeong, Abbas Abdolmaleki, Jost Tobias Springenberg, Yuanyuan Shi, Jackie Kay, Todd Hester, Timothy Mann, Martin Riedmiller", "link": "https://arxiv.org/abs/1906.07516", "summary": "We provide a framework for incorporating robustness -- to perturbations in\nthe transition dynamics which we refer to as model misspecification -- into\ncontinuous control Reinforcement Learning (RL) algorithms. We specifically\nfocus on incorporating robustness into a state-of-the-art continuous control RL\nalgorithm called Maximum a-posteriori Policy Optimization (MPO). We achieve\nthis by learning a policy that optimizes for a worst case expected return\nobjective and derive a corresponding robust entropy-regularized Bellman\ncontraction operator. In addition, we introduce a less conservative,\nsoft-robust, entropy-regularized objective with a corresponding Bellman\noperator. We show that both, robust and soft-robust policies, outperform their\nnon-robust counterparts in nine Mujoco domains with environment perturbations.\nIn addition, we show improved robust performance on a high-dimensional,\nsimulated, dexterous robotic hand. Finally, we present multiple investigative\nexperiments that provide a deeper insight into the robustness framework. This\nincludes an adaptation to another continuous control RL algorithm as well as\nlearning the uncertainty set from offline data. Performance videos can be found\nonline at https://sites.google.com/view/robust-rl."}]