{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search arXiv Link\n",
    "\n",
    "Imported from [roomylee's implementation](https://github.com/roomylee/ACL-2020-Papers/blob/master/generate_paper_list_with_arxiv_link.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from googlesearch import search\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def search_arxiv_link(paper):\n",
    "    for j in search(paper[\"title\"], tld=\"co.in\", num=10, stop=1, pause=1.0, user_agent=\"acl2020\"):\n",
    "        if 'arxiv.org/abs' in j:\n",
    "            thepage = urllib.request.urlopen(j)\n",
    "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
    "            if similarity(paper[\"title\"], searched_title) > 0.8:\n",
    "                paper[\"link\"] = j\n",
    "                j = j.replace(\"https\", \"http\")\n",
    "                res = arxiv.query(query=\"\", id_list=[j.replace(\"http://arxiv.org/abs/\", \"\")])\n",
    "                for ppr in res:\n",
    "                  paper[\"summary\"] = ppr[\"summary\"]\n",
    "                break\n",
    "            else:\n",
    "                print(\"NOT MATCHED\")\n",
    "                paper[\"link\"] = \"\"\n",
    "                paper[\"summary\"] = \"\"\n",
    "                print(paper[\"title\"])\n",
    "                print(searched_title)\n",
    "    return paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find arXiv Data for Extracted Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFERENCE = \"ICML\" # Can be ACL, ICML, ICLR, CVPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conferences/{}/data/extracted_papers.json\".format(CONFERENCE)) as f:\n",
    "    extracted_papers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = [pool.apply(search_arxiv_link, (paper,)) for paper in extracted_papers]\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conferences/{}/data/papers_with_arixv_data.json\".format(CONFERENCE), \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(conference):\n",
    "    data = open(\"conferences/{}/data/papers_with_arxiv_data.json\".format(conference)).read()\n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(\"ICML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for paper in data:\n",
    "    title = paper[\"title\"].lower().replace(\"-\", \"\")\n",
    "    splitted = title.split()\n",
    "    counter.update(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('optimization', 64),\n",
       " ('reinforcement', 58),\n",
       " ('stochastic', 45),\n",
       " ('adversarial', 45),\n",
       " ('graph', 39),\n",
       " ('optimal', 35),\n",
       " ('gradient', 34),\n",
       " ('robust', 33),\n",
       " ('efficient', 32),\n",
       " ('inference', 31),\n",
       " ('generative', 31),\n",
       " ('training', 29),\n",
       " ('linear', 29),\n",
       " ('bayesian', 29),\n",
       " ('online', 28),\n",
       " ('generalization', 25),\n",
       " ('bandits', 23),\n",
       " ('representations', 23),\n",
       " ('sampling', 23),\n",
       " ('gaussian', 23)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_deep_learning = [\n",
    "    \"\", \"deep\", \"learning\", \"neural\", \"network\", \"networks\", \"via\", \"using\", \"based\", \"towards\",\n",
    "    \"text\", \"natural\", \"language\", \"model\", \"models\", \"approach\", \"improving\", \"data\", \"fast\", \n",
    "    \"analysis\", \"methods\", \"method\"\n",
    "]\n",
    "\n",
    "keywords = []\n",
    "for w in counter.most_common():\n",
    "    if w[0] not in stopwords.words('english') and w[0] not in stopwords_deep_learning:\n",
    "        keywords.append(w)\n",
    "\n",
    "keywords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"conferences/{}/data/keywords.json\".format(CONFERENCE), \"w\") as f:\n",
    "    json.dump(keywords, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
