[{"title": "Reverse-engineering deep ReLU networks", "authors": "David Rolnick, Konrad Kording ", "link": "https://arxiv.org/abs/1910.00744", "summary": "It has been widely assumed that a neural network cannot be recovered from its\noutputs, as the network depends on its parameters in a highly nonlinear way.\nHere, we prove that in fact it is often possible to identify the architecture,\nweights, and biases of an unknown deep ReLU network by observing only its\noutput. Every ReLU network defines a piecewise linear function, where the\nboundaries between linear regions correspond to inputs for which some neuron in\nthe network switches between inactive and active ReLU states. By dissecting the\nset of region boundaries into components associated with particular neurons, we\nshow both theoretically and empirically that it is possible to recover the\nweights of neurons and their arrangement within the network, up to isomorphism."}, {"title": "My Fair Bandit: Distributed Learning of Max-Min Fairness with Multi-player Bandits", "authors": "Ilai Bistritz, Tavor Baharav, Amir Leshem, Nicholas Bambos ", "link": "https://arxiv.org/abs/2002.09808", "summary": "Consider N cooperative but non-communicating players where each plays one out\nof M arms for T turns. Players have different utilities for each arm,\nrepresentable as an N x M matrix. These utilities are unknown to the players.\nIn each turn players receive noisy observations of their utility for their\nselected arm. However, if any other players selected the same arm that turn,\nthey will all receive zero utility due to the conflict. No other communication\nor coordination between the players is possible. Our goal is to design a\ndistributed algorithm that learns the matching between players and arms that\nachieves max-min fairness while minimizing the regret. We present an algorithm\nand prove that it is regret optimal up to a $\\log\\log T$ factor. This is the\nfirst max-min fairness multi-player bandit algorithm with (near) order optimal\nregret."}, {"title": "Scalable Differentiable Physics for Learning and Control", "authors": "Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, Ming Lin "}, {"title": "Generalization to New Actions in Reinforcement Learning", "authors": "Ayush Jain, Andrew Szot, Joseph Lim "}, {"title": "Randomized Block-Diagonal Preconditioning for Parallel Learning", "authors": "Celestine Mendler-D\u00fcnner, Aurelien Lucchi "}, {"title": "Stochastic Flows and Geometric Optimization on the Orthogonal Group", "authors": "Krzysztof Choromanski, Valerii Likhosherstov, Jared Q Davis, David Cheikhi, Achille Nazaret, Xingyou Song, Achraf Bahamou, Jack Parker-Holder, Mrugank Akarte, YUAN GAO, Jacob Bergquist, Aldo Pacchiano, Vikas Sindhwani, Tamas Sarlos, Adrian Weller ", "link": "https://arxiv.org/abs/2003.13563", "summary": "We present a new class of stochastic, geometrically-driven optimization\nalgorithms on the orthogonal group $O(d)$ and naturally reductive homogeneous\nmanifolds obtained from the action of the rotation group $SO(d)$. We\ntheoretically and experimentally demonstrate that our methods can be applied in\nvarious fields of machine learning including deep, convolutional and recurrent\nneural networks, reinforcement learning, normalizing flows and metric learning.\nWe show an intriguing connection between efficient stochastic optimization on\nthe orthogonal group and graph theory (e.g. matching problem, partition\nfunctions over graphs, graph-coloring). We leverage the theory of Lie groups\nand provide theoretical results for the designed class of algorithms. We\ndemonstrate broad applicability of our methods by showing strong performance on\nthe seemingly unrelated tasks of learning world models to obtain stable\npolicies for the most difficult $\\mathrm{Humanoid}$ agent from\n$\\mathrm{OpenAI}$ $\\mathrm{Gym}$ and improving convolutional neural networks."}, {"title": "PackIt: A Virtual Environment for Geometric Planning", "authors": "Ankit Goyal, Jia Deng "}, {"title": "Soft Threshold Weight Reparameterization for Learnable Sparsity", "authors": "Aditya Kusupati, Vivek Ramanujan, Raghav Somani, Mitchell Wortsman, Prateek Jain, Sham Kakade, Ali Farhadi ", "link": "https://arxiv.org/abs/2002.03231", "summary": "Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus\nof maximizing prediction accuracy given an overall parameter budget. Existing\nmethods rely on uniform or heuristic non-uniform sparsity budgets which have\nsub-optimal layer-wise parameter allocation resulting in a) lower prediction\naccuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold\nReparameterization (STR), a novel use of the soft-threshold operator on DNN\nweights. STR smoothly induces sparsity while learning pruning thresholds\nthereby obtaining a non-uniform sparsity budget. Our method achieves\nstate-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and\nMobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that\nempirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy\nover existing results by up to 10% in the ultra sparse (99%) regime and can\nalso be used to induce low-rank (structured sparsity) in RNNs. In short, STR is\na simple mechanism which learns effective sparsity budgets that contrast with\npopular heuristics. Code and pretrained models are available to download at\nhttps://github.com/RAIVNLab/STR."}, {"title": "Stochastic Latent Residual Video Prediction", "authors": "Jean-Yves Franceschi, Edouard Delasalles, Mickael Chen, Sylvain Lamprier, Patrick Gallinari ", "link": "https://arxiv.org/abs/2002.09219", "summary": "Designing video prediction models that account for the inherent uncertainty\nof the future is challenging. Most works in the literature are based on\nstochastic image-autoregressive recurrent networks, which raises several\nperformance and applicability issues. An alternative is to use fully latent\ntemporal models which untie frame synthesis and temporal dynamics. However, no\nsuch model for stochastic video prediction has been proposed in the literature\nyet, due to design and training difficulties. In this paper, we overcome these\ndifficulties by introducing a novel stochastic temporal model whose dynamics\nare governed in a latent space by a residual update rule. This first-order\nscheme is motivated by discretization schemes of differential equations. It\nnaturally models video dynamics as it allows our simpler, more interpretable,\nlatent model to outperform prior state-of-the-art methods on challenging\ndatasets."}, {"title": "Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise", "authors": "Umut Simsekli, Lingjiong Zhu, Yee Whye Teh, Mert Gurbuzbalaban ", "link": "https://arxiv.org/abs/2002.05685", "summary": "Stochastic gradient descent with momentum (SGDm) is one of the most popular\noptimization algorithms in deep learning. While there is a rich theory of SGDm\nfor convex problems, the theory is considerably less developed in the context\nof deep learning where the problem is non-convex and the gradient noise might\nexhibit a heavy-tailed behavior, as empirically observed in recent studies. In\nthis study, we consider a \\emph{continuous-time} variant of SGDm, known as the\nunderdamped Langevin dynamics (ULD), and investigate its asymptotic properties\nunder heavy-tailed perturbations. Supported by recent studies from statistical\nphysics, we argue both theoretically and empirically that the heavy-tails of\nsuch perturbations can result in a bias even when the step-size is small, in\nthe sense that \\emph{the optima of stationary distribution} of the dynamics\nmight not match \\emph{the optima of the cost function to be optimized}. As a\nremedy, we develop a novel framework, which we coin as \\emph{fractional} ULD\n(FULD), and prove that FULD targets the so-called Gibbs distribution, whose\noptima exactly match the optima of the original cost. We observe that the Euler\ndiscretization of FULD has noteworthy algorithmic similarities with\n\\emph{natural gradient} methods and \\emph{gradient clipping}, bringing a new\nperspective on understanding their role in deep learning. We support our theory\nwith experiments conducted on a synthetic model and neural networks."}, {"title": "Context Aware Local Differential Privacy", "authors": "Jayadev Acharya, Keith Bonawitz, Peter Kairouz, Daniel  Ramage, Ziteng Sun ", "link": "https://arxiv.org/abs/1911.00038", "summary": "Local differential privacy (LDP) is a strong notion of privacy for individual\nusers that often comes at the expense of a significant drop in utility. The\nclassical definition of LDP assumes that all elements in the data domain are\nequally sensitive. However, in many applications, some symbols are more\nsensitive than others. This work proposes a context-aware framework of local\ndifferential privacy that allows a privacy designer to incorporate the\napplication's context into the privacy definition. For binary data domains, we\nprovide a universally optimal privatization scheme and highlight its\nconnections to Warner's randomized response (RR) and Mangat's improved\nresponse. Motivated by geolocation and web search applications, for $k$-ary\ndata domains, we consider two special cases of context-aware LDP:\nblock-structured LDP and high-low LDP. We study discrete distribution\nestimation and provide communication-efficient, sample-optimal schemes and\ninformation-theoretic lower bounds for both models. We show that using\ncontextual information can require fewer samples than classical LDP to achieve\nthe same accuracy."}, {"title": "Privately Learning Markov Random Fields", "authors": "Gautam Kamath, Janardhan Kulkarni, Steven Wu, Huanyu Zhang ", "link": "https://arxiv.org/abs/2002.09463", "summary": "We consider the problem of learning Markov Random Fields (including the\nprototypical example, the Ising model) under the constraint of differential\nprivacy. Our learning goals include both structure learning, where we try to\nestimate the underlying graph structure of the model, as well as the harder\ngoal of parameter learning, in which we additionally estimate the parameter on\neach edge. We provide algorithms and lower bounds for both problems under a\nvariety of privacy constraints -- namely pure, concentrated, and approximate\ndifferential privacy. While non-privately, both learning goals enjoy roughly\nthe same complexity, we show that this is not the case under differential\nprivacy. In particular, only structure learning under approximate differential\nprivacy maintains the non-private logarithmic dependence on the dimensionality\nof the data, while a change in either the learning goal or the privacy notion\nwould necessitate a polynomial dependence. As a result, we show that the\nprivacy constraint imposes a strong separation between these two learning\nproblems in the high-dimensional data regime."}, {"title": "A Mean Field Analysis Of Deep ResNet And Beyond: Towards  Provably Optimization Via Overparameterization From Depth", "authors": "Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, Lexing Ying ", "link": "https://arxiv.org/abs/2003.05508", "summary": "Training deep neural networks with stochastic gradient descent (SGD) can\noften achieve zero training loss on real-world tasks although the optimization\nlandscape is known to be highly non-convex. To understand the success of SGD\nfor training deep neural networks, this work presents a mean-field analysis of\ndeep residual networks, based on a line of works that interpret the continuum\nlimit of the deep residual network as an ordinary differential equation when\nthe network capacity tends to infinity. Specifically, we propose a new\ncontinuum limit of deep residual networks, which enjoys a good landscape in the\nsense that every local minimizer is global. This characterization enables us to\nderive the first global convergence result for multilayer neural networks in\nthe mean-field regime. Furthermore, without assuming the convexity of the loss\nlandscape, our proof relies on a zero-loss assumption at the global minimizer\nthat can be achieved when the model shares a universal approximation property.\nKey to our result is the observation that a deep residual network resembles a\nshallow network ensemble, i.e. a two-layer network. We bound the difference\nbetween the shallow network and our ResNet model via the adjoint sensitivity\nmethod, which enables us to apply existing mean-field analyses of two-layer\nnetworks to deep networks. Furthermore, we propose several novel training\nschemes based on the new continuous model, including one training procedure\nthat switches the order of the residual blocks and results in strong empirical\nperformance on the benchmark datasets."}, {"title": "Provable Smoothness Guarantees for Black-Box Variational Inference", "authors": "Justin Domke ", "link": "https://arxiv.org/abs/1901.08431", "summary": "Black-box variational inference tries to approximate a complex target\ndistribution though a gradient-based optimization of the parameters of a\nsimpler distribution. Provable convergence guarantees require structural\nproperties of the objective. This paper shows that for location-scale family\napproximations, if the target is M-Lipschitz smooth, then so is the objective,\nif the entropy is excluded. The key proof idea is to describe gradients in a\ncertain inner-product space, thus permitting use of Bessel's inequality. This\nresult gives insight into how to parameterize distributions, gives bounds the\nlocation of the optimal parameters, and is a key ingredient for convergence\nguarantees."}, {"title": "Enhancing Simple Models by Exploiting What They Already Know", "authors": "Amit Dhurandhar, Karthikeyan Shanmugam, Ronny Luss "}, {"title": "Fiduciary Bandits", "authors": "Gal Bahar, Omer Ben Porat, Kevin Leyton-Brown, Moshe Tennenholtz ", "link": "https://arxiv.org/abs/1905.07043", "summary": "Recommendation systems often face exploration-exploitation tradeoffs: the\nsystem can only learn about the desirability of new options by recommending\nthem to some user. Such systems can thus be modeled as multi-armed bandit\nsettings; however, users are self-interested and cannot be made to follow\nrecommendations. We ask whether exploration can nevertheless be performed in a\nway that scrupulously respects agents' interests---i.e., by a system that acts\nas a fiduciary. More formally, we introduce a model in which a recommendation\nsystem faces an exploration-exploitation tradeoff under the constraint that it\ncan never recommend any action that it knows yields lower reward in expectation\nthan an agent would achieve if it acted alone. Our main contribution is a\npositive result: an asymptotically optimal, incentive compatible, and ex-ante\nindividually rational recommendation algorithm."}, {"title": "Training Deep Energy-Based Models with f-Divergence Minimization", "authors": "Lantao Yu, Yang Song, Jiaming Song, Stefano Ermon ", "link": "https://arxiv.org/abs/2003.03463", "summary": "Deep energy-based models (EBMs) are very flexible in distribution\nparametrization but computationally challenging because of the intractable\npartition function. They are typically trained via maximum likelihood, using\ncontrastive divergence to approximate the gradient of the KL divergence between\ndata and model distribution. While KL divergence has many desirable properties,\nother f-divergences have shown advantages in training implicit density\ngenerative models such as generative adversarial networks. In this paper, we\npropose a general variational framework termed f-EBM to train EBMs using any\ndesired f-divergence. We introduce a corresponding optimization algorithm and\nprove its local convergence property with non-linear dynamical systems theory.\nExperimental results demonstrate the superiority of f-EBM over contrastive\ndivergence, as well as the benefits of training EBMs using f-divergences other\nthan KL."}, {"title": "Progressive Graph Learning for Open-Set Domain Adaptation", "authors": "Yadan Luo, Zijian Wang, Mahsa Baktashmotlagh, Zi Huang "}, {"title": "Learning De-biased Representations with Biased Representations", "authors": "Hyojin Bahng, SANGHYUK CHUN, Sangdoo Yun, Jaegul Choo, Seong Joon Oh ", "link": "https://arxiv.org/abs/1910.02806", "summary": "Many machine learning algorithms are trained and evaluated by splitting data\nfrom a single source into training and test sets. While such focus on\nin-distribution learning scenarios has led to interesting advancement, it has\nnot been able to tell if models are relying on dataset biases as shortcuts for\nsuccessful prediction (e.g., using snow cues for recognising snowmobiles). Such\nbiased models fail to generalise when the bias shifts to a different class. The\ncross-bias generalisation problem has been addressed by de-biasing training\ndata through augmentation or re-sampling, which are often prohibitive due to\nthe data collection cost (e.g., collecting images of a snowmobile on a desert)\nand the difficulty of quantifying or expressing biases in the first place. In\nthis work, we propose a novel framework to train a de-biased representation by\nencouraging it to be different from a set of representations that are biased by\ndesign. This tactic is feasible in many scenarios where it is much easier to\ndefine a set of biased representations than to define and quantify bias. We\ndemonstrate the efficacy of our method across a variety of synthetic and\nreal-world biases. Our experiments and analyses show that the method\ndiscourages models from taking bias shortcuts, resulting in improved\ngeneralisation."}, {"title": "Generalized Neural Policies for Relational MDPs", "authors": "Sankalp Garg, Aniket Bajpai, Mausam  ", "link": "https://arxiv.org/abs/2002.07375", "summary": "A Relational Markov Decision Process (RMDP) is a first-order representation\nto express all instances of a single probabilistic planning domain with\npossibly unbounded number of objects. Early work in RMDPs outputs generalized\n(instance-independent) first-order policies or value functions as a means to\nsolve all instances of a domain at once. Unfortunately, this line of work met\nwith limited success due to inherent limitations of the representation space\nused in such policies or value functions. Can neural models provide the missing\nlink by easily representing more complex generalized policies, thus making them\neffective on all instances of a given domain?\n  We present the first neural approach for solving RMDPs, expressed in the\nprobabilistic planning language of RDDL. Our solution first converts an RDDL\ninstance into a ground DBN. We then extract a graph structure from the DBN. We\ntrain a relational neural model that computes an embedding for each node in the\ngraph and also scores each ground action as a function over the first-order\naction variable and object embeddings on which the action is applied. In\nessence, this represents a neural generalized policy for the whole domain.\nGiven a new test problem of the same domain, we can compute all node embeddings\nusing trained parameters and score each ground action to choose the best action\nusing a single forward pass without any retraining. Our experiments on nine\nRDDL domains from IPPC demonstrate that neural generalized policies are\nsignificantly better than random and sometimes even more effective than\ntraining a state-of-the-art deep reactive policy from scratch."}, {"title": "Feature-map-level Online Adversarial Knowledge Distillation", "authors": "Inseop Chung, Seonguk Park, Kim Jangho, NOJUN KWAK ", "link": "http://arxiv.org/abs/2002.01775", "summary": "Feature maps contain rich information about image intensity and spatial\ncorrelation. However, previous online knowledge distillation methods only\nutilize the class probabilities. Thus in this paper, we propose an online\nknowledge distillation method that transfers not only the knowledge of the\nclass probabilities but also that of the feature map using the adversarial\ntraining framework. We train multiple networks simultaneously by employing\ndiscriminators to distinguish the feature map distributions of different\nnetworks. Each network has its corresponding discriminator which discriminates\nthe feature map from its own as fake while classifying that of the other\nnetwork as real. By training a network to fool the corresponding discriminator,\nit can learn the other network's feature map distribution. We show that our\nmethod performs better than the conventional direct alignment method such as L1\nand is more suitable for online distillation. Also, we propose a novel cyclic\nlearning scheme for training more than two networks together. We have applied\nour method to various network architectures on the classification task and\ndiscovered a significant improvement of performance especially in the case of\ntraining a pair of a small network and a large one."}, {"title": "DRWR: A Differentiable Renderer without Rendering for Unsupervised 3D Structure Learning from Silhouette Images", "authors": "Zhizhong Han, Chao Chen, Yu-Shen Liu, Matthias Zwicker "}, {"title": "Towards Accurate Post-training Network Quantization via Bit-Split and Stitching", "authors": "Peisong  Wang, Qiang Chen, Xiangyu He, Jian Cheng "}, {"title": "Hybrid Stochastic-Deterministic Minibatch Proximal Gradient: Less-Than-Single-Pass Optimization with Nearly Optimal Generalization", "authors": "Pan Zhou, Xiao-Tong Yuan "}, {"title": "Reserve Pricing in Repeated Second-Price Auctions with Strategic Bidders", "authors": "Alexey Drutsa ", "link": "https://arxiv.org/abs/1906.09331", "summary": "We study revenue optimization learning algorithms for repeated second-price\nauctions with reserve where a seller interacts with multiple strategic bidders\neach of which holds a fixed private valuation for a good and seeks to maximize\nhis expected future cumulative discounted surplus. We propose a novel algorithm\nthat has strategic regret upper bound of $O(\\log\\log T)$ for worst-case\nvaluations. This pricing is based on our novel transformation that upgrades an\nalgorithm designed for the setup with a single buyer to the multi-buyer case.\nWe provide theoretical guarantees on the ability of a transformed algorithm to\nlearn the valuation of a strategic buyer, which has uncertainty about the\nfuture due to the presence of rivals."}, {"title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems", "authors": "Tianyi Lin, Chi Jin, Michael Jordan ", "link": "https://arxiv.org/abs/1906.00331", "summary": "We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications."}, {"title": "Learning Binary Neurons with Noisy Supervision", "authors": "Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Enhua Wu, Chang Xu "}, {"title": "Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization", "authors": "Geoffrey Negiar, Gideon Dresdner, Alicia Yi-Ting Tsai, Laurent El Ghaoui, Francesco Locatello, Fabian Pedregosa ", "link": "https://arxiv.org/abs/2002.11860", "summary": "We propose a novel Stochastic Frank-Wolfe (a.k.a. Conditional Gradient)\nalgorithm with a fixed batch size tailored to the constrained optimization of a\nfinite sum of smooth objectives. The design of our method hinges on a\nprimal-dual interpretation of the Frank-Wolfe algorithm.\n  Recent work to design stochastic variants of the Frank-Wolfe algorithm falls\ninto two categories: algorithms with increasing batch size, and algorithms with\na given, constant, batch size. The former have faster convergence rates but are\nimpractical; the latter are practical but slower. The proposed method combines\nthe advantages of both: it converges for unit batch size, and has faster\ntheoretical worst-case rates than previous unit batch size algorithms. Our\nexperiments also show faster empirical convergence than previous unit batch\nsize methods for several tasks.\n  Finally, we construct a stochastic estimator of the Frank-Wolfe gap. It\nallows us to bound the true Frank-Wolfe gap, which in the convex setting bounds\nthe primal-dual gap in the convex case while in general is a measure of\nstationarity. Our gap estimator can therefore be used as a practical stopping\ncriterion in all cases."}, {"title": "Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation", "authors": "Jian Liang, Dapeng Hu, Jiashi Feng ", "link": "https://arxiv.org/abs/2002.08546", "summary": "Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned\nfrom a labeled source dataset to solve similar tasks in a new unlabeled domain.\nPrior UDA methods typically require to access the source data when learning to\nadapt the model, making them risky and inefficient for decentralized private\ndata. In this work we tackle a novel setting where only a trained source model\nis available and investigate how we can effectively utilize such a model\nwithout source data to solve UDA problems. To this end, we propose a simple yet\ngeneric representation learning framework, named \\emph{Source HypOthesis\nTransfer} (SHOT). Specifically, SHOT freezes the classifier module (hypothesis)\nof the source model and learns the target-specific feature extraction module by\nexploiting both information maximization and self-supervised pseudo-labeling to\nimplicitly align representations from the target domains to the source\nhypothesis. In this way, the learned target model can directly predict the\nlabels of target data. We further investigate several techniques to refine the\nnetwork architecture to parameterize the source model for better transfer\nperformance. To verify its versatility, we evaluate SHOT in a variety of\nadaptation cases including closed-set, partial-set, and open-set domain\nadaptation. Experiments indicate that SHOT yields state-of-the-art results\namong multiple domain adaptation benchmarks."}, {"title": "Acceleration through spectral density estimation", "authors": "Fabian Pedregosa, Damien Scieur ", "link": "https://arxiv.org/abs/2002.04756", "summary": "We develop a framework for designing optimal quadratic optimization methods\nin terms of their average-case runtime. This yields a new class of methods that\nachieve acceleration through a model of the Hessian's expected spectral\ndensity. We develop explicit algorithms for the uniform, Marchenko-Pastur, and\nexponential distributions. These methods are momentum-based gradient algorithms\nwhose hyper-parameters can be estimated without knowledge of the Hessian's\nsmallest singular value, in contrast with classical accelerated methods like\nNesterov acceleration and Polyak momentum. Empirical results on quadratic,\nlogistic regression and neural networks show the proposed methods always match\nand in many cases significantly improve over classical accelerated methods."}, {"title": "Graph Structure of Neural Networks", "authors": "Jiaxuan You, Kaiming He, Jure Leskovec, Saining Xie "}, {"title": "Optimal Continual Learning has Perfect Memory and is NP-hard", "authors": "Jeremias Knoblauch, Hisham Husain, Tom Diethe "}, {"title": "Clinician-in-the-Loop Decision Making: Reinforcement Learning with Near-Optimal Set-Valued Policies", "authors": "Shengpu Tang, Aditya Modi, Michael Sjoding, Jenna Wiens "}, {"title": "Computational and Statistical Tradeoffs in Inferring Combinatorial Structures of Ising Model", "authors": "Ying Jin, Zhaoran Wang, Junwei Lu "}, {"title": "On the Number of Linear Regions of Convolutional Neural Networks", "authors": "Huan Xiong, Lei Huang, Mengyang Yu, Li Liu, Fan Zhu, Ling Shao "}, {"title": "Deep Streaming Label Learning", "authors": "Zhen Wang, Liu Liu, Dacheng Tao ", "link": "", "summary": ""}, {"title": "From Importance Sampling to Doubly Robust Policy Gradient", "authors": "Jiawei Huang, Nan Jiang ", "link": "https://arxiv.org/abs/1910.09066", "summary": "We show that on-policy policy gradient (PG) and its variance reduction\nvariants can be derived by taking finite difference of function evaluations\nsupplied by estimators from the importance sampling (IS) family for off-policy\nevaluation (OPE). Starting from the doubly robust (DR) estimator (Jiang & Li,\n2016), we provide a simple derivation of a very general and flexible form of\nPG, which subsumes the state-of-the-art variance reduction technique (Cheng et\nal., 2019) as its special case and immediately hints at further variance\nreduction opportunities overlooked by existing literature. We analyze the\nvariance of the new DR-PG estimator, compare it to existing methods as well as\nthe Cramer-Rao lower bound of policy gradient, and empirically show its\neffectiveness."}, {"title": "Loss Function Search for Face Recognition", "authors": "Xiaobo Wang, Shuo Wang, Shifeng Zhang, Cheng Chi, Tao Mei ", "link": "", "summary": ""}, {"title": "Breaking the Curse of Space Explosion: Towards Efficient NAS with Curriculum Search", "authors": "Yong Guo, Yaofo Chen, Yin Zheng, Peilin Zhao, Jian Chen, Junzhou Huang, Mingkui Tan "}, {"title": "Automatic Reparameterisation of Probabilistic Programs", "authors": "Maria Gorinova, Dave Moore, Matthew Hoffman ", "link": "https://arxiv.org/abs/1906.03028", "summary": "Probabilistic programming has emerged as a powerful paradigm in statistics,\napplied science, and machine learning: by decoupling modelling from inference,\nit promises to allow modellers to directly reason about the processes\ngenerating data. However, the performance of inference algorithms can be\ndramatically affected by the parameterisation used to express a model,\nrequiring users to transform their programs in non-intuitive ways. We argue for\nautomating these transformations, and demonstrate that mechanisms available in\nrecent modeling frameworks can implement non-centring and related\nreparameterisations. This enables new inference algorithms, and we propose two:\na simple approach using interleaved sampling and a novel variational\nformulation that searches over a continuous space of parameterisations. We show\nthat these approaches enable robust inference across a range of models, and can\nyield more efficient samplers than the best fixed parameterisation."}, {"title": "Kernel Methods for Cooperative Multi-Agent Learning with Delays", "authors": "Abhimanyu Dubey, Alex `Sandy' Pentland "}, {"title": "Robust Multi-Agent Decision-Making with Heavy-Tailed Payoffs", "authors": "Abhimanyu Dubey, Alex `Sandy' Pentland "}, {"title": "Learning the Valuations of a $k$-demand Agent", "authors": "Hanrui Zhang, Vincent Conitzer "}, {"title": "Rigging the Lottery: Making All Tickets Winners", "authors": "Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, Erich Elsen "}, {"title": "Active Learning on Attributed Graphs via Graph   Cognizant Logistic Regression and Preemptive Query Generation", "authors": "Florence Regol, Soumyasundar Pal, Yingxue Zhang, Mark Coates "}, {"title": "Performative Prediction", "authors": "Juan Perdomo, Tijana Zrnic, Celestine Mendler-D\u00fcnner, University of California Moritz Hardt ", "link": "https://arxiv.org/abs/2002.06673", "summary": "When predictions support decisions they may influence the outcome they aim to\npredict. We call such predictions performative; the prediction influences the\ntarget. Performativity is a well-studied phenomenon in policy-making that has\nso far been neglected in supervised learning. When ignored, performativity\nsurfaces as undesirable distribution shift, routinely addressed with\nretraining.\n  We develop a risk minimization framework for performative prediction bringing\ntogether concepts from statistics, game theory, and causality. A conceptual\nnovelty is an equilibrium notion we call performative stability. Performative\nstability implies that the predictions are calibrated not against past\noutcomes, but against the future outcomes that manifest from acting on the\nprediction. Our main results are necessary and sufficient conditions for the\nconvergence of retraining to a performatively stable point of nearly minimal\nloss.\n  In full generality, performative prediction strictly subsumes the setting\nknown as strategic classification. We thus also give the first sufficient\nconditions for retraining to overcome strategic feedback effects."}, {"title": "On Layer Normalization in the Transformer Architecture", "authors": "Ruinbin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu ", "link": "https://arxiv.org/abs/2002.04745", "summary": "The Transformer is widely used in natural language processing tasks. To train\na Transformer however, one usually needs a carefully designed learning rate\nwarm-up stage, which is shown to be crucial to the final performance but will\nslow down the optimization and bring more hyper-parameter tunings. In this\npaper, we first study theoretically why the learning rate warm-up stage is\nessential and show that the location of layer normalization matters.\nSpecifically, we prove with mean field theory that at initialization, for the\noriginal-designed Post-LN Transformer, which places the layer normalization\nbetween the residual blocks, the expected gradients of the parameters near the\noutput layer are large. Therefore, using a large learning rate on those\ngradients makes the training unstable. The warm-up stage is practically helpful\nfor avoiding this problem. On the other hand, our theory also shows that if the\nlayer normalization is put inside the residual blocks (recently proposed as\nPre-LN Transformer), the gradients are well-behaved at initialization. This\nmotivates us to remove the warm-up stage for the training of Pre-LN\nTransformers. We show in our experiments that Pre-LN Transformers without the\nwarm-up stage can reach comparable results with baselines while requiring\nsignificantly less training time and hyper-parameter tuning on a wide range of\napplications."}, {"title": "The many Shapley values for model explanation", "authors": "Mukund Sundararajan, Amir Najmi ", "link": "https://arxiv.org/abs/1908.08474", "summary": "The Shapley value has become a popular method to attribute the prediction of\na machine-learning model on an input to its base features. The use of the\nShapley value is justified by citing [16] showing that it is the \\emph{unique}\nmethod that satisfies certain good properties (\\emph{axioms}).\n  There are, however, a multiplicity of ways in which the Shapley value is\noperationalized in the attribution problem. These differ in how they reference\nthe model, the training data, and the explanation context. These give very\ndifferent results, rendering the uniqueness result meaningless. Furthermore, we\nfind that previously proposed approaches can produce counterintuitive\nattributions in theory and in practice---for instance, they can assign non-zero\nattributions to features that are not even referenced by the model.\n  In this paper, we use the axiomatic approach to study the differences between\nsome of the many operationalizations of the Shapley value for attribution, and\npropose a technique called Baseline Shapley (BShap) that is backed by a proper\nuniqueness result. We also contrast BShap with Integrated Gradients, another\nextension of Shapley value to the continuous setting."}, {"title": "Linear Convergence of Randomized Primal-Dual Coordinate Method for Large-scale Linear Constrained Convex Programming", "authors": "Daoli Zhu, Lei Zhao ", "link": "", "summary": ""}, {"title": "New Oracle-Efficient Algorithms for Private Synthetic Data Release", "authors": "Giuseppe Vietri, Steven Wu, Mark Bun, Thomas Steinke, Grace Tian "}, {"title": "Oracle Efficient Private Non-Convex Optimization", "authors": "Seth Neel, Aaron Roth, Giuseppe Vietri, Steven Wu ", "link": "", "summary": ""}, {"title": "Universal Asymptotic Optimality of Polyak Momentum", "authors": "Damien Scieur, Fabian Pedregosa ", "link": "", "summary": ""}, {"title": "Adversarial Robustness via Runtime Masking and Cleansing", "authors": "Yi-Hsuan Wu, Chia-Hung Yuan, Shan-Hung  Wu "}, {"title": "Implicit Euler Skip Connections: Enhancing Adversarial Robustness via Numerical Stability", "authors": "Mingjie Li, Lingshen He, Zhouchen Lin "}, {"title": "Best Arm Identification for Cascading Bandits in the Fixed Confidence Setting", "authors": "Zixin Zhong, Wang Chi Cheung, Vincent Tan ", "link": "https://arxiv.org/abs/2001.08655", "summary": "We design and analyze CascadeBAI, an algorithm for finding the best set of\n$K$ items, also called an arm, within the framework of cascading bandits. An\nupper bound on the time complexity of CascadeBAI is derived by overcoming a\ncrucial analytical challenge, namely, that of probabilistically estimating the\namount of available feedback at each step. To do so, we define a new class of\nrandom variables (r.v.'s) which we term as left-sided sub-Gaussian r.v.'s;\nthese are r.v.'s whose cumulant generating functions (CGFs) can be bounded by a\nquadratic only for non-positive arguments of the CGFs. This enables the\napplication of a sufficiently tight Bernstein-type concentration inequality. We\nshow, through the derivation of a lower bound on the time complexity, that the\nperformance of CascadeBAI is optimal in some practical regimes. Finally,\nextensive numerical simulations corroborate the efficacy of CascadeBAI as well\nas the tightness of our upper bound on its time complexity."}, {"title": "Robustness to Programmable String Transformations via Augmented Abstract Training", "authors": "Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni ", "link": "https://arxiv.org/abs/2002.09579", "summary": "Deep neural networks for natural language processing tasks are vulnerable to\nadversarial input perturbations. In this paper, we present a versatile language\nfor programmatically specifying string transformations -- e.g., insertions,\ndeletions, substitutions, swaps, etc. -- that are relevant to the task at hand.\nWe then present an approach to adversarially training models that are robust to\nsuch user-defined string transformations. Our approach combines the advantages\nof search-based techniques for adversarial training with abstraction-based\ntechniques. Specifically, we show how to decompose a set of user-defined string\ntransformations into two component specifications, one that benefits from\nsearch and another from abstraction. We use our technique to train models on\nthe AG and SST2 datasets and show that the resulting models are robust to\ncombinations of user-defined transformations mimicking spelling mistakes and\nother meaning-preserving transformations."}, {"title": "The Complexity of Finding Stationary Points with Stochastic Gradient Descent", "authors": "Yoel Drori, Ohad Shamir ", "link": "https://arxiv.org/abs/1910.01845", "summary": "We study the iteration complexity of stochastic gradient descent (SGD) for\nminimizing the gradient norm of smooth, possibly nonconvex functions. We\nprovide several results, implying that the classical\n$\\mathcal{O}(\\epsilon^{-4})$ upper bound (for making the average gradient norm\nless than $\\epsilon$) cannot be improved upon, unless a combination of\nadditional assumptions is made. Notably, this holds even if we limit ourselves\nto convex quadratic functions. We also show that for nonconvex functions, the\nfeasibility of minimizing gradients with SGD is surprisingly sensitive to the\nchoice of optimality criteria."}, {"title": "Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable Embeddings with Generative Priors", "authors": "Zhaoqiang Liu, Selwyn Gomes, Avtansh Tiwari, Jonathan Scarlett ", "link": "https://arxiv.org/abs/2002.01697", "summary": "The goal of standard 1-bit compressive sensing is to accurately recover an\nunknown sparse vector from binary-valued measurements, each indicating the sign\nof a linear function of the vector. Motivated by recent advances in compressive\nsensing with generative models, where a generative modeling assumption replaces\nthe usual sparsity assumption, we study the problem of 1-bit compressive\nsensing with generative models. We first consider noiseless 1-bit measurements,\nand provide sample complexity bounds for approximate recovery under\ni.i.d.~Gaussian measurements and a Lipschitz continuous generative prior, as\nwell as a near-matching algorithm-independent lower bound. Moreover, we\ndemonstrate that the Binary $\\epsilon$-Stable Embedding property, which\ncharacterizes the robustness of the reconstruction to measurement errors and\nnoise, also holds for 1-bit compressive sensing with Lipschitz continuous\ngenerative models with sufficiently many Gaussian measurements. In addition, we\napply our results to neural network generative models, and provide a\nproof-of-concept numerical experiment demonstrating significant improvements\nover sparsity-based approaches."}, {"title": "Class-Weighted Classification: Trade-offs and Robust Approaches", "authors": "Ziyu Xu, Chen Dan, Justin Khim, Pradeep Ravikumar ", "link": "https://arxiv.org/abs/2005.12914", "summary": "We address imbalanced classification, the problem in which a label may have\nlow marginal probability relative to other labels, by weighting losses\naccording to the correct class. First, we examine the convergence rates of the\nexpected excess weighted risk of plug-in classifiers where the weighting for\nthe plug-in classifier and the risk may be different. This leads to irreducible\nerrors that do not converge to the weighted Bayes risk, which motivates our\nconsideration of robust risks. We define a robust risk that minimizes risk over\na set of weightings and show excess risk bounds for this problem. Finally, we\nshow that particular choices of the weighting set leads to a special instance\nof conditional value at risk (CVaR) from stochastic programming, which we call\nlabel conditional value at risk (LCVaR). Additionally, we generalize this\nweighting to derive a new robust risk problem that we call label heterogeneous\nconditional value at risk (LHCVaR). Finally, we empirically demonstrate the\nefficacy of LCVaR and LHCVaR on improving class conditional risks."}, {"title": "Neural Architecture Search in a Proxy Validation Loss Landscape", "authors": "Yanxi Li, Minjing Dong, Yunhe Wang, Chang Xu "}, {"title": "Almost Tune-Free Variance Reduction", "authors": "Bingcong Li, Lingda Wang, Georgios B. Giannakis ", "link": "https://arxiv.org/abs/1908.09345", "summary": "The variance reduction class of algorithms including the representative ones,\nabbreviated as SVRG and SARAH, have well documented merits for empirical risk\nminimization tasks. However, they require grid search to optimally tune\nparameters (step size and the number of iterations per inner loop) for best\nperformance. This work introduces `almost tune-free' SVRG and SARAH schemes by\nequipping them with Barzilai-Borwein (BB) step sizes. To achieve the best\nperformance, both i) averaging schemes; and, ii) the inner loop length are\nadjusted according to the BB step size. SVRG and SARAH are first reexamined\nthrough an `estimate sequence' lens. Such analysis provides new averaging\nmethods that tighten the convergence rates of both SVRG and SARAH\ntheoretically, and improve their performance empirically when the step size is\nchosen large. Then a simple yet effective means of adjusting the number of\niterations per inner loop is developed, which completes the tune-free variance\nreduction together with BB step sizes. Numerical tests corroborate the proposed\nmethods."}, {"title": "Uniform Convergence of Rank-weighted Learning ", "authors": "Liu Leqi, Justin Khim, Adarsh Prasad, Pradeep Ravikumar "}, {"title": "Parallel Machine Translation with Disentangled Context Transformer", "authors": "Jungo Kasai, James Cross, Marjan Ghazvininejad, Jiatao Gu ", "link": "https://arxiv.org/abs/2001.05136", "summary": "State-of-the-art neural machine translation models generate a translation\nfrom left to right and every step is conditioned on the previously generated\ntokens. The sequential nature of this generation process causes fundamental\nlatency in inference since we cannot generate multiple tokens in each sentence\nin parallel. We propose an attention-masking based model, called Disentangled\nContext (DisCo) transformer, that simultaneously generates all tokens given\ndifferent contexts. The DisCo transformer is trained to predict every output\ntoken given an arbitrary subset of the other reference tokens. We also develop\nthe parallel easy-first inference algorithm, which iteratively refines every\ntoken in parallel and reduces the number of required iterations. Our extensive\nexperiments on 7 directions with varying data sizes demonstrate that our model\nachieves competitive, if not better, performance compared to the state of the\nart in non-autoregressive machine translation while significantly reducing\ndecoding time on average."}, {"title": "More Information Supervised Probabilistic Deep Face Embedding Learning", "authors": "Ying Huang, Shangfeng Qiu, Wenwei Zhang, Xianghui Luo, Jinzhuo Wang "}, {"title": "Parameter-Free Learning for Evolving Markov Decision Processes: The Blessing of (More) Optimism", "authors": "Wang Chi Cheung, David Simchi-Levi, Ruihao Zhu "}, {"title": "Improved Sleeping Bandits with Stochastic Action Sets and Adversarial Rewards", "authors": "Aadirupa Saha, Bangalore, Pierre Gaillard, Michal Valko ", "link": "https://arxiv.org/abs/2004.06248", "summary": "In this paper, we consider the problem of sleeping bandits with stochastic\naction sets and adversarial rewards. In this setting, in contrast to most work\nin bandits, the actions may not be available at all times. For instance, some\nproducts might be out of stock in item recommendation. The best existing\nefficient (i.e., polynomial-time) algorithms for this problem only guarantee a\n$O(T^{2/3})$ upper-bound on the regret. Yet, inefficient algorithms based on\nEXP4 can achieve $O(\\sqrt{T})$. In this paper, we provide a new computationally\nefficient algorithm inspired by EXP3 satisfying a regret of order $O(\\sqrt{T})$\nwhen the availabilities of each action $i \\in \\cA$ are independent. We then\nstudy the most general version of the problem where at each round available\nsets are generated from some unknown arbitrary distribution (i.e., without the\nindependence assumption) and propose an efficient algorithm with $O(\\sqrt {2^K\nT})$ regret guarantee. Our theoretical results are corroborated with\nexperimental evaluations."}, {"title": "From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model", "authors": "Aadirupa Saha, Bangalore, Aditya Gopalan ", "link": "https://arxiv.org/abs/1903.00558", "summary": "We consider PAC-learning a good item from $k$-subsetwise feedback information\nsampled from a Plackett-Luce probability model, with instance-dependent sample\ncomplexity performance. In the setting where subsets of a fixed size can be\ntested and top-ranked feedback is made available to the learner, we give an\nalgorithm with optimal instance-dependent sample complexity, for PAC best arm\nidentification, of $O\\bigg(\\frac{\\theta_{[k]}}{k}\\sum_{i =\n2}^n\\max\\Big(1,\\frac{1}{\\Delta_i^2}\\Big) \\ln\\frac{k}{\\delta}\\Big(\\ln\n\\frac{1}{\\Delta_i}\\Big)\\bigg)$, $\\Delta_i$ being the Plackett-Luce parameter\ngap between the best and the $i^{th}$ best item, and $\\theta_{[k]}$ is the sum\nof the \\pl\\, parameters for the top-$k$ items. The algorithm is based on a\nwrapper around a PAC winner-finding algorithm with weaker performance\nguarantees to adapt to the hardness of the input instance. The sample\ncomplexity is also shown to be multiplicatively better depending on the length\nof rank-ordered feedback available in each subset-wise play. We show optimality\nof our algorithms with matching sample complexity lower bounds. We next address\nthe winner-finding problem in Plackett-Luce models in the fixed-budget setting\nwith instance dependent upper and lower bounds on the misidentification\nprobability, of $\\Omega\\left(\\exp(-2 \\tilde \\Delta Q) \\right)$ for a given\nbudget $Q$, where $\\tilde \\Delta$ is an explicit instance-dependent problem\ncomplexity parameter. Numerical performance results are also reported."}, {"title": "Reliable Fidelity and Diversity Metrics for Generative Models", "authors": "Muhammad Ferjad Naeem, Seong Joon Oh, Yunjey Choi, Youngjung Uh, Jaejun Yoo ", "link": "https://arxiv.org/abs/2002.09797", "summary": "Devising indicative evaluation metrics for the image generation task remains\nan open problem. The most widely used metric for measuring the similarity\nbetween real and generated images has been the Fr\\'echet Inception Distance\n(FID) score. Because it does not differentiate the fidelity and diversity\naspects of the generated images, recent papers have introduced variants of\nprecision and recall metrics to diagnose those properties separately. In this\npaper, we show that even the latest version of the precision and recall metrics\nare not reliable yet. For example, they fail to detect the match between two\nidentical distributions, they are not robust against outliers, and the\nevaluation hyperparameters are selected arbitrarily. We propose density and\ncoverage metrics that solve the above issues. We analytically and\nexperimentally show that density and coverage provide more interpretable and\nreliable signals for practitioners than the existing metrics. Code:\nhttps://github.com/clovaai/generative-evaluation-prdc."}, {"title": "Learning Factorized Weight Matrix for Joint Image Filtering", "authors": "Xiangyu Xu, Yongrui Ma, Wenxiu Sun "}, {"title": "Likelihood-free MCMC with Amortized Approximate Ratio Estimators", "authors": "Joeri Hermans, Volodimir Begy, Gilles Louppe ", "link": "https://arxiv.org/abs/1903.04057", "summary": "Posterior inference with an intractable likelihood is becoming an\nincreasingly common task in scientific domains which rely on sophisticated\ncomputer simulations. Typically, these forward models do not admit tractable\ndensities forcing practitioners to rely on approximations. This work introduces\na novel approach to address the intractability of the likelihood and the\nmarginal model. We achieve this by learning a flexible amortized estimator\nwhich approximates the likelihood-to-evidence ratio. We demonstrate that the\nlearned ratio estimator can be embedded in MCMC samplers to approximate\nlikelihood-ratios between consecutive states in the Markov chain, allowing us\nto draw samples from the intractable posterior. Techniques are presented to\nimprove the numerical stability and to measure the quality of an approximation.\nThe accuracy of our approach is demonstrated on a variety of benchmarks against\nwell-established techniques. Scientific applications in physics show its\napplicability."}, {"title": "Attacks Which Do Not Kill Training Make Adversarial Learning Stronger", "authors": "Jingfeng Zhang, XU Xilie, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli ", "link": "http://arxiv.org/abs/2002.11242", "summary": "Adversarial training based on the minimax formulation is necessary for\nobtaining adversarial robustness of trained models. However, it is conservative\nor even pessimistic so that it sometimes hurts the natural generalization. In\nthis paper, we raise a fundamental question---do we have to trade off natural\ngeneralization for adversarial robustness? We argue that adversarial training\nis to employ confident adversarial data for updating the current model. We\npropose a novel approach of friendly adversarial training (FAT): rather than\nemploying most adversarial data maximizing the loss, we search for least\nadversarial (i.e., friendly adversarial) data minimizing the loss, among the\nadversarial data that are confidently misclassified. Our novel formulation is\neasy to implement by just stopping the most adversarial data searching\nalgorithms such as PGD (projected gradient descent) early, which we call\nearly-stopped PGD. Theoretically, FAT is justified by an upper bound of the\nadversarial risk. Empirically, early-stopped PGD allows us to answer the\nearlier question negatively---adversarial robustness can indeed be achieved\nwithout compromising the natural generalization."}, {"title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson ", "link": "https://arxiv.org/abs/2001.11113", "summary": "We present GradientDICE for estimating the density ratio between the state\ndistribution of the target policy and the sampling distribution in off-policy\nreinforcement learning. GradientDICE fixes several problems of GenDICE (Zhang\net al., 2020), the state-of-the-art for estimating such density ratios. Namely,\nthe optimization problem in GenDICE is not a convex-concave saddle-point\nproblem once nonlinearity in optimization variable parameterization is\nintroduced to ensure positivity, so any primal-dual algorithm is not guaranteed\nto converge or find the desired solution. However, such nonlinearity is\nessential to ensure the consistency of GenDICE even with a tabular\nrepresentation. This is a fundamental contradiction, resulting from GenDICE's\noriginal formulation of the optimization problem. In GradientDICE, we optimize\na different objective from GenDICE by using the Perron-Frobenius theorem and\neliminating GenDICE's use of divergence. Consequently, nonlinearity in\nparameterization is not necessary for GradientDICE, which is provably\nconvergent under linear function approximation."}, {"title": "Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation", "authors": "Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson ", "link": "https://arxiv.org/abs/1911.04384", "summary": "We present the first provably convergent two-timescale off-policy\nactor-critic algorithm (COF-PAC) with function approximation. Key to COF-PAC is\nthe introduction of a new critic, the emphasis critic, which is trained via\nGradient Emphasis Learning (GEM), a novel combination of the key ideas of\nGradient Temporal Difference Learning and Emphatic Temporal Difference\nLearning. With the help of the emphasis critic and the canonical value function\ncritic, we show convergence for COF-PAC, where the critics are linear and the\nactor can be nonlinear."}, {"title": "Adversarial Attacks on Probabilistic Autoregressive Forecasting Models", "authors": "Rapha\u00ebl Dang-Nhu, Gagandeep Singh, Pavol Bielik, Martin Vechev ", "link": "http://arxiv.org/abs/2003.03778", "summary": "We develop an effective generation of adversarial attacks on neural models\nthat output a sequence of probability distributions rather than a sequence of\nsingle values. This setting includes the recently proposed deep probabilistic\nautoregressive forecasting models that estimate the probability distribution of\na time series given its past and achieve state-of-the-art results in a diverse\nset of application domains. The key technical challenge we address is\neffectively differentiating through the Monte-Carlo estimation of statistics of\nthe joint distribution of the output sequence. Additionally, we extend prior\nwork on probabilistic forecasting to the Bayesian setting which allows\nconditioning on future observations, instead of only on past observations. We\ndemonstrate that our approach can successfully generate attacks with small\ninput perturbations in two challenging tasks where robust decision making is\ncrucial: stock market trading and prediction of electricity consumption."}, {"title": "Informative Dropout for Robust Representation Learning: A Shape-bias Perspective", "authors": "Baifeng Shi, Dinghuai Zhang, Qi Dai, Jingdong Wang, Zhanxing Zhu, Yadong Mu ", "link": "", "summary": ""}, {"title": "Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters", "authors": "Wenhui Yu, Zheng Qin "}, {"title": "SoftSort: A Differantiable Continuous Relaxation of the argsort Operator", "authors": "Sebastian Prillo, Julian Eisenschlos "}, {"title": "Too Relaxed to Be Fair", "authors": "Michael Lohaus, Michael Perrot, Ulrike von Luxburg "}, {"title": "Lorentz Group Equivariant Neural Network for Particle Physics", "authors": "Alexander Bogatskiy, Brandon Anderson, Jan Offermann, Marwah Roussi, David Miller, Risi Kondor "}, {"title": "One-shot distributed ridge regression in high dimensions", "authors": "Yue Sheng, Edgar Dobriban ", "link": "https://arxiv.org/abs/1903.09321", "summary": "In many areas, practitioners need to analyze large datasets that challenge\nconventional single-machine computing. To scale up data analysis, distributed\nand parallel computing approaches are increasingly needed.\n  Here we study a fundamental and highly important problem in this area: How to\ndo ridge regression in a distributed computing environment? Ridge regression is\nan extremely popular method for supervised learning, and has several optimality\nproperties, thus it is important to study. We study one-shot methods that\nconstruct weighted combinations of ridge regression estimators computed on each\nmachine. By analyzing the mean squared error in a high dimensional\nrandom-effects model where each predictor has a small effect, we discover\nseveral new phenomena.\n  1. Infinite-worker limit: The distributed estimator works well for very large\nnumbers of machines, a phenomenon we call \"infinite-worker limit\".\n  2. Optimal weights: The optimal weights for combining local estimators sum to\nmore than unity, due to the downward bias of ridge. Thus, all averaging methods\nare suboptimal.\n  We also propose a new Weighted ONe-shot DistributEd Ridge regression (WONDER)\nalgorithm. We test WONDER in simulation studies and using the Million Song\nDataset as an example. There it can save at least 100x in computation time,\nwhile nearly preserving test accuracy."}, {"title": "Streaming k-Submodular Maximization under Noise subject to Size Constraint", "authors": "Lan Nguyen, My Thai "}, {"title": "Variational Imitation Learning with Diverse-quality Demonstrations", "authors": "Voot Tangkaratt, Bo Han, Mohammad Emtiyaz Khan, Masashi Sugiyama ", "link": "https://arxiv.org/abs/1909.06769", "summary": "The goal of imitation learning (IL) is to learn a good policy from\nhigh-quality demonstrations. However, the quality of demonstrations in reality\ncan be diverse, since it is easier and cheaper to collect demonstrations from a\nmix of experts and amateurs. IL in such situations can be challenging,\nespecially when the level of demonstrators' expertise is unknown. We propose a\nnew IL method called \\underline{v}ariational \\underline{i}mitation\n\\underline{l}earning with \\underline{d}iverse-quality demonstrations (VILD),\nwhere we explicitly model the level of demonstrators' expertise with a\nprobabilistic graphical model and estimate it along with a reward function. We\nshow that a naive approach to estimation is not suitable to large state and\naction spaces, and fix its issues by using a variational approach which can be\neasily implemented using existing reinforcement learning methods. Experiments\non continuous-control benchmarks demonstrate that VILD outperforms\nstate-of-the-art methods. Our work enables scalable and data-efficient IL under\nmore realistic settings than before."}, {"title": "Task Understanding from Confusing Mulit-task Data", "authors": "Xin Su, yizhou Jiang, Shangqi Guo, Feng Chen "}, {"title": "Cost-effective Interactive Attention Learning with Neural Attention Process", "authors": "Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, Juho Lee, Eunho Yang, Sung Ju Hwang "}, {"title": "Channel Equilibrium Networks for Learning Deep Representation", "authors": "Wenqi Shao, Shitao Tang, Xingang Pan, Ping Tan, Xiaogang Wang, Ping Luo ", "link": "https://arxiv.org/abs/2003.00214", "summary": "Convolutional Neural Networks (CNNs) are typically constructed by stacking\nmultiple building blocks, each of which contains a normalization layer such as\nbatch normalization (BN) and a rectified linear function such as ReLU. However,\nthis work shows that the combination of normalization and rectified linear\nfunction leads to inhibited channels, which have small magnitude and contribute\nlittle to the learned feature representation, impeding the generalization\nability of CNNs. Unlike prior arts that simply removed the inhibited channels,\nwe propose to \"wake them up\" during training by designing a novel neural\nbuilding block, termed Channel Equilibrium (CE) block, which enables channels\nat the same layer to contribute equally to the learned representation. We show\nthat CE is able to prevent inhibited channels both empirically and\ntheoretically. CE has several appealing benefits. (1) It can be integrated into\nmany advanced CNN architectures such as ResNet and MobileNet, outperforming\ntheir original networks. (2) CE has an interesting connection with the Nash\nEquilibrium, a well-known solution of a non-cooperative game. (3) Extensive\nexperiments show that CE achieves state-of-the-art performance on various\nchallenging benchmarks such as ImageNet and COCO."}, {"title": "Optimal Non-parametric Learning in Repeated Contextual Auctions with  Strategic Buyer", "authors": "Alexey Drutsa "}, {"title": "Topological Autoencoders", "authors": "Michael Moor, Max Horn, Bastian Rieck, Karsten Borgwardt ", "link": "https://arxiv.org/abs/1906.00722", "summary": "We propose a novel approach for preserving topological structures of the\ninput space in latent representations of autoencoders. Using persistent\nhomology, a technique from topological data analysis, we calculate topological\nsignatures of both the input and latent space to derive a topological loss\nterm. Under weak theoretical assumptions, we construct this loss in a\ndifferentiable manner, such that the encoding learns to retain multi-scale\nconnectivity information. We show that our approach is theoretically\nwell-founded and that it exhibits favourable latent representations on a\nsynthetic manifold as well as on real-world image data sets, while preserving\nlow reconstruction errors."}, {"title": "An Accelerated DFO Algorithm for Finite-sum Convex Functions", "authors": "Yuwen Chen, Antonio Orvieto, Aurelien Lucchi "}, {"title": "The Shapley Taylor Interaction Index", "authors": "Mukund Sundararajan, Kedar Dhamdhere, Ashish Agarwal ", "link": "https://arxiv.org/abs/1902.05622", "summary": "The attribution problem, that is the problem of attributing a model's\nprediction to its base features, is well-studied. We extend the notion of\nattribution to also apply to feature interactions.\n  The Shapley value is a commonly used method to attribute a model's prediction\nto its base features. We propose a generalization of the Shapley value called\nShapley-Taylor index that attributes the model's prediction to interactions of\nsubsets of features up to some size k. The method is analogous to how the\ntruncated Taylor Series decomposes the function value at a certain point using\nits derivatives at a different point. In fact, we show that the Shapley Taylor\nindex is equal to the Taylor Series of the multilinear extension of the\nset-theoretic behavior of the model.\n  We axiomatize this method using the standard Shapley axioms -- linearity,\ndummy, symmetry and efficiency -- and an additional axiom that we call the\ninteraction distribution axiom. This new axiom explicitly characterizes how\ninteractions are distributed for a class of functions that model pure\ninteraction.\n  We contrast the Shapley-Taylor index against the previously proposed Shapley\nInteraction index (cf. [9]) from the cooperative game theory literature. We\nalso apply the Shapley Taylor index to three models and identify interesting\nqualitative insights."}, {"title": "Privately detecting changes in unknown distributions", "authors": "Rachel Cummings, Sara Krehbiel, Yuliia Lut, Wanrong Zhang ", "link": "https://arxiv.org/abs/1910.01327", "summary": "The change-point detection problem seeks to identify distributional changes\nin streams of data. Increasingly, tools for change-point detection are applied\nin settings where data may be highly sensitive and formal privacy guarantees\nare required, such as identifying disease outbreaks based on hospital records,\nor IoT devices detecting activity within a home. Differential privacy has\nemerged as a powerful technique for enabling data analysis while preventing\ninformation leakage about individuals. Much of the prior work on change-point\ndetection---including the only private algorithms for this problem---requires\ncomplete knowledge of the pre-change and post-change distributions. However,\nthis assumption is not realistic for many practical applications of interest.\nThis work develops differentially private algorithms for solving the\nchange-point problem when the data distributions are unknown. Additionally, the\ndata may be sampled from distributions that change smoothly over time, rather\nthan fixed pre-change and post-change distributions. We apply our algorithms to\ndetect changes in the linear trends of such data streams. Finally, we also\nprovide experimental results to empirically validate the performance of our\nalgorithms."}, {"title": "CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods", "authors": "Wei Zhang, Thomas  Panum, Somesh Jha, Prasad Chalasani, David Page ", "link": "https://arxiv.org/abs/2002.07906", "summary": "We study the problem of learning Granger causality between event types from\nasynchronous, interdependent, multi-type event sequences. Existing work suffers\nfrom either limited model flexibility or poor model explainability and thus\nfails to uncover Granger causality across a wide variety of event sequences\nwith diverse event interdependency. To address these weaknesses, we propose\nCAUSE (Causality from AttribUtions on Sequence of Events), a novel framework\nfor the studied task. The key idea of CAUSE is to first implicitly capture the\nunderlying event interdependency by fitting a neural point process, and then\nextract from the process a Granger causality statistic using an axiomatic\nattribution method. Across multiple datasets riddled with diverse event\ninterdependency, we demonstrate that CAUSE achieves superior performance on\ncorrectly inferring the inter-type Granger causality over a range of\nstate-of-the-art methods."}, {"title": "Efficient Continuous Pareto Exploration in Multi-Task Learning", "authors": "Pingchuan Ma, Tao Du, Wojciech Matusik ", "link": "", "summary": ""}, {"title": "WaveFlow: A Compact Flow-based Model for Raw Audio", "authors": "Wei Ping, Kainan Peng, Kexin Zhao, Zhao Song ", "link": "https://arxiv.org/abs/1912.01219", "summary": "In this work, we propose WaveFlow, a small-footprint generative flow for raw\naudio, which is directly trained with maximum likelihood. It handles the\nlong-range structure of waveform with a dilated 2-D convolutional architecture,\nwhile modeling the local variations using expressive autoregressive functions.\nWaveFlow provides a unified view of likelihood-based models for raw audio,\nincluding WaveNet and WaveGlow as special cases. It generates high-fidelity\nspeech as WaveNet, while synthesizing several orders of magnitude faster as it\nonly requires a few sequential steps to generate very long waveforms.\nFurthermore, it can significantly reduce the likelihood gap that has existed\nbetween autoregressive models and flow-based models for efficient synthesis.\nFinally, our small-footprint WaveFlow has only 5.91M parameters, which is\n15$\\times$ smaller than WaveGlow. It can generate 22.05 kHz high-fidelity audio\n42.6$\\times$ faster than real-time on a V100 GPU without engineered inference\nkernels."}, {"title": "Multi-Agent Determinantal Q-Learning", "authors": "Yaodong Yang, Ying Wen, Jun Wang, Liheng Chen, Kun Shao, David Mguni, Weinan Zhang ", "link": "http://arxiv.org/abs/2006.01482", "summary": "Centralized training with decentralized execution has become an important\nparadigm in multi-agent learning. Though practical, current methods rely on\nrestrictive assumptions to decompose the centralized value function across\nagents for execution. In this paper, we eliminate this restriction by proposing\nmulti-agent determinantal Q-learning. Our method is established on Q-DPP, a\nnovel extension of determinantal point process (DPP) to multi-agent setting.\nQ-DPP promotes agents to acquire diverse behavioral models; this allows a\nnatural factorization of the joint Q-functions with no need for \\emph{a priori}\nstructural constraints on the value function or special network architectures.\nWe demonstrate that Q-DPP generalizes major solutions including VDN, QMIX, and\nQTRAN on decentralizable cooperative tasks. To efficiently draw samples from\nQ-DPP, we develop a linear-time sampler with theoretical approximation\nguarantee. Our sampler also benefits exploration by coordinating agents to\ncover orthogonal directions in the state space during training. We evaluate our\nalgorithm on multiple cooperative benchmarks; its effectiveness has been\ndemonstrated when compared with the state-of-the-art."}, {"title": "Revisiting Spatial Invariance with Low-Rank Local Connectivity", "authors": "Gamaleldin Elsayed, Prajit Ramachandran, Jon Shlens, Simon Kornblith ", "link": "https://arxiv.org/abs/2002.02959", "summary": "Convolutional neural networks are among the most successful architectures in\ndeep learning. This success is at least partially attributable to the efficacy\nof spatial invariance as an inductive bias. Locally connected layers, which\ndiffer from convolutional layers in their lack of spatial invariance, usually\nperform poorly in practice. However, these observations still leave open the\npossibility that some degree of relaxation of spatial invariance may yield a\nbetter inductive bias than either convolution or local connectivity. To test\nthis hypothesis, we design a method to relax the spatial invariance of a\nnetwork layer in a controlled manner. In particular, we create a\n\\textit{low-rank} locally connected layer, where the filter bank applied at\neach position is constructed as a linear combination of basis set of filter\nbanks. By varying the number of filter banks in the basis set, we can control\nthe degree of departure from spatial invariance. In our experiments, we find\nthat relaxing spatial invariance improves classification accuracy over both\nconvolution and locally connected layers across MNIST, CIFAR-10, and CelebA\ndatasets. These results suggest that spatial invariance in convolution layers\nmay be overly restrictive."}, {"title": "Minimax Weight and Q-Function Learning for Off-Policy Evaluation", "authors": "Masatoshi Uehara, Jiawei Huang, Nan Jiang ", "link": "https://arxiv.org/abs/1910.12809", "summary": "We provide theoretical investigations into off-policy evaluation in\nreinforcement learning using function approximators for (marginalized)\nimportance weights and value functions. Our contributions include: (1) A new\nestimator, MWL, that directly estimates importance ratios over the state-action\ndistributions, removing the reliance on knowledge of the behavior policy as in\nprior work (Liu et al., 2018). (2) Another new estimator, MQL, obtained by\nswapping the roles of importance weights and value-functions in MWL. MQL has an\nintuitive interpretation of minimizing average Bellman errors and can be\ncombined with MWL in a doubly robust manner. (3) Several additional results\nthat offer further insights into these methods, including the sample complexity\nanalyses of MWL and MQL, their asymptotic optimality in the tabular setting,\nhow the learned importance weights depend the choice of the discriminator\nclass, and how our methods provide a unified view of some old and new\nalgorithms in RL."}, {"title": "Tensor denoising and completion based on ordinal observations", "authors": "Chanwoo Lee, Miaoyan Wang ", "link": "https://arxiv.org/abs/2002.06524", "summary": "Higher-order tensors arise frequently in applications such as neuroimaging,\nrecommendation system, social network analysis, and psychological studies. We\nconsider the problem of low-rank tensor estimation from possibly incomplete,\nordinal-valued observations. Two related problems are studied, one on tensor\ndenoising and another on tensor completion. We propose a multi-linear\ncumulative link model, develop a rank-constrained M-estimator, and obtain\ntheoretical accuracy guarantees. Our mean squared error bound enjoys a faster\nconvergence rate than previous results, and we show that the proposed estimator\nis minimax optimal under the class of low-rank models. Furthermore, the\nprocedure developed serves as an efficient completion method which guarantees\nconsistent recovery of an order-$K$ $(d,\\ldots,d)$-dimensional low-rank tensor\nusing only $\\tilde{\\mathcal{O}}(Kd)$ noisy, quantized observations. We\ndemonstrate the outperformance of our approach over previous methods on the\ntasks of clustering and collaborative filtering."}, {"title": "Learning Human Objectives by Evaluating Hypothetical Behavior", "authors": "Siddharth Reddy, EECS Anca Dragan, Sergey Levine, Shane Legg, Jan Leike ", "link": "https://arxiv.org/abs/1912.05652", "summary": "We seek to align agent behavior with a user's objectives in a reinforcement\nlearning setting with unknown dynamics, an unknown reward function, and unknown\nunsafe states. The user knows the rewards and unsafe states, but querying the\nuser is expensive. To address this challenge, we propose an algorithm that\nsafely and interactively learns a model of the user's reward function. We start\nwith a generative model of initial states and a forward dynamics model trained\non off-policy data. Our method uses these models to synthesize hypothetical\nbehaviors, asks the user to label the behaviors with rewards, and trains a\nneural network to predict the rewards. The key idea is to actively synthesize\nthe hypothetical behaviors from scratch by maximizing tractable proxies for the\nvalue of information, without interacting with the environment. We call this\nmethod reward query synthesis via trajectory optimization (ReQueST). We\nevaluate ReQueST with simulated users on a state-based 2D navigation task and\nthe image-based Car Racing video game. The results show that ReQueST\nsignificantly outperforms prior methods in learning reward models that transfer\nto new environments with different initial state distributions. Moreover,\nReQueST safely trains the reward model to detect unsafe states, and corrects\nreward hacking before deploying the agent."}, {"title": "Counterfactual Cross-Validation: Stable Model Selection Procedure for Causal Inference Models", "authors": "Yuta Saito, Shota Yasui ", "link": "https://arxiv.org/abs/1909.05299", "summary": "We study the model selection problem in conditional average treatment effect\n(CATE) prediction. Unlike previous works on this topic, we focus on preserving\nthe rank order of the performance of candidate CATE predictors to enable\naccurate and stable model selection. To this end, we analyze the model\nperformance ranking problem and formulate guidelines to obtain a better\nevaluation metric. We then propose a novel metric that can identify the ranking\nof the performance of CATE predictors with high confidence. Empirical\nevaluations demonstrate that our metric outperforms existing metrics in both\nmodel selection and hyperparameter tuning tasks."}, {"title": "Learning Efficient Multi-agent Communication: An Information Bottleneck Approach", "authors": "Rundong Wang, Xu He, Runsheng Yu, Wei Qiu, Bo An, Zinovi Rabinovich ", "link": "https://arxiv.org/abs/1911.06992", "summary": "Many real-world multi-agent reinforcement learning applications require\nagents to communicate, assisted by a communication protocol. These applications\nface a common and critical issue of communication's limited bandwidth that\nconstrains agents' ability to cooperate successfully. In this paper, rather\nthan proposing a fixed communication protocol, we develop an Informative\nMulti-Agent Communication (IMAC) method to learn efficient communication\nprotocols. Our contributions are threefold. First, we notice a fact that a\nlimited bandwidth translates into a constraint on the communicated message\nentropy, thus paving the way of controlling the bandwidth. Second, we introduce\na customized batch-norm layer, which controls the messages' entropy to simulate\nthe limited bandwidth constraint. Third, we apply the information bottleneck\nmethod to discover the optimal communication protocol, which can satisfy a\nbandwidth constraint via training with the prior distribution in the method. To\ndemonstrate the efficacy of our method, we conduct extensive experiments in\nvarious cooperative and competitive multi-agent tasks across two dimensions:\nthe number of agents and different bandwidths. We show that IMAC converges\nfast, and leads to efficient communication among agents under the\nlimited-bandwidth constraint as compared to many baseline methods."}, {"title": "MoNet3D: Towards Accurate Monocular 3D Object Localization in Real Time", "authors": "XICHUAN ZHOU, YiChong Peng, Chunqiao Long, Fengbo Ren, Cong Shi "}, {"title": "S2GA: Robust Deep Learning with Noisy Labels without Early Stopping", "authors": "Bo Han, Gang Niu, Xingrui Yu, QUANMING YAO, Miao Xu, Ivor Tsang, Masashi Sugiyama ", "link": "", "summary": ""}, {"title": "Multinomial Logit Bandit with Low Switching Cost", "authors": "Kefan Dong, Yingkai Li, Qin Zhang, Yuan Zhou ", "link": "", "summary": ""}, {"title": "Deep Reasoning Networks for Unsupervised Pattern De-mixing with Constraint Reasoning", "authors": "Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John Gregoire, Carla Gomes ", "link": "", "summary": ""}, {"title": "Uncertainty-Aware Lookahead Factor Models for Improved Quantitative Investing", "authors": "Lakshay Chauhan, John Alberg, Zachary Lipton ", "link": "", "summary": ""}, {"title": "On the Unreasonable Effectiveness of the Greedy Algorithm: Greedy Adapts to Sharpness", "authors": "Sebastian Pokutta, Mohit Singh, Alfredo Torrico ", "link": "https://arxiv.org/abs/2002.04063", "summary": "Submodular maximization has been widely studied over the past decades, mostly\nbecause of its numerous applications in real-world problems. It is well known\nthat the standard greedy algorithm guarantees a worst-case approximation factor\nof 1-1/e when maximizing a monotone submodular function under a cardinality\nconstraint. However, empirical studies show that its performance is\nsubstantially better in practice. This raises a natural question of explaining\nthis improved performance of the greedy algorithm. In this work, we define\nsharpness for submodular functions as a candidate explanation for this\nphenomenon. The sharpness criterion is inspired by the concept of strong\nconvexity in convex optimization. We show that the greedy algorithm provably\nperforms better as the sharpness of the submodular function increases. This\nimprovement ties in closely with the faster convergence rates of first order\nmethods for sharp functions in convex optimization. Finally, we perform a\ncomputational study to empirically support our theoretical results and show\nthat sharpness explains the greedy performance better than other justifications\nin the literature."}, {"title": "Stronger and Faster Wasserstein Adversarial Attacks", "authors": "Kaiwen Wu, Allen Wang, Yaoliang Yu "}, {"title": "Optimizing Multiagent Cooperation via Policy Evolution and Shared Experiences", "authors": "Somdeb Majumdar, Shauharda Khadka, Santiago Miret, Stephen Mcaleer, Kagan Tumer "}, {"title": "Why are learned indexes so effective?", "authors": "Paolo Ferragina, Fabrizio Lillo, Giorgio Vinciguerra "}, {"title": "Fast OSCAR and OWL with Safe Screening Rules", "authors": "Runxue Bao, Bin Gu, Heng Huang "}, {"title": "Which Tasks Should Be Learned Together in Multi-task Learning?", "authors": "Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, Silvio Savarese ", "link": "https://arxiv.org/abs/1905.07553", "summary": "Many computer vision applications require solving multiple tasks in\nreal-time. A neural network can be trained to solve multiple tasks\nsimultaneously using `multi-task learning'. This saves computation at inference\ntime as only a single network needs to be evaluated. Unfortunately, this often\nleads to inferior overall performance as task objectives compete, which\nconsequently poses the question: which tasks should and should not be learned\ntogether in one network when employing multi-task learning? We systematically\nstudy task cooperation and competition and propose a framework for assigning\ntasks to a few neural networks such that cooperating tasks are computed by the\nsame neural network, while competing tasks are computed by different networks.\nOur framework offers a time-accuracy trade-off and can produce better accuracy\nusing less inference time than not only a single large multi-task neural\nnetwork but also many single-task networks."}, {"title": "Inertial Block Proximal Methods for Non-Convex Non-Smooth Optimization", "authors": "Hien Le, Nicolas Gillis, Panagiotis Patrinos ", "link": "https://arxiv.org/abs/1903.01818", "summary": "We propose inertial versions of block coordinate descent methods for solving\nnon-convex non-smooth composite optimization problems. Our methods possess\nthree main advantages compared to current state-of-the-art accelerated\nfirst-order methods: (1) they allow using two different extrapolation points to\nevaluate the gradients and to add the inertial force (we will empirically show\nthat it is more efficient than using a single extrapolation point), (2) they\nallow to randomly picking the block of variables to update, and (3) they do not\nrequire a restarting step. We prove the subsequential convergence of the\ngenerated sequence under mild assumptions, prove the global convergence under\nsome additional assumptions, and provide convergence rates. We deploy the\nproposed methods to solve non-negative matrix factorization (NMF) and show that\nthey compete favorably with the state-of-the-art NMF algorithms. Additional\nexperiments on non-negative approximate canonical polyadic decomposition, also\nknown as non-negative tensor factorization, are also provided."}, {"title": "Adversarial Neural Pruning with Latent Vulnerability Suppression", "authors": "Divyam Madaan, Jinwoo Shin, Sung Ju Hwang ", "link": "https://arxiv.org/abs/1908.04355", "summary": "Despite the remarkable performance of deep neural networks on various\ncomputer vision tasks, they are known to be highly susceptible to adversarial\nperturbations which makes it difficult to deploy them in real-world\nsafety-critical applications. In this paper, we conjecture that the main cause\nof this adversarial vulnerability is the distortion in the latent feature\nspace, and provide methods to effectively suppress them. Specifically, we\ndefine \\textbf{vulnerability} for each latent feature and then propose a new\nloss for adversarial learning, \\textbf{Vulnerability Suppression (VS)} loss,\nthat aims to minimize the feature-level vulnerability during training. We\nfurther propose a Bayesian framework to prune features with high vulnerability,\nin order to reduce both vulnerability and loss on adversarial samples. We\nvalidate our \\textbf{Adversarial Neural Pruning (ANP)} method on multiple\nbenchmark datasets, on which it not only obtains state-of-the-art adversarial\nrobustness but also improves the performance on clean examples, using only a\nfraction of the parameters used by the full network. Further qualitative\nanalysis suggests that the improvements actually come from the suppression of\nfeature-level vulnerability."}, {"title": "Lifted Disjoint Paths with Application in Multiple Object Tracking", "authors": "Andrea Hornakova, Roberto Henschel, Bodo Rosenhahn, Paul Swoboda "}, {"title": "Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks", "authors": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig ", "link": "https://arxiv.org/abs/2002.10118", "summary": "The point estimates of ReLU classification networks---arguably the most\nwidely used neural network architecture---have been shown to yield arbitrarily\nhigh confidence far away from the training data. This architecture, in\nconjunction with a maximum a posteriori estimation scheme, is thus not\ncalibrated nor robust. Approximate Bayesian inference has been empirically\ndemonstrated to improve predictive uncertainty in neural networks, although the\ntheoretical analysis of such Bayesian approximations is limited. We\ntheoretically analyze approximate Gaussian posterior distributions on the\nweights of ReLU networks and show that they fix the overconfidence problem.\nFurthermore, we show that even a simplistic, thus cheap, Bayesian\napproximation, also fixes these issues. This indicates that a sufficient\ncondition for a calibrated uncertainty on a ReLU network is ``to be a bit\nBayesian''. These theoretical results validate the usage of last-layer Bayesian\napproximation and motivate a range of a fidelity-cost trade-off. We further\nvalidate these findings empirically via various standard experiments using\ncommon deep ReLU networks and Laplace approximations."}, {"title": "SCAFFOLD: Stochastic Controlled Averaging for Federated Learning", "authors": "Sai Praneeth Reddy Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Jakkam Reddi, Sebastian Stich, Ananda Theertha Suresh ", "link": "", "summary": ""}, {"title": "Statistically Preconditioned Accelerated Gradient Method for Distributed Optimization", "authors": "Hadrien Hendrikx, Lin Xiao, Sebastien Bubeck, Francis Bach, Laurent Massouli\u00e9 ", "link": "https://arxiv.org/abs/2002.10726", "summary": "We consider the setting of distributed empirical risk minimization where\nmultiple machines compute the gradients in parallel and a centralized server\nupdates the model parameters. In order to reduce the number of communications\nrequired to reach a given accuracy, we propose a \\emph{preconditioned}\naccelerated gradient method where the preconditioning is done by solving a\nlocal optimization problem over a subsampled dataset at the server. The\nconvergence rate of the method depends on the square root of the relative\ncondition number between the global and local loss functions. We estimate the\nrelative condition number for linear prediction models by studying\n\\emph{uniform} concentration of the Hessians over a bounded domain, which\nallows us to derive improved convergence rates for existing preconditioned\ngradient methods and our accelerated method. Experiments on real-world datasets\nillustrate the benefits of acceleration in the ill-conditioned regime."}, {"title": "Pretrained Generalized Autoregressive Model with Adaptive Probabilistic Label Cluster for Extreme Multi-label Text Classification", "authors": "Hui Ye, Zhiyu Chen, Da-Han Wang, Brian Davison ", "link": "", "summary": ""}, {"title": "Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions", "authors": "Ahmed Alaa, M van der Schaar "}, {"title": "Disentangling Trainability and Generalization in Deep Neural Networks", "authors": "Lechao Xiao, Jeffrey Pennington, Samuel Schoenholz ", "link": "", "summary": ""}, {"title": "Moniqua: Modulo Quantized Communication in Decentralized SGD", "authors": "Yucheng Lu, Christopher De Sa ", "link": "https://arxiv.org/abs/2002.11787", "summary": "Running Stochastic Gradient Descent (SGD) in a decentralized fashion has\nshown promising results. In this paper we propose Moniqua, a technique that\nallows decentralized SGD to use quantized communication. We prove in theory\nthat Moniqua communicates a provably bounded number of bits per iteration,\nwhile converging at the same asymptotic rate as the original algorithm does\nwith full-precision communication. Moniqua improves upon prior works in that it\n(1) requires zero additional memory, (2) works with 1-bit quantization, and (3)\nis applicable to a variety of decentralized algorithms. We demonstrate\nempirically that Moniqua converges faster with respect to wall clock time than\nother quantized decentralized algorithms. We also show that Moniqua is robust\nto very low bit-budgets, allowing 1-bit-per-parameter communication without\ncompromising validation accuracy when training ResNet20 and ResNet110 on\nCIFAR10."}, {"title": "Expectation Maximization with Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation", "authors": "Amr Mohamed Alexandari, Anshul Kundaje, Avanti Shrikumar ", "link": "", "summary": ""}, {"title": "Expert Learning through Generalized Inverse Multiobjective Optimization: Models, Insights and Algorithms", "authors": "Chaosheng Dong, Bo Zeng "}, {"title": "Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures", "authors": "Mohamed El Amine Seddik, Cosme Louart, Mohamed Tamaazousti, Romain  COUILLET ", "link": "https://arxiv.org/abs/2001.08370", "summary": "This paper shows that deep learning (DL) representations of data produced by\ngenerative adversarial nets (GANs) are random vectors which fall within the\nclass of so-called \\textit{concentrated} random vectors. Further exploiting the\nfact that Gram matrices, of the type $G = X^T X$ with $X=[x_1,\\ldots,x_n]\\in\n\\mathbb{R}^{p\\times n}$ and $x_i$ independent concentrated random vectors from\na mixture model, behave asymptotically (as $n,p\\to \\infty$) as if the $x_i$\nwere drawn from a Gaussian mixture, suggests that DL representations of\nGAN-data can be fully described by their first two statistical moments for a\nwide range of standard classifiers. Our theoretical findings are validated by\ngenerating images with the BigGAN model and across different popular deep\nrepresentation networks."}, {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": "Xinyi Wang, Hieu Pham, Paul Michel, Antonios  Anastasopoulos, Jaime Carbonell, Graham Neubig ", "link": "https://arxiv.org/abs/1911.10088", "summary": "To acquire a new skill, humans learn better and faster if a tutor, based on\ntheir current knowledge level, informs them of how much attention they should\npay to particular content or practice problems. Similarly, a machine learning\nmodel could potentially be trained better with a scorer that \"adapts\" to its\ncurrent learning state and estimates the importance of each training data\ninstance. Training such an adaptive scorer efficiently is a challenging\nproblem; in order to precisely quantify the effect of a data instance at a\ngiven time during the training, it is typically necessary to first complete the\nentire training process. To efficiently optimize data usage, we propose a\nreinforcement learning approach called Differentiable Data Selection (DDS). In\nDDS, we formulate a scorer network as a learnable function of the training\ndata, which can be efficiently updated along with the main model being trained.\nSpecifically, DDS updates the scorer with an intuitive reward signal: it should\nup-weigh the data that has a similar gradient with a dev set upon which we\nwould finally like to perform well. Without significant computing overhead, DDS\ndelivers strong and consistent improvements over several strong baselines on\ntwo very different tasks of machine translation and image classification."}, {"title": "Optimistic Policy Optimization with Bandit Feedback", "authors": "Lior Shani, Yonathan Efroni, Aviv Rosenberg, Shie Mannor ", "link": "https://arxiv.org/abs/2002.08243", "summary": "Policy optimization methods are one of the most widely used classes of\nReinforcement Learning (RL) algorithms. Yet, so far, such methods have been\nmostly analyzed from an optimization perspective, without addressing the\nproblem of exploration, or by making strong assumptions on the interaction with\nthe environment. In this paper we consider model-based RL in the tabular\nfinite-horizon MDP setting with unknown transitions and bandit feedback. For\nthis setting, we propose an optimistic trust region policy optimization (TRPO)\nalgorithm for which we establish $\\tilde O(\\sqrt{S^2 A H^4 K})$ regret for\nstochastic rewards. Furthermore, we prove $\\tilde O( \\sqrt{ S^2 A H^4 } K^{2/3}\n) $ regret for adversarial rewards. Interestingly, this result matches previous\nbounds derived for the bandit feedback case, yet with known transitions. To the\nbest of our knowledge, the two results are the first sub-linear regret bounds\nobtained for policy optimization algorithms with unknown transitions and bandit\nfeedback."}, {"title": "Maximum-and-Concatenation Networks", "authors": "Xingyu Xie, Hao Kong, Jianlong Wu, Wayne Zhang, Guangcan Liu, Zhouchen Lin "}, {"title": "Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition", "authors": "Chi Jin, Tiancheng Jin, Haipeng Luo, Suvrit Sra, Tiancheng Yu ", "link": "", "summary": ""}, {"title": "Kernelized Stein Discrepancy Tests of Goodness-of-fit  for Time-to-Event Data", "authors": "Wenkai Xu, Tamara Fernandez, Nicolas Rivera, Arthur Gretton ", "link": "", "summary": ""}, {"title": "Efficient Intervention Design for Causal Discovery with Latents", "authors": "Raghavendra Addanki, Shiva Kasiviswanathan, Andrew McGregor, Cameron Musco ", "link": "https://arxiv.org/abs/2005.11736", "summary": "We consider recovering a causal graph in presence of latent variables, where\nwe seek to minimize the cost of interventions used in the recovery process. We\nconsider two intervention cost models: (1) a linear cost model where the cost\nof an intervention on a subset of variables has a linear form, and (2) an\nidentity cost model where the cost of an intervention is the same, regardless\nof what variables it is on, i.e., the goal is just to minimize the number of\ninterventions. Under the linear cost model, we give an algorithm to identify\nthe ancestral relations of the underlying causal graph, achieving within a\n$2$-factor of the optimal intervention cost. This approximation factor can be\nimproved to $1+\\epsilon$ for any $\\epsilon > 0$ under some mild restrictions.\nUnder the identity cost model, we bound the number of interventions needed to\nrecover the entire causal graph, including the latent variables, using a\nparameterization of the causal graph through a special type of colliders. In\nparticular, we introduce the notion of $p$-colliders, that are colliders\nbetween pair of nodes arising from a specific type of conditioning in the\ncausal graph, and provide an upper bound on the number of interventions as a\nfunction of the maximum number of $p$-colliders between any two nodes in the\ncausal graph."}, {"title": "Certified Data Removal from Machine Learning Models", "authors": "Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten ", "link": "https://arxiv.org/abs/1911.03030", "summary": "Good data stewardship requires removal of data at the request of the data's\nowner. This raises the question if and how a trained machine-learning model,\nwhich implicitly stores information about its training data, should be affected\nby such a removal request. Is it possible to \"remove\" data from a\nmachine-learning model? We study this problem by defining certified removal: a\nvery strong theoretical guarantee that a model from which data is removed\ncannot be distinguished from a model that never observed the data to begin\nwith. We develop a certified-removal mechanism for linear classifiers and\nempirically study learning settings in which this mechanism is practical."}, {"title": "One Size Fits All: Can We Train One Denoiser for All Noise Levels?", "authors": "Abhiram Gnanasambandam, Stanley Chan ", "link": "https://arxiv.org/abs/2005.09627", "summary": "When training an estimator such as a neural network for tasks like image\ndenoising, it is generally preferred to train \\emph{one} estimator and apply it\nto \\emph{all} noise levels. The de facto training protocol to achieve this goal\nis to train the estimator with noisy samples whose noise levels are uniformly\ndistributed across the range of interest. However, why should we allocate the\nsamples uniformly? Can we have more training samples that are less noisy, and\nfewer samples that are more noisy? What is the optimal distribution? How do we\nobtain such a distribution? The goal of this paper is to address this training\nsample distribution problem from a minimax risk optimization perspective. We\nderive a dual ascent algorithm to determine the optimal sampling distribution\nof which the convergence is guaranteed as long as the set of admissible\nestimators is closed and convex. For estimators with non-convex admissible sets\nsuch as deep neural networks, our dual formulation converges to a solution of\nthe convex relaxation. We discuss how the algorithm can be implemented in\npractice. We evaluate the algorithm on linear estimators and deep networks."}, {"title": "GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation", "authors": "Marc Brockschmidt ", "link": "https://arxiv.org/abs/1906.12192", "summary": "This paper presents a new Graph Neural Network (GNN) type using feature-wise\nlinear modulation (FiLM). Many standard GNN variants propagate information\nalong the edges of a graph by computing \"messages\" based only on the\nrepresentation of the source of each edge. In GNN-FiLM, the representation of\nthe target node of an edge is additionally used to compute a transformation\nthat can be applied to all incoming messages, allowing feature-wise modulation\nof the passed information.\n  Results of experiments comparing different GNN architectures on three tasks\nfrom the literature are presented, based on re-implementations of baseline\nmethods. Hyperparameters for all methods were found using extensive search,\nyielding somewhat surprising results: differences between baseline models are\nsmaller than reported in the literature. Nonetheless, GNN-FiLM outperforms\nbaseline methods on a regression task on molecular graphs and performs\ncompetitively on other tasks."}, {"title": "Sparse Gaussian Processes with Spherical Harmonic Features", "authors": "Vincent Dutordoir, Nicolas Durrande, James Hensman "}, {"title": "Asynchronous Coagent Networks", "authors": "James Kostas, Chris Nota, Philip Thomas ", "link": "", "summary": ""}, {"title": "Adaptive Checkpoint Adjoint Method for Gradient Estimation in Neural ODE", "authors": "Juntang Zhuang, Nicha Dvornek, Xiaoxiao Li, Sekhar Tatikonda, Xenophon Papademetris, James Duncan "}, {"title": "Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling", "authors": "Yao Liu, Pierre-Luc Bacon, Emma Brunskill ", "link": "https://arxiv.org/abs/1910.06508", "summary": "We establish a connection between the importance sampling estimators\ntypically used for off-policy policy evaluation in reinforcement learning and\nthe extended conditional Monte Carlo method. We show with some examples that in\nthe finite horizon case there is no strict ordering in general between the\nvariance of such conditional importance sampling estimators: the variance of\nthe per-decision or stationary variants may, in fact, be higher than that of\nthe crude importance sampling estimator. We also provide sufficient conditions\nfor the finite horizon case under which the per-decision or stationary\nestimators can reduce the variance. We then develop an asymptotic analysis and\nderive sufficient conditions under which there exists an exponential v.s.\npolynomial gap (in terms of horizon $T$) between the variance of importance\nsampling and that of the per-decision or stationary estimators."}, {"title": "Taylor Expansion Policy Optimization", "authors": "Yunhao Tang, Michal Valko, Remi Munos ", "link": "https://arxiv.org/abs/2003.06259", "summary": "In this work, we investigate the application of Taylor expansions in\nreinforcement learning. In particular, we propose Taylor expansion policy\noptimization, a policy optimization formalism that generalizes prior work\n(e.g., TRPO) as a first-order special case. We also show that Taylor expansions\nintimately relate to off-policy evaluation. Finally, we show that this new\nformulation entails modifications which improve the performance of several\nstate-of-the-art distributed algorithms."}, {"title": "Reinforcement Learning for Integer Programming: Learning to Cut", "authors": "Yunhao Tang, Shipra Agrawal, Yuri Faenza ", "link": "https://arxiv.org/abs/1906.04859", "summary": "Integer programming (IP) is a general optimization framework widely\napplicable to a variety of unstructured and structured problems arising in,\ne.g., scheduling, production planning, and graph optimization. As IP models\nmany provably hard to solve problems, modern IP solvers rely on many\nheuristics. These heuristics are usually human-designed, and naturally prone to\nsuboptimality. The goal of this work is to show that the performance of those\nsolvers can be greatly enhanced using reinforcement learning (RL). In\nparticular, we investigate a specific methodology for solving IPs, known as the\nCutting Plane Method. This method is employed as a subroutine by all modern IP\nsolvers. We present a deep RL formulation, network architecture, and algorithms\nfor intelligent adaptive selection of cutting planes (aka cuts). Across a wide\nrange of IP tasks, we show that the trained RL agent significantly outperforms\nhuman-designed heuristics, and effectively generalizes to 10X larger instances\nand across IP problem classes. The trained agent is also demonstrated to\nbenefit the popular downstream application of cutting plane methods in\nBranch-and-Cut algorithm, which is the backbone of state-of-the-art commercial\nIP solvers."}, {"title": "Safe Reinforcement Learning in Constrained Markov Decision Processes", "authors": "Akifumi Wachi, Yanan Sui "}, {"title": "Layered Sampling for Robust Optimization Problems", "authors": "Hu Ding, Zixiu Wang ", "link": "http://arxiv.org/abs/2002.11904", "summary": "In real world, our datasets often contain outliers. Moreover, the outliers\ncan seriously affect the final machine learning result. Most existing\nalgorithms for handling outliers take high time complexities (e.g. quadratic or\ncubic complexity). {\\em Coreset} is a popular approach for compressing data so\nas to speed up the optimization algorithms. However, the current coreset\nmethods cannot be easily extended to handle the case with outliers. In this\npaper, we propose a new variant of coreset technique, {\\em layered sampling},\nto deal with two fundamental robust optimization problems: {\\em\n$k$-median/means clustering with outliers} and {\\em linear regression with\noutliers}. This new coreset method is in particular suitable to speed up the\niterative algorithms (which often improve the solution within a local range)\nfor those robust optimization problems. Moreover, our method is easy to be\nimplemented in practice. We expect that our framework of layered sampling will\nbe applicable to other robust optimization problems."}, {"title": "Learning to Encode Position for Transformer with Continuous Dynamical Model", "authors": "Xuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, Cho-Jui Hsieh ", "link": "https://arxiv.org/abs/2003.09229", "summary": "We introduce a new way of learning to encode position information for\nnon-recurrent models, such as Transformer models. Unlike RNN and LSTM, which\ncontain inductive bias by loading the input tokens sequentially, non-recurrent\nmodels are less sensitive to position. The main reason is that position\ninformation among input units is not inherently encoded, i.e., the models are\npermutation equivalent; this problem justifies why all of the existing models\nare accompanied by a sinusoidal encoding/embedding layer at the input. However,\nthis solution has clear limitations: the sinusoidal encoding is not flexible\nenough as it is manually designed and does not contain any learnable\nparameters, whereas the position embedding restricts the maximum length of\ninput sequences. It is thus desirable to design a new position layer that\ncontains learnable parameters to adjust to different datasets and different\narchitectures. At the same time, we would also like the encodings to\nextrapolate in accordance with the variable length of inputs. In our proposed\nsolution, we borrow from the recent Neural ODE approach, which may be viewed as\na versatile continuous version of a ResNet. This model is capable of modeling\nmany kinds of dynamical systems. We model the evolution of encoded results\nalong position index by such a dynamical system, thereby overcoming the above\nlimitations of existing methods. We evaluate our new position layers on a\nvariety of neural machine translation and language understanding tasks, the\nexperimental results show consistent improvements over the baselines."}, {"title": "Do RNN and LSTM have Long Memory?", "authors": "Jingyu Zhao, Feiqing Huang, Jia Lv, Yanjie Duan, Zhen Qin, Guodong Li, Guangjian Tian "}, {"title": "Training Linear Neural Networks: Non-Local Convergence and Complexity Results", "authors": "Armin Eftekhari ", "link": "http://arxiv.org/abs/2002.09852", "summary": "Linear networks provide valuable insight into the workings of neural networks\nin general. In this paper, we improve the state of the art in [bah2019learning]\nby identifying conditions under which gradient flow successfully trains a\nlinear network, in spite of the non-strict saddle points present in the\noptimization landscape. We also improve the state of the art for computational\ncomplexity of training linear networks in [arora2018convergence] by\nestablishing non-local linear convergence rates for gradient flow.\n  Crucially, these new results are not in the lazy training regime, cautioned\nagainst in [chizat2019lazy,yehudai2019power]. Our results require the network\nto have a layer with one neuron, which corresponds to the popular spiked\ncovariance model in statistics, and subsumes the important case of networks\nwith a scalar output. Extending these results to all linear networks remains an\nopen problem."}, {"title": "On Validation and Planning of An Optimal Decision Rule with Application in Healthcare Studies", "authors": "Hengrui Cai, Wenbin  Lu, Rui Song "}, {"title": "Graph Optimal Transport for Cross-Domain Alignment", "authors": "Liqun Chen, Zhe Gan, Yu Cheng, Linjie Li, Lawrence Carin, Jingjing Liu "}, {"title": "Approximation Capabilities of Neural ODEs and Invertible Residual Networks", "authors": "Han Zhang, Xi Gao, Jacob Unterman, Tomasz Arodz ", "link": "https://arxiv.org/abs/1907.12998", "summary": "Neural ODEs and i-ResNet are recently proposed methods for enforcing\ninvertibility of residual neural models. Having a generic technique for\nconstructing invertible models can open new avenues for advances in learning\nsystems, but so far the question of whether Neural ODEs and i-ResNets can model\nany continuous invertible function remained unresolved. Here, we show that both\nof these models are limited in their approximation capabilities. We then prove\nthat any homeomorphism on a $p$-dimensional Euclidean space can be approximated\nby a Neural ODE operating on a $2p$-dimensional Euclidean space, and a similar\nresult for i-ResNets. We conclude by showing that capping a Neural ODE or an\ni-ResNet with a single linear layer is sufficient to turn the model into a\nuniversal approximator for non-invertible continuous functions."}, {"title": "Refined bounds for algorithm configuration: The knife-edge of dual class approximability", "authors": "Nina Balcan, Tuomas Sandholm, Ellen Vitercik "}, {"title": "Teaching with Limited Information on the Learner's Behaviour", "authors": "Ferdinando Cicalese, Sergio Filho, Eduardo Laber, Marco Molinaro "}, {"title": "Interpretations are Useful: Penalizing Explanations to Align Neural Networks with Prior Knowledge", "authors": "Laura Rieger, Chandan Singh, William Murdoch, Bin Yu ", "link": "https://arxiv.org/abs/1909.13584", "summary": "For an explanation of a deep learning model to be effective, it must provide\nboth insight into a model and suggest a corresponding action in order to\nachieve some objective. Too often, the litany of proposed explainable deep\nlearning methods stop at the first step, providing practitioners with insight\ninto a model, but no way to act on it. In this paper, we propose contextual\ndecomposition explanation penalization (CDEP), a method which enables\npractitioners to leverage existing explanation methods in order to increase the\npredictive accuracy of deep learning models. In particular, when shown that a\nmodel has incorrectly assigned importance to some features, CDEP enables\npractitioners to correct these errors by directly regularizing the provided\nexplanations. Using explanations provided by contextual decomposition (CD)\n(Murdoch et al., 2018), we demonstrate the ability of our method to increase\nperformance on an array of toy and real datasets."}, {"title": "DeltaGrad: Rapid retraining of machine learning models", "authors": "Yinjun Wu, Edgar Dobriban, Susan Davidson "}, {"title": "The Cost-free Nature of Optimally Tuning Tikhonov Regularizers and Other Ordered Smoothers", "authors": "Pierre Bellec, Dana Yang ", "link": "https://arxiv.org/abs/1905.12517", "summary": "We consider the problem of selecting the best estimator among a family of\nTikhonov regularized estimators, or, alternatively, to select a linear\ncombination of these regularizers that is as good as the best regularizer in\nthe family. Our theory reveals that if the Tikhonov regularizers share the same\npenalty matrix with different tuning parameters, a convex procedure based on\n$Q$-aggregation achieves the mean square error of the best estimator, up to a\nsmall error term no larger than $C\\sigma^2$, where $\\sigma^2$ is the noise\nlevel and $C>0$ is an absolute constant. Remarkably, the error term does not\ndepend on the penalty matrix or the number of estimators as long as they share\nthe same penalty matrix, i.e., it applies to any grid of tuning parameters, no\nmatter how large the cardinality of the grid is. This reveals the surprising\n\"cost-free\" nature of optimally tuning Tikhonov regularizers, in striking\ncontrast with the existing literature on aggregation of estimators where one\ntypically has to pay a cost of $\\sigma^2\\log(M)$ where $M$ is the number of\nestimators in the family. The result holds, more generally, for any family of\nordered linear smoothers. This encompasses Ridge regression as well as\nPrincipal Component Regression. The result is extended to the problem of tuning\nTikhonov regularizers with different penalty matrices."}, {"title": "Approximation Guarantees of Local Search Algorithms via Localizability of Set Functions", "authors": "Kaito Fujii ", "link": "http://arxiv.org/abs/2006.01400", "summary": "This paper proposes a new framework for providing approximation guarantees of\nlocal search algorithms. Local search is a basic algorithm design technique and\nis widely used for various combinatorial optimization problems. To analyze\nlocal search algorithms for set function maximization, we propose a new notion\ncalled localizability of set functions, which measures how effective local\nimprovement is. Moreover, we provide approximation guarantees of standard local\nsearch algorithms under various combinatorial constraints in terms of\nlocalizability. The main application of our framework is sparse optimization,\nfor which we show that restricted strong concavity and restricted smoothness of\nthe objective function imply localizability, and further develop accelerated\nversions of local search algorithms. We conduct experiments in sparse\nregression and structure learning of graphical models to confirm the practical\nefficiency of the proposed local search algorithms."}, {"title": "Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent", "authors": "Yunwen Lei, Yiming Ying "}, {"title": "Online Dense Subgraph Discovery  via Blurred-Graph Feedback", "authors": "Yuko Kuroki, Atsushi Miyauchi, Junya Honda, Masashi Sugiyama "}, {"title": "LazyIter: A Fast Algorithm for Counting Markov Equivalent DAGs and Designing Experiments", "authors": "Ali AhmadiTeshnizi, Saber Salehkaleybar, Negar Kiyavash "}, {"title": "Perceptual Generative Autoencoders", "authors": "Zijun Zhang, Ruixiang ZHANG, Zongpeng Li, Yoshua Bengio, Liam Paull ", "link": "https://arxiv.org/abs/1906.10335", "summary": "Modern generative models are usually designed to match target distributions\ndirectly in the data space, where the intrinsic dimensionality of data can be\nmuch lower than the ambient dimensionality. We argue that this discrepancy may\ncontribute to the difficulties in training generative models. We therefore\npropose to map both the generated and target distributions to the latent space\nusing the encoder of a standard autoencoder, and train the generator (or\ndecoder) to match the target distribution in the latent space. The resulting\nmethod, perceptual generative autoencoder (PGA), is then incorporated with a\nmaximum likelihood or variational autoencoder (VAE) objective to train the\ngenerative model. With maximum likelihood, PGAs generalize the idea of\nreversible generative models to unrestricted neural network architectures and\narbitrary latent dimensionalities. When combined with VAEs, PGAs can generate\nsharper samples than vanilla VAEs. Compared to other autoencoder-based\ngenerative models using simple priors, PGAs achieve state-of-the-art FID scores\non CIFAR-10 and CelebA."}, {"title": "Towards Understanding the Regularization of Adversarial Robustness on Neural Networks", "authors": "Yuxin Wen, Shuai Li, Kui Jia "}, {"title": "Stochastic Gradient and Langevin Processes", "authors": "Xiang Cheng, Dong Yin, Peter Bartlett, Michael Jordan "}, {"title": "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles", "authors": "Tonghan Wang, Heng Dong, Victor Lesser, Chongjie Zhang ", "link": "https://arxiv.org/abs/2003.08039", "summary": "The role concept provides a useful tool to design and understand complex\nmulti-agent systems, which allows agents with a similar role to share similar\nbehaviors. However, existing role-based methods use prior domain knowledge and\npredefine role structures and behaviors. In contrast, multi-agent reinforcement\nlearning (MARL) provides flexibility and adaptability, but less efficiency in\ncomplex tasks. In this paper, we synergize these two paradigms and propose a\nrole-oriented MARL framework (ROMA). In this framework, roles are emergent, and\nagents with similar roles tend to share their learning to be specialized on\ncertain sub-tasks. To this end, we construct a stochastic role embedding space\nby introducing two novel regularizers and conditioning individual policies on\nroles. Experiments show that our method can learn dynamic, versatile,\nidentifiable, and specialized roles, which help our method push forward the\nstate of the art on the StarCraft II micromanagement benchmark. Demonstrative\nvideos are available at https://sites.google.com/view/romarl/."}, {"title": "Minimax Pareto Fairness: A Multi Objective Perspective", "authors": "Martin Bertran, Natalia Martinez, Guillermo Sapiro "}, {"title": "Online Pricing with Offline Data: Phase Transition and Inverse Square Law", "authors": "Jinzhi Bu, David Simchi-Levi, Yunzong Xu ", "link": "https://arxiv.org/abs/1910.08693", "summary": "This paper investigates the impact of pre-existing offline data on online\nlearning, in the context of dynamic pricing. We study a single-product dynamic\npricing problem over a selling horizon of $T$ periods. The demand in each\nperiod is determined by the price of the product according to a linear demand\nmodel with unknown parameters. We assume that before the start of the selling\nhorizon, the seller already has some pre-existing offline data. The offline\ndata set contains $n$ samples, each of which is an input-output pair consisting\nof a historical price and an associated demand observation. The seller wants to\nutilize both the pre-existing offline data and the sequential online data to\nminimize the regret of the online learning process.\n  We characterize the joint effect of the size, location and dispersion of the\noffline data on the optimal regret of the online learning process.\nSpecifically, the size, location and dispersion of the offline data are\nmeasured by the number of historical samples $n$, the absolute difference\nbetween the average historical price and the optimal price $\\delta$, and the\nstandard deviation of the historical prices $\\sigma$, respectively. We show\nthat the optimal regret is $\\widetilde \\Theta\\left(\\sqrt{T}\\wedge\n\\frac{T}{(n\\wedge T)\\delta^2+n\\sigma^2}\\right)$, and design a learning\nalgorithm based on the \"optimism in the face of uncertainty\" principle, whose\nregret is optimal up to a logarithmic factor. Our results reveal surprising\ntransformations of the optimal regret rate with respect to the size of the\noffline data, which we refer to as phase transitions. In addition, our results\ndemonstrate that the location and dispersion of the offline data also have an\nintrinsic effect on the optimal regret, and we quantify this effect via the\ninverse-square law."}, {"title": "Explicit Gradient Learning for Black-Box Optimization", "authors": "Elad Sarafian, mor sinay, yoram louzoun, Noa Agmon, Sarit Kraus ", "link": "", "summary": ""}, {"title": "Optimization and Analysis of the pAp@k Metric for Recommender Systems", "authors": "Gaurush Hiranandani, Warut Vijitbenjaronk, Sanmi Koyejo, Prateek Jain "}, {"title": "When Explanations Lie: Why Many Modified BP Attributions Fail", "authors": "Leon Sixt, Maximilian Granz, Tim Landgraf ", "link": "https://arxiv.org/abs/1912.09818", "summary": "Attribution methods aim to explain a neural network's prediction by\nhighlighting the most relevant image areas. A popular approach is to\nbackpropagate (BP) a custom relevance score using modified rules, rather than\nthe gradient. We analyze an extensive set of modified BP methods: Deep Taylor\nDecomposition, Layer-wise Relevance Propagation (LRP), Excitation BP,\nPatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find\nempirically that the explanations of all mentioned methods, except for\nDeepLIFT, are independent of the parameters of later layers. We provide\ntheoretical insights for this surprising behavior and also analyze why DeepLIFT\ndoes not suffer from this limitation. Empirically, we measure how information\nof later layers is ignored by using our new metric, cosine similarity\nconvergence (CSC). The paper provides a framework to assess the faithfulness of\nnew and existing modified BP methods theoretically and empirically. For code\nsee: https://github.com/berleon/when-explanations-lie"}, {"title": "Naive Exploration is Optimal for Online LQR", "authors": "Max Simchowitz, Dylan Foster ", "link": "https://arxiv.org/abs/2001.09576", "summary": "We consider the problem of online adaptive control of the linear quadratic\nregulator, where the true system parameters are unknown. We prove new upper and\nlower bounds demonstrating that the optimal regret scales as\n$\\widetilde{\\Theta}({\\sqrt{d_{\\mathbf{u}}^2 d_{\\mathbf{x}} T}})$, where $T$ is\nthe number of time steps, $d_{\\mathbf{u}}$ is the dimension of the input space,\nand $d_{\\mathbf{x}}$ is the dimension of the system state. Notably, our lower\nbounds rule out the possibility of a $\\mathrm{poly}(\\log{}T)$-regret algorithm,\nwhich has been conjectured due to the apparent strong convexity of the problem.\nOur upper bounds are attained by a simple variant of \\emph{certainty\nequivalence control}, where the learner selects control inputs according to the\noptimal controller for their estimate of the system while injecting exploratory\nrandom noise. While this approach was shown to achieve $\\sqrt{T}$-regret by\nMania et al. 2019, we show that if the learner continually refines their\nestimates of the system matrices, the method attains optimal dimension\ndependence as well.\n  Central to our upper and lower bounds is a new approach for controlling\nperturbations of Ricatti equations, which we call the \\emph{self-bounding ODE\nmethod}. The approach enables regret upper bounds which hold for \\emph{any\nstabilizable instance}, require no foreknowledge of the system except for a\nsingle stabilizing controller, and scale with natural control-theoretic\nquantities."}, {"title": "Learning Structured Latent Factors from Dependent Data:A Generative Model Framework from Information-Theoretic Perspective", "authors": "Ruixiang ZHANG, Katsuhiko Ishiguro, Masanori Koyama "}, {"title": "Implicit Generative Modeling for Efficient Exploration", "authors": "Neale Ratzlaff, Qinxun Bai, Fuxin Li, Wei Xu ", "link": "https://arxiv.org/abs/1911.08017", "summary": "Efficient exploration remains a challenging problem in reinforcement\nlearning, especially for those tasks where rewards from environments are\nsparse. A commonly used approach for exploring such environments is to\nintroduce some \"intrinsic\" reward. In this work, we focus on model uncertainty\nestimation as an intrinsic reward for efficient exploration. In particular, we\nintroduce an implicit generative modeling approach to estimate a Bayesian\nuncertainty of the agent's belief of the environment dynamics. Each random draw\nfrom our generative model is a neural network that instantiates the dynamic\nfunction, hence multiple draws would approximate the posterior, and the\nvariance in the future prediction based on this posterior is used as an\nintrinsic reward for exploration. We design a training algorithm for our\ngenerative model based on the amortized Stein Variational Gradient Descent. In\nexperiments, we compare our implementation with state-of-the-art intrinsic\nreward-based exploration approaches, including two recent approaches based on\nan ensemble of dynamic models. In challenging exploration tasks, our implicit\ngenerative model consistently outperforms competing approaches regarding data\nefficiency in exploration."}, {"title": "Prediction-Guided Multi-Objective Reinforcement Learning for Continuous Robot Control", "authors": "Jie Xu, Yunsheng Tian, Pingchuan Ma, Daniela Rus, Shinjiro Sueda, Wojciech Matusik "}, {"title": "Goodness-of-Fit Tests for Inhomogeneous Random Graphs", "authors": "Soham Dan, Bhaswar B.  Bhattacharya "}, {"title": "Few-shot Domain Adaptation by Causal Mechanism Transfer", "authors": "Takeshi Teshima, Issei Sato, Masashi Sugiyama ", "link": "https://arxiv.org/abs/2002.03497", "summary": "We study few-shot supervised domain adaptation (DA) for regression problems,\nwhere only a few labeled target domain data and many labeled source domain data\nare available. Many of the current DA methods base their transfer assumptions\non either parametrized distribution shift or apparent distribution\nsimilarities, e.g., identical conditionals or small distributional\ndiscrepancies. However, these assumptions may preclude the possibility of\nadaptation from intricately shifted and apparently very different\ndistributions. To overcome this problem, we propose mechanism transfer, a\nmeta-distributional scenario in which a data generating mechanism is invariant\namong domains. This transfer assumption can accommodate nonparametric shifts\nresulting in apparently different distributions while providing a solid\nstatistical basis for DA. We take the structural equations in causal modeling\nas an example and propose a novel DA method, which is shown to be useful both\ntheoretically and experimentally. Our method can be seen as the first attempt\nto fully leverage the structural causal models for DA."}, {"title": "Adaptive Adversarial Multi-task Representation Learning", "authors": "YUREN MAO, Weiwei Liu, Xuemin Lin "}, {"title": "Streaming Submodular Maximization under a k-Set System Constraint", "authors": "Ran Haba, Ehsan Kazemi, Moran Feldman, Amin Karbasi ", "link": "https://arxiv.org/abs/2002.03352", "summary": "In this paper, we propose a novel framework that converts streaming\nalgorithms for monotone submodular maximization into streaming algorithms for\nnon-monotone submodular maximization. This reduction readily leads to the\ncurrently tightest deterministic approximation ratio for submodular\nmaximization subject to a $k$-matchoid constraint. Moreover, we propose the\nfirst streaming algorithm for monotone submodular maximization subject to\n$k$-extendible and $k$-set system constraints. Together with our proposed\nreduction, we obtain $O(k\\log k)$ and $O(k^2\\log k)$ approximation ratio for\nsubmodular maximization subject to the above constraints, respectively. We\nextensively evaluate the empirical performance of our algorithm against the\nexisting work in a series of experiments including finding the maximum\nindependent set in randomly generated graphs, maximizing linear functions over\nsocial networks, movie recommendation, Yelp location summarization, and Twitter\ndata summarization."}, {"title": "A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton", "authors": "Risheng Liu, Pan Mu, Xiaoming Yuan, Shangzhi Zeng, Jin Zhang "}, {"title": "Optimal approximation for unconstrained non-submodular minimization", "authors": "Marwa El Halabi, Stefanie Jegelka ", "link": "https://arxiv.org/abs/1905.12145", "summary": "Submodular function minimization is a well studied problem; existing\nalgorithms solve it exactly or up to arbitrary accuracy. However, in many\napplications, the objective function is not exactly submodular. No theoretical\nguarantees exist in this case. While submodular minimization algorithms rely on\nintricate connections between submodularity and convexity, we show that these\nrelations can be extended sufficiently to obtain approximation guarantees for\nnon-submodular minimization. In particular, we prove how a projected\nsubgradient method can perform well even for certain non-submodular functions.\n  This includes important examples, such as objectives for structured sparse\nlearning and variance reduction in Bayesian optimization. We also extend this\nresult to noisy function evaluations. Our algorithm works in the value oracle\nmodel. We prove that in this model, the approximation result we obtain is the\nbest possible with a subexponential number of queries."}, {"title": "Generating Programmatic Referring Expressions via Program Synthesis", "authors": "Jiani Huang, Calvin Smith, Osbert Bastani, Rishabh Singh, Aws Albarghouthi, Mayur Naik "}, {"title": "Nearly Linear Row Sampling Algorithm for Quantile Regression", "authors": "Yi Li, Ruosong Wang, Lin Yang, Hanrui Zhang "}, {"title": "On Leveraging Pretrained GANs for Limited-Data Generation", "authors": "Miaoyun Zhao, Yulai Cong, Lawrence Carin ", "link": "https://arxiv.org/abs/2002.11810", "summary": "Recent work has shown GANs can generate highly realistic images that are\nindistinguishable by human. Of particular interest here is the empirical\nobservation that most generated images are not contained in training datasets,\nindicating potential generalization with GANs. That generalizability makes it\nappealing to exploit GANs to help applications with limited available data,\ne.g., augment training data to alleviate overfitting. To better facilitate\ntraining a GAN on limited data, we propose to leverage already-available GAN\nmodels pretrained on large-scale datasets (like ImageNet) to introduce\nadditional common knowledge (which may not exist within the limited data)\nfollowing the transfer learning idea. Specifically, exampled by natural image\ngeneration tasks, we reveal the fact that low-level filters (those close to\nobservations) of both the generator and discriminator of pretrained GANs can be\ntransferred to help the target limited-data generation. For better adaption of\nthe transferred filters to the target domain, we introduce a new technique\nnamed adaptive filter modulation (AdaFM), which provides boosted performance\nover baseline methods. Unifying the transferred filters and the introduced\ntechniques, we present our method and conduct extensive experiments to\ndemonstrate its training efficiency and better performance on limited-data\ngeneration."}, {"title": "More Data Can Expand The Generalization Gap Between Adversarially Robust and Standard Models", "authors": "Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi ", "link": "https://arxiv.org/abs/2002.04725", "summary": "Despite remarkable success in practice, modern machine learning models have\nbeen found to be susceptible to adversarial attacks that make\nhuman-imperceptible perturbations to the data, but result in serious and\npotentially dangerous prediction errors. To address this issue, practitioners\noften use adversarial training to learn models that are robust against such\nattacks at the cost of weaker generalization accuracy on unperturbed test sets.\nThe conventional wisdom is that more training data should shrink the\ngeneralization gap between adversarially-trained models and standard models.\nHowever, we study the training of robust classifiers for both Gaussian and\nBernoulli models under $\\ell_\\infty$ attacks, and we prove that more data may\nactually increase this gap. Furthermore, our theoretical results identify if\nand when additional data will finally begin to shrink the gap. Lastly, we\nexperimentally demonstrate that our results also hold for linear regression\nmodels, which may indicate that this phenomenon occurs more broadly."}, {"title": "Double Reinforcement Learning for Efficient and Robust Off-Policy Evaluation", "authors": "Nathan Kallus, Masatoshi Uehara ", "link": "", "summary": ""}, {"title": "Statistically Efficient Off-Policy Policy Gradients", "authors": "Nathan Kallus, Masatoshi Uehara ", "link": "https://arxiv.org/abs/2002.04014", "summary": "Policy gradient methods in reinforcement learning update policy parameters by\ntaking steps in the direction of an estimated gradient of policy value. In this\npaper, we consider the statistically efficient estimation of policy gradients\nfrom off-policy data, where the estimation is particularly non-trivial. We\nderive the asymptotic lower bound on the feasible mean-squared error in both\nMarkov and non-Markov decision processes and show that existing estimators fail\nto achieve it in general settings. We propose a meta-algorithm that achieves\nthe lower bound without any parametric assumptions and exhibits a unique 3-way\ndouble robustness property. We discuss how to estimate nuisances that the\nalgorithm relies on. Finally, we establish guarantees on the rate at which we\napproach a stationary point when we take steps in the direction of our new\nestimated policy gradient."}, {"title": "Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training", "authors": "Xuxi Chen, Wuyang Chen, Tianlong Chen, Ye Yuan, Chen Gong, Kewei Chen, Zhangyang Wang "}, {"title": "When Does Self-Supervision Help Graph Convolutional Networks?", "authors": "Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen ", "link": "", "summary": ""}, {"title": "On Differentially Private Stochastic Convex Optimization  with Heavy-tailed Data", "authors": "Di Wang, Hanshen Xiao, Srinivas Devadas, Jinhui Xu ", "link": "", "summary": ""}, {"title": "Variance Reduced Coordinate Descent with Acceleration: New Method With a Surprising Application to Finite-Sum Problems", "authors": "Filip Hanzely, Dmitry Kovalev, Peter Richtarik ", "link": "http://arxiv.org/abs/2002.04670", "summary": "We propose an accelerated version of stochastic variance reduced coordinate\ndescent -- ASVRCD. As other variance reduced coordinate descent methods such as\nSEGA or SVRCD, our method can deal with problems that include a non-separable\nand non-smooth regularizer, while accessing a random block of partial\nderivatives in each iteration only. However, ASVRCD incorporates Nesterov's\nmomentum, which offers favorable iteration complexity guarantees over both SEGA\nand SVRCD. As a by-product of our theory, we show that a variant of Allen-Zhu\n(2017) is a specific case of ASVRCD, recovering the optimal oracle complexity\nfor the finite sum objective."}, {"title": "Stochastic Subspace Cubic Newton Method", "authors": "Filip Hanzely, Nikita Doikov, Yurii Nesterov, Peter Richtarik ", "link": "http://arxiv.org/abs/2002.09526", "summary": "In this paper, we propose a new randomized second-order optimization\nalgorithm---Stochastic Subspace Cubic Newton (SSCN)---for minimizing a high\ndimensional convex function $f$. Our method can be seen both as a {\\em\nstochastic} extension of the cubically-regularized Newton method of Nesterov\nand Polyak (2006), and a {\\em second-order} enhancement of stochastic subspace\ndescent of Kozak et al. (2019). We prove that as we vary the minibatch size,\nthe global convergence rate of SSCN interpolates between the rate of stochastic\ncoordinate descent (CD) and the rate of cubic regularized Newton, thus giving\nnew insights into the connection between first and second-order methods.\nRemarkably, the local convergence rate of SSCN matches the rate of stochastic\nsubspace descent applied to the problem of minimizing the quadratic function\n$\\frac12 (x-x^*)^\\top \\nabla^2f(x^*)(x-x^*)$, where $x^*$ is the minimizer of\n$f$, and hence depends on the properties of $f$ at the optimum only. Our\nnumerical experiments show that SSCN outperforms non-accelerated first-order CD\nalgorithms while being competitive to their accelerated variants."}, {"title": "Ready Policy One: World Building Through Active Learning", "authors": "Philip Ball, Jack Parker-Holder, Aldo Pacchiano, Krzysztof Choromanski, Stephen Roberts ", "link": "https://arxiv.org/abs/2002.02693", "summary": "Model-Based Reinforcement Learning (MBRL) offers a promising direction for\nsample efficient learning, often achieving state of the art results for\ncontinuous control tasks. However, many existing MBRL methods rely on combining\ngreedy policies with exploration heuristics, and even those which utilize\nprincipled exploration bonuses construct dual objectives in an ad hoc fashion.\nIn this paper we introduce Ready Policy One (RP1), a framework that views MBRL\nas an active learning problem, where we aim to improve the world model in the\nfewest samples possible. RP1 achieves this by utilizing a hybrid objective\nfunction, which crucially adapts during optimization, allowing the algorithm to\ntrade off reward v.s. exploration at different stages of learning. In addition,\nwe introduce a principled mechanism to terminate sample collection once we have\na rich enough trajectory batch to improve the model. We rigorously evaluate our\nmethod on a variety of continuous control tasks, and demonstrate statistically\nsignificant gains over existing approaches."}, {"title": "Structural Language Models of Code", "authors": "Uri Alon, Roy Sadaka, Omer Levy, Eran Yahav ", "link": "https://arxiv.org/abs/1910.00577", "summary": "We address the problem of any-code completion - generating a missing piece of\nsource code in a given program without any restriction on the vocabulary or\nstructure. We introduce a new approach to any-code completion that leverages\nthe strict syntax of programming languages to model a code snippet as a tree -\nstructural language modeling (SLM). SLM estimates the probability of the\nprogram's abstract syntax tree (AST) by decomposing it into a product of\nconditional probabilities over its nodes. We present a neural model that\ncomputes these conditional probabilities by considering all AST paths leading\nto a target node. Unlike previous techniques that have severely restricted the\nkinds of expressions that can be generated in this task, our approach can\ngenerate arbitrary code in any programming language. Our model significantly\noutperforms both seq2seq and a variety of structured approaches in generating\nJava and C# code. We make our code, datasets, and models publicly available."}, {"title": "PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization", "authors": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu ", "link": "https://arxiv.org/abs/1912.08777", "summary": "Recent work pre-training Transformers with self-supervised objectives on\nlarge text corpora has shown great success when fine-tuned on downstream NLP\ntasks including text summarization. However, pre-training objectives tailored\nfor abstractive text summarization have not been explored. Furthermore there is\na lack of systematic evaluation across diverse domains. In this work, we\npropose pre-training large Transformer-based encoder-decoder models on massive\ntext corpora with a new self-supervised objective. In PEGASUS, important\nsentences are removed/masked from an input document and are generated together\nas one output sequence from the remaining sentences, similar to an extractive\nsummary. We evaluated our best PEGASUS model on 12 downstream summarization\ntasks spanning news, science, stories, instructions, emails, patents, and\nlegislative bills. Experiments demonstrate it achieves state-of-the-art\nperformance on all 12 downstream datasets measured by ROUGE scores. Our model\nalso shows surprising performance on low-resource summarization, surpassing\nprevious state-of-the-art results on 6 datasets with only 1000 examples.\nFinally we validated our results using human evaluation and show that our model\nsummaries achieve human performance on multiple datasets."}, {"title": "Aggregation of Multiple Knockoffs", "authors": "Tuan-Binh Nguyen, Jerome-Alexis Chevalier, Sylvain Arlot, Thirion Bertrand ", "link": "https://arxiv.org/abs/2002.09269", "summary": "We develop an extension of the Knockoff Inference procedure, introduced by\nBarber and Candes (2015). This new method, called Aggregation of Multiple\nKnockoffs (AKO), addresses the instability inherent to the random nature of\nKnockoff-based inference. Specifically, AKO improves both the stability and\npower compared with the original Knockoff algorithm while still maintaining\nguarantees for False Discovery Rate control. We provide a new inference\nprocedure, prove its core properties, and demonstrate its benefits in a set of\nexperiments on synthetic and real datasets."}, {"title": "Off-Policy Actor-Critic with Shared Experience Replay", "authors": "Simon Schmitt, Matteo Hessel, Karen Simonyan ", "link": "https://arxiv.org/abs/1909.11583", "summary": "We investigate the combination of actor-critic reinforcement learning\nalgorithms with uniform large-scale experience replay and propose solutions for\ntwo challenges: (a) efficient actor-critic learning with experience replay (b)\nstability of off-policy learning where agents learn from other agents\nbehaviour. We employ those insights to accelerate hyper-parameter sweeps in\nwhich all participating agents run concurrently and share their experience via\na common replay module. To this end we analyze the bias-variance tradeoffs in\nV-trace, a form of importance sampling for actor-critic methods. Based on our\nanalysis, we then argue for mixing experience sampled from replay with\non-policy experience, and propose a new trust region scheme that scales\neffectively to data distributions where V-trace becomes unstable. We provide\nextensive empirical validation of the proposed solution. We further show the\nbenefits of this setup by demonstrating state-of-the-art data efficiency on\nAtari among agents trained up until 200M environment frames."}, {"title": "Graph-based Nearest Neighbor Search: From Practice to Theory", "authors": "Liudmila Prokhorenkova, Aleksandr Shekhovtsov ", "link": "https://arxiv.org/abs/1907.00845", "summary": "Graph-based approaches are empirically shown to be very successful for the\nnearest neighbor search (NNS). However, there has been very little research on\ntheir theoretical guarantees. We fill this gap and rigorously analyze the\nperformance of graph-based NNS algorithms, specifically focusing on the\nlow-dimensional (d << \\log(n)) regime. In addition to the basic greedy\nalgorithm on nearest neighbor graphs, we also analyze the most successful\nheuristics commonly used in practice: speeding up via adding shortcut edges and\nimproving accuracy via maintaining a dynamic list of candidates. We believe\nthat our theoretical insights supported by experimental analysis are an\nimportant step towards understanding the limits and benefits of graph-based NNS\nalgorithms."}, {"title": "Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Jerry Zhu, Adish Singla ", "link": "https://arxiv.org/abs/2003.12909", "summary": "We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes average reward in undiscounted\ninfinite-horizon problem settings. The attacker can manipulate the rewards or\nthe transition dynamics in the learning environment at training-time and is\ninterested in doing so in a stealthy manner. We propose an optimization\nframework for finding an \\emph{optimal stealthy attack} for different measures\nof attack cost. We provide sufficient technical conditions under which the\nattack is feasible and provide lower/upper bounds on the attack cost. We\ninstantiate our attacks in two settings: (i) an \\emph{offline} setting where\nthe agent is doing planning in the poisoned environment, and (ii) an\n\\emph{online} setting where the agent is learning a policy using a\nregret-minimization framework with poisoned feedback. Our results show that the\nattacker can easily succeed in teaching any target policy to the victim under\nmild conditions and highlight a significant security threat to reinforcement\nlearning agents in practice."}, {"title": "Semismooth Newton Algorithm for Efficient Projections onto $\\ell_{1, \\infty}$-norm Ball", "authors": "Dejun Chu, Changshui Zhang, Shiliang Sun, Qing Tao ", "link": "", "summary": ""}, {"title": "Influenza forecasting framework based on Gaussian processes", "authors": "Christoph Zimmer, Reza Yaesoubi "}, {"title": "Unique Properties of Wide Minima in Deep Networks", "authors": "Rotem Mulayoff, Tomer Michaeli ", "link": "https://arxiv.org/abs/2002.04710", "summary": "It is well known that (stochastic) gradient descent has an implicit bias\ntowards wide minima. In deep neural network training, this mechanism serves to\nscreen out minima. However, the precise effect that this has on the trained\nnetwork is not yet fully understood. In this paper, we characterize the wide\nminima in linear neural networks trained with a quadratic loss. First, we show\nthat linear ResNets with zero initialization necessarily converge to the widest\nof all minima. We then prove that these minima correspond to nearly balanced\nnetworks whereby the gain from the input to any intermediate representation\ndoes not change drastically from one layer to the next. Finally, we show that\nconsecutive layers in wide minima solutions are coupled. That is, one of the\nleft singular vectors of each weight matrix, equals one of the right singular\nvectors of the next matrix. This forms a distinct path from input to output,\nthat, as we show, is dedicated to the signal that experiences the largest gain\nend-to-end. Experiments indicate that these properties are characteristic of\nboth linear and nonlinear models trained in practice."}, {"title": "Does the Markov Decision Process Fit the Data: Testing for the Markov Property in Sequential Decision Making", "authors": "Chengchun Shi, Runzhe Wan, Rui Song, Wenbin  Lu, Ling Leng ", "link": "http://arxiv.org/abs/2002.01751", "summary": "The Markov assumption (MA) is fundamental to the empirical validity of\nreinforcement learning. In this paper, we propose a novel Forward-Backward\nLearning procedure to test MA in sequential decision making. The proposed test\ndoes not assume any parametric form on the joint distribution of the observed\ndata and plays an important role for identifying the optimal policy in\nhigh-order Markov decision processes and partially observable MDPs. We apply\nour test to both synthetic datasets and a real data example from mobile health\nstudies to illustrate its usefulness."}, {"title": "LTF: A Label Transformation Framework for Correcting Label Shift", "authors": "Jiaxian Guo, Mingming Gong, Tongliang Liu, Kun Zhang, Dacheng Tao ", "link": "", "summary": ""}, {"title": "Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic Programs with Stochastic Support", "authors": "Yuan Zhou, Hongseok Yang, Yee Whye Teh, Tom Rainforth ", "link": "https://arxiv.org/abs/1910.13324", "summary": "Universal probabilistic programming systems (PPSs) provide a powerful\nframework for specifying rich and complex probabilistic models. They further\nattempt to automate the process of drawing inferences from these models, but\ndoing this successfully is severely hampered by the wide range of non--standard\nmodels they can express. As a result, although one can specify complex models\nin a universal PPS, the provided inference engines often fall far short of what\nis required. In particular, we show they produce surprisingly unsatisfactory\nperformance for models where the support may vary between executions, often\ndoing no better than importance sampling from the prior. To address this, we\nintroduce a new inference framework: Divide, Conquer, and Combine, which\nremains efficient for such models, and show how it can be implemented as an\nautomated and general-purpose PPS inference engine. We empirically demonstrate\nsubstantial performance improvements over existing approaches on two examples."}, {"title": "Duality in RKHSs with Infinite Dimensional Outputs: Application to Robust Losses", "authors": "Pierre Laforgue, Alex Lambert, Luc Brogat-Motte, Florence d'Alche-Buc "}, {"title": "Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health", "authors": "Liangyu Zhu, Wenbin  Lu, Rui Song "}, {"title": "Towards Understanding the Dynamics of the First-Order Adversaries", "authors": "Zhun Deng, Hangfeng He, Jiaoyang Huang, Weijie Su "}, {"title": "Interpreting Robust Optimization via Adversarial Influence Functions", "authors": "Zhun Deng, Cynthia Dwork, Jialiang Wang, Linjun Zhang "}, {"title": "Multilinear Latent Conditioning for Generating Unseen Attribute Combinations", "authors": "Markos Georgopoulos, Grigorios Chrysos, Yannis Panagakis, Maja Pantic "}, {"title": "No-Regret Exploration in Goal-Oriented Reinforcement Learning", "authors": "Jean Tarbouriech, Evrard Garcelon, Michal Valko, Matteo Pirotta, Alessandro Lazaric ", "link": "https://arxiv.org/abs/1912.03517", "summary": "Many popular reinforcement learning problems (e.g., navigation in a maze,\nsome Atari games, mountain car) are instances of the episodic setting under its\nstochastic shortest path (SSP) formulation, where an agent has to achieve a\ngoal state while minimizing the cumulative cost. Despite the popularity of this\nsetting, the exploration-exploitation dilemma has been sparsely studied in\ngeneral SSP problems, with most of the theoretical literature focusing on\ndifferent problems (i.e., fixed-horizon and infinite-horizon) or making the\nrestrictive loop-free SSP assumption (i.e., no state can be visited twice\nduring an episode). In this paper, we study the general SSP problem with no\nassumption on its dynamics (some policies may actually never reach the goal).\nWe introduce UC-SSP, the first no-regret algorithm in this setting, and prove a\nregret bound scaling as $\\displaystyle \\widetilde{\\mathcal{O}}( D S \\sqrt{ A D\nK})$ after $K$ episodes for any unknown SSP with $S$ states, $A$ actions,\npositive costs and SSP-diameter $D$, defined as the smallest expected hitting\ntime from any starting state to the goal. We achieve this result by crafting a\nnovel stopping rule, such that UC-SSP may interrupt the current policy if it is\ntaking too long to achieve the goal and switch to alternative policies that are\ndesigned to rapidly terminate the episode."}, {"title": "OPtions as REsponses: Grounding behavioural hierarchies in multi-agent reinforcement learning", "authors": "Alexander Vezhnevets, Yuhuai Wu, Maria Eckstein, R\u00e9mi Leblond, Joel Z Leibo ", "link": "https://arxiv.org/abs/1906.01470", "summary": "We propose a novel hierarchical agent architecture for multi-agent\nreinforcement learning with concealed information. The hierarchy is grounded in\nthe concealed information about other players, which resolves \"the chicken or\nthe egg\" nature of option discovery. We factorise the value function over a\nlatent representation of the concealed information and then re-use this latent\nspace to factorise the policy into options. Low-level policies (options) are\ntrained to respond to particular states of other agents grouped by the latent\nrepresentation, while the top level (meta-policy) learns to infer the latent\nrepresentation from its own observation thereby to select the right option.\nThis grounding facilitates credit assignment across the levels of hierarchy. We\nshow that this helps generalisation---performance against a held-out set of\npre-trained competitors, while training in self- or population-play---and\nresolution of social dilemmas in self-play."}, {"title": "Feature Noise Induces Loss Discrepancy Across Groups", "authors": "Fereshte Khani, Percy Liang ", "link": "", "summary": ""}, {"title": "Reinforcement Learning for Molecular Design Guided by Quantum Mechanics", "authors": "Gregor Simm, Robert Pinsler, Jose Hernandez-Lobato ", "link": "https://arxiv.org/abs/2002.07717", "summary": "Automating molecular design using deep reinforcement learning (RL) holds the\npromise of accelerating the discovery of new chemical compounds. A limitation\nof existing approaches is that they work with molecular graphs and thus ignore\nthe location of atoms in space, which restricts them to 1) generating single\norganic molecules and 2) heuristic reward functions. To address this, we\npresent a novel RL formulation for molecular design in Cartesian coordinates,\nthereby extending the class of molecules that can be built. Our reward function\nis directly based on fundamental physical properties such as the energy, which\nwe approximate via fast quantum-chemical methods. To enable progress towards\nde-novo molecular design, we introduce MolGym, an RL environment comprising\nseveral challenging molecular design tasks along with baselines. In our\nexperiments, we show that our agent can efficiently learn to solve these tasks\nfrom scratch by working in a translation and rotation invariant state-action\nspace."}, {"title": "Small-GAN: Speeding up GAN Training using Core-Sets ", "authors": "Samrath Sinha, Han Zhang, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Augustus Odena ", "link": "", "summary": ""}, {"title": "Conditional gradient methods for stochastically constrained convex minimization", "authors": "Maria-Luiza Vladarean, Ahmet Alacaoglu, Ya-Ping Hsieh, Volkan Cevher ", "link": "", "summary": ""}, {"title": "Undirected Graphical Models as Approximate Posteriors", "authors": "Arash Vahdat, Evgeny Andriyash, William Macready ", "link": "", "summary": ""}, {"title": "Dynamics of Deep Neural Networks and  Neural Tangent Hierarchy", "authors": "Jiaoyang Huang, Horng-Tzer Yau ", "link": "https://arxiv.org/abs/1909.08156", "summary": "The evolution of a deep neural network trained by the gradient descent can be\ndescribed by its neural tangent kernel (NTK) as introduced in [20], where it\nwas proven that in the infinite width limit the NTK converges to an explicit\nlimiting kernel and it stays constant during training. The NTK was also\nimplicit in some other recent papers [6,13,14]. In the overparametrization\nregime, a fully-trained deep neural network is indeed equivalent to the kernel\nregression predictor using the limiting NTK. And the gradient descent achieves\nzero training loss for a deep overparameterized neural network. However, it was\nobserved in [5] that there is a performance gap between the kernel regression\nusing the limiting NTK and the deep neural networks. This performance gap is\nlikely to originate from the change of the NTK along training due to the finite\nwidth effect. The change of the NTK along the training is central to describe\nthe generalization features of deep neural networks.\n  In the current paper, we study the dynamic of the NTK for finite width deep\nfully-connected neural networks. We derive an infinite hierarchy of ordinary\ndifferential equations, the neural tangent hierarchy (NTH) which captures the\ngradient descent dynamic of the deep neural network. Moreover, under certain\nconditions on the neural network width and the data set dimension, we prove\nthat the truncated hierarchy of NTH approximates the dynamic of the NTK up to\narbitrary precision. This description makes it possible to directly study the\nchange of the NTK for deep neural networks, and sheds light on the observation\nthat deep neural networks outperform kernel regressions using the corresponding\nlimiting NTK."}, {"title": "Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics", "authors": "Debjani Saha, Candice Schumann, Duncan McElfresh, John P Dickerson, Michelle Mazurek, Michael Tschantz ", "link": "https://arxiv.org/abs/2001.00089", "summary": "Bias in machine learning has manifested injustice in several areas, such as\nmedicine, hiring, and criminal justice. In response, computer scientists have\ndeveloped myriad definitions of fairness to correct this bias in fielded\nalgorithms. While some definitions are based on established legal and ethical\nnorms, others are largely mathematical. It is unclear whether the general\npublic agrees with these fairness definitions, and perhaps more importantly,\nwhether they understand these definitions. We take initial steps toward\nbridging this gap between ML researchers and the public, by addressing the\nquestion: does a lay audience understand a basic definition of ML fairness? We\ndevelop a metric to measure comprehension of three such\ndefinitions--demographic parity, equal opportunity, and equalized odds. We\nevaluate this metric using an online survey, and investigate the relationship\nbetween comprehension and sentiment, demographics, and the definition itself."}, {"title": "Encoding Musical Style with Transformer Autoencoders", "authors": "Kristy Choi, Curtis Hawthorne, Ian Simon, Monica  Dinculescu, Jesse Engel ", "link": "https://arxiv.org/abs/1912.05537", "summary": "We consider the problem of learning high-level controls over the global\nstructure of sequence generation, particularly in the context of symbolic music\ngeneration with complex language models. In this work, we present the\nTransformer autoencoder, which aggregates encodings of the input data across\ntime to obtain a global representation of style from a given performance. We\nshow it is possible to combine this global embedding with other temporally\ndistributed embeddings, enabling improved control over the separate aspects of\nperformance style and and melody. Empirically, we demonstrate the effectiveness\nof our method on a variety of music generation tasks on the MAESTRO dataset and\na YouTube dataset with 10,000+ hours of piano performances, where we achieve\nimprovements in terms of log-likelihood and mean listening scores as compared\nto relevant baselines."}, {"title": "Min-Max Optimization without Gradients: Convergence and Applications to Black-Box Evasion and Poisoning Attacks", "authors": "Sijia Liu, Songtao Lu, XIANGYI CHEN, Yao Feng, Kaidi Xu, Abdullah Al-Dujaili, Mingyi Hong, Una-May O'Reilly ", "link": "", "summary": ""}, {"title": "ConQUR: Mitigating Delusional Bias in Deep Q-Learning ", "authors": "DiJia Su, Jayden Ooi, Tyler Lu, Dale Schuurmans, Craig Boutilier "}, {"title": "Self-Modulating Nonparametric Event-Tensor Factorization", "authors": "Zheng Wang, Xinqi Chu, Shandian Zhe "}, {"title": "Extreme Multi-label Classification from Aggregated Labels", "authors": "Yanyao Shen, Hsiang-Fu Yu, Sujay Sanghavi, Inderjit Dhillon ", "link": "https://arxiv.org/abs/2004.00198", "summary": "Extreme multi-label classification (XMC) is the problem of finding the\nrelevant labels for an input, from a very large universe of possible labels. We\nconsider XMC in the setting where labels are available only for groups of\nsamples - but not for individual ones. Current XMC approaches are not built for\nsuch multi-instance multi-label (MIML) training data, and MIML approaches do\nnot scale to XMC sizes. We develop a new and scalable algorithm to impute\nindividual-sample labels from the group labels; this can be paired with any\nexisting XMC method to solve the aggregated label problem. We characterize the\nstatistical properties of our algorithm under mild assumptions, and provide a\nnew end-to-end framework for MIML as an extension. Experiments on both\naggregated label XMC and MIML tasks show the advantages over existing\napproaches."}, {"title": "Full Law Identification In Graphical Models Of Missing Data: Completeness Results", "authors": "Razieh Nabi, Rohit Bhattacharya, Ilya Shpitser ", "link": "https://arxiv.org/abs/2004.04872", "summary": "Missing data has the potential to affect analyses conducted in all fields of\nscientific study, including healthcare, economics, and the social sciences.\nSeveral approaches to unbiased inference in the presence of non-ignorable\nmissingness rely on the specification of the target distribution and its\nmissingness process as a probability distribution that factorizes with respect\nto a directed acyclic graph. In this paper, we address the longstanding\nquestion of the characterization of models that are identifiable within this\nclass of missing data distributions. We provide the first completeness result\nin this field of study -- necessary and sufficient graphical conditions under\nwhich, the full data distribution can be recovered from the observed data\ndistribution. We then simultaneously address issues that may arise due to the\npresence of both missing data and unmeasured confounding, by extending these\ngraphical conditions and proofs of completeness, to settings where some\nvariables are not just missing, but completely unobserved."}, {"title": "Self-Attentive Associative Memory", "authors": "Hung Le, Truyen Tran, Svetha Venkatesh ", "link": "https://arxiv.org/abs/2002.03519", "summary": "Heretofore, neural networks with external memory are restricted to single\nmemory with lossy representations of memory interactions. A rich representation\nof relationships between memory pieces urges a high-order and segregated\nrelational memory. In this paper, we propose to separate the storage of\nindividual experiences (item memory) and their occurring relationships\n(relational memory). The idea is implemented through a novel Self-attentive\nAssociative Memory (SAM) operator. Found upon outer product, SAM forms a set of\nassociative memories that represent the hypothetical high-order relationships\nbetween arbitrary pairs of memory elements, through which a relational memory\nis constructed from an item memory. The two memories are wired into a single\nsequential model capable of both memorization and relational reasoning. We\nachieve competitive results with our proposed two-memory model in a diversity\nof machine learning tasks, from challenging synthetic problems to practical\ntestbeds such as geometry, graph, reinforcement learning, and question\nanswering."}, {"title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming", "authors": "William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi, Navdeep Jaitly ", "link": "https://arxiv.org/abs/2002.08926", "summary": "This paper presents the Imputer, a neural sequence model that generates\noutput sequences iteratively via imputations. The Imputer is an iterative\ngenerative model, requiring only a constant number of generation steps\nindependent of the number of input or output tokens. The Imputer can be trained\nto approximately marginalize over all possible alignments between the input and\noutput sequences, and all possible generation orders. We present a tractable\ndynamic programming training algorithm, which yields a lower bound on the log\nmarginal likelihood. When applied to end-to-end speech recognition, the Imputer\noutperforms prior non-autoregressive models and achieves competitive results to\nautoregressive models. On LibriSpeech test-other, the Imputer achieves 11.1\nWER, outperforming CTC at 13.0 WER and seq2seq at 12.5 WER."}, {"title": "Continuously Indexed Domain Adaptation", "authors": "Hao Wang, Hao He, Dina Katabi "}, {"title": "Evolving Machine Learning Algorithms From Scratch", "authors": "Esteban Real, Chen Liang, David So, Quoc Le ", "link": "", "summary": ""}, {"title": "Self-Attentive Hawkes Process", "authors": "Qiang Zhang, Aldo Lipani, Omer Kirnap, Emine Yilmaz ", "link": "https://arxiv.org/abs/1907.07561", "summary": "Asynchronous events on the continuous time domain, e.g., social media actions\nand stock transactions, occur frequently in the world. The ability to recognize\noccurrence patterns of event sequences is crucial to predict which typeof\nevents will happen next and when. A de facto standard mathematical framework to\ndo this is the Hawkes process. In order to enhance expressivity of multivariate\nHawkes processes, conventional statistical methods and deep recurrent networks\nhave been employed to modify its intensity function. The former is highly\ninterpretable and requires small size of training data but relies on correct\nmodel design while the latter has less dependency on prior knowledge and is\nmore powerful in capturing complicated patterns. We leverage pros and cons of\nthese models and propose a self-attentive Hawkes process(SAHP). The proposed\nmethod adapts self-attention to fit the intensity function of Hawkes processes.\nThis design has two benefits:(1) compared with conventional statistical\nmethods, the SAHP is more powerful to identify complicated dependency\nrelationships between temporal events; (2)compared with deep recurrent\nnetworks, the self-attention mechanism is able to capture longer historical\ninformation, and is more interpretable because the learnt attention weight\ntensor shows contributions of each historical event. Experiments on four\nreal-world datasets demonstrate the effectiveness of the proposed method."}, {"title": "On hyperparameter tuning in general clustering problemsm", "authors": "Xinjie Fan, Yuguang Yue, Purnamrita Sarkar, Y. X. Rachel Wang ", "link": "", "summary": ""}, {"title": "Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks", "authors": "Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao Yang ", "link": "https://arxiv.org/abs/2005.02426", "summary": "In this paper, we study distributed algorithms for large-scale AUC\nmaximization with a deep neural network as a predictive model. Although\ndistributed learning techniques have been investigated extensively in deep\nlearning, they are not directly applicable to stochastic AUC maximization with\ndeep neural networks due to its striking differences from standard loss\nminimization problems (e.g., cross-entropy). Towards addressing this challenge,\nwe propose and analyze a communication-efficient distributed optimization\nalgorithm based on a {\\it non-convex concave} reformulation of the AUC\nmaximization, in which the communication of both the primal variable and the\ndual variable between each worker and the parameter server only occurs after\nmultiple steps of gradient-based updates in each worker. Compared with the\nnaive parallel version of an existing algorithm that computes stochastic\ngradients at individual machines and averages them for updating the model\nparameter, our algorithm requires a much less number of communication rounds\nand still achieves a linear speedup in theory. To the best of our knowledge,\nthis is the \\textbf{first} work that solves the {\\it non-convex concave\nmin-max} problem for AUC maximization with deep neural networks in a\ncommunication-efficient distributed manner while still maintaining the linear\nspeedup property in theory. Our experiments on several benchmark datasets show\nthe effectiveness of our algorithm and also confirm our theory."}, {"title": "Adaptive Region-Based Active Learning", "authors": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Ningshan Zhang ", "link": "https://arxiv.org/abs/2002.07348", "summary": "We present a new active learning algorithm that adaptively partitions the\ninput space into a finite number of regions, and subsequently seeks a distinct\npredictor for each region, both phases actively requesting labels. We prove\ntheoretical guarantees for both the generalization error and the label\ncomplexity of our algorithm, and analyze the number of regions defined by the\nalgorithm under some mild assumptions. We also report the results of an\nextensive suite of experiments on several real-world datasets demonstrating\nsubstantial empirical benefits over existing single-region and non-adaptive\nregion-based active learning baselines."}, {"title": "Robust Outlier Arm Identification", "authors": "Yinglun Zhu, Sumeet Katariya, Robert Nowak "}, {"title": "Provably Efficient Exploration in Policy Optimization", "authors": "Qi Cai, Zhuoran Yang, Chi Jin, Zhaoran Wang ", "link": "https://arxiv.org/abs/1912.05830", "summary": "While policy-based reinforcement learning (RL) achieves tremendous successes\nin practice, it is significantly less understood in theory, especially compared\nwith value-based RL. In particular, it remains elusive how to design a provably\nefficient policy optimization algorithm that incorporates exploration. To\nbridge such a gap, this paper proposes an Optimistic variant of the Proximal\nPolicy Optimization algorithm (OPPO), which follows an \"optimistic version\" of\nthe policy gradient direction. This paper proves that, in the problem of\nepisodic Markov decision process with linear function approximation, unknown\ntransition, and adversarial reward with full-information feedback, OPPO\nachieves $\\tilde{O}(\\sqrt{d^3 H^3 T})$ regret. Here $d$ is the feature\ndimension, $H$ is the episode horizon, and $T$ is the total number of steps. To\nthe best of our knowledge, OPPO is the first provably efficient policy\noptimization algorithm that explores."}, {"title": "Striving for simplicity and performance in off-policy DRL: Output Normalization and Non-Uniform Sampling", "authors": "Che Wang, Yanqiu Wu, Quan Vuong, Keith Ross ", "link": "https://arxiv.org/abs/1910.02208", "summary": "We aim to develop off-policy DRL algorithms that not only exceed\nstate-of-the-art performance but are also simple and minimalistic. For standard\ncontinuous control benchmarks, Soft Actor Critic (SAC), which employs entropy\nmaximization, currently provides state-of-the-art performance. We first\ndemonstrate that the entropy term in SAC addresses action saturation due to the\nbounded nature of the action spaces. With this insight, we propose a\nstreamlined algorithm with a simple normalization scheme or with inverted\ngradients. We show that both approaches can match SAC's sample efficiency\nperformance without the need of entropy maximization. We then propose a simple\nnon-uniform sampling method for selecting transitions from the replay buffer\nduring training. Extensive experimental results demonstrate that our proposed\nsampling scheme leads to state of the art sample efficiency on challenging\ncontinuous control tasks. We combine all of our findings into one simple\nalgorithm, which we call Streamlined Off Policy with Emphasizing Recent\nExperience, for which we provide robust public-domain code."}, {"title": "Multidimensional Shape Constraints", "authors": "Maya Gupta, Erez Louidor, Oleksandr Mangylov, Nobu Morioka, Tamann Narayan, Sen Zhao "}, {"title": "Fast Deterministic CUR Matrix Decomposition with Accuracy Assurance", "authors": "Yasutoshi Ida, Sekitoshi Kanai, Yasuhiro Fujiwara, Tomoharu Iwata, Koh Takeuchi, Hisashi Kashima "}, {"title": "Operation-Aware Soft Channel Pruning using Differentiable Masks", "authors": "Minsoo Kang, Bohyung Han "}, {"title": "Normalized Loss Functions for Deep Learning with Noisy Labels", "authors": "Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, James Bailey "}, {"title": "Learning Deep Kernels for Non-Parametric Two-Sample Tests", "authors": "Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, D.J. Sutherland ", "link": "https://arxiv.org/abs/2002.09116", "summary": "We propose a class of kernel-based two-sample tests, which aim to determine\nwhether two sets of samples are drawn from the same distribution. Our tests are\nconstructed from kernels parameterized by deep neural nets, trained to maximize\ntest power. These tests adapt to variations in distribution smoothness and\nshape over space, and are especially suited to high dimensions and complex\ndata. By contrast, the simpler kernels used in prior kernel testing work are\nspatially homogeneous, and adaptive only in lengthscale. We explain how this\nscheme includes popular classifier-based two-sample tests as a special case,\nbut improves on them in general. We provide the first proof of consistency for\nthe proposed adaptation method, which applies both to kernels on deep features\nand to simpler radial basis kernels or multiple kernel learning. In\nexperiments, we establish the superior performance of our deep kernels in\nhypothesis testing on benchmark and real-world data. The code of our\ndeep-kernel-based two sample tests is available at\nhttps://github.com/fengliu90/DK-for-TST."}, {"title": "DeBayes: a Bayesian method for debiasing network embeddings", "authors": "Maarten Buyl, Tijl De Bie ", "link": "https://arxiv.org/abs/2002.11442", "summary": "As machine learning algorithms are increasingly deployed for high-impact\nautomated decision making, ethical and increasingly also legal standards demand\nthat they treat all individuals fairly, without discrimination based on their\nage, gender, race or other sensitive traits. In recent years much progress has\nbeen made on ensuring fairness and reducing bias in standard machine learning\nsettings. Yet, for network embedding, with applications in vulnerable domains\nranging from social network analysis to recommender systems, current options\nremain limited both in number and performance. We thus propose DeBayes: a\nconceptually elegant Bayesian method that is capable of learning debiased\nembeddings by using a biased prior. Our experiments show that these\nrepresentations can then be used to perform link prediction that is\nsignificantly more fair in terms of popular metrics such as demographic parity\nand equalized opportunity."}, {"title": "Principled learning method for Wasserstein distributionally robust optimization with local perturbations", "authors": "Yongchan Kwon, Wonyoung Kim, Joong-Ho Won, Myunghee Cho Paik "}, {"title": "Low-Variance and Zero-Variance Baselines for Extensive-Form Games", "authors": "Trevor Davis, Martin Schmid, Michael Bowling ", "link": "https://arxiv.org/abs/1907.09633", "summary": "Extensive-form games (EFGs) are a common model of multi-agent interactions\nwith imperfect information. State-of-the-art algorithms for solving these games\ntypically perform full walks of the game tree that can prove prohibitively slow\nin large games. Alternatively, sampling-based methods such as Monte Carlo\nCounterfactual Regret Minimization walk one or more trajectories through the\ntree, touching only a fraction of the nodes on each iteration, at the expense\nof requiring more iterations to converge due to the variance of sampled values.\nIn this paper, we extend recent work that uses baseline estimates to reduce\nthis variance. We introduce a framework of baseline-corrected values in EFGs\nthat generalizes the previous work. Within our framework, we propose new\nbaseline functions that result in significantly reduced variance compared to\nexisting techniques. We show that one particular choice of such a function ---\npredictive baseline --- is provably optimal under certain sampling schemes.\nThis allows for efficient computation of zero-variance value estimates even\nalong sampled trajectories."}, {"title": "Converging to Team-Maxmin Equilibria in Zero-Sum Multiplayer Games", "authors": "Youzhi Zhang, Bo An "}, {"title": "Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks", "authors": "Alexander Shevchenko, Marco Mondelli ", "link": "http://arxiv.org/abs/1912.10095", "summary": "The optimization of multilayer neural networks typically leads to a solution\nwith zero training error, yet the landscape can exhibit spurious local minima\nand the minima can be disconnected. In this paper, we shed light on this\nphenomenon: we show that the combination of stochastic gradient descent (SGD)\nand over-parameterization makes the landscape of multilayer neural networks\napproximately connected and thus more favorable to optimization. More\nspecifically, we prove that SGD solutions are connected via a piecewise linear\npath, and the increase in loss along this path vanishes as the number of\nneurons grows large. This result is a consequence of the fact that the\nparameters found by SGD are increasingly dropout stable as the network becomes\nwider. We show that, if we remove part of the neurons (and suitably rescale the\nremaining ones), the change in loss is independent of the total number of\nneurons, and it depends only on how many neurons are left. Our results exhibit\na mild dependence on the input dimension: they are dimension-free for two-layer\nnetworks and depend linearly on the dimension for multilayer networks. We\nvalidate our theoretical findings with numerical experiments for different\narchitectures and classification tasks."}, {"title": "Leveraging Frequency Analysis for Deep Fake Image Recognition", "authors": "Joel Frank, Thorsten Eisenhofer, Lea Sch\u00f6nherr, Dorothea Kolossa, Thorsten Holz, Asja Fischer ", "link": "https://arxiv.org/abs/2003.08685", "summary": "Deep neural networks can generate images that are astonishingly realistic, so\nmuch so that it is often hard for humans to distinguish them from actual\nphotos. These achievements have been largely made possible by Generative\nAdversarial Networks (GANs). While these deep fake images have been thoroughly\ninvestigated in the image domain-a classical approach from the area of image\nforensics-an analysis in the frequency domain has been missing so far.\n  In this paper, we address this shortcoming and our results reveal that in\nfrequency space, GAN-generated images exhibit severe artifacts that can be\neasily identified. We perform a comprehensive analysis, showing that these\nartifacts are consistent across different neural network architectures, data\nsets, and resolutions. In a further investigation, we demonstrate that these\nartifacts are caused by upsampling operations found in all current GAN\narchitectures, indicating a structural and fundamental problem in the way\nimages are generated via GANs. Based on this analysis, we demonstrate how the\nfrequency representation can be used to identify deep fake images in an\nautomated way, surpassing state-of-the-art methods."}, {"title": "Tails of Lipschitz Triangular Flows", "authors": "Priyank Jaini, Ivan Kobyzev, Yaoliang Yu, Marcus Brubaker ", "link": "", "summary": ""}, {"title": "Deep Coordination Graphs", "authors": "Wendelin Boehmer, Vitaly Kurin, Shimon Whiteson ", "link": "https://arxiv.org/abs/1910.00091", "summary": "This paper introduces the deep coordination graph (DCG) for collaborative\nmulti-agent reinforcement learning. DCG strikes a flexible trade-off between\nrepresentational capacity and generalization by factoring the joint value\nfunction of all agents according to a coordination graph into payoffs between\npairs of agents. The value can be maximized by local message passing along the\ngraph, which allows training of the value function end-to-end with Q-learning.\nPayoff functions are approximated with deep neural networks that employ\nparameter sharing and low-rank approximations to significantly improve sample\nefficiency. We show that DCG can solve predator-prey tasks that highlight the\nrelative overgeneralization pathology, as well as challenging StarCraft II\nmicromanagement tasks."}, {"title": "Voice Separation with an Unknown Number of Multiple Speakers", "authors": "Eliya Nachmani, Yossi Adi, Lior Wolf ", "link": "https://arxiv.org/abs/2003.01531", "summary": "We present a new method for separating a mixed audio sequence, in which\nmultiple voices speak simultaneously. The new method employs gated neural\nnetworks that are trained to separate the voices at multiple processing steps,\nwhile maintaining the speaker in each output channel fixed. A different model\nis trained for every number of possible speakers, and a the model with the\nlargest number of speakers is employed to select the actual number of speakers\nin a given sample. Our method greatly outperforms the current state of the art,\nwhich, as we show, is not competitive for more than two speakers."}, {"title": "Predicting Choice with Set-Dependent Aggregation", "authors": "Nir Rosenfeld, Kojin Oshiba, Yaron Singer ", "link": "https://arxiv.org/abs/1906.06365", "summary": "Providing users with alternatives to choose from is an essential component in\nmany online platforms, making the accurate prediction of choice vital to their\nsuccess. A renewed interest in learning choice models has led to significant\nprogress in modeling power, but most current methods are either limited in the\ntypes of choice behavior they capture, cannot be applied to large-scale data,\nor both.\n  Here we propose a learning framework for predicting choice that is accurate,\nversatile, theoretically grounded, and scales well. Our key modeling point is\nthat to account for how humans choose, predictive models must capture certain\nset-related invariances. Building on recent results in economics, we derive a\nclass of models that can express any behavioral choice pattern, enjoy favorable\nsample complexity guarantees, and can be efficiently trained end-to-end.\nExperiments on three large choice datasets demonstrate the utility of our\napproach."}, {"title": "Thompson Sampling Algorithms for Mean-Variance Bandits", "authors": "Qiuyu Zhu, Vincent Tan ", "link": "https://arxiv.org/abs/2002.00232", "summary": "The multi-armed bandit (MAB) problem is a classical learning task that\nexemplifies the exploration-exploitation tradeoff. However, standard\nformulations do not take into account risk. In online decision making systems,\nrisk is a primary concern. In this regard, the mean-variance risk measure is\none of the most common objective functions. Existing algorithms for\nmean-variance optimization in the context of MAB problems have unrealistic\nassumptions on the reward distributions. We develop Thompson Sampling-style\nalgorithms for mean-variance MAB and provide comprehensive regret analyses for\nGaussian and Bernoulli bandits with fewer assumptions. Our algorithms achieve\nthe best known regret bounds for mean-variance MABs and also attain the\ninformation-theoretic bounds in some parameter regimes. Empirical simulations\nshow that our algorithms significantly outperform existing LCB-based algorithms\nfor all risk tolerances."}, {"title": "Differentiable Likelihoods for Fast Inversion of 'Likelihood-Free' Dynamical Systems", "authors": "Hans Kersting, Nicholas Kr\u00e4mer, Martin Schiegg, Christian Daniel, Michael Schober, Philipp Hennig ", "link": "https://arxiv.org/abs/2002.09301", "summary": "Likelihood-free (a.k.a. simulation-based) inference problems are inverse\nproblems with expensive, or intractable, forward models. ODE inverse problems\nare commonly treated as likelihood-free, as their forward map has to be\nnumerically approximated by an ODE solver. This, however, is not a fundamental\nconstraint but just a lack of functionality in classic ODE solvers, which do\nnot return a likelihood but a point estimate. To address this shortcoming, we\nemploy Gaussian ODE filtering (a probabilistic numerical method for ODEs) to\nconstruct a local Gaussian approximation to the likelihood. This approximation\nyields tractable estimators for the gradient and Hessian of the\n(log-)likelihood. Insertion of these estimators into existing gradient-based\noptimization and sampling methods engenders new solvers for ODE inverse\nproblems. We demonstrate that these methods outperform standard likelihood-free\napproaches on three benchmark-systems."}, {"title": "Debiased Sinkhorn barycenters", "authors": "Hicham Janati, Marco Cuturi, Alexandre Gramfort "}, {"title": "Double Trouble in Double Descent:  Bias and Variance(s) in the Lazy Regime", "authors": "St\u00e9phane d'Ascoli, Maria Refinetti, Giulio Biroli, Florent Krzakala ", "link": "https://arxiv.org/abs/2003.01054", "summary": "Deep neural networks can achieve remarkable generalization performances while\ninterpolating the training data perfectly. Rather than the U-curve emblematic\nof the bias-variance trade-off, their test error often follows a \"double\ndescent\" - a mark of the beneficial role of overparametrization. In this work,\nwe develop a quantitative theory for this phenomenon in the so-called lazy\nlearning regime of neural networks, by considering the problem of learning a\nhigh-dimensional function with random features regression. We obtain a precise\nasymptotic expression for the bias-variance decomposition of the test error,\nand show that the bias displays a phase transition at the interpolation\nthreshold, beyond which it remains constant. We disentangle the variances\nstemming from the sampling of the dataset, from the additive noise corrupting\nthe labels, and from the initialization of the weights. Following up on Geiger\net al. 2019, we first show that the latter two contributions are the crux of\nthe double descent: they lead to the overfitting peak at the interpolation\nthreshold and to the decay of the test error upon overparametrization. We then\nquantify how they are suppressed by ensemble averaging the outputs of K\nindependently initialized estimators. When K is sent to infinity, the test\nerror remains constant beyond the interpolation threshold. We further compare\nthe effects of overparametrizing, ensembling and regularizing. Finally, we\npresent numerical experiments on classic deep learning setups to show that our\nresults hold qualitatively in realistic lazy learning scenarios."}, {"title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering Skills", "authors": "Victor Campos, Alexander Trott, Caiming Xiong, Richard Socher, Xavier Giro-i-Nieto, Jordi  Torres ", "link": "https://arxiv.org/abs/2002.03647", "summary": "Acquiring abilities in the absence of a task-oriented reward function is at\nthe frontier of reinforcement learning research. This problem has been studied\nthrough the lens of empowerment, which draws a connection between option\ndiscovery and information theory. Information-theoretic skill discovery methods\nhave garnered much interest from the community, but little research has been\nconducted in understanding their limitations. Through theoretical analysis and\nempirical evidence, we show that existing algorithms suffer from a common\nlimitation -- they discover options that provide a poor coverage of the state\nspace. In light of this, we propose 'Explore, Discover and Learn' (EDL), an\nalternative approach to information-theoretic skill discovery. Crucially, EDL\noptimizes the same information-theoretic objective derived from the empowerment\nliterature, but addresses the optimization problem using different machinery.\nWe perform an extensive evaluation of skill discovery methods on controlled\nenvironments and show that EDL offers significant advantages, such as\novercoming the coverage problem, reducing the dependence of learned skills on\nthe initial state, and allowing the user to define a prior over which behaviors\nshould be learned. Code is publicly available at\nhttps://github.com/victorcampos7/edl."}, {"title": "Sparsified Linear Programming for Zero-Sum Equilibrium Finding", "authors": "Brian Zhang, Tuomas Sandholm ", "link": "", "summary": ""}, {"title": "Extra-gradient with player sampling for faster convergence in n-player games", "authors": "Samy Jelassi, Carles Domingo-Enrich, Damien Scieur, Arthur Mensch, Joan Bruna ", "link": "https://arxiv.org/abs/1905.12363", "summary": "Data-driven model training is increasingly relying on finding Nash equilibria\nwith provable techniques, e.g., for GANs and multi-agent RL. In this paper, we\nanalyse a new extra-gradient method, that performs gradient extrapolations and\nupdates on a random subset of players at each iteration. This approach provably\nexhibits the same rate of convergence as full extra-gradient in non-smooth\nconvex games. We propose an additional variance reduction mechanism for this to\nhold for smooth convex games. Our approach makes extrapolation amenable to\nmassive multiplayer settings, and brings empirical speed-ups, in particular\nwhen using cyclic sampling schemes. We demonstrate the efficiency of player\nsampling on large-scale non-smooth and non-strictly convex games. We show that\nthe joint use of extrapolation and player sampling allows to train better GANs\non CIFAR10."}, {"title": "Entropy Minimization In Emergent Languages", "authors": "Evgeny Kharitonov, Rahma Chaabouni, Diane Bouchacourt, Marco Baroni ", "link": "https://arxiv.org/abs/1905.13687", "summary": "There is a growing interest in studying the languages emerging when neural\nagents are jointly trained to solve tasks requiring communication through a\ndiscrete channel. We investigate here the information-theoretic complexity of\nsuch languages, focusing on the basic two-agent, one-exchange setup. We find\nthat, under common training procedures, the emergent languages are subject to\nan entropy minimization pressure that has also been detected in human language,\nwhereby the mutual information between the communicating agent's inputs and the\nmessages is minimized, within the range afforded by the need for successful\ncommunication. This pressure is amplified as we increase communication channel\ndiscreteness. Further, we observe that stronger discrete-channel-driven entropy\nminimization leads to representations with increased robustness to overfitting\nand adversarial attacks. We conclude by discussing the implications of our\nfindings for the study of natural and artificial communication systems."}, {"title": "Spectral Clustering with Graph Neural Networks for Graph Pooling", "authors": "Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi "}, {"title": "VFlow: More Expressive Generative Flows with Variational Data Augmentation", "authors": "Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, Tian Tian ", "link": "https://arxiv.org/abs/2002.09741", "summary": "Generative flows are promising tractable models for density modeling that\ndefine probabilistic distributions with invertible transformations. However,\ntractability imposes architectural constraints on generative flows, making them\nless expressive than other types of generative models. In this work, we study a\npreviously overlooked constraint that all the intermediate representations must\nhave the same dimensionality with the original data due to invertibility,\nlimiting the width of the network. We tackle this constraint by augmenting the\ndata with some extra dimensions and jointly learning a generative flow for\naugmented data as well as the distribution of augmented dimensions under a\nvariational inference framework. Our approach, VFlow, is a generalization of\ngenerative flows and therefore always performs better. Combining with existing\ngenerative flows, VFlow achieves a new state-of-the-art 2.98 bits per dimension\non the CIFAR-10 dataset and is more compact than previous models to reach\nsimilar modeling quality."}, {"title": "Fully Parallel Hyperparameter Search: Reshaped Space-Filling", "authors": "Marie-Liesse Cauwet, CNRS, ESIEE Paris, Camille Couprie, Julien Dehos, Pauline Luc, Jeremy Rapin, Morgane Riviere, Fabien Teytaud, Olivier Teytaud, Nicolas Usunier ", "link": "https://arxiv.org/abs/1910.08406", "summary": "Space-filling designs such as scrambled-Hammersley, Latin Hypercube Sampling\nand Jittered Sampling have been proposed for fully parallel hyperparameter\nsearch, and were shown to be more effective than random or grid search. In this\npaper, we show that these designs only improve over random search by a constant\nfactor. In contrast, we introduce a new approach based on reshaping the search\ndistribution, which leads to substantial gains over random search, both\ntheoretically and empirically. We propose two flavors of reshaping. First, when\nthe distribution of the optimum is some known $P_0$, we propose Recentering,\nwhich uses as search distribution a modified version of $P_0$ tightened closer\nto the center of the domain, in a dimension-dependent and budget-dependent\nmanner. Second, we show that in a wide range of experiments with $P_0$ unknown,\nusing a proposed Cauchy transformation, which simultaneously has a heavier tail\n(for unbounded hyperparameters) and is closer to the boundaries (for bounded\nhyperparameters), leads to improved performances. Besides artificial\nexperiments and simple real world tests on clustering or Salmon mappings, we\ncheck our proposed methods on expensive artificial intelligence tasks such as\nattend/infer/repeat, video next frame segmentation forecasting and progressive\ngenerative adversarial networks."}, {"title": "Discount Factor as a Regularizer in Reinforcement Learning ", "authors": "Ron Amit, Kamil Ciosek, Ron Meir ", "link": "", "summary": ""}, {"title": "On Learning Sets of Symmetric Elements", "authors": "Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya ", "link": "https://arxiv.org/abs/2002.08599", "summary": "Learning from unordered sets is a fundamental learning setup, which is\nattracting increasing attention. Research in this area has focused on the case\nwhere elements of the set are represented by feature vectors, and far less\nemphasis has been given to the common case where set elements themselves adhere\nto certain symmetries. That case is relevant to numerous applications, from\ndeblurring image bursts to multi-view 3D shape recognition and reconstruction.\n  In this paper, we present a principled approach to learning sets of general\nsymmetric elements. We first characterize the space of linear layers that are\nequivariant both to element reordering and to the inherent symmetries of\nelements, like translation in the case of images. We further show that networks\nthat are composed of these layers, called Deep Sets for Symmetric elements\nlayers (DSS), are universal approximators of both invariant and equivariant\nfunctions. DSS layers are also straightforward to implement. Finally, we show\nthat they improve over existing set-learning architectures in a series of\nexperiments with images, graphs, and point-clouds."}, {"title": "Non-convex Learning via Replica Exchange Stochastic Gradient MCMC", "authors": "Wei Deng, Qi Feng, Liyao Gao, Faming Liang, Guang Lin "}, {"title": "Learning Similarity Metrics for Numerical Simulations", "authors": "Georg Kohl, Kiwon Um, Nils Thuerey ", "link": "https://arxiv.org/abs/2002.07863", "summary": "We propose a neural network-based approach that computes a stable and\ngeneralizing metric (LSiM), to compare field data from a variety of numerical\nsimulation sources. Our method employs a Siamese network architecture that is\nmotivated by the mathematical properties of a metric. We leverage a\ncontrollable data generation setup with partial differential equation (PDE)\nsolvers to create increasingly different outputs from a reference simulation in\na controlled environment. A central component of our learned metric is a\nspecialized loss function that introduces knowledge about the correlation\nbetween single data samples into the training process. To demonstrate that the\nproposed approach outperforms existing simple metrics for vector spaces and\nother learned, image-based metrics, we evaluate the different methods on a\nlarge range of test data. Additionally, we analyze benefits for generalization\nand the impact of an adjustable training data difficulty. The robustness of\nLSiM is demonstrated via an evaluation on three real-world data sets."}, {"title": "FR-Train: A mutual information-based approach to fair and robust training", "authors": "Yuji Roh, Kangwook Lee, Steven Whang, Changho Suh ", "link": "https://arxiv.org/abs/2002.10234", "summary": "Trustworthy AI is a critical issue in machine learning where, in addition to\ntraining a model that is accurate, one must consider both fair and robust\ntraining in the presence of data bias and poisoning. However, the existing\nmodel fairness techniques mistakenly view poisoned data as an additional bias,\nresulting in severe performance degradation. To fix this problem, we propose\nFR-Train, which holistically performs fair and robust model training. We\nprovide a mutual information-based interpretation of an existing adversarial\ntraining-based fairness-only method, and apply this idea to architect an\nadditional discriminator that can identify poisoned data using a clean\nvalidation set and reduce its influence. In our experiments, FR-Train shows\nalmost no decrease in fairness and accuracy in the presence of data poisoning\nby both mitigating the bias and defending against poisoning. We also\ndemonstrate how to construct clean validation sets using crowdsourcing, and\nrelease new benchmark datasets."}, {"title": "Real-Time Optimisation for Online Learning in Auctions", "authors": "Lorenzo Croissant, Marc Abeille, Clement Calauzenes "}, {"title": "Graph Random Neural Features for Distance-Preserving Graph Representations", "authors": "Daniele Zambon, Cesare Alippi, Lorenzo Livi ", "link": "https://arxiv.org/abs/1909.03790", "summary": "We present Graph Random Neural Features (GRNF), a novel embedding method from\ngraph-structured data to real vectors based on a family of graph neural\nnetworks. The embedding naturally deals with graph isomorphism and preserves\nthe metric structure of the graph domain, in probability. In addition to being\nan explicit embedding method, it also allows us to efficiently and effectively\napproximate graph metric distances (as well as complete kernel functions); a\ncriterion to select the embedding dimension trading off the approximation\naccuracy with the computational cost is also provided. GRNF can be used within\ntraditional processing methods or as a training-free input layer of a graph\nneural network. The theoretical guarantees that accompany GRNF ensure that the\nconsidered graph distance is metric, hence allowing to distinguish any pair of\nnon-isomorphic graphs."}, {"title": "Modulating Surrogates for Bayesian Optimization", "authors": "Erik Bodin, Markus Kaiser, Ieva Kazlauskaite, Zhenwen Dai, Neill Campbell, Carl Henrik Ek ", "link": "https://arxiv.org/abs/1906.11152", "summary": "Bayesian optimization (BO) methods often rely on the assumption that the\nobjective function is well-behaved, but in practice, this is seldom true for\nreal-world objectives even if noise-free observations can be collected. Common\napproaches, which try to model the objective as precisely as possible, often\nfail to make progress by spending too many evaluations modeling irrelevant\ndetails. We address this issue by proposing surrogate models that focus on the\nwell-behaved structure in the objective function, which is informative for\nsearch, while ignoring detrimental structure that is challenging to model from\nfew observations. First, we demonstrate that surrogate models with appropriate\nnoise distributions can absorb challenging structures in the objective function\nby treating them as irreducible uncertainty. Secondly, we show that a latent\nGaussian process is an excellent surrogate for this purpose, comparing with\nGaussian processes with standard noise distributions. We perform numerous\nexperiments on a range of BO benchmarks and find that our approach improves\nreliability and performance when faced with challenging objective functions."}, {"title": "Convolutional Kernel Networks for Graph-Structured Data", "authors": "Dexiong Chen, Laurent Jacob, Julien Mairal ", "link": "https://arxiv.org/abs/2003.05189", "summary": "We introduce a family of multilayer graph kernels and establish new links\nbetween graph convolutional neural networks and kernel methods. Our approach\ngeneralizes convolutional kernel networks to graph-structured data, by\nrepresenting graphs as a sequence of kernel feature maps, where each node\ncarries information about local graph substructures. On the one hand, the\nkernel point of view offers an unsupervised, expressive, and easy-to-regularize\ndata representation, which is useful when limited samples are available. On the\nother hand, our model can also be trained end-to-end on large-scale data,\nleading to new types of graph convolutional neural networks. We show that our\nmethod achieves competitive performance on several graph classification\nbenchmarks, while offering simple model interpretation. Our code is freely\navailable at https://github.com/claying/GCKN."}, {"title": "Improving the Sample and Communication Complexity for Decentralized Non-Convex Optimization: Joint Gradient Estimation and Tracking", "authors": "Haoran Sun, Songtao Lu, Mingyi Hong ", "link": "https://arxiv.org/abs/1910.05857", "summary": "Many modern large-scale machine learning problems benefit from decentralized\nand stochastic optimization. Recent works have shown that utilizing both\ndecentralized computing and local stochastic gradient estimates can outperform\nstate-of-the-art centralized algorithms, in applications involving highly\nnon-convex problems, such as training deep neural networks.\n  In this work, we propose a decentralized stochastic algorithm to deal with\ncertain smooth non-convex problems where there are $m$ nodes in the system, and\neach node has a large number of samples (denoted as $n$). Differently from the\nmajority of the existing decentralized learning algorithms for either\nstochastic or finite-sum problems, our focus is given to both reducing the\ntotal communication rounds among the nodes, while accessing the minimum number\nof local data samples. In particular, we propose an algorithm named D-GET\n(decentralized gradient estimation and tracking), which jointly performs\ndecentralized gradient estimation (which estimates the local gradient using a\nsubset of local samples) and gradient tracking (which tracks the global full\ngradient using local estimates). We show that, to achieve certain $\\epsilon$\nstationary solution of the deterministic finite sum problem, the proposed\nalgorithm achieves an $\\mathcal{O}(mn^{1/2}\\epsilon^{-1})$ sample complexity\nand an $\\mathcal{O}(\\epsilon^{-1})$ communication complexity. These bounds\nsignificantly improve upon the best existing bounds of\n$\\mathcal{O}(mn\\epsilon^{-1})$ and $\\mathcal{O}(\\epsilon^{-1})$, respectively.\nSimilarly, for online problems, the proposed method achieves an $\\mathcal{O}(m\n\\epsilon^{-3/2})$ sample complexity and an $\\mathcal{O}(\\epsilon^{-1})$\ncommunication complexity, while the best existing bounds are\n$\\mathcal{O}(m\\epsilon^{-2})$ and $\\mathcal{O}(\\epsilon^{-2})$, respectively."}, {"title": "Proper Network Interpretability Helps Adversarial Robustness in Classification", "authors": "Akhilan Boopathy, Sijia Liu, Gaoyuan Zhang, Cynthia Liu, Pin-Yu Chen, Shiyu Chang, Luca Daniel "}, {"title": "Generalization Guarantees for Sparse Kernel Approximation with Entropic Optimal Features", "authors": "Liang Ding, Rui Tuo, Shahin Shahrampour ", "link": "https://arxiv.org/abs/2002.04195", "summary": "Despite their success, kernel methods suffer from a massive computational\ncost in practice. In this paper, in lieu of commonly used kernel expansion with\nrespect to $N$ inputs, we develop a novel optimal design maximizing the entropy\namong kernel features. This procedure results in a kernel expansion with\nrespect to entropic optimal features (EOF), improving the data representation\ndramatically due to features dissimilarity. Under mild technical assumptions,\nour generalization bound shows that with only $O(N^{\\frac{1}{4}})$ features\n(disregarding logarithmic factors), we can achieve the optimal statistical\naccuracy (i.e., $O(1/\\sqrt{N})$). The salient feature of our design is its\nsparsity that significantly reduces the time and space cost. Our numerical\nexperiments on benchmark datasets verify the superiority of EOF over the\nstate-of-the-art in kernel approximation."}, {"title": "Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle", "authors": "Shaocong Ma, Yi Zhou "}, {"title": "Calibration, Entropy Rates, and Memory in Language Models", "authors": "Mark Braverman, Xinyi Chen, Sham Kakade, Karthik Narasimhan, Cyril Zhang, Yi Zhang ", "link": "https://arxiv.org/abs/1906.05664", "summary": "Building accurate language models that capture meaningful long-term\ndependencies is a core challenge in natural language processing. Towards this\nend, we present a calibration-based approach to measure long-term discrepancies\nbetween a generative sequence model and the true distribution, and use these\ndiscrepancies to improve the model. Empirically, we show that state-of-the-art\nlanguage models, including LSTMs and Transformers, are \\emph{miscalibrated}:\nthe entropy rates of their generations drift dramatically upward over time. We\nthen provide provable methods to mitigate this phenomenon. Furthermore, we show\nhow this calibration-based approach can also be used to measure the amount of\nmemory that language models use for prediction."}, {"title": "Learning Opinions in Social Networks", "authors": "Vincent Conitzer, Debmalya Panigrahi, Hanrui Zhang "}, {"title": "Latent Variable Modelling with Hyperbolic Normalizing Flows", "authors": "Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden, Will Hamilton ", "link": "https://arxiv.org/abs/2002.06336", "summary": "The choice of approximate posterior distributions plays a central role in\nstochastic variational inference (SVI). One effective solution is the use of\nnormalizing flows \\cut{defined on Euclidean spaces} to construct flexible\nposterior distributions. However, one key limitation of existing normalizing\nflows is that they are restricted to the Euclidean space and are ill-equipped\nto model data with an underlying hierarchical structure. To address this\nfundamental limitation, we present the first extension of normalizing flows to\nhyperbolic spaces. We first elevate normalizing flows to hyperbolic spaces\nusing coupling transforms defined on the tangent bundle, termed Tangent\nCoupling ($\\mathcal{TC}$). We further introduce Wrapped Hyperboloid Coupling\n($\\mathcal{W}\\mathbb{H}C$), a fully invertible and learnable transformation\nthat explicitly utilizes the geometric structure of hyperbolic spaces, allowing\nfor expressive posteriors while being efficient to sample from. We demonstrate\nthe efficacy of our novel normalizing flow over hyperbolic VAEs and Euclidean\nnormalizing flows. Our approach achieves improved performance on density\nestimation, as well as reconstruction of real-world graph data, which exhibit a\nhierarchical structure. Finally, we show that our approach can be used to power\na generative model over hierarchical data using hyperbolic latent variables."}, {"title": "StochasticRank: Global Optimization of Scale-Free Discrete Functions", "authors": "Aleksei Ustimenko, Liudmila Prokhorenkova ", "link": "https://arxiv.org/abs/2003.02122", "summary": "In this paper, we introduce a powerful and efficient framework for the direct\noptimization of ranking metrics. The problem is ill-posed due to the discrete\nstructure of the loss, and to deal with that, we introduce two important\ntechniques: a stochastic smoothing and a novel gradient estimate based on\npartial integration. We also address the problem of smoothing bias and present\na universal solution for a proper debiasing. To guarantee the global\nconvergence of our method, we adopt a recently proposed Stochastic Gradient\nLangevin Boosting algorithm. Our algorithm is implemented as a part of the\nCatBoost gradient boosting library and outperforms the existing approaches on\nseveral learning to rank datasets. In addition to ranking metrics, our\nframework applies to any scale-free discreet loss function."}, {"title": "Working Memory Graphs", "authors": "Ricky Loynd, Roland Fernandez, Asli Celikyilmaz, Adith Swaminathan, Matthew Hausknecht ", "link": "https://arxiv.org/abs/1911.07141", "summary": "Transformers have increasingly outperformed gated RNNs in obtaining new\nstate-of-the-art results on supervised tasks involving text sequences. Inspired\nby this trend, we study the question of how Transformer-based models can\nimprove the performance of sequential decision-making agents. We present the\nWorking Memory Graph (WMG), an agent that employs multi-head self-attention to\nreason over a dynamic set of vectors representing observed and recurrent state.\nWe evaluate WMG in three environments featuring factored observation spaces: a\nPathfinding environment that requires complex reasoning over past observations,\nBabyAI gridworld levels that involve text instructions, and Sokoban which\nemphasizes future planning. We find that the combination of WMG's\nTransformer-based architecture with factored observation spaces leads to\nsignificant gains in learning efficiency compared to other architectures across\nall tasks. Our results imply that for environments where it is possible to\nfactorize environment observations, WMG's Transformer-based architecture can\ndramatically boost sample efficiency."}, {"title": "Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules", "authors": "Sarthak  Mittal, Alex Lamb, Anirudh Goyal, Vikram Voleti, Murray Shanahan, Guillaume Lajoie, Michael Mozer, Yoshua Bengio "}, {"title": "Spread Divergence", "authors": "Mingtian Zhang, Peter Hayes, Thomas Bird, Raza Habib, David Barber ", "link": "https://arxiv.org/abs/1811.08968", "summary": "For distributions p and q with different supports, the divergence D(p|q) may\nnot exist. We define a spread divergence on modified p and q and describe\nsufficient conditions for the existence of such a divergence. We demonstrate\nhow to maximize the discriminatory power of a given divergence by\nparameterizing and learning the spread. We also give examples of using a spread\ndivergence to train and improve implicit generative models, including linear\nmodels (Independent Components Analysis) and non-linear models (Deep Generative\nNetworks)."}, {"title": "Optimizing Black-box Metrics with Adaptive Surrogates", "authors": "Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani Fard, Maya Gupta ", "link": "https://arxiv.org/abs/2002.08605", "summary": "We address the problem of training models with black-box and hard-to-optimize\nmetrics by expressing the metric as a monotonic function of a small number of\neasy-to-optimize surrogates. We pose the training problem as an optimization\nover a relaxed surrogate space, which we solve by estimating local gradients\nfor the metric and performing inexact convex projections. We analyze gradient\nestimates based on finite differences and local linear interpolations, and show\nconvergence of our approach under smoothness assumptions with respect to the\nsurrogates. Experimental results on classification and ranking problems verify\nthe proposal performs on par with methods that know the mathematical\nformulation, and adds notable value when the form of the metric is unknown."}, {"title": "Domain Adaptive Imitation Learning", "authors": "Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, Stefano Ermon ", "link": "", "summary": ""}, {"title": "A general recurrent state space framework for modeling neural dynamics during decision-making", "authors": "David Zoltowski, Jonathan Pillow, Scott Linderman ", "link": "", "summary": ""}, {"title": "An Imitation Learning Approach for Cache Replacement", "authors": "Evan Liu, Milad Hashemi, Kevin Swersky, Parthasarathy Ranganathan, Junwhan Ahn "}, {"title": "Revisiting Training Strategies and Generalization Performance in Deep Metric Learning", "authors": "Karsten Roth, Timo Milbich, Samrath Sinha, Prateek Gupta, Bjorn Ommer, Joseph Paul Cohen ", "link": "https://arxiv.org/abs/2002.08473", "summary": "Deep Metric Learning (DML) is arguably one of the most influential lines of\nresearch for learning visual similarities with many proposed approaches every\nyear. Although the field benefits from the rapid progress, the divergence in\ntraining protocols, architectures, and parameter choices make an unbiased\ncomparison difficult. To provide a consistent reference point, we revisit the\nmost widely used DML objective functions and conduct a study of the crucial\nparameter choices as well as the commonly neglected mini-batch sampling\nprocess. Based on our analysis, we uncover a correlation between the embedding\nspace compression and the generalization performance of DML models. Exploiting\nthese insights, we propose a simple, yet effective, training regularization to\nreliably boost the performance of ranking-based DML models on various standard\nbenchmark datasets."}, {"title": "Temporal Phenotyping using Deep Predicting Clustering of Disease Progression", "authors": "Changhee Lee, M van der Schaar "}, {"title": "Countering Language Drift with Seeded Iterated Learning", "authors": "Yuchen Lu, Soumye Singhal, Florian Strub, Aaron Courville, Olivier Pietquin ", "link": "https://arxiv.org/abs/2003.12694", "summary": "Supervised learning methods excel at capturing statistical properties of\nlanguage when trained over large text corpora. Yet, these models often produce\ninconsistent outputs in goal-oriented language settings as they are not trained\nto complete the underlying task. Moreover, as soon as the agents are finetuned\nto maximize task completion, they suffer from the so-called language drift\nphenomenon: they slowly lose syntactic and semantic properties of language as\nthey only focus on solving the task. In this paper, we propose a generic\napproach to counter language drift by using iterated learning. We iterate\nbetween fine-tuning agents with interactive training steps, and periodically\nreplacing them with new agents that are seeded from last iteration and trained\nto imitate the latest finetuned models. Iterated learning does not require\nexternal syntactic constraint nor semantic knowledge, making it a valuable\ntask-agnostic finetuning protocol. We first explore iterated learning in the\nLewis Game. We then scale-up the approach in the translation game. In both\nsettings, our results show that iterated learn-ing drastically counters\nlanguage drift as well as it improves the task completion metric."}, {"title": "Stochastic Gauss-Newton Algorithms for Nonconvex Compositional Optimization", "authors": "Quoc Tran-Dinh, Nhan H Pham, Lam Nguyen ", "link": "https://arxiv.org/abs/2002.07290", "summary": "We develop two new stochastic Gauss-Newton algorithms for solving a class of\nstochastic nonconvex compositional optimization problems frequently arising in\npractice. We consider both the expectation and finite-sum settings under\nstandard assumptions. We use both classical stochastic and SARAH estimators for\napproximating function values and Jacobians. In the expectation case, we\nestablish $\\mathcal{O}(\\varepsilon^{-2})$ iteration complexity to achieve a\nstationary point in expectation and estimate the total number of stochastic\noracle calls for both function values and its Jacobian, where $\\varepsilon$ is\na desired accuracy. In the finite sum case, we also estimate the same iteration\ncomplexity and the total oracle calls with high probability. To our best\nknowledge, this is the first time such global stochastic oracle complexity is\nestablished for stochastic Gauss-Newton methods. We illustrate our theoretical\nresults via numerical examples on both synthetic and real datasets."}, {"title": "Strategyproof Mean Estimation from Multiple-Choice Questions", "authors": "Anson Kahng, Gregory Kehne, Ariel Procaccia "}, {"title": "Sequential Cooperative Bayesian Inference", "authors": "Junqi Wang, Pei Wang, Patrick Shafto ", "link": "https://arxiv.org/abs/2002.05706", "summary": "Cooperation is often implicitly assumed when learning from other agents.\nCooperation implies that the agent selecting the data, and the agent learning\nfrom the data, have the same goal, that the learner infer the intended\nhypothesis. Recent models in human and machine learning have demonstrated the\npossibility of cooperation. We seek foundational theoretical results for\ncooperative inference by Bayesian agents through sequential data. We develop\nnovel approaches analyzing consistency, rate of convergence and stability of\nSequential Cooperative Bayesian Inference (SCBI). Our analysis of the\neffectiveness, sample efficiency and robustness show that cooperation is not\nonly possible in specific instances but theoretically well-founded in general.\nWe discuss implications for human-human and human-machine cooperation."}, {"title": "Spectral Graph Matching and Regularized Quadratic Relaxations: Algorithm and Theory", "authors": "Zhou Fan, Cheng Mao, Yihong Wu, Jiaming Xu ", "link": "", "summary": ""}, {"title": "Zeno++: Robust Fully Asynchronous SGD", "authors": "Cong Xie, Sanmi Koyejo, Indranil Gupta ", "link": "https://arxiv.org/abs/1903.07020", "summary": "We propose Zeno++, a new robust asynchronous Stochastic Gradient\nDescent~(SGD) procedure which tolerates Byzantine failures of the workers. In\ncontrast to previous work, Zeno++ removes some unrealistic restrictions on\nworker-server communications, allowing for fully asynchronous updates from\nanonymous workers, arbitrarily stale worker updates, and the possibility of an\nunbounded number of Byzantine workers. The key idea is to estimate the descent\nof the loss value after the candidate gradient is applied, where large descent\nvalues indicate that the update results in optimization progress. We prove the\nconvergence of Zeno++ for non-convex problems under Byzantine failures.\nExperimental results show that Zeno++ outperforms existing approaches."}, {"title": "Network Pruning by Greedy Subnetwork Selection", "authors": "Mao Ye, Chengyue Gong, Lizhen Nie, Denny Zhou, Adam Klivans, Qiang Liu ", "link": "", "summary": ""}, {"title": "Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently", "authors": "Asaf Cassel, Alon Cohen, Tomer Koren ", "link": "https://arxiv.org/abs/2002.08095", "summary": "We consider the problem of learning in Linear Quadratic Control systems whose\ntransition parameters are initially unknown. Recent results in this setting\nhave demonstrated efficient learning algorithms with regret growing with the\nsquare root of the number of decision steps. We present new efficient\nalgorithms that achieve, perhaps surprisingly, regret that scales only\n(poly)logarithmically with the number of steps in two scenarios: when only the\nstate transition matrix $A$ is unknown, and when only the state-action\ntransition matrix $B$ is unknown and the optimal policy satisfies a certain\nnon-degeneracy condition. On the other hand, we give a lower bound that shows\nthat when the latter condition is violated, square root regret is unavoidable."}, {"title": "Hierarchical Verification for Adversarial Robustness", "authors": "Cong Han Lim, Raquel Urtasun, Ersin Yumer "}, {"title": "BINOCULARS for efficient, nonmyopic sequential experimental design", "authors": "Shali Jiang, Henry Chai, Javier Gonzalez, Roman Garnett ", "link": "https://arxiv.org/abs/1909.04568", "summary": "Finite-horizon sequential experimental design (SED) arises naturally in many\ncontexts, including hyperparameter tuning in machine learning among more\ntraditional settings. Computing the optimal policy for such problems requires\nsolving Bellman equations, which are generally intractable. Most existing work\nresorts to severely myopic approximations by limiting the decision horizon to\nonly a single time-step, which can underweight exploration in favor of\nexploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using\nLong-horizons for Adaptive, Rapid SED, a general framework for deriving\nefficient, nonmyopic approximations to the optimal experimental policy. Our key\nidea is simple and surprisingly effective: we first compute a one-step optimal\nbatch of experiments, then select a single point from this batch to evaluate.\nWe realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two\nnotable SED problems with radically different objectives -- and demonstrate\nthat BINOCULARS significantly outperforms myopic alternatives in real-world\nscenarios."}, {"title": "On the Global Optimality of Model-Agnostic Meta-Learning", "authors": "Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang "}, {"title": "Breaking the Curse of Many Agents: Provable Mean Embedding $Q$-Iteration for Mean-Field Reinforcement Learning", "authors": "Lingxiao Wang, Zhuoran Yang, Zhaoran Wang ", "link": "", "summary": ""}, {"title": "Learning with Bounded Instance- and Label-dependent Label Noise", "authors": "Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, Dacheng Tao ", "link": "https://arxiv.org/abs/1709.03768", "summary": "Instance- and Label-dependent label Noise (ILN) is widely existed in\nreal-world datasets but has been rarely studied. In this paper, we focus on\nBounded Instance- and Label-dependent label Noise (BILN), a particular case of\nILN where the label noise rates, the probabilities that the true labels of\nexamples flip into the corrupted ones, have upper bounds. Specifically, we\nintroduce the concept of distilled examples, i.e. examples whose labels are\nidentical with the labels assigned for them by the Bayes optimal classifier,\nand prove that under certain conditions classifier learnt on distilled examples\nwill converge to the Bayes optimal classifier. Inspired by the idea of learning\nwith distilled examples, we then propose a learning algorithm with theoretical\nguarantees for its robustness to BILN. At last, empirical evaluations on both\nsynthetic and real-world datasets show effectiveness of our algorithm in\nlearning with BILN."}, {"title": "Transparency Promotion with Model-Agnostic Linear Competitors", "authors": " Hassan Rafique, Tong Wang, Qihang Lin, Arshia Singhani ", "link": "", "summary": ""}, {"title": "Learning Mixtures of Graphs from Epidemic Cascades ", "authors": "Jessica Hoffmann, Soumya Basu, Surbhi Goel, Constantine Caramanis ", "link": "http://arxiv.org/abs/1906.06057", "summary": "We consider the problem of learning the weighted edges of a balanced mixture\nof two undirected graphs from epidemic cascades. While mixture models are\npopular modeling tools, algorithmic development with rigorous guarantees has\nlagged. Graph mixtures are apparently no exception: until now, very little is\nknown about whether this problem is solvable.\n  To the best of our knowledge, we establish the first necessary and sufficient\nconditions for this problem to be solvable in polynomial time on edge-separated\ngraphs. When the conditions are met, i.e., when the graphs are connected with\nat least three edges, we give an efficient algorithm for learning the weights\nof both graphs with optimal sample complexity (up to log factors).\n  We give complimentary results and provide sample-optimal (up to log factors)\nalgorithms for mixtures of directed graphs of out-degree at least three, for\nmixture of undirected graphs of unbalanced and/or unknown priors."}, {"title": "Implicit differentiation of Lasso-type models for hyperparameter optimization", "authors": "Quentin Bertrand, Quentin Klopfenstein, Mathieu Blondel, Samuel Vaiter, Alexandre Gramfort, Joseph Salmon ", "link": "https://arxiv.org/abs/2002.08943", "summary": "Setting regularization parameters for Lasso-type estimators is notoriously\ndifficult, though crucial in practice. The most popular hyperparameter\noptimization approach is grid-search using held-out validation data.\nGrid-search however requires to choose a predefined grid for each parameter,\nwhich scales exponentially in the number of parameters. Another approach is to\ncast hyperparameter optimization as a bi-level optimization problem, one can\nsolve by gradient descent. The key challenge for these methods is the\nestimation of the gradient with respect to the hyperparameters. Computing this\ngradient via forward or backward automatic differentiation is possible yet\nusually suffers from high memory consumption. Alternatively implicit\ndifferentiation typically involves solving a linear system which can be\nprohibitive and numerically unstable in high dimension. In addition, implicit\ndifferentiation usually assumes smooth loss functions, which is not the case\nfor Lasso-type problems. This work introduces an efficient implicit\ndifferentiation algorithm, without matrix inversion, tailored for Lasso-type\nproblems. Our approach scales to high-dimensional data by leveraging the\nsparsity of the solutions. Experiments demonstrate that the proposed method\noutperforms a large number of standard methods to optimize the error on\nheld-out data, or the Stein Unbiased Risk Estimator (SURE)."}, {"title": "Latent Space Factorisation and Manipulation via Matrix Subspace Projection", "authors": "Xiao Li, Chenghua Lin, Ruizhe Li, Chaozheng Wang, Frank Guerin ", "link": "https://arxiv.org/abs/1907.12385", "summary": "This paper proposes a novel method for factorising the information in the\nlatent space of an autoencoder (AE), to improve the interpretability of the\nlatent space and facilitate controlled generation. When trained on a dataset\nwith labelled attributes we can produce a latent vector which separates\ninformation encoding the attributes from other characteristic information, and\nalso disentangles the attribute information. This then allows us to manipulate\neach attribute of the latent representation individually without affecting\nothers. Our method, matrix subspace projection, is simpler than the state of\nthe art adversarial network approaches to latent space factorisation. We\ndemonstrate the utility of the method for attribute manipulation tasks on the\nCelebA image dataset and the E2E text corpus."}, {"title": "Active World Model Learning in Agent-rich Environments with Progress Curiosity", "authors": "Kuno Kim, Megumi Sano, Julian De Freitas, Nick Haber, Daniel Yamins "}, {"title": "SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates", "authors": "Lingkai Kong, Jimeng Sun, Chao Zhang "}, {"title": "GANs May Have No Nash Equilibria", "authors": "Farzan Farnia, Asuman Ozdaglar ", "link": "", "summary": ""}, {"title": "Gradient Temporal-Difference Learning with Regularized Corrections", "authors": "Sina Ghiassian, Andrew Patterson, Shivam Garg, Dhawal Gutpa, Adam White, Martha White "}, {"title": "Online mirror descent and dual averaging: keeping pace in the dynamic case", "authors": "Huang Fang, Victor Sanches Portella, Nick Harvey, Michael Friedlander ", "link": "", "summary": ""}, {"title": "Choice Set Optimization Under Discrete Choice Models of Group Decisions", "authors": "Kiran Tomlinson, Austin Benson ", "link": "https://arxiv.org/abs/2002.00421", "summary": "The way that people make choices or exhibit preferences can be strongly\naffected by the set of available alternatives, often called the choice set.\nFurthermore, there are usually heterogeneous preferences, either at an\nindividual level within small groups or within sub-populations of large groups.\nGiven the availability of choice data, there are now many models that capture\nthis behavior in order to make effective predictions. However, there is little\nwork in understanding how directly changing the choice set can be used to\ninfluence a group's preferences or decisions. Here, we use discrete choice\nmodeling to develop an optimization framework of such interventions for several\nproblems of group influence, including maximizing agreement or disagreement and\npromoting a particular choice. We show that these problems are NP-hard in\ngeneral but imposing restrictions reveals a fundamental boundary: promoting an\nitem is easier than maximizing agreement or disagreement. After, we design\napproximation algorithms for the hard problems and show that they work\nextremely well for real-world choice data."}, {"title": "Complexity of Finding Stationary Points of Nonconvex Nonsmooth Functions", "authors": "Jingzhao Zhang, Hongzhou Lin, Stefanie Jegelka, Suvrit Sra, Ali Jadbabaie ", "link": "", "summary": ""}, {"title": "Multi-Agent Routing Value Iteration Network", "authors": "Quinlan Sykora, Mengye Ren, Raquel Urtasun "}, {"title": "Adversarial Attacks on Copyright Detection Systems", "authors": "Parsa Saadatpanah, Ali Shafahi, Tom Goldstein ", "link": "https://arxiv.org/abs/1906.07153", "summary": "It is well-known that many machine learning models are susceptible to\nadversarial attacks, in which an attacker evades a classifier by making small\nperturbations to inputs. This paper discusses how industrial copyright\ndetection tools, which serve a central role on the web, are susceptible to\nadversarial attacks. We discuss a range of copyright detection systems, and why\nthey are particularly vulnerable to attacks. These vulnerabilities are\nespecially apparent for neural network based systems. As a proof of concept, we\ndescribe a well-known music identification method, and implement this system in\nthe form of a neural net. We then attack this system using simple gradient\nmethods. Adversarial music created this way successfully fools industrial\nsystems, including the AudioTag copyright detector and YouTube's Content ID\nsystem. Our goal is to raise awareness of the threats posed by adversarial\nexamples in this space, and to highlight the importance of hardening copyright\ndetection systems to attacks."}, {"title": "Differentiating through the Fr\u00e9chet Mean", "authors": "Aaron Lou, Isay Katsman, Qingxuan Jiang, Serge Belongie, Ser Nam Lim, Christopher De Sa ", "link": "https://arxiv.org/abs/2003.00335", "summary": "Recent advances in deep representation learning on Riemannian manifolds\nextend classical deep learning operations to better capture the geometry of the\nmanifold. One possible extension is the Fr\\'echet mean, the generalization of\nthe Euclidean mean; however, it has been difficult to apply because it lacks a\nclosed form with an easily computable derivative. In this paper, we show how to\ndifferentiate through the Fr\\'echet mean for arbitrary Riemannian manifolds.\nThen, focusing on hyperbolic space, we derive explicit gradient expressions and\na fast, accurate, and hyperparameter-free Fr\\'echet mean solver. This fully\nintegrates the Fr\\'echet mean into the hyperbolic neural network pipeline. To\ndemonstrate this integration, we present two case studies. First, we apply our\nFr\\'echet mean to the existing Hyperbolic Graph Convolutional Network,\nreplacing its projected aggregation to obtain state-of-the-art results on\ndatasets with high hyperbolicity. Second, to demonstrate the Fr\\'echet mean's\ncapacity to generalize Euclidean neural network operations, we develop a\nhyperbolic batch normalization method that gives an improvement parallel to the\none observed in the Euclidean setting."}, {"title": "Online Learning for Active Cache Synchronization", "authors": "Andrey Kolobov, Sebastien Bubeck, Julian Zimmert ", "link": "https://arxiv.org/abs/2002.12014", "summary": "Existing multi-armed bandit (MAB) models make two implicit assumptions: an\narm generates a payoff only when it is played, and the agent observes every\npayoff that is generated. This paper introduces synchronization bandits, a MAB\nvariant where all arms generate costs at all times, but the agent observes an\narm's instantaneous cost only when the arm is played. Synchronization MABs are\ninspired by online caching scenarios such as Web crawling, where an arm\ncorresponds to a cached item and playing the arm means downloading its fresh\ncopy from a server. We present MirrorSync, an online learning algorithm for\nsynchronization bandits, establish an adversarial regret of $O(T^{2/3})$ for\nit, and show how to make it efficient in practice."}, {"title": "PoKED: A Semi-Supervised System for Word Sense Disambiguation", "authors": "Feng Wei ", "link": "", "summary": ""}, {"title": "A Finite-Time Analysis of  Q-Learning with Neural Network Function Approximation", "authors": "Pan Xu, Quanquan Gu ", "link": "https://arxiv.org/abs/1912.04511", "summary": "Q-learning with neural network function approximation (neural Q-learning for\nshort) is among the most prevalent deep reinforcement learning algorithms.\nDespite its empirical success, the non-asymptotic convergence rate of neural\nQ-learning remains virtually unknown. In this paper, we present a finite-time\nanalysis of a neural Q-learning algorithm, where the data are generated from a\nMarkov decision process and the action-value function is approximated by a deep\nReLU neural network. We prove that neural Q-learning finds the optimal policy\nwith $O(1/\\sqrt{T})$ convergence rate if the neural function approximator is\nsufficiently overparameterized, where $T$ is the number of iterations. To our\nbest knowledge, our result is the first finite-time analysis of neural\nQ-learning under non-i.i.d. data assumption."}, {"title": "Understanding and Stabilizing GANs' Training Dynamics Using Control Theory", "authors": "Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang "}, {"title": "Scalable Nearest Neighbor Search for Optimal Transport", "authors": "Arturs Backurs, Yihe Dong, Piotr Indyk, Ilya Razenshteyn, Tal Wagner ", "link": "https://arxiv.org/abs/1910.04126", "summary": "The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly\npopular similarity measure for rich data domains, such as images or text\ndocuments. This raises the necessity for fast nearest neighbor search with\nrespect to this distance, a problem that poses a substantial computational\nbottleneck for various tasks on massive datasets.\n  In this work, we study fast tree-based approximation algorithms for searching\nnearest neighbors w.r.t. the Wasserstein-1 distance. A standard tree-based\ntechnique, known as Quadtree, has been previously shown to obtain good results.\nWe introduce a variant of this algorithm, called Flowtree, and formally prove\nit achieves asymptotically better accuracy. Our extensive experiments, on\nreal-world text and image datasets, show that Flowtree improves over various\nbaselines and existing methods in either running time or accuracy. In\nparticular, its quality of approximation is in line with previous high-accuracy\nmethods, while its running time is much faster."}, {"title": "Supervised learning: no loss no cry", "authors": "Richard Nock, Aditya Menon ", "link": "https://arxiv.org/abs/2002.03555", "summary": "Supervised learning requires the specification of a loss function to\nminimise. While the theory of admissible losses from both a computational and\nstatistical perspective is well-developed, these offer a panoply of different\nchoices. In practice, this choice is typically made in an \\emph{ad hoc} manner.\nIn hopes of making this procedure more principled, the problem of\n\\emph{learning the loss function} for a downstream task (e.g., classification)\nhas garnered recent interest. However, works in this area have been generally\nempirical in nature.\n  In this paper, we revisit the {\\sc SLIsotron} algorithm of Kakade et al.\n(2011) through a novel lens, derive a generalisation based on Bregman\ndivergences, and show how it provides a principled procedure for learning the\nloss. In detail, we cast {\\sc SLIsotron} as learning a loss from a family of\ncomposite square losses. By interpreting this through the lens of \\emph{proper\nlosses}, we derive a generalisation of {\\sc SLIsotron} based on Bregman\ndivergences. The resulting {\\sc BregmanTron} algorithm jointly learns the loss\nalong with the classifier. It comes equipped with a simple guarantee of\nconvergence for the loss it learns, and its set of possible outputs comes with\na guarantee of agnostic approximability of Bayes rule. Experiments indicate\nthat the {\\sc BregmanTron} substantially outperforms the {\\sc SLIsotron}, and\nthat the loss it learns can be minimized by other algorithms for different\ntasks, thereby opening the interesting problem of \\textit{loss transfer}\nbetween domains."}, {"title": "Label-Noise Robust Domain Adaptation", "authors": "Xiyu Yu, Tongliang Liu, Mingming Gong, Kun Zhang, Kayhan Batmanghelich, Dacheng Tao "}, {"title": "Description Based Text Classification with Reinforcement Learning", "authors": "Wei Wu, Duo Chai, Qinghong Han, Fei Wu, Jiwei Li ", "link": "https://arxiv.org/abs/2002.03067", "summary": "The task of text classification is usually divided into two stages: {\\it text\nfeature extraction} and {\\it classification}. In this standard formalization\ncategories are merely represented as indexes in the label vocabulary, and the\nmodel lacks for explicit instructions on what to classify. Inspired by the\ncurrent trend of formalizing NLP problems as question answering tasks, we\npropose a new framework for text classification, in which each category label\nis associated with a category description. Descriptions are generated by\nhand-crafted templates or using abstractive/extractive models from\nreinforcement learning. The concatenation of the description and the text is\nfed to the classifier to decide whether or not the current label should be\nassigned to the text. The proposed strategy forces the model to attend to the\nmost salient texts with respect to the label, which can be regarded as a hard\nversion of attention, leading to better performances. We observe significant\nperformance boosts over strong baselines on a wide range of text classification\ntasks including single-label classification, multi-label classification and\nmulti-aspect sentiment analysis."}, {"title": "Bandits for BMO Functions", "authors": "Tianyu Wang, Cynthia Rudin "}, {"title": "Cost-effectively Identifying Causal Effect When Only Response Variable Observable", "authors": "Tian-Zuo Wang, Xi-Zhu Wu, Sheng-Jun Huang, Zhi-Hua Zhou "}, {"title": "Learning with Multiple Complementary Labels", "authors": "LEI FENG, Takuo Kaneko, Bo Han, Gang Niu, Bo An, Masashi Sugiyama ", "link": "http://arxiv.org/abs/1912.12927", "summary": "A complementary label (CL) simply indicates an incorrect class of an example,\nbut learning with CLs results in multi-class classifiers that can predict the\ncorrect class. Unfortunately, the problem setting of previous research only\nallows a single CL for each example, which notably limits its potential since\nour labelers may easily identify multiple complementary labels (MCLs) to one\nexample. In this paper, we propose a novel problem setting to allow MCLs for\neach example and two ways for learning with MCLs. In the first way, we design\ntwo wrappers that decompose MCLs into many single CLs in different manners, so\nthat we could use any method for learning with CLs. However, we find that the\nsupervision information that MCLs hold is conceptually diluted after\ndecomposition. Thus, in the second way, we derive an unbiased risk estimator;\nminimizing it processes each set of MCLs as a whole and possesses an estimation\nerror bound. In addition, we improve the second way into minimizing properly\nchosen upper bounds for practical implementation. Experiments show that the\nformer way works well for learning with MCLs while the latter is even better on\nvarious benchmark datasets."}, {"title": "Graph Representation Learning by Maximizing Mutual Information Between Spatial and Spectral Views", "authors": "Kaveh Hassani, Amir Hosein Khasahmadi ", "link": "", "summary": ""}, {"title": "A Chance-Constrained Generative Framework for Sequence Optimization", "authors": "Liu Xianggen, Jian Peng, Qiang Liu, Sen  Song  ", "link": "", "summary": ""}, {"title": "dS^2LBI: Exploring Structural Sparsity on Deep Network via Differential Inclusion Paths", "authors": "Yanwei Fu, Chen Liu, Donghao Li, Xinwei Sun, Jinshan ZENG, Yuan Yao "}, {"title": "Sparse Subspace Clustering with Entropy-Norm", "authors": "Liang Bai, Jiye Liang "}, {"title": "On the Generalization Effects of Linear Transformations in Data Augmentation", "authors": "Sen Wu, Hongyang Zhang, Gregory Valiant, Christopher Re ", "link": "https://arxiv.org/abs/2005.00695", "summary": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations which preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations which mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms RandAugment by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR datasets."}, {"title": "Sparse Shrunk Additive Models", "authors": "Hong Chen, guodong liu, Heng Huang "}, {"title": "Unsupervised Discovery of Interpretable Directions in the GAN Latent Space", "authors": "Andrey Voynov, Artem Babenko ", "link": "https://arxiv.org/abs/2002.03754", "summary": "The latent spaces of typical GAN models often have semantically meaningful\ndirections. Moving in these directions corresponds to human-interpretable image\ntransformations, such as zooming or recoloring, enabling a more controllable\ngeneration process. However, the discovery of such directions is currently\nperformed in a supervised manner, requiring human labels, pretrained models, or\nsome form of self-supervision. These requirements can severely limit a range of\ndirections existing approaches can discover. In this paper, we introduce an\nunsupervised method to identify interpretable directions in the latent space of\na pretrained GAN model. By a simple model-agnostic procedure, we find\ndirections corresponding to sensible semantic manipulations without any form of\n(self-)supervision. Furthermore, we reveal several non-trivial findings, which\nwould be difficult to obtain by existing methods, e.g., a direction\ncorresponding to background removal. As an immediate practical benefit of our\nwork, we show how to exploit this finding to achieve a new state-of-the-art for\nthe problem of saliency detection."}, {"title": "DropNet: Reducing Neural Network Complexity via Iterative Pruning", "authors": "Chong Min John Tan, Mehul Motani "}, {"title": "Self-supervised Label Augmentation via Input Transformations", "authors": "Hankook Lee, Sung Ju Hwang, Jinwoo Shin "}, {"title": "Mapping natural-language problems to formal-language solutions using structured neural representations", "authors": "Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Ken Forbus, Jianfeng Gao "}, {"title": "Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time", "authors": "Zahra Monfared, Daniel Durstewitz "}, {"title": "Implicit Geometric Regularization for Learning Shapes", "authors": "Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman ", "link": "https://arxiv.org/abs/2002.10099", "summary": "Representing shapes as level sets of neural networks has been recently proved\nto be useful for different shape analysis and reconstruction tasks So far, such\nrepresentations were computed using either: (i) pre-computed implicit shape\nrepresentations; or (ii) loss functions explicitly defined over the neural\nlevel sets. In this paper we offer a new paradigm for computing high fidelity\nimplicit neural representations directly from raw data (i.e., point clouds,\nwith or without normal information). We observe that a rather simple loss\nfunction, encouraging the neural network to vanish on the input point cloud and\nto have a unit norm gradient, possesses an implicit geometric regularization\nproperty that favors smooth and natural zero level set surfaces, avoiding bad\nzero-loss solutions. We provide a theoretical analysis of this property for the\nlinear case, and show that, in practice, our method leads to state of the art\nimplicit neural representations with higher level-of-details and fidelity\ncompared to previous methods."}, {"title": "Influence Diagram Bandits", "authors": "Tong Yu, Branislav Kveton, Zheng Wen, Ruiyi Zhang, Ole J. Mengshoel "}, {"title": "Information Particle Filter Tree: An Online Algorithm for POMDPs with Belief-Based Rewards on Continuous Domains", "authors": "Johannes Fischer, \u00d6mer Sahin Tas "}, {"title": "Convergence Rates of Variational Inference in Sparse Deep Learning", "authors": "Badr-Eddine Ch\u00e9rief-Abdellatif ", "link": "https://arxiv.org/abs/1908.04847", "summary": "Variational inference is becoming more and more popular for approximating\nintractable posterior distributions in Bayesian statistics and machine\nlearning. Meanwhile, a few recent works have provided theoretical justification\nand new insights on deep neural networks for estimating smooth functions in\nusual settings such as nonparametric regression. In this paper, we show that\nvariational inference for sparse deep learning retains the same generalization\nproperties than exact Bayesian inference. In particular, we highlight the\nconnection between estimation and approximation theories via the classical\nbias-variance trade-off and show that it leads to near-minimax rates of\nconvergence for H\\\"older smooth functions. Additionally, we show that the model\nselection framework over the neural network architecture via ELBO maximization\ndoes not overfit and adaptively achieves the optimal rate of convergence."}, {"title": "Unsupervised Transfer Learning for Spatiotemporal Predictive Networks", "authors": "Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang ", "link": "", "summary": ""}, {"title": "DINO: Distributed Newton-Type Optimization Method", "authors": "Rixon Crane, Fred Roosta ", "link": "", "summary": ""}, {"title": "Quantum Expectation-Maximization for Gaussian Mixture Models", "authors": "Alessandro Luongo, Iordanis Kerenidis, Anupam Prakash ", "link": "https://arxiv.org/abs/1908.06657", "summary": "The Expectation-Maximization (EM) algorithm is a fundamental tool in\nunsupervised machine learning. It is often used as an efficient way to solve\nMaximum Likelihood (ML) estimation problems, especially for models with latent\nvariables. It is also the algorithm of choice to fit mixture models: generative\nmodels that represent unlabelled points originating from $k$ different\nprocesses, as samples from $k$ multivariate distributions. In this work we\ndefine and use a quantum version of EM to fit a Gaussian Mixture Model. Given\nquantum access to a dataset of $n$ vectors of dimension $d$, our algorithm has\nconvergence and precision guarantees similar to the classical algorithm, but\nthe runtime is only polylogarithmic in the number of elements in the training\nset, and is polynomial in other parameters - as the dimension of the feature\nspace, and the number of components in the mixture. We generalize further the\nalgorithm in two directions. First, we show how to fit any mixture model of\nprobability distributions in the exponential family. Then, we show how to use\nthis algorithm to compute the Maximum a Posteriori (MAP) estimate of a mixture\nmodel: the Bayesian approach to likelihood estimation problems. We discuss the\nperformance of the algorithm on datasets that are expected to be classified\nsuccessfully by those algorithms, arguing that on those cases we can give\nstrong guarantees on the runtime."}, {"title": "Consistent Structured Prediction with Max-Min Margin Markov Networks", "authors": "Alex Nowak, Francis Bach, Alessandro Rudi "}, {"title": "Concentration bounds for CVaR estimation: The cases of light-tailed and heavy-tailed distributions", "authors": "Prashanth L.A., Krishna Jagannathan, Ravi Kolla ", "link": "https://arxiv.org/abs/1901.00997", "summary": "Conditional Value-at-Risk (CVaR) is a widely used risk metric in applications\nsuch as finance. We derive concentration bounds for CVaR estimates, considering\nseparately the cases of light-tailed and heavy-tailed distributions. In the\nlight-tailed case, we use a classical CVaR estimator based on the empirical\ndistribution constructed from the samples. For heavy-tailed random variables,\nwe assume a mild `bounded moment' condition, and derive a concentration bound\nfor a truncation-based estimator. Notably, our concentration bounds enjoy an\nexponential decay in the sample size, for heavy-tailed as well as light-tailed\ndistributions. To demonstrate the applicability of our concentration results,\nwe consider a CVaR optimization problem in a multi-armed bandit setting.\nSpecifically, we address the best CVaR-arm identification problem under a fixed\nbudget. We modify the well-known successive rejects algorithm to incorporate a\nCVaR-based criterion. Using the CVaR concentration result, we derive an\nupper-bound on the probability of incorrect identification by the proposed\nalgorithm."}, {"title": "Robust Pricing in Dynamic Mechanism Design", "authors": "Yuan Deng, S\u00e9bastien Lahaie, Vahab Mirrokni "}, {"title": "Nested Subspace Arrangement for Representation of Relational Data", "authors": "Nozomi Hata, Shizuo Kaji, Akihiro Yoshida, Katsuki Fujisawa "}, {"title": "Equivariant Neural Rendering", "authors": "Emilien Dupont, Miguel Bautista Martin, Alex Colburn, Aditya Sankar, Joshua M Susskind, Qi Shan ", "link": "", "summary": ""}, {"title": "Bounding the fairness and accuracy of classifiers from population statistics", "authors": "Sivan Sabato, Elad Yom-Tov "}, {"title": "Healing Gaussian Process Experts", "authors": "samuel cohen, Rendani Mbuvha, Tshilidzi Marwala, Marc Deisenroth ", "link": "", "summary": ""}, {"title": "Beyond UCB: Optimal and Efficient Contextual Bandits with Regression Oracles", "authors": "Dylan Foster, Alexander Rakhlin ", "link": "https://arxiv.org/abs/2002.04926", "summary": "A fundamental challenge in contextual bandits is to develop flexible,\ngeneral-purpose algorithms with computational requirements no worse than\nclassical supervised learning tasks such as classification and regression.\nAlgorithms based on regression have shown promising empirical success, but\ntheoretical guarantees have remained elusive except in special cases. We\nprovide the first universal and optimal reduction from contextual bandits to\nonline regression. We show how to transform any oracle for online regression\nwith a given value function class into an algorithm for contextual bandits with\nthe induced policy class, with no overhead in runtime or memory requirements.\nWe characterize the minimax rates for contextual bandits with general,\npotentially nonparametric function classes, and show that our algorithm is\nminimax optimal whenever the oracle obtains the optimal rate for regression.\nCompared to previous results, our algorithm requires no distributional\nassumptions beyond realizability, and works even when contexts are chosen\nadversarially."}, {"title": "Simple and Deep Graph Convolutional Networks", "authors": "Ming  Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, Yaliang Li "}, {"title": "Projection-free Distributed Online Convex Optimization with $O(\\sqrt{T})$ Communication Complexity", "authors": "Yuanyu Wan, Wei-Wei Tu, Lijun Zhang "}, {"title": "Meta Variance Transfer: Learning to Augment from the Others", "authors": "Seong-Jin Park, Seungju Han, Ji-won Baek, Insoo Kim, Juhwan Song, Hae Beom Lee, Jae-Joon Han, Sung Ju Hwang "}, {"title": "Coresets for Clustering in Graphs of Bounded Treewidth", "authors": "Daniel Baker, Vladimir Braverman, Lingxiao Huang, Shaofeng H.-C. Jiang, Robert Krauthgamer, Xuan Wu ", "link": "https://arxiv.org/abs/1907.04733", "summary": "We initiate the study of coresets for clustering in graph metrics, i.e., the\nshortest-path metric of edge-weighted graphs. Such clustering problems are\nessential to data analysis and used for example in road networks and data\nvisualization. A coreset is a compact summary of the data that approximately\npreserves the clustering objective for every possible center set, and it offers\nsignificant efficiency improvements in terms of running time, storage, and\ncommunication, including in streaming and distributed settings. Our main result\nis a near-linear time construction of a coreset for k-Median in a general graph\n$G$, with size $O_{\\epsilon, k}(\\mathrm{tw}(G))$ where $\\mathrm{tw}(G)$ is the\ntreewidth of $G$, and we complement the construction with a nearly-tight size\nlower bound. The construction is based on the framework of Feldman and Langberg\n[STOC 2011], and our main technical contribution, as required by this\nframework, is a uniform bound of $O(\\mathrm{tw}(G))$ on the shattering\ndimension under any point weights. We validate our coreset on real-world road\nnetworks, and our scalable algorithm constructs tiny coresets with high\naccuracy, which translates to a massive speedup of existing approximation\nalgorithms such as local search for graph k-Median."}, {"title": "On Breaking Deep Generative Model-based Defenses and Beyond", "authors": "Yanzhi Chen, Renjie Xie, Zhanxing Zhu "}, {"title": "Exploration Through Bias: Revisiting Biased Maximum Likelihood Estimation in Stochastic Multi-Armed Bandits", "authors": "Xi Liu, Ping-Chun Hsieh, Yu Heng Hung, Anirban  Bhattacharya, P. Kumar "}, {"title": "Bisection-Based Pricing for Repeated Contextual Auctions against Strategic Buyer", "authors": "Anton Zhiyanov, Alexey Drutsa "}, {"title": "Haar Graph Pooling", "authors": "Yuguang Wang, Ming Li, Zheng Ma, Guido Montufar, Xiaosheng Zhuang, Yanan Fan ", "link": "https://arxiv.org/abs/1909.11580", "summary": "Deep Graph Neural Networks (GNNs) are useful models for graph classification\nand graph-based regression tasks. In these tasks, graph pooling is a critical\ningredient by which GNNs adapt to input graphs of varying size and structure.\nWe propose a new graph pooling operation based on compressive Haar transforms\n--- \\emph{HaarPooling}. HaarPooling implements a cascade of pooling operations;\nit is computed by following a sequence of clusterings of the input graph. A\nHaarPooling layer transforms a given input graph to an output graph with a\nsmaller node number and the same feature dimension; the compressive Haar\ntransform filters out fine detail information in the Haar wavelet domain. In\nthis way, all the HaarPooling layers together synthesize the features of any\ngiven input graph into a feature vector of uniform size. Such transforms\nprovide a sparse characterization of the data and preserve the structure\ninformation of the input graph. GNNs implemented with standard graph\nconvolution layers and HaarPooling layers achieve state of the art performance\non diverse graph classification and regression problems."}, {"title": "Explaining Groups of Points in Low-Dimensional Representations", "authors": "Gregory Plumb, Jonathan Terhorst, Sriram Sankararaman, Ameet Talwalkar ", "link": "https://arxiv.org/abs/2003.01640", "summary": "A common workflow in data exploration is to learn a low-dimensional\nrepresentation of the data, identify groups of points in that representation,\nand examine the differences between the groups to determine what they\nrepresent. We treat this as an interpretable machine learning problem by\nleveraging the model that learned the low-dimensional representation to help\nidentify the key differences between the groups. To solve this problem, we\nintroduce a new type of explanation, a Global Counterfactual Explanation (GCE),\nand our algorithm, Transitive Global Translations (TGT), for computing GCEs.\nTGT identifies the differences between each pair of groups using compressed\nsensing but constrains those pairwise differences to be consistent among all of\nthe groups. Empirically, we demonstrate that TGT is able to identify\nexplanations that accurately explain the model while being relatively sparse,\nand that these explanations match real patterns in the data."}, {"title": "Learning Portable Representations for High-Level Planning", "authors": "Steven James, Benjamin Rosman, George Konidaris ", "link": "https://arxiv.org/abs/1905.12006", "summary": "We present a framework for autonomously learning a portable representation\nthat describes a collection of low-level continuous environments. We show that\nthese abstract representations can be learned in a task-independent egocentric\nspace specific to the agent that, when grounded with problem-specific\ninformation, are provably sufficient for planning. We demonstrate transfer in\ntwo different domains, where an agent learns a portable, task-independent\nsymbolic vocabulary, as well as rules expressed in that vocabulary, and then\nlearns to instantiate those rules on a per-task basis. This reduces the number\nof samples required to learn a representation of a new task."}, {"title": "Adaptive Estimator Selection for Off-Policy Evaluation", "authors": "Yi Su, Pavithra Srinath, Akshay Krishnamurthy ", "link": "https://arxiv.org/abs/2002.07729", "summary": "We develop a generic data-driven method for estimator selection in off-policy\npolicy evaluation settings. We establish a strong performance guarantee for the\nmethod, showing that it is competitive with the oracle estimator, up to a\nconstant factor. Via in-depth case studies in contextual bandits and\nreinforcement learning, we demonstrate the generality and applicability of the\nmethod. We also perform comprehensive experiments, demonstrating the empirical\nefficacy of our approach and comparing with related approaches. In both case\nstudies, our method compares favorably with existing methods."}, {"title": "Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables", "authors": "Qi Wang, Herke van Hoof "}, {"title": "Generative Flows with Matrix Exponential", "authors": "Changyi Xiao, Ligang Liu "}, {"title": "Composable Sketches for  Functions of Frequencies: Beyond the Worst Case", "authors": "Edith Cohen, Ofir Geri, Rasmus Pagh ", "link": "https://arxiv.org/abs/2004.04772", "summary": "Recently there has been increased interest in using machine learning\ntechniques to improve classical algorithms. In this paper we study when it is\npossible to construct compact, composable sketches for weighted sampling and\nstatistics estimation according to functions of data frequencies. Such\nstructures are now central components of large-scale data analytics and machine\nlearning pipelines. However, many common functions, such as thresholds and\n$p$th frequency moments with $p>2$, are known to require polynomial size\nsketches in the worst case. We explore performance beyond the worst case under\ntwo different types of assumptions. The first is having access to noisy advice\non item frequencies. This continues the line of work of Hsu et al. (ICLR 2019),\nwho assume predictions are provided by a machine learning model. The second is\nproviding guaranteed performance on a restricted class of input frequency\ndistributions that are better aligned with what is observed in practice. This\nextends the work on heavy hitters under Zipfian distributions in a seminal\npaper of Charikar et al. (ESA 2002). Surprisingly, we show analytically and\nempirically that \"in practice\" small polylogarithmic-size sketches provide\naccuracy for \"hard\" functions."}, {"title": "Self-concordant analysis of Frank-Wolfe algorithm", "authors": "Mathias Staudigl, Pavel Dvurechenskii, Shimrit Shtein, Kamil Safin, Petr Ostroukhov ", "link": "https://arxiv.org/abs/2002.04320", "summary": "Projection-free optimization via different variants of the Frank-Wolfe (FW)\nmethod has become one of the cornerstones in optimization for machine learning\nsince in many cases the linear minimization oracle is much cheaper to implement\nthan projections and some sparsity needs to be preserved. In a number of\napplications, e.g. Poisson inverse problems or quantum state tomography, the\nloss is given by a self-concordant (SC) function having unbounded curvature,\nimplying absence of theoretical guarantees for the existing FW methods. We use\nthe theory of SC functions to provide a new adaptive step size for FW methods\nand prove global convergence rate O(1/k), k being the iteration counter. If the\nproblem can be represented by a local linear minimization oracle, we are the\nfirst to propose a FW method with linear convergence rate without assuming\nneither strong convexity nor a Lipschitz continuous gradient."}, {"title": "Towards non-parametric drift detection via Dynamic Adapting Window Independence Drift Detection (DAWIDD)", "authors": "Fabian Hinder, Andr\u00e9 Artelt, CITEC Barbara Hammer "}, {"title": "Non-Stationary Bandits with Intermediate Observations", "authors": "Claire Vernade, Andras Gyorgy, Timothy Mann "}, {"title": "Does label smoothing mitigate label noise?", "authors": "Lukasik Michal, Srinadh Bhojanapalli, Aditya Menon, Sanjiv Kumar ", "link": "https://arxiv.org/abs/2003.02819", "summary": "Label smoothing is commonly used in training deep learning models, wherein\none-hot training labels are mixed with uniform label vectors. Empirically,\nsmoothing has been shown to improve both predictive performance and model\ncalibration. In this paper, we study whether label smoothing is also effective\nas a means of coping with label noise. While label smoothing apparently\namplifies this problem --- being equivalent to injecting symmetric noise to the\nlabels --- we show how it relates to a general family of loss-correction\ntechniques from the label noise literature. Building on this connection, we\nshow that label smoothing is competitive with loss-correction under label\nnoise. Further, we show that when distilling models from noisy data, label\nsmoothing of the teacher is beneficial; this is in contrast to recent findings\nfor noise-free problems, and sheds further light on settings where label\nsmoothing is beneficial."}, {"title": "Proving the Lottery Ticket Hypothesis: Pruning is All You Need", "authors": "Gilad Yehudai, Eran Malach, Shai Shalev-Schwartz, Ohad Shamir ", "link": "https://arxiv.org/abs/2002.00585", "summary": "The lottery ticket hypothesis (Frankle and Carbin, 2018), states that a\nrandomly-initialized network contains a small subnetwork such that, when\ntrained in isolation, can compete with the performance of the original network.\nWe prove an even stronger hypothesis (as was also conjectured in Ramanujan et\nal., 2019), showing that for every bounded distribution and every target\nnetwork with bounded weights, a sufficiently over-parameterized neural network\nwith random weights contains a subnetwork with roughly the same accuracy as the\ntarget network, without any further training."}, {"title": "Linear bandits with Stochastic Delayed Feedback", "authors": "Claire Vernade, Alexandra Carpentier, Tor Lattimore, Giovanni Zappella, Beyza Ermis, Michael Brueckner ", "link": "https://arxiv.org/abs/1807.02089", "summary": "Stochastic linear bandits are a natural and well-studied model for structured\nexploration/exploitation problems and are widely used in applications such as\nonline marketing and recommendation. One of the main challenges faced by\npractitioners hoping to apply existing algorithms is that usually the feedback\nis randomly delayed and delays are only partially observable. For example,\nwhile a purchase is usually observable some time after the display, the\ndecision of not buying is never explicitly sent to the system. In other words,\nthe learner only observes delayed positive events. We formalize this problem as\na novel stochastic delayed linear bandit and propose ${\\tt OTFLinUCB}$ and\n${\\tt OTFLinTS}$, two computationally efficient algorithms able to integrate\nnew information as it becomes available and to deal with the permanently\ncensored feedback. We prove optimal $\\tilde O(\\smash{d\\sqrt{T}})$ bounds on the\nregret of the first algorithm and study the dependency on delay-dependent\nparameters. Our model, assumptions and results are validated by experiments on\nsimulated and real data."}, {"title": "Time Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders", "authors": "Ioana Bica, Ahmed Alaa, Mihaela van der Schaar ", "link": "https://arxiv.org/abs/1902.00450", "summary": "The estimation of treatment effects is a pervasive problem in medicine.\nExisting methods for estimating treatment effects from longitudinal\nobservational data assume that there are no hidden confounders. This assumption\nis not testable in practice and, if it does not hold, leads to biased\nestimates. In this paper, we develop the Time Series Deconfounder, a method\nthat leverages the assignment of multiple treatments over time to enable the\nestimation of treatment effects even in the presence of hidden confounders. The\nTime Series Deconfounder uses a novel recurrent neural network architecture\nwith multitask output to build a factor model over time and infer substitute\nconfounders that render the assigned treatments conditionally independent. Then\nit performs causal inference using the substitute confounders. We provide a\ntheoretical analysis for obtaining unbiased causal effects of time-varying\nexposures using the Time Series Deconfounder. Using simulations we show the\neffectiveness of our method in deconfounding the estimation of treatment\nresponses in longitudinal data."}, {"title": "Negative Sampling in Semi-Supervised learning", "authors": "John Chen, Vatsal Shah, Anastasios Kyrillidis ", "link": "https://arxiv.org/abs/1911.05166", "summary": "We introduce Negative Sampling in Semi-Supervised Learning (NS3L), a simple,\nfast, easy to tune algorithm for semi-supervised learning (SSL). NS3L is\nmotivated by the success of negative sampling/contrastive estimation. We\ndemonstrate that adding the NS3L loss to state-of-the-art SSL algorithms, such\nas the Virtual Adversarial Training (VAT), significantly improves upon vanilla\nVAT and its variant, VAT with Entropy Minimization. By adding the NS3L loss to\nMixMatch, the current state-of-the-art approach on semi-supervised tasks, we\nobserve significant improvements over vanilla MixMatch. We conduct extensive\nexperiments on the CIFAR10, CIFAR100, SVHN and STL10 benchmark datasets."}, {"title": "Adaptive Sketching for Fast and Convergent Canonical Polyadic Decomposition", "authors": "Alex Gittens, Kareem Aggour, B\u00fclent Yener "}, {"title": "Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Rasmus Pagh "}, {"title": "On the generalization benefit of noise in stochastic gradient descent", "authors": "Samuel L Smith, Erich Elsen, Soham De ", "link": "", "summary": ""}, {"title": "Momentum-Based Policy Gradient Methods", "authors": "Feihu Huang, Shangqian Gao, Jian Pei, Heng Huang ", "link": "", "summary": ""}, {"title": "Knowing The What But Not The Where in Bayesian Optimization", "authors": "Vu Nguyen, Michael A Osborne ", "link": "https://arxiv.org/abs/1905.02685", "summary": "Bayesian optimization has demonstrated impressive success in finding the\noptimum input x* and output f* = f(x*) = max f(x) of a black-box function f. In\nsome applications, however, the optimum output f* is known in advance and the\ngoal is to find the corresponding optimum input x*. In this paper, we consider\na new setting in BO in which the knowledge of the optimum output f* is\navailable. Our goal is to exploit the knowledge about f* to search for the\ninput x* efficiently. To achieve this goal, we first transform the Gaussian\nprocess surrogate using the information about the optimum output. Then, we\npropose two acquisition functions, called confidence bound minimization and\nexpected regret minimization. We show that our approaches work intuitively and\ngive quantitatively better performance against standard BO methods. We\ndemonstrate real applications in tuning a deep reinforcement learning algorithm\non the CartPole problem and XGBoost on Skin Segmentation dataset in which the\noptimum values are publicly available."}, {"title": "Robust Bayesian Classification Using An Optimistic Score Ratio", "authors": "Viet Anh Nguyen, Nian Si, Jose Blanchet "}, {"title": "Boosted Histogram Transform for Regression", "authors": "Yuchao Cai, Hanyuan Hang, Hanfang Yang, Zhouchen Lin "}, {"title": "Stochastic bandits with arm-dependent delays", "authors": "Anne Gael Manegueu, Claire Vernade, Alexandra Carpentier, Michal Valko ", "link": "https://arxiv.org/abs/1910.02757", "summary": "Motivated by recommendation problems in music streaming platforms, we propose\na nonstationary stochastic bandit model in which the expected reward of an arm\ndepends on the number of rounds that have passed since the arm was last pulled.\nAfter proving that finding an optimal policy is NP-hard even when all model\nparameters are known, we introduce a class of ranking policies provably\napproximating, to within a constant factor, the expected reward of the optimal\npolicy. We show an algorithm whose regret with respect to the best ranking\npolicy is bounded by $\\widetilde{\\mathcal{O}}\\big(\\!\\sqrt{kT}\\big)$, where $k$\nis the number of arms and $T$ is time. Our algorithm uses only\n$\\mathcal{O}\\big(k\\ln\\ln T\\big)$ switches, which helps when switching between\npolicies is costly. As constructing the class of learning policies requires\nordering the arms according to their expectations, we also bound the number of\npulls required to do so. Finally, we run experiments to compare our algorithm\nagainst UCB on different problem instances."}, {"title": "Projective Preferential Bayesian Optimization", "authors": "Petrus Mikkola, Milica Todorovi\u0107, Jari J\u00e4rvi, Patrick Rinke, Samuel Kaski ", "link": "https://arxiv.org/abs/2002.03113", "summary": "Bayesian optimization is an effective method for finding extrema of a\nblack-box function. We propose a new type of Bayesian optimization for learning\nuser preferences in high-dimensional spaces. The central assumption is that the\nunderlying objective function cannot be evaluated directly, but instead a\nminimizer along a projection can be queried, which we call a projective\npreferential query. The form of the query allows for feedback that is natural\nfor a human to give, and which enables interaction. This is demonstrated in a\nuser experiment in which the user feedback comes in the form of optimal\nposition and orientation of a molecule adsorbing to a surface. We demonstrate\nthat our framework is able to find a global minimum of a high-dimensional\nblack-box function, which is an infeasible task for existing preferential\nBayesian optimization frameworks that are based on pairwise comparisons."}, {"title": "On Relativistic f-Divergences", "authors": "Alexia Jolicoeur-Martineau ", "link": "https://arxiv.org/abs/1901.02474", "summary": "This paper provides a more rigorous look at Relativistic Generative\nAdversarial Networks (RGANs). We prove that the objective function of the\ndiscriminator is a statistical divergence for any concave function $f$ with\nminimal properties ($f(0)=0$, $f'(0) \\neq 0$, $\\sup_x f(x)>0$). We also devise\na few variants of relativistic $f$-divergences. Wasserstein GAN was originally\njustified by the idea that the Wasserstein distance (WD) is most sensible\nbecause it is weak (i.e., it induces a weak topology). We show that the WD is\nweaker than $f$-divergences which are weaker than relativistic $f$-divergences.\nGiven the good performance of RGANs, this suggests that WGAN does not performs\nwell primarily because of the weak metric, but rather because of regularization\nand the use of a relativistic discriminator. We also take a closer look at\nestimators of relativistic $f$-divergences. We introduce the minimum-variance\nunbiased estimator (MVUE) for Relativistic paired GANs (RpGANs; originally\ncalled RGANs which could bring confusion) and show that it does not perform\nbetter. Furthermore, we show that the estimator of Relativistic average GANs\n(RaGANs) is only asymptotically unbiased, but that the finite-sample bias is\nsmall. Removing this bias does not improve performance."}, {"title": "A Flexible Framework for Nonparametric Graphical Modeling that Accommodates Machine Learning", "authors": "Yunhua Xiang, Noah Simon "}, {"title": "The Natural Lottery Ticket Winner: Reinforcement Learning with Ordinary Neural Circuits", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu Grosu "}, {"title": "Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension", "authors": "Aditya Krishnan, Roi Sinoff, Robert Krauthgamer, Vladimir Braverman ", "link": "https://arxiv.org/abs/1907.05457", "summary": "Spectral functions of large matrices contains important structural\ninformation about the underlying data, and is thus becoming increasingly\nimportant. Many times, large matrices representing real-world data are\n\\emph{sparse} or \\emph{doubly sparse} (i.e., sparse in both rows and columns),\nand are accessed as a \\emph{stream} of updates, typically organized in\n\\emph{row-order}. In this setting, where space (memory) is the limiting\nresource, all known algorithms require space that is polynomial in the\ndimension of the matrix, even for sparse matrices. We address this challenge by\nproviding the first algorithms whose space requirement is \\emph{independent of\nthe matrix dimension}, assuming the matrix is doubly-sparse and presented in\nrow-order. Our algorithms approximate the Schatten $p$-norms, which we use in\nturn to approximate other spectral functions, such as logarithm of the\ndeterminant, trace of matrix inverse, and Estrada index. We validate these\ntheoretical performance bounds by numerical experiments on real-world matrices\nrepresenting social networks. We further prove that multiple passes are\nunavoidable in this setting, and show extensions of our primary technique,\nincluding a trade-off between space requirements and number of passes."}, {"title": "Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning", "authors": "Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni, Marcello Restelli ", "link": "https://arxiv.org/abs/2002.06836", "summary": "The choice of the control frequency of a system has a relevant impact on the\nability of reinforcement learning algorithms to learn a highly performing\npolicy. In this paper, we introduce the notion of action persistence that\nconsists in the repetition of an action for a fixed number of decision steps,\nhaving the effect of modifying the control frequency. We start analyzing how\naction persistence affects the performance of the optimal policy, and then we\npresent a novel algorithm, Persistent Fitted Q-Iteration (PFQI), that extends\nFQI, with the goal of learning the optimal value function at a given\npersistence. After having provided a theoretical study of PFQI and a heuristic\napproach to identify the optimal persistence, we present an experimental\ncampaign on benchmark domains to show the advantages of action persistence and\nproving the effectiveness of our persistence selection method."}, {"title": "Minimax Rate for Learning From Pairwise Comparisons in the BTL Model", "authors": "Julien Hendrickx, Alex Olshevsky, Venkatesh Saligrama "}, {"title": "Interferometric Graph Transform:a Deep Unsupervised Graph Invariant Representation", "authors": "Edouard Oyallon ", "link": "", "summary": ""}, {"title": "Stochastic Differential Equations with variational Wishart diffusions", "authors": "Martin J\u00f8rgensen, Marc Deisenroth, Hugh Salimbeni ", "link": "", "summary": ""}, {"title": "What Can Learned Intrinsic Rewards Capture?", "authors": "Zeyu Zheng, Junhyuk Oh, Matteo Hessel, Zhongwen Xu, Manuel Kroiss, Hado van Hasselt, David Silver, Satinder Singh ", "link": "https://arxiv.org/abs/1912.05500", "summary": "Reinforcement learning agents can include different components, such as\npolicies, value functions, state representations, and environment models. Any\nor all of these can be the loci of knowledge, i.e., structures where knowledge,\nwhether given or learned, can be deposited and reused. The objective of an\nagent is to behave so as to maximise the sum of a suitable scalar function of\nstate: the reward. As far as the learning algorithm is concerned, these rewards\nare typically given and immutable. In this paper we instead consider the\nproposition that the reward function itself may be a good locus of knowledge.\nThis is consistent with a common use, in the literature, of hand-designed\nintrinsic rewards to improve the learning dynamics of an agent. We adopt the\nmulti-lifetime setting of the Optimal Rewards Framework, and propose to\nmeta-learn an intrinsic reward function from experience that allows agents to\nmaximise their extrinsic rewards accumulated until the end of their lifetimes.\nRewards as a locus of knowledge provide guidance on \"what\" the agent should\nstrive to do rather than \"how\" the agent should behave; the latter is more\ndirectly captured in policies or value functions for example. Thus, our focus\nhere is on demonstrating the following: (1) that it is feasible to meta-learn\ngood reward functions, (2) that the learned reward functions can capture\ninteresting kinds of \"what\" knowledge, and (3) that because of the indirectness\nof this form of knowledge the learned reward functions can generalise to other\nkinds of agents and to changes in the dynamics of the environment."}, {"title": "Random extrapolation for primal-dual coordinate descent", "authors": "Ahmet Alacaoglu, Olivier Fercoq, Volkan Cevher "}, {"title": "Reinforcement Learning with Differential Privacy", "authors": "Giuseppe Vietri, Borja de Balle Pigem, Steven Wu, Akshay Krishnamurthy "}, {"title": "Median Matrix Completion: from Embarrassment to Optimality", "authors": "Weidong Liu, Xiaojun Mao, Raymond K. W. Wong "}, {"title": "Improved Optimistic Algorithms for Logistic Bandits", "authors": "Louis Faury, Marc Abeille, Clement Calauzenes, Olivier Fercoq ", "link": "https://arxiv.org/abs/2002.07530", "summary": "The generalized linear bandit framework has attracted a lot of attention in\nrecent years by extending the well-understood linear setting and allowing to\nmodel richer reward structures. It notably covers the logistic model, widely\nused when rewards are binary. For logistic bandits, the frequentist regret\nguarantees of existing algorithms are $\\tilde{\\mathcal{O}}(\\kappa \\sqrt{T})$,\nwhere $\\kappa$ is a problem-dependent constant. Unfortunately, $\\kappa$ can be\narbitrarily large as it scales exponentially with the size of the decision set.\nThis may lead to significantly loose regret bounds and poor empirical\nperformance. In this work, we study the logistic bandit with a focus on the\nprohibitive dependencies introduced by $\\kappa$. We propose a new optimistic\nalgorithm based on a finer examination of the non-linearities of the reward\nfunction. We show that it enjoys a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret with\nno dependency in $\\kappa$, but for a second order term. Our analysis is based\non a new tail-inequality for self-normalized martingales, of independent\ninterest."}, {"title": "Learning to Rank Learning Curves", "authors": "Martin Wistuba, Tejaswini Pedapati "}, {"title": "Model Fusion with Kullback--Leibler Divergence", "authors": "Sebastian Claici, Mikhail Yurochkin, Soumya Ghosh, Justin Solomon "}, {"title": "Randomization matters How to defend against strong adversarial attacks", "authors": "Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal Atif ", "link": "https://arxiv.org/abs/2002.11565", "summary": "Is there a classifier that ensures optimal robustness against all adversarial\nattacks? This paper answers this question by adopting a game-theoretic point of\nview. We show that adversarial attacks and defenses form an infinite zero-sum\ngame where classical results (e.g. Sion theorem) do not apply. We demonstrate\nthe non-existence of a Nash equilibrium in our game when the classifier and the\nAdversary are both deterministic, hence giving a negative answer to the above\nquestion in the deterministic regime. Nonetheless, the question remains open in\nthe randomized regime. We tackle this problem by showing that, undermild\nconditions on the dataset distribution, any deterministic classifier can be\noutperformed by a randomized one. This gives arguments for using randomization,\nand leads us to a new algorithm for building randomized classifiers that are\nrobust to strong adversarial attacks. Empirical results validate our\ntheoretical analysis, and show that our defense method considerably outperforms\nAdversarial Training against state-of-the-art attacks."}, {"title": "Evolutionary Topology Search for Tensor Network Decomposition", "authors": "Chao Li, Zhun Sun "}, {"title": "Quadratically Regularized Subgradient Methods for Weakly Convex Optimization with Weakly Convex Constraints", "authors": "Runchao Ma, Qihang Lin, Tianbao Yang "}, {"title": "Scalable and Efficient Comparison-based Search without Features", "authors": "Daniyar Chumbalov, Lucas Maystre, Matthias Grossglauser ", "link": "https://arxiv.org/abs/1905.05049", "summary": "We consider the problem of finding a target object $t$ using pairwise\ncomparisons, by asking an oracle questions of the form \\emph{\"Which object from\nthe pair $(i,j)$ is more similar to $t$?''}. Objects live in a space of latent\nfeatures, from which the oracle generates noisy answers. First, we consider the\n{\\em non-blind} setting where these features are accessible. We propose a new\nBayesian comparison-based search algorithm with noisy answers; it has low\ncomputational complexity yet is efficient in the number of queries. We provide\ntheoretical guarantees, deriving the form of the optimal query and proving\nalmost sure convergence to the target $t$. Second, we consider the \\emph{blind}\nsetting, where the object features are hidden from the search algorithm. In\nthis setting, we combine our search method and a new distributional triplet\nembedding algorithm into one scalable learning framework called\n\\textsc{Learn2Search}. We show that the query complexity of our approach on two\nreal-world datasets is on par with the non-blind setting, which is not\nachievable using any of the current state-of-the-art embedding methods."}, {"title": "Error-Bounded Correction of Noisy Labels", "authors": "Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, Chao Chen "}, {"title": "Learning with Feature and Distribution Evolvable Streams", "authors": "Zhen-Yu Zhang, Peng Zhao, Yuan Jiang, Zhi-Hua Zhou "}, {"title": "On Unbalanced Optimal Transport: An Analysis of Sinkhorn Algorithm", "authors": "Khiem Pham, Khang Le, Nhat Ho, Tung Pham, Hung Bui ", "link": "http://arxiv.org/abs/2002.03293", "summary": "We provide a computational complexity analysis for the Sinkhorn algorithm\nthat solves the entropic regularized Unbalanced Optimal Transport (UOT) problem\nbetween two measures of possibly different masses with at most $n$ components.\nWe show that the complexity of the Sinkhorn algorithm for finding an\n$\\varepsilon$-approximate solution to the UOT problem is of order\n$\\widetilde{\\mathcal{O}}(n^2/ \\varepsilon)$, which is near-linear time. To the\nbest of our knowledge, this complexity is better than the complexity of the\nSinkhorn algorithm for solving the Optimal Transport (OT) problem, which is of\norder $\\widetilde{\\mathcal{O}}(n^2/\\varepsilon^2)$. Our proof technique is\nbased on the geometric convergence of the Sinkhorn updates to the optimal dual\nsolution of the entropic regularized UOT problem and some properties of the\nprimal solution. It is also different from the proof for the complexity of the\nSinkhorn algorithm for approximating the OT problem since the UOT solution does\nnot have to meet the marginal constraints."}, {"title": "Learning Optimal Tree Models under Beam Search", "authors": "Jingwei Zhuo, Ziru Xu, Wei Dai, Han Zhu, HAN LI, Jian Xu, Kun Gai "}, {"title": "Estimating the number and effect sizes of non-null hypotheses", "authors": "Jennifer Brennan, Ramya Korlakai Vinayak, Kevin Jamieson ", "link": "https://arxiv.org/abs/2002.07297", "summary": "We study the problem of estimating the distribution of effect sizes (the mean\nof the test statistic under the alternate hypothesis) in a multiple testing\nsetting. Knowing this distribution allows us to calculate the power (type II\nerror) of any experimental design. We show that it is possible to estimate this\ndistribution using an inexpensive pilot experiment, which takes significantly\nfewer samples than would be required by an experiment that identified the\ndiscoveries. Our estimator can be used to guarantee the number of discoveries\nthat will be made using a given experimental design in a future experiment. We\nprove that this simple and computationally efficient estimator enjoys a number\nof favorable theoretical properties, and demonstrate its effectiveness on data\nfrom a gene knockout experiment on influenza inhibition in Drosophila."}, {"title": "Estimating Model Uncertainty of Neural Network in Sparse Information Form", "authors": "Jongseok Lee, Matthias Humt  - German Aerospace Center, Jianxiang Feng, Rudolph Triebel "}, {"title": "Double-Loop Unadjusted Langevin Algorithm", "authors": "Paul Rolland, Armin Eftekhari, Ali Kavis, Volkan Cevher "}, {"title": "Growing Action Spaces", "authors": "Gregory Farquhar, Laura  Gustafson, Zeming Lin, Shimon Whiteson, Nicolas Usunier, Gabriel Synnaeve ", "link": "https://arxiv.org/abs/1906.12266", "summary": "In complex tasks, such as those with large combinatorial action spaces,\nrandom exploration may be too inefficient to achieve meaningful learning\nprogress. In this work, we use a curriculum of progressively growing action\nspaces to accelerate learning. We assume the environment is out of our control,\nbut that the agent may set an internal curriculum by initially restricting its\naction space. Our approach uses off-policy reinforcement learning to estimate\noptimal value functions for multiple action spaces simultaneously and\nefficiently transfers data, value estimates, and state representations from\nrestricted action spaces to the full task. We show the efficacy of our approach\nin proof-of-concept control tasks and on challenging large-scale StarCraft\nmicromanagement tasks with large, multi-agent action spaces."}, {"title": "Analytic Marching: An Analytic Meshing Solution from Deep Implicit Surface Networks", "authors": "Jiabao Lei, Kui Jia ", "link": "https://arxiv.org/abs/2002.06597", "summary": "This paper studies a problem of learning surface mesh via implicit functions\nin an emerging field of deep learning surface reconstruction, where implicit\nfunctions are popularly implemented as multi-layer perceptrons (MLPs) with\nrectified linear units (ReLU). To achieve meshing from learned implicit\nfunctions, existing methods adopt the de-facto standard algorithm of marching\ncubes; while promising, they suffer from loss of precision learned in the MLPs,\ndue to the discretization nature of marching cubes. Motivated by the knowledge\nthat a ReLU based MLP partitions its input space into a number of linear\nregions, we identify from these regions analytic cells and analytic faces that\nare associated with zero-level isosurface of the implicit function, and\ncharacterize the theoretical conditions under which the identified analytic\nfaces are guaranteed to connect and form a closed, piecewise planar surface.\nBased on our theorem, we propose a naturally parallelizable algorithm of\nanalytic marching, which marches among analytic cells to exactly recover the\nmesh captured by a learned MLP. Experiments on deep learning mesh\nreconstruction verify the advantages of our algorithm over existing ones."}, {"title": "Anderson Acceleration of Proximal Gradient Methods", "authors": "Vien Van Mai, Mikael Johansson ", "link": "https://arxiv.org/abs/1910.08590", "summary": "Anderson acceleration is a well-established and simple technique for speeding\nup fixed-point computations with countless applications. Previous studies of\nAnderson acceleration in optimization have only been able to provide\nconvergence guarantees for unconstrained and smooth problems. This work\nintroduces novel methods for adapting Anderson acceleration to (non-smooth and\nconstrained) proximal gradient algorithms. Under some technical conditions, we\nextend the existing local convergence results of Anderson acceleration for\nsmooth fixed-point mappings to the proposed scheme. We also prove analytically\nthat it is not, in general, possible to guarantee global convergence of native\nAnderson acceleration. We therefore propose a simple scheme for stabilization\nthat combines the global worst-case guarantees of proximal gradient methods\nwith the local adaptation and practical speed-up of Anderson acceleration."}, {"title": "Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure", "authors": "John Sipple "}, {"title": "Certified Robustness to Label-Flipping Attacks via Randomized Smoothing", "authors": "Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, Zico Kolter ", "link": "https://arxiv.org/abs/2002.03018", "summary": "Machine learning algorithms are known to be susceptible to data poisoning\nattacks, where an adversary manipulates the training data to degrade\nperformance of the resulting classifier. While many heuristic defenses have\nbeen proposed, few defenses exist which are certified against worst-case\ncorruption of the training data. In this work, we propose a strategy to build\nlinear classifiers that are certifiably robust against a strong variant of\nlabel-flipping, where each test example is targeted independently. In other\nwords, for each test point, our classifier makes a prediction and includes a\ncertification that its prediction would be the same had some number of training\nlabels been changed adversarially. Our approach leverages randomized smoothing,\na technique that has previously been used to guarantee---with high\nprobability---test-time robustness to adversarial manipulation of the input to\na classifier. We derive a variant which provides a deterministic, analytical\nbound, sidestepping the probabilistic certificates that traditionally result\nfrom the sampling subprocedure. Further, we obtain these certified bounds with\nno additional runtime cost over standard classification. We generalize our\nresults to the multi-class case, providing what we believe to be the first\nmulti-class classification algorithm that is certifiably robust to\nlabel-flipping attacks."}, {"title": "Responsive Safety in Reinforcement Learning", "authors": "Adam  Stooke, Joshua Achiam, Pieter Abbeel "}, {"title": "Deep k-NN for Noisy Labels", "authors": "Dara Bahri, Heinrich Jiang, Maya Gupta "}, {"title": "Learning the piece-wise constant graph structure of a varying Ising model", "authors": "Batiste Le Bars, Pierre Humbert, Argyris Kalogeratos, Nicolas Vayatis ", "link": "", "summary": ""}, {"title": "Stabilizing Transformers for Reinforcement Learning", "authors": "Emilio Parisotto, Francis Song, Jack Rae, Razvan Pascanu, Caglar Gulcehre, Siddhant Jayakumar, Max Jaderberg, Raphael Lopez Kaufman, Aidan Clark, Seb Noury, Matthew Botvinick, Nicolas Heess, Raia Hadsell ", "link": "https://arxiv.org/abs/1910.06764", "summary": "Owing to their ability to both effectively integrate information over long\ntime horizons and scale to massive amounts of data, self-attention\narchitectures have recently shown breakthrough success in natural language\nprocessing (NLP), achieving state-of-the-art results in domains such as\nlanguage modeling and machine translation. Harnessing the transformer's ability\nto process long time horizons of information could provide a similar\nperformance boost in partially observable reinforcement learning (RL) domains,\nbut the large-scale transformers used in NLP have yet to be successfully\napplied to the RL setting. In this work we demonstrate that the standard\ntransformer architecture is difficult to optimize, which was previously\nobserved in the supervised learning setting but becomes especially pronounced\nwith RL objectives. We propose architectural modifications that substantially\nimprove the stability and learning speed of the original Transformer and XL\nvariant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses\nLSTMs on challenging memory environments and achieves state-of-the-art results\non the multi-task DMLab-30 benchmark suite, exceeding the performance of an\nexternal memory architecture. We show that the GTrXL, trained using the same\nlosses, has stability and performance that consistently matches or exceeds a\ncompetitive LSTM baseline, including on more reactive tasks where memory is\nless critical. GTrXL offers an easy-to-train, simple-to-implement but\nsubstantially more expressive architectural alternative to the standard\nmulti-layer LSTM ubiquitously used for RL agents in partially observable\nenvironments."}, {"title": "An Explicitly Relational Neural Network Architecture", "authors": "Murray Shanahan, Kyriacos Nikiforou, Antoina Creswell, Christos Kaplanis, David GT Barrett, Marta Garnelo ", "link": "https://arxiv.org/abs/1905.10307", "summary": "With a view to bridging the gap between deep learning and symbolic AI, we\npresent a novel end-to-end neural network architecture that learns to form\npropositional representations with an explicitly relational structure from raw\npixel data. In order to evaluate and analyse the architecture, we introduce a\nfamily of simple visual relational reasoning tasks of varying complexity. We\nshow that the proposed architecture, when pre-trained on a curriculum of such\ntasks, learns to generate reusable representations that better facilitate\nsubsequent learning on previously unseen tasks when compared to a number of\nbaseline architectures. The workings of a successfully trained model are\nvisualised to shed some light on how the architecture functions."}, {"title": "Harmonic Decompositions of Convolutional Networks", "authors": "Meyer Scetbon, Zaid Harchaoui ", "link": "https://arxiv.org/abs/2003.12756", "summary": "We consider convolutional networks from a reproducing kernel Hilbert space\nviewpoint. We establish harmonic decompositions of convolutional networks, that\nis expansions into sums of elementary functions of increasing order. The\nelementary functions are related to the spherical harmonics, a fundamental\nclass of special functions on spheres. The harmonic decompositions allow us to\ncharacterize the integral operators associated with convolutional networks, and\nobtain as a result statistical bounds for convolutional networks."}, {"title": "Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions", "authors": "Ahmed Alaa, M van der Schaar "}, {"title": "Robust Graph Representation Learning via Neural Sparsification", "authors": "Cheng Zheng, Bo Zong, Wei Cheng, Dongjin  Song, Jingchao Ni, Wenchao Yu, Haifeng Chen, Wei Wang "}, {"title": "Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees", "authors": "Sen Na, Yuwei Luo, Zhuoran Yang, Zhaoran Wang, Mladen Kolar ", "link": "https://arxiv.org/abs/2003.01013", "summary": "Graph representation learning is a ubiquitous task in machine learning where\nthe goal is to embed each vertex into a low-dimensional vector space. We\nconsider the bipartite graph and formalize its representation learning problem\nas a statistical estimation problem of parameters in a semiparametric\nexponential family distribution. The bipartite graph is assumed to be generated\nby a semiparametric exponential family distribution, whose parametric component\nis given by the proximity of outputs of two one-layer neural networks, while\nnonparametric (nuisance) component is the base measure. Neural networks take\nhigh-dimensional features as inputs and output embedding vectors. In this\nsetting, the representation learning problem is equivalent to recovering the\nweight matrices. The main challenges of estimation arise from the nonlinearity\nof activation functions and the nonparametric nuisance component of the\ndistribution. To overcome these challenges, we propose a pseudo-likelihood\nobjective based on the rank-order decomposition technique and focus on its\nlocal geometry. We show that the proposed objective is strongly convex in a\nneighborhood around the ground truth, so that a gradient descent-based method\nachieves linear convergence rate. Moreover, we prove that the sample complexity\nof the problem is linear in dimensions (up to logarithmic factors), which is\nconsistent with parametric Gaussian models. However, our estimator is robust to\nany model misspecification within the exponential family, which is validated in\nextensive experiments."}, {"title": "Forecasting sequential data using Consistent Koopman Autoencoders", "authors": "Omri Azencot, N. Benjamin Erichson, Vanessa Lin, Michael Mahoney ", "link": "https://arxiv.org/abs/2003.02236", "summary": "Recurrent neural networks are widely used on time series data, yet such\nmodels often ignore the underlying physical structures in such sequences. A new\nclass of physically-based methods related to Koopman theory has been\nintroduced, offering an alternative for processing nonlinear dynamical systems.\nIn this work, we propose a novel Consistent Koopman Autoencoder model which,\nunlike the majority of existing work, leverages the forward and backward\ndynamics. Key to our approach is a new analysis that unravels the interplay\nbetween consistent dynamics and their associated Koopman operators. Our network\nis interpretable from a physical viewpoint and its computational requirements\nare comparable to other baselines. We evaluate our method on a wide range of\nhigh-dimensional and short-term dependent problems. The datasets include\nnonlinear oscillators, sea surface temperature data, and fluid flows on a\ncurved domain. The results show that our model yields accurate estimates for\nsignificant prediction horizons, while being robust to noise."}, {"title": "Scalable Identification of Partially Observed Systems with Certainty-Equivalent EM", "authors": "Kunal Menda, Jean de Becdelievre, Jayesh Gupta, Ilan Kroo, Mykel Kochenderfer, Zachary Manchester "}, {"title": "Learning to Score Behaviors for Guided Policy Optimization", "authors": "Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, Krzysztof Choromanski, Anna Choromanska, Michael Jordan ", "link": "http://arxiv.org/abs/1906.04349", "summary": "We introduce a new approach for comparing reinforcement learning policies,\nusing Wasserstein distances (WDs) in a newly defined latent behavioral space.\nWe show that by utilizing the dual formulation of the WD, we can learn score\nfunctions over policy behaviors that can in turn be used to lead policy\noptimization towards (or away from) (un)desired behaviors. Combined with\nsmoothed WDs, the dual formulation allows us to devise efficient algorithms\nthat take stochastic gradient descent steps through WD regularizers. We\nincorporate these regularizers into two novel on-policy algorithms,\nBehavior-Guided Policy Gradient and Behavior-Guided Evolution Strategies, which\nwe demonstrate can outperform existing methods in a variety of challenging\nenvironments. We also provide an open source demo."}, {"title": "Improved Communication Cost in Distributed PageRank Computation \u2013 A Theoretical Study", "authors": "Siqiang Luo "}, {"title": "Learning Autoencoders with Relational Regularization", "authors": "Hongteng Xu, Dixin Luo, Ricardo Henao, Svati Shah, Lawrence Carin ", "link": "https://arxiv.org/abs/2002.02913", "summary": "A new algorithmic framework is proposed for learning autoencoders of data\ndistributions. We minimize the discrepancy between the model and target\ndistributions, with a \\emph{relational regularization} on the learnable latent\nprior. This regularization penalizes the fused Gromov-Wasserstein (FGW)\ndistance between the latent prior and its corresponding posterior, allowing one\nto flexibly learn a structured prior distribution associated with the\ngenerative model. Moreover, it helps co-training of multiple autoencoders even\nif they have heterogeneous architectures and incomparable latent spaces. We\nimplement the framework with two scalable algorithms, making it applicable for\nboth probabilistic and deterministic autoencoders. Our relational regularized\nautoencoder (RAE) outperforms existing methods, $e.g.$, the variational\nautoencoder, Wasserstein autoencoder, and their variants, on generating images.\nAdditionally, our relational co-training strategy for autoencoders achieves\nencouraging results in both synthesis and real-world multi-view learning tasks."}, {"title": "Neural Contextual Bandits with UCB-based Exploration", "authors": "Dongruo Zhou, Lihong Li, Quanquan Gu ", "link": "https://arxiv.org/abs/1911.04462", "summary": "We study the stochastic contextual bandit problem, where the reward is\ngenerated from an unknown function with additive noise. No assumption is made\nabout the reward function other than boundedness. We propose a new algorithm,\nNeuralUCB, which leverages the representation power of deep neural networks and\nuses a neural network-based random feature mapping to construct an upper\nconfidence bound (UCB) of reward for efficient exploration. We prove that,\nunder standard assumptions, NeuralUCB achieves $\\tilde O(\\sqrt{T})$ regret,\nwhere $T$ is the number of rounds. To the best of our knowledge, it is the\nfirst neural network-based contextual bandit algorithm with a near-optimal\nregret guarantee. We also show the algorithm is empirically competitive against\nrepresentative baselines in a number of benchmarks."}, {"title": "Super-efficiency of automatic differentiation for functions defined as a minimum", "authors": "Pierre Ablin, Gabriel Peyr\u00e9, Thomas Moreau ", "link": "https://arxiv.org/abs/2002.03722", "summary": "In min-min optimization or max-min optimization, one has to compute the\ngradient of a function defined as a minimum. In most cases, the minimum has no\nclosed-form, and an approximation is obtained via an iterative algorithm. There\nare two usual ways of estimating the gradient of the function: using either an\nanalytic formula obtained by assuming exactness of the approximation, or\nautomatic differentiation through the algorithm. In this paper, we study the\nasymptotic error made by these estimators as a function of the optimization\nerror. We find that the error of the automatic estimator is close to the square\nof the error of the analytic estimator, reflecting a super-efficiency\nphenomenon. The convergence of the automatic estimator greatly depends on the\nconvergence of the Jacobian of the algorithm. We analyze it for gradient\ndescent and stochastic gradient descent and derive convergence rates for the\nestimators in these cases. Our analysis is backed by numerical experiments on\ntoy problems and on Wasserstein barycenter computation. Finally, we discuss the\ncomputational complexity of these estimators and give practical guidelines to\nchose between them."}, {"title": "Rethinking Batch Normalization in Transformers", "authors": "Sheng Shen, Zhewei Yao, Amir Gholaminejad, Michael Mahoney, Kurt Keutzer ", "link": "https://arxiv.org/abs/2003.07845", "summary": "The standard normalization method for neural network (NN) models used in\nNatural Language Processing (NLP) is layer normalization (LN). This is\ndifferent than batch normalization (BN), which is widely-adopted in Computer\nVision. The preferred use of LN in NLP is principally due to the empirical\nobservation that a (naive/vanilla) use of BN leads to significant performance\ndegradation for NLP tasks; however, a thorough understanding of the underlying\nreasons for this is not always evident. In this paper, we perform a systematic\nstudy of NLP transformer models to understand why BN has a poor performance, as\ncompared to LN. We find that the statistics of NLP data across the batch\ndimension exhibit large fluctuations throughout training. This results in\ninstability, if BN is naively implemented. To address this, we propose Power\nNormalization (PN), a novel normalization scheme that resolves this issue by\n(i) relaxing zero-mean normalization in BN, (ii) incorporating a running\nquadratic mean instead of per batch statistics to stabilize fluctuations, and\n(iii) using an approximate backpropagation for incorporating the running\nstatistics in the forward pass. We show theoretically, under mild assumptions,\nthat PN leads to a smaller Lipschitz constant for the loss, compared with BN.\nFurthermore, we prove that the approximate backpropagation scheme leads to\nbounded gradients. We extensively test PN for transformers on a range of NLP\ntasks, and we show that it significantly outperforms both LN and BN. In\nparticular, PN outperforms LN by 0.4/0.6 BLEU on IWSLT14/WMT14 and 5.6/3.0 PPL\non PTB/WikiText-103."}, {"title": "Invertible generative models for inverse problems: mitigating representation error and dataset bias", "authors": "Muhammad Asim, Max Daniels, Oscar Leong, Paul Hand, Ali Ahmed ", "link": "https://arxiv.org/abs/1905.11672", "summary": "Trained generative models have shown remarkable performance as priors for\ninverse problems in imaging. For example, Generative Adversarial Network priors\npermit recovery of test images from 5-10x fewer measurements than sparsity\npriors. Unfortunately, these models may be unable to represent any particular\nimage because of architectural choices, mode collapse, and bias in the training\ndataset. In this paper, we demonstrate that invertible neural networks, which\nhave zero representation error by design, can be effective natural signal\npriors at inverse problems such as denoising, compressive sensing, and\ninpainting. Our formulation is an empirical risk minimization that does not\ndirectly optimize the likelihood of images, as one would expect. Instead we\noptimize the likelihood of the latent representation of images as a proxy, as\nthis is empirically easier. For compressive sensing, our formulation can yield\nhigher accuracy than sparsity priors across almost all undersampling ratios.\nFor the same accuracy on test images, they can use 10-20x fewer measurements.\nWe demonstrate that invertible priors can yield better reconstructions than\nsparsity priors for images that have rare features of variation within the\nbiased training set, including out-of-distribution natural images."}, {"title": "Acceleration for Compressed Gradient Descent in Distributed Optimization", "authors": "Zhize Li, Dmitry Kovalev, Xun Qian, Peter Richtarik ", "link": "https://arxiv.org/abs/2002.11364", "summary": "Due to the high communication cost in distributed and federated learning\nproblems, methods relying on compression of communicated messages are becoming\nincreasingly popular. While in other contexts the best performing gradient-type\nmethods invariably rely on some form of acceleration/momentum to reduce the\nnumber of iterations, there are no methods which combine the benefits of both\ngradient compression and acceleration. In this paper, we remedy this situation\nand propose the first accelerated compressed gradient descent (ACGD) methods.\nIn the single machine regime, we prove that ACGD enjoys the rate\n$O\\left((1+\\omega)\\sqrt{\\frac{L}{\\mu}}\\log \\frac{1}{\\epsilon}\\right)$ for\n$\\mu$-strongly convex problems and\n$O\\left((1+\\omega)\\sqrt{\\frac{L}{\\epsilon}}\\right)$ for convex problems,\nrespectively, where $L$ is the smoothness constant and $\\omega$ is the\ncompression parameter. Our results improve upon the existing non-accelerated\nrates $O\\left((1+\\omega)\\frac{L}{\\mu}\\log \\frac{1}{\\epsilon}\\right)$ and\n$O\\left((1+\\omega)\\frac{L}{\\epsilon}\\right)$, respectively, and recover the\noptimal rates of accelerated gradient descent as a special case when no\ncompression ($\\omega=0$) is applied. We further propose a distributed variant\nof ACGD (called ADIANA) and prove the convergence rate\n$\\widetilde{O}\\left(\\omega+\\sqrt{\\frac{L}{\\mu}}\n+\\sqrt{\\left(\\frac{\\omega}{n}+\\sqrt{\\frac{\\omega}{n}}\\right)\\frac{\\omega\nL}{\\mu}}\\right)$, where $n$ is the number of devices/workers and\n$\\widetilde{O}$ hides the logarithmic factor $\\log \\frac{1}{\\epsilon}$. This\nimproves upon the previous best result $\\widetilde{O}\\left(\\omega +\n\\frac{L}{\\mu}+\\frac{\\omega L}{n\\mu} \\right)$ achieved by the DIANA method of\nMishchenko et al (2019). Finally, we conduct several experiments on real-world\ndatasets which corroborate our theoretical results and confirm the practical\nsuperiority of our methods."}, {"title": "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization Formulations for Two-Layer Networks", "authors": "Mert Pilanci, Tolga Ergen ", "link": "https://arxiv.org/abs/2002.10553", "summary": "We develop exact representations of two layer neural networks with rectified\nlinear units in terms of a single convex program with number of variables\npolynomial in the number of training samples and number of hidden neurons. Our\ntheory utilizes semi-infinite duality and minimum norm regularization.\nMoreover, we show that certain standard multi-layer convolutional neural\nnetworks are equivalent to L1 regularized linear models in a polynomial sized\ndiscrete Fourier feature space. We also introduce exact semi-definite\nprogramming representations of convolutional and fully connected linear\nmulti-layer networks which are polynomial size in both the sample size and\ndimension."}, {"title": "Learning Quadratic Games on Networks", "authors": "Yan Leng, Xiaowen Dong, Junfeng Wu, Alex `Sandy' Pentland ", "link": "https://arxiv.org/abs/1811.08790", "summary": "Individuals, or organizations, cooperate with or compete against one another\nin a wide range of practical situations. In the economics literature, such\nstrategic interactions are often modeled as games played on networks, where an\nindividual's payoff depends not only on her action but also that of her\nneighbors. The current literature has largely focused on analyzing the\ncharacteristics of network games in the scenario where the structure of the\nnetwork, which is represented by a graph, is known beforehand. It is often the\ncase, however, that the actions of the players are readily observable while the\nunderlying interaction network remains hidden. In this paper, we propose two\nnovel frameworks for learning, from the observations on individual actions,\nnetwork games with linear-quadratic payoffs, and in particular the structure of\nthe interaction network. Our frameworks are based on the Nash equilibrium of\nsuch games and involve solving a joint optimization problem for the graph\nstructure and the individual marginal benefits. We test the proposed frameworks\nin synthetic settings and further study several factors that affect their\nlearning performance. Moreover, with experiments on three real world examples,\nwe show that our methods can effectively and more accurately learn the games\nthan the baselines. The proposed approach is among the first of its kind for\nlearning quadratic games, and have both theoretical and practical implications\nfor understanding strategic interactions in a network environment."}, {"title": "Margin-aware Adversarial Domain Adaptation with Optimal Transport", "authors": "Sofien Dhouib, Ievgen Redko, Carole Lartizien "}, {"title": "The Sample Complexity of Best-$k$ Items Selection from Pairwise Comparisons", "authors": "Wenbo Ren, Jia Liu, Ness Shroff ", "link": "", "summary": ""}, {"title": "GraphOpt: Learning Optimization Models of Graph Formation", "authors": "Rakshit Trivedi, Jiachen Yang, Hongyuan Zha "}, {"title": "Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits", "authors": "Nian Si, Fan Zhang, Zhengyuan Zhou, Jose Blanchet "}, {"title": "Incremental Sampling Without Replacement for Sequence Models", "authors": "Kensen Shi, David Bieber, Charles Sutton ", "link": "https://arxiv.org/abs/2002.09067", "summary": "Sampling is a fundamental technique, and sampling without replacement is\noften desirable when duplicate samples are not beneficial. Within machine\nlearning, sampling is useful for generating diverse outputs from a trained\nmodel. We present an elegant procedure for sampling without replacement from a\nbroad class of randomized programs, including generative neural models that\nconstruct outputs sequentially. Our procedure is efficient even for\nexponentially-large output spaces. Unlike prior work, our approach is\nincremental, i.e., samples can be drawn one at a time, allowing for increased\nflexibility. We also present a new estimator for computing expectations from\nsamples drawn without replacement. We show that incremental sampling without\nreplacement is applicable to many domains, e.g., program synthesis and\ncombinatorial optimization."}, {"title": "Variable Skipping for Autoregressive Range Density Estimation", "authors": "Eric Liang, Zongheng Yang, Ion Stoica, Pieter Abbeel, Yan Duan, Peter Chen ", "link": "", "summary": ""}, {"title": "TaskNorm: Rethinking Batch Normalization for Meta-Learning", "authors": "John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, Richard E Turner ", "link": "https://arxiv.org/abs/2003.03284", "summary": "Modern meta-learning approaches for image classification rely on increasingly\ndeep networks to achieve state-of-the-art performance, making batch\nnormalization an essential component of meta-learning pipelines. However, the\nhierarchical nature of the meta-learning setting presents several challenges\nthat can render conventional batch normalization ineffective, giving rise to\nthe need to rethink normalization in this setting. We evaluate a range of\napproaches to batch normalization for meta-learning scenarios, and develop a\nnovel approach that we call TaskNorm. Experiments on fourteen datasets\ndemonstrate that the choice of batch normalization has a dramatic effect on\nboth classification accuracy and training time for both gradient based and\ngradient-free meta-learning approaches. Importantly, TaskNorm is found to\nconsistently improve performance. Finally, we provide a set of best practices\nfor normalization that will allow fair comparison of meta-learning algorithms."}, {"title": "Scalable Gaussian Process Regression for Kernels with a Non-Stationary Phase", "authors": "Jan Gra\u00dfhoff, Alexandra Jankowski, Philipp Rostalski ", "link": "https://arxiv.org/abs/1912.11713", "summary": "The application of Gaussian processes (GPs) to large data sets is limited due\nto heavy memory and computational requirements. A variety of methods has been\nproposed to enable scalability, one of which is to exploit structure in the\nkernel matrix. Previous methods, however, cannot easily deal with\nnon-stationary processes. This paper presents an efficient GP framework, that\nextends structured kernel interpolation methods to GPs with a non-stationary\nphase. We particularly treat mixtures of non-stationary processes, which are\ncommonly used in the context of separation problems e.g. in biomedical signal\nprocessing. Our approach employs multiple sets of non-equidistant inducing\npoints to account for the non-stationarity and retrieve Toeplitz and Kronecker\nstructure in the kernel matrix allowing for efficient inference. Kernel\nlearning is done by optimizing the marginal likelihood, which can be\napproximated efficiently using stochastic trace estimation methods. Our\napproach is demonstrated on numerical examples and large biomedical datasets."}, {"title": "Transformer Hawkes Process", "authors": "Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha ", "link": "https://arxiv.org/abs/2002.09291", "summary": "Modern data acquisition routinely produce massive amounts of event sequence\ndata in various domains, such as social media, healthcare, and financial\nmarkets. These data often exhibit complicated short-term and long-term temporal\ndependencies. However, most of the existing recurrent neural network-based\npoint process models fail to capture such dependencies, and yield unreliable\nprediction performance. To address this issue, we propose a Transformer Hawkes\nProcess (THP) model, which leverages the self-attention mechanism to capture\nlong-term dependencies and meanwhile enjoys computational efficiency. Numerical\nexperiments on various datasets show that THP outperforms existing models in\nterms of both likelihood and event prediction accuracy by a notable margin.\nMoreover, THP is quite general and can incorporate additional structural\nknowledge. We provide a concrete example, where THP achieves improved\nprediction performance for learning multiple point processes when incorporating\ntheir relational information."}, {"title": "An EM Approach to Non-autoregressive Conditional Sequence Generation", "authors": "Zhiqing Sun, Yiming Yang "}, {"title": "Variance Reduction in Stochastic Particle-Optimization Sampling", "authors": "Jianyi Zhang, Yang Zhao, Changyou Chen ", "link": "https://arxiv.org/abs/1811.08052", "summary": "Stochastic particle-optimization sampling (SPOS) is a recently-developed\nscalable Bayesian sampling framework that unifies stochastic gradient MCMC\n(SG-MCMC) and Stein variational gradient descent (SVGD) algorithms based on\nWasserstein gradient flows. With a rigorous non-asymptotic convergence theory\ndeveloped recently, SPOS avoids the particle-collapsing pitfall of SVGD.\nNevertheless, variance reduction in SPOS has never been studied. In this paper,\nwe bridge the gap by presenting several variance-reduction techniques for SPOS.\nSpecifically, we propose three variants of variance-reduced SPOS, called SAGA\nparticle-optimization sampling (SAGA-POS), SVRG particle-optimization sampling\n(SVRG-POS) and a variant of SVRG-POS which avoids full gradient computations,\ndenoted as SVRG-POS$^+$. Importantly, we provide non-asymptotic convergence\nguarantees for these algorithms in terms of 2-Wasserstein metric and analyze\ntheir complexities. Remarkably, the results show our algorithms yield better\nconvergence rates than existing variance-reduced variants of stochastic\nLangevin dynamics, even though more space is required to store the particles in\ntraining. Our theory well aligns with experimental results on both synthetic\nand real datasets."}, {"title": "CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information", "authors": "Pengyu Cheng, Weituo Hao, Shuyang Dai, Jiachang Liu, Zhe Gan, Lawrence Carin "}, {"title": "State Space Expectation Propagation: Efficient Inference Schemes for Temporal Gaussian Processes", "authors": "William Wilkinson, Paul Chang, Michael Andersen, Arno Solin "}, {"title": "Training Neural Networks for and by Interpolation", "authors": "Leonard Berrada, M. Pawan Kumar, Andrew Zisserman ", "link": "https://arxiv.org/abs/1906.05661", "summary": "The majority of modern deep learning models are able to interpolate the data:\nthe empirical loss can be driven near zero on all samples simultaneously. In\nthis work, we explicitly exploit this interpolation property for the design of\na new optimization algorithm for deep learning. Specifically, we use it to\ncompute an adaptive learning-rate given a stochastic gradient direction. This\nresults in the Adaptive Learning-rates for Interpolation with Gradients (ALI-G)\nalgorithm. ALI-G retains the advantages of SGD, which are low computational\ncost and provable convergence in the convex setting. But unlike SGD, the\nlearning-rate of ALI-G can be computed inexpensively in closed-form and does\nnot require a manual schedule. We provide a detailed analysis of ALI-G in the\nstochastic convex setting with explicit convergence rates. In order to obtain\ngood empirical performance in deep learning, we extend the algorithm to use a\nmaximal learning-rate, which gives a single hyper-parameter to tune. We show\nthat employing such a maximal learning-rate has an intuitive proximal\ninterpretation and preserves all convergence guarantees. We provide experiments\non a variety of architectures and tasks: (i) learning a differentiable neural\ncomputer; (ii) training a wide residual network on the SVHN data set; (iii)\ntraining a Bi-LSTM on the SNLI data set; and (iv) training wide residual\nnetworks and densely connected networks on the CIFAR data sets. We empirically\nshow that ALI-G outperforms adaptive gradient methods such as Adam, and\nprovides comparable performance with SGD, although SGD benefits from manual\nlearning rate schedules. We release PyTorch and Tensorflow implementations of\nALI-G as standalone optimizers that can be used as a drop-in replacement in\nexisting code (code available at https://github.com/oval-group/ali-g )."}, {"title": "Learning Representations that Support Extrapolation", "authors": "Taylor Webb, Zachary Dulberg, Steven M Frankland, Alexander Petrov, Randall O'Reilly, Jonathan Cohen "}, {"title": " Topic Modeling via Full Dependence Mixtures", "authors": "Dan  Fisher, Mark Kozdoba, Shie Mannor ", "link": "https://arxiv.org/abs/1906.06181", "summary": "In this paper we introduce a new approach to topic modelling that scales to\nlarge datasets by using a compact representation of the data and by leveraging\nthe GPU architecture. In this approach, topics are learned directly from the\nco-occurrence data of the corpus. In particular, we introduce a novel mixture\nmodel which we term the Full Dependence Mixture (FDM) model. FDMs model second\nmoment under general generative assumptions on the data. While there is\nprevious work on topic modeling using second moments, we develop a direct\nstochastic optimization procedure for fitting an FDM with a single Kullback\nLeibler objective. Moment methods in general have the benefit that an iteration\nno longer needs to scale with the size of the corpus. Our approach allows us to\nleverage standard optimizers and GPUs for the problem of topic modeling. In\nparticular, we evaluate the approach on two large datasets, NeurIPS papers and\na Twitter corpus, with a large number of topics, and show that the approach\nperforms comparably or better than the the standard benchmarks."}, {"title": "Instance-hiding Schemes for Private Distributed Learning", "authors": "Yangsibo Huang, Zhao Song, Sanjeev Arora, Kai Li "}, {"title": "The Implicit Regularization of Stochastic Gradient Flow for Least Squares", "authors": "Alnur Ali, Edgar Dobriban, Ryan Tibshirani ", "link": "http://arxiv.org/abs/2003.07802", "summary": "We study the implicit regularization of mini-batch stochastic gradient\ndescent, when applied to the fundamental problem of least squares regression.\nWe leverage a continuous-time stochastic differential equation having the same\nmoments as stochastic gradient descent, which we call stochastic gradient flow.\nWe give a bound on the excess risk of stochastic gradient flow at time $t$,\nover ridge regression with tuning parameter $\\lambda = 1/t$. The bound may be\ncomputed from explicit constants (e.g., the mini-batch size, step size, number\nof iterations), revealing precisely how these quantities drive the excess risk.\nNumerical examples show the bound can be small, indicating a tight relationship\nbetween the two estimators. We give a similar result relating the coefficients\nof stochastic gradient flow and ridge. These results hold under no conditions\non the data matrix $X$, and across the entire optimization path (not just at\nconvergence)."}, {"title": "Decentralised Learning with Random Features and Distributed Gradient Descent", "authors": "Dominic Richards, Patrick Rebeschini, Lorenzo Rosasco "}, {"title": "Hierarchical Generation of Molecular Graphs using Structural Motifs", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola ", "link": "https://arxiv.org/abs/2002.03230", "summary": "Graph generation techniques are increasingly being adopted for drug\ndiscovery. Previous graph generation approaches have utilized relatively small\nmolecular building blocks such as atoms or simple cycles, limiting their\neffectiveness to smaller molecules. Indeed, as we demonstrate, their\nperformance degrades significantly for larger molecules. In this paper, we\npropose a new hierarchical graph encoder-decoder that employs significantly\nlarger and more flexible graph motifs as basic building blocks. Our encoder\nproduces a multi-resolution representation for each molecule in a\nfine-to-coarse fashion, from atoms to connected motifs. Each level integrates\nthe encoding of constituents below with the graph at that level. Our\nautoregressive coarse-to-fine decoder adds one motif at a time, interleaving\nthe decision of selecting a new motif with the process of resolving its\nattachments to the emerging molecule. We evaluate our model on multiple\nmolecule generation tasks, including polymers, and show that our model\nsignificantly outperforms previous state-of-the-art baselines."}, {"title": "Composing Molecules with Multiple Property Constraints", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola ", "link": "", "summary": ""}, {"title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "authors": "Elisa Celis, Vijay Keswani, Nisheeth Vishnoi "}, {"title": "On Efficient Low Distortion Ultrametric Embedding", "authors": "Vincent Cohen-Addad, Karthik C. S., Guillaume Lagarde "}, {"title": "Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models", "authors": "Yiding Feng, Ekaterina Khmelnitskaya, Denis Nekipelov "}, {"title": "Efficient Policy Learning from Surrogate-Loss Classification Reductions", "authors": "Andrew Bennett, Nathan Kallus ", "link": "https://arxiv.org/abs/2002.05153", "summary": "Recent work on policy learning from observational data has highlighted the\nimportance of efficient policy evaluation and has proposed reductions to\nweighted (cost-sensitive) classification. But, efficient policy evaluation need\nnot yield efficient estimation of policy parameters. We consider the estimation\nproblem given by a weighted surrogate-loss classification reduction of policy\nlearning with any score function, either direct, inverse-propensity weighted,\nor doubly robust. We show that, under a correct specification assumption, the\nweighted classification formulation need not be efficient for policy\nparameters. We draw a contrast to actual (possibly weighted) binary\nclassification, where correct specification implies a parametric model, while\nfor policy learning it only implies a semiparametric model. In light of this,\nwe instead propose an estimation approach based on generalized method of\nmoments, which is efficient for the policy parameters. We propose a particular\nmethod based on recent developments on solving moment problems using neural\nnetworks and demonstrate the efficiency and regret benefits of this method\nempirically."}, {"title": "On Contrastive Learning for Likelihood-free Inference ", "authors": "Conor Durkan, Iain Murray, George Papamakarios ", "link": "https://arxiv.org/abs/2002.03712", "summary": "Likelihood-free methods perform parameter inference in stochastic simulator\nmodels where evaluating the likelihood is intractable but sampling synthetic\ndata is possible. One class of methods for this likelihood-free problem uses a\nclassifier to distinguish between pairs of parameter-observation samples\ngenerated using the simulator and pairs sampled from some reference\ndistribution, which implicitly learns a density ratio proportional to the\nlikelihood. Another popular class of methods fits a conditional distribution to\nthe parameter posterior directly, and a particular recent variant allows for\nthe use of flexible neural density estimators for this task. In this work, we\nshow that both of these approaches can be unified under a general contrastive\nlearning scheme, and clarify how they should be run and compared."}, {"title": "Obtaining Adjustable Regularization for Free via Iterate Averaging", "authors": "Jingfeng Wu, Vladimir Braverman, Lin Yang "}, {"title": "Invariant Risk Minimization Games", "authors": "Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, Amit Dhurandhar ", "link": "https://arxiv.org/abs/2002.04692", "summary": "The standard risk minimization paradigm of machine learning is brittle when\noperating in environments whose test distributions are different from the\ntraining distribution due to spurious correlations. Training on data from many\nenvironments and finding invariant predictors reduces the effect of spurious\nfeatures by concentrating models on features that have a causal relationship\nwith the outcome. In this work, we pose such invariant risk minimization as\nfinding the Nash equilibrium of an ensemble game among several environments. By\ndoing so, we develop a simple training algorithm that uses best response\ndynamics and, in our experiments, yields similar or better empirical accuracy\nwith much lower variance than the challenging bi-level optimization problem of\nArjovsky et al. (2019). One key theoretical contribution is showing that the\nset of Nash equilibria for the proposed game are equivalent to the set of\ninvariant predictors for any finite number of environments, even with nonlinear\nclassifiers and transformations. As a result, our method also retains the\ngeneralization guarantees to a large set of environments shown in Arjovsky et\nal. (2019). The proposed algorithm adds to the collection of successful\ngame-theoretic machine learning algorithms such as generative adversarial\nnetworks."}, {"title": "Video Prediction via Example Guidance", "authors": "Jingwei Xu, Harry  Xu, Bingbing Ni, Xiaokang Yang, Trevor Darrell "}, {"title": "Learning Discrete Structured Representations by Adversarially Maximizing Mutual Information", "authors": "Karl Stratos, Sam Wiseman ", "link": "http://arxiv.org/abs/2004.03991", "summary": "We propose learning discrete structured representations from unlabeled data\nby maximizing the mutual information between a structured latent variable and a\ntarget variable. Calculating mutual information is intractable in this setting.\nOur key technical contribution is an adversarial objective that can be used to\ntractably estimate mutual information assuming only the feasibility of cross\nentropy calculation. We develop a concrete realization of this general\nformulation with Markov distributions over binary encodings. We report critical\nand unexpected findings on practical aspects of the objective such as the\nchoice of variational priors. We apply our model on document hashing and show\nthat it outperforms current best baselines based on discrete and vector\nquantized variational autoencoders. It also yields highly compressed\ninterpretable representations."}, {"title": "Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound", "authors": "Lin Yang, Mengdi Wang ", "link": "https://arxiv.org/abs/1905.10389", "summary": "Exploration in reinforcement learning (RL) suffers from the curse of\ndimensionality when the state-action space is large. A common practice is to\nparameterize the high-dimensional value and policy functions using given\nfeatures. However existing methods either have no theoretical guarantee or\nsuffer a regret that is exponential in the planning horizon $H$. In this paper,\nwe propose an online RL algorithm, namely the MatrixRL, that leverages ideas\nfrom linear bandit to learn a low-dimensional representation of the probability\ntransition model while carefully balancing the exploitation-exploration\ntradeoff. We show that MatrixRL achieves a regret bound ${O}\\big(H^2d\\log\nT\\sqrt{T}\\big)$ where $d$ is the number of features. MatrixRL has an equivalent\nkernelized version, which is able to work with an arbitrary kernel Hilbert\nspace without using explicit features. In this case, the kernelized MatrixRL\nsatisfies a regret bound ${O}\\big(H^2\\widetilde{d}\\log T\\sqrt{T}\\big)$, where\n$\\widetilde{d}$ is the effective dimension of the kernel space. To our best\nknowledge, for RL using features or kernels, our results are the first regret\nbounds that are near-optimal in time $T$ and dimension $d$ (or $\\widetilde{d}$)\nand polynomial in the planning horizon $H$."}, {"title": "Frequency Bias in Neural Networks for Input of Non-Uniform Density", "authors": "Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten, Shira Kritchman ", "link": "https://arxiv.org/abs/2003.04560", "summary": "Recent works have partly attributed the generalization ability of\nover-parameterized neural networks to frequency bias -- networks trained with\ngradient descent on data drawn from a uniform distribution find a low frequency\nfit before high frequency ones. As realistic training sets are not drawn from a\nuniform distribution, we here use the Neural Tangent Kernel (NTK) model to\nexplore the effect of variable density on training dynamics. Our results, which\ncombine analytic and empirical observations, show that when learning a pure\nharmonic function of frequency $\\kappa$, convergence at a point $\\x \\in\n\\Sphere^{d-1}$ occurs in time $O(\\kappa^d/p(\\x))$ where $p(\\x)$ denotes the\nlocal density at $\\x$. Specifically, for data in $\\Sphere^1$ we analytically\nderive the eigenfunctions of the kernel associated with the NTK for two-layer\nnetworks. We further prove convergence results for deep, fully connected\nnetworks with respect to the spectral decomposition of the NTK. Our empirical\nstudy highlights similarities and differences between deep and shallow networks\nin this model."}, {"title": "Constrained Markov Decision Processes via Backward Value Functions", "authors": "harsh satija, Philip Amortila, Joelle Pineau "}, {"title": "Adding seemingly uninformative labels helps in low data regimes", "authors": "Christos Matsoukas, Albert Bou Hernandez, Yue Liu, Karin Dembrower, Gisele Miranda, Emir Konuk, Johan Fredin Haslum, Athanasios Zouzos, Peter Lindholm, Fredrik Strand, Kevin Smith "}, {"title": "When are Non-Parametric Methods Robust?", "authors": "Robi Bhattacharjee, Kamalika Chaudhuri ", "link": "https://arxiv.org/abs/2003.06121", "summary": "A growing body of research has shown that many classifiers are susceptible to\n{\\em{adversarial examples}} -- small strategic modifications to test inputs\nthat lead to misclassification. In this work, we study general non-parametric\nmethods, with a view towards understanding when they are robust to these\nmodifications. We establish general conditions under which non-parametric\nmethods are r-consistent -- in the sense that they converge to optimally robust\nand accurate classifiers in the large sample limit.\n  Concretely, our results show that when data is well-separated, nearest\nneighbors and kernel classifiers are r-consistent, while histograms are not.\nFor general data distributions, we prove that preprocessing by Adversarial\nPruning (Yang et. al., 2019) -- that makes data well-separated -- followed by\nnearest neighbors or kernel classifiers also leads to r-consistency."}, {"title": "Learning Calibratable Policies using Programmatic Style-Consistency", "authors": "Eric Zhan, Albert Tseng, Yisong Yue, Adith Swaminathan, Matthew Hausknecht ", "link": "https://arxiv.org/abs/1910.01179", "summary": "We study the problem of controllable generation of long-term sequential\nbehaviors. Solutions to this important problem would enable many applications,\nsuch as calibrating behaviors of AI agents in games or predicting player\ntrajectories in sports. In contrast to the well-studied areas of controllable\ngeneration of images, text, and speech, there are two questions that pose\nsignificant challenges when generating long-term behaviors: how should we\nspecify the factors of variation to control, and how can we ensure that the\ngenerated temporal behavior faithfully demonstrates diverse styles? In this\npaper, we leverage large amounts of raw behavioral data to learn policies that\ncan be calibrated to generate a diverse range of behavior styles (e.g.,\naggressive versus passive play in sports). Inspired by recent work on\nleveraging programmatic labeling functions, we present a novel framework that\ncombines imitation learning with data programming to learn style-calibratable\npolicies. Our primary technical contribution is a formal notion of\nstyle-consistency as a learning objective, and its integration with\nconventional imitation learning approaches. We evaluate our framework using\ndemonstrations from professional basketball players and agents in the MuJoCo\nphysics environment, and show that our learned policies can be calibrated to\ngenerate interesting behavior styles in both domains."}, {"title": "Momentum Improves Normalized SGD", "authors": "Ashok Cutkosky, Harsh Mehta ", "link": "https://arxiv.org/abs/2002.03305", "summary": "We provide an improved analysis of normalized SGD showing that adding\nmomentum provably removes the need for large batch sizes on non-convex\nobjectives. Then, we consider the case of objectives with bounded second\nderivative and show that in this case a small tweak to the momentum formula\nallows normalized SGD with momentum to find an $\\epsilon$-critical point in\n$O(1/\\epsilon^{3.5})$ iterations, matching the best-known rates without\naccruing any logarithmic factors or dependence on dimension. We also provide an\nadaptive method that automatically improves convergence rates when the variance\nin the gradients is small. Finally, we show that our method is effective when\nemployed on popular large scale tasks such as ResNet-50 and BERT pretraining,\nmatching the performance of the disparate methods used to get state-of-the-art\nresults on both tasks."}, {"title": "Parameter-free, Dynamic, and Strongly-Adaptive Online Learning", "authors": "Ashok Cutkosky "}, {"title": "PENNI: Pruned Kernel Sharing for Efficient CNN Inference", "authors": "Shiyu Li, Edward Hanson, Hai Li, Yiran Chen ", "link": "", "summary": ""}, {"title": "Optimal transport mapping via input convex neural networks", "authors": "Ashok Vardhan Makkuva, Amirhossein Taghvaei, Sewoong Oh, Jason Lee ", "link": "https://arxiv.org/abs/1908.10962", "summary": "In this paper, we present a novel and principled approach to learn the\noptimal transport between two distributions, from samples. Guided by the\noptimal transport theory, we learn the optimal Kantorovich potential which\ninduces the optimal transport map. This involves learning two convex functions,\nby solving a novel minimax optimization. Building upon recent advances in the\nfield of input convex neural networks, we propose a new framework where the\ngradient of one convex function represents the optimal transport mapping.\nNumerical experiments confirm that we learn the optimal transport mapping. This\napproach ensures that the transport mapping we find is optimal independent of\nhow we initialize the neural networks. Further, target distributions from a\ndiscontinuous support can be easily captured, as gradient of a convex function\nnaturally models a {\\em discontinuous} transport mapping."}, {"title": "All in the (Exponential) Family: Information Geometry and Thermodynamic Variational Inference", "authors": "Robert Brekelmans, Vaden W Masrani, Frank Wood, Greg Ver Steeg, Aram Galstyan ", "link": "", "summary": ""}, {"title": "SimGANs: Simulator-Based Generative Adversarial Networks for ECG Synthesis to Improve Deep ECG Classification", "authors": "Tomer Golany, Kira Radinsky, Daniel Freedman ", "link": "", "summary": ""}, {"title": "Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using Mismatched Hypothesis Testing", "authors": "Sanghamitra Dutta, Dennis Wei, Hazar Yueksel, Pin-Yu Chen, Sijia Liu, Kush Varshney ", "link": "", "summary": ""}, {"title": "Convex Calibrated Surrogates for the Multi-Label F-Measure", "authors": "Mingyuan Zhang, Harish Guruprasad Ramaswamy, Shivani Agarwal "}, {"title": "Learning Robot Skills with Temporal Variational Inference", "authors": "Tanmay Shankar, Abhinav Gupta "}, {"title": "Adaptive Gradient Descent without Descent", "authors": "Konstantin Mishchenko, Yura Malitsky ", "link": "https://arxiv.org/abs/1910.09529", "summary": "We present a strikingly simple proof that two rules are sufficient to\nautomate gradient descent: 1) don't increase the stepsize too fast and 2) don't\noverstep the local curvature. No need for functional values, no line search, no\ninformation about the function except for the gradients. By following these\nrules, you get a method adaptive to the local geometry, with convergence\nguarantees depending only on smoothness in a neighborhood of a solution. Given\nthat the problem is convex, our method will converge even if the global\nsmoothness constant is infinity. As an illustration, it can minimize arbitrary\ncontinuously twice-differentiable convex function. We examine its performance\non a range of convex and nonconvex problems, including matrix factorization and\ntraining of ResNet-18."}, {"title": "An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm", "authors": "Christopher R DeCarolis, Mukul A Ram, Seyed  Esmaeili, Yu-Xiang Wang, Furong Huang ", "link": "https://arxiv.org/abs/1805.10341", "summary": "We provide an end-to-end differentially private spectral algorithm for\nlearning LDA, based on matrix/tensor decompositions, and establish theoretical\nguarantees on utility/consistency of the estimated model parameters. The\nspectral algorithm consists of multiple algorithmic steps, named as \"{edges}\",\nto which noise could be injected to obtain differential privacy. We identify\n\\emph{subsets of edges}, named as \"{configurations}\", such that adding noise to\nall edges in such a subset guarantees differential privacy of the end-to-end\nspectral algorithm. We characterize the sensitivity of the edges with respect\nto the input and thus estimate the amount of noise to be added to each edge for\nany required privacy level. We then characterize the utility loss for each\nconfiguration as a function of injected noise. Overall, by combining the\nsensitivity and utility characterization, we obtain an end-to-end\ndifferentially private spectral algorithm for LDA and identify the\ncorresponding configuration that outperforms others in any specific regime. We\nare the first to achieve utility guarantees under the required level of\ndifferential privacy for learning in LDA. Overall our method systematically\noutperforms differentially private variational inference."}, {"title": "Dual Mirror Descent for Online Allocation Problems", "authors": "Haihao Lu, Santiago Balseiro, Vahab Mirrokni ", "link": "https://arxiv.org/abs/2002.10421", "summary": "We consider online allocation problems with concave revenue functions and\nresource constraints, which are central problems in revenue management and\nonline advertising. In these settings, requests arrive sequentially during a\nfinite horizon and, for each request, a decision maker needs to choose an\naction that consumes a certain amount of resources and generates revenue. The\nrevenue function and resource consumption of each request are drawn\nindependently and at random from a probability distribution that is unknown to\nthe decision maker. The objective is to maximize cumulative revenues subject to\na constraint on the total consumption of resources.\n  We design a general class of algorithms that achieve sub-linear expected\nregret compared to the hindsight optimal allocation. Our algorithms operate in\nthe Lagrangian dual space: they maintain a dual multiplier for each resource\nthat is updated using online mirror descent. By choosing the reference function\naccordingly, we recover dual sub-gradient descent and dual exponential weights\nalgorithm. The resulting algorithms are simple, efficient, and shown to attain\nthe optimal order of regret when the length of the horizon and the initial\nnumber of resources are scaled proportionally. We discuss applications to\nonline bidding in repeated auctions with budget constraints and online\nproportional matching with high entropy."}, {"title": "Optimal Robust Learning of Discrete Distributions from Batches", "authors": "Ayush Jain, Alon Orlitsky ", "link": "https://arxiv.org/abs/1911.08532", "summary": "Many applications, including natural language processing, sensor networks,\ncollaborative filtering, and federated learning, call for estimating discrete\ndistributions from data collected in batches, some of which may be\nuntrustworthy, erroneous, faulty, or even adversarial.\n  Previous estimators for this setting ran in exponential time, and for some\nregimes required a suboptimal number of batches. We provide the first\npolynomial-time estimator that is optimal in the number of batches and achieves\nessentially the best possible estimation accuracy."}, {"title": "BoXHED: Boosted eXact Hazard Estimator with Dynamic covariates", "authors": "Xiaochen Wang, Arash Pakbin, Bobak Mortazavi, Hongyu Zhao, Donald Lee "}, {"title": "Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift  ", "authors": "Alexander Chan, Ahmed Alaa, Zhaozhi Qian, M van der Schaar "}, {"title": "Universal Equivariant Multilayer Perceptrons", "authors": "Siamak Ravanbakhsh ", "link": "https://arxiv.org/abs/2002.02912", "summary": "Group invariant and equivariant Multilayer Perceptrons (MLP), also known as\nEquivariant Networks, have achieved remarkable success in learning on a variety\nof data structures, such as sequences, images, sets, and graphs. Using tools\nfrom group theory, this paper proves the universality of a broad class of\nequivariant MLPs with a single hidden layer. In particular, it is shown that\nhaving a hidden layer on which the group acts regularly is sufficient for\nuniversal equivariance. Next, Burnside's table of marks is used to decompose\nproduct spaces. It is shown that the product of two G-sets always contains an\norbit larger than the input orbits. Therefore high order hidden layers\ninevitably contain a regular orbit, leading to the universality of the\ncorresponding MLP. It is shown that with an order larger than the logarithm of\nthe size of the stabilizer group, a high-order equivariant MLP is equivariant\nuniversal."}, {"title": "Improving generalization by controlling label-noise information in neural network weights", "authors": "Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan ", "link": "https://arxiv.org/abs/2002.07933", "summary": "In the presence of noisy or incorrect labels, neural networks have the\nundesirable tendency to memorize information about the noise. Standard\nregularization techniques such as dropout, weight decay or data augmentation\nsometimes help, but do not prevent this behavior. If one considers neural\nnetwork weights as random variables that depend on the data and stochasticity\nof training, the amount of memorized information can be quantified with the\nShannon mutual information between weights and the vector of all training\nlabels given inputs, $I(w : \\mathbf{y} \\mid \\mathbf{x})$. We show that for any\ntraining algorithm, low values of this term correspond to reduction in\nmemorization of label-noise and better generalization bounds. To obtain these\nlow values, we propose training algorithms that employ an auxiliary network\nthat predicts gradients in the final layers of a classifier without accessing\nlabels. We illustrate the effectiveness of our approach on versions of MNIST,\nCIFAR-10, and CIFAR-100 corrupted with various noise models, and on a\nlarge-scale dataset Clothing1M that has noisy labels."}, {"title": "DeepMatch: Balancing Deep Covariate Representations for Causal Inference Using Adversarial Training", "authors": "Nathan Kallus ", "link": "https://arxiv.org/abs/1802.05664", "summary": "We study optimal covariate balance for causal inferences from observational\ndata when rich covariates and complex relationships necessitate flexible\nmodeling with neural networks. Standard approaches such as propensity weighting\nand matching/balancing fail in such settings due to miscalibrated propensity\nnets and inappropriate covariate representations, respectively. We propose a\nnew method based on adversarial training of a weighting and a discriminator\nnetwork that effectively addresses this methodological gap. This is\ndemonstrated through new theoretical characterizations of the method as well as\nempirical results using both fully connected architectures to learn complex\nrelationships and convolutional architectures to handle image confounders,\nshowing how this new method can enable strong causal analyses in these\nchallenging settings."}, {"title": "Bayesian Optimisation over Multiple Continuous and Categorical Inputs", "authors": "Binxin Ru, Ahsan Alvi, Vu Nguyen, Michael A Osborne, Stephen Roberts ", "link": "https://arxiv.org/abs/1906.08878", "summary": "Efficient optimisation of black-box problems that comprise both continuous\nand categorical inputs is important, yet poses significant challenges. We\npropose a new approach, Continuous and Categorical Bayesian Optimisation\n(CoCaBO), which combines the strengths of multi-armed bandits and Bayesian\noptimisation to select values for both categorical and continuous inputs. We\nmodel this mixed-type space using a Gaussian Process kernel, designed to allow\nsharing of information across multiple categorical variables, each with\nmultiple possible values; this allows CoCaBO to leverage all available data\nefficiently. We extend our method to the batch setting and propose an efficient\nselection procedure that dynamically balances exploration and exploitation\nwhilst encouraging batch diversity. We demonstrate empirically that our method\noutperforms existing approaches on both synthetic and real-world optimisation\ntasks with continuous and categorical inputs."}, {"title": "Generalization and Representational Limits of Graph Neural Networks", "authors": "Vikas K Garg, Stefanie Jegelka, Tommi Jaakkola ", "link": "https://arxiv.org/abs/2002.06157", "summary": "We address two fundamental questions about graph neural networks (GNNs).\nFirst, we prove that several important graph properties cannot be computed by\nGNNs that rely entirely on local information. Such GNNs include the standard\nmessage passing models, and more powerful spatial variants that exploit local\ngraph structure (e.g., via relative orientation of messages, or local port\nordering) to distinguish neighbors of each node. Our treatment includes a novel\ngraph-theoretic formalism. Second, we provide the first data dependent\ngeneralization bounds for message passing GNNs. This analysis explicitly\naccounts for the local permutation invariance of GNNs. Our bounds are much\ntighter than existing VC-dimension based guarantees for GNNs, and are\ncomparable to Rademacher bounds for recurrent neural networks."}, {"title": "Multi-Precision Policy Enforced Training (MuPPET) : A Precision-Switching Strategy for Quantised Fixed-Point Training of CNNs", "authors": "Aditya Rajagopal, Diederik Vink, Stylianos Venieris, Christos-Savvas Bouganis "}, {"title": "LowFER: Low-rank Bilinear Pooling for Link Prediction", "authors": "Saadullah Amin, Stalin Varanasi, Katherine Ann Dunfield, G\u00fcnter Neumann ", "link": "", "summary": ""}, {"title": "Parameterized Rate-Distortion Stochastic Encoder", "authors": "Quan  Hoang, Trung Le, Dinh Phung "}, {"title": "Incidence Networks for Geometric Deep Learning", "authors": "Marjan Albooyeh, Daniele Bertolini, Siamak Ravanbakhsh ", "link": "https://arxiv.org/abs/1905.11460", "summary": "Sparse incidence tensors can represent a variety of structured data. For\nexample, we may represent attributed graphs using their node-node, node-edge,\nor edge-edge incidence matrices. In higher dimensions, incidence tensors can\nrepresent simplicial complexes and polytopes. In this paper, we formalize\nincidence tensors, analyze their structure, and present the family of\nequivariant networks that operate on them. We show that any incidence tensor\ndecomposes into invariant subsets. This decomposition, in turn, leads to a\ndecomposition of the corresponding equivariant linear maps, for which we prove\nan efficient pooling-and-broadcasting implementation. We demonstrate the\neffectiveness of this family of networks by reporting state-of-the-art on graph\nlearning tasks for many targets in the QM9 dataset."}, {"title": "Energy-Based Processes for Exchangeable Data", "authors": "Sherry Yang, Bo Dai, Hanjun Dai, Dale Schuurmans ", "link": "http://arxiv.org/abs/2003.07521", "summary": "Recently there has been growing interest in modeling sets with\nexchangeability such as point clouds. A shortcoming of current approaches is\nthat they restrict the cardinality of the sets considered or can only express\nlimited forms of distribution over unobserved data. To overcome these\nlimitations, we introduce Energy-Based Processes (EBPs), which extend energy\nbased models to exchangeable data while allowing neural network\nparameterizations of the energy function. A key advantage of these models is\nthe ability to express more flexible distributions over sets without\nrestricting their cardinality. We develop an efficient training procedure for\nEBPs that demonstrates state-of-the-art performance on a variety of tasks such\nas point cloud generation, classification, denoising, and image completion."}, {"title": "Deep Isometric Learning for Visual Recognition", "authors": "Haozhi Qi, Chong You, Xiaolong Wang, Yi Ma, Jitendra Malik ", "link": "", "summary": ""}, {"title": "Second-Order Provable Defenses against Adversarial Attacks", "authors": "Sahil Singla, Soheil Feizi ", "link": "http://arxiv.org/abs/2006.00731", "summary": "A robustness certificate is the minimum distance of a given input to the\ndecision boundary of the classifier (or its lower bound). For {\\it any} input\nperturbations with a magnitude smaller than the certificate value, the\nclassification output will provably remain unchanged. Exactly computing the\nrobustness certificates for neural networks is difficult since it requires\nsolving a non-convex optimization. In this paper, we provide\ncomputationally-efficient robustness certificates for neural networks with\ndifferentiable activation functions in two steps. First, we show that if the\neigenvalues of the Hessian of the network are bounded, we can compute a\nrobustness certificate in the $l_2$ norm efficiently using convex optimization.\nSecond, we derive a computationally-efficient differentiable upper bound on the\ncurvature of a deep network. We also use the curvature bound as a\nregularization term during the training of the network to boost its certified\nrobustness. Putting these results together leads to our proposed {\\bf\nC}urvature-based {\\bf R}obustness {\\bf C}ertificate (CRC) and {\\bf\nC}urvature-based {\\bf R}obust {\\bf T}raining (CRT). Our numerical results show\nthat CRT leads to significantly higher certified robust accuracy compared to\ninterval-bound propagation (IBP) based training. We achieve certified robust\naccuracy 69.79\\%, 57.78\\% and 53.19\\% while IBP-based methods achieve 44.96\\%,\n44.74\\% and 44.66\\% on 2,3 and 4 layer networks respectively on the\nMNIST-dataset."}, {"title": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention", "authors": "Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, Francois Fleuret "}, {"title": "Overfitting in adversarially robust deep learning", "authors": "Eric Wong, Leslie Rice, Zico Kolter ", "link": "https://arxiv.org/abs/2002.11569", "summary": "It is common practice in deep learning to use overparameterized networks and\ntrain for as long as possible; there are numerous studies that show, both\ntheoretically and empirically, that such practices surprisingly do not unduly\nharm the generalization performance of the classifier. In this paper, we\nempirically study this phenomenon in the setting of adversarially trained deep\nnetworks, which are trained to minimize the loss under worst-case adversarial\nperturbations. We find that overfitting to the training set does in fact harm\nrobust performance to a very large degree in adversarially robust training\nacross multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and\nperturbation models ($\\ell_\\infty$ and $\\ell_2$). Based upon this observed\neffect, we show that the performance gains of virtually all recent algorithmic\nimprovements upon adversarial training can be matched by simply using early\nstopping. We also show that effects such as the double descent curve do still\noccur in adversarially trained models, yet fail to explain the observed\noverfitting. Finally, we study several classical and modern deep learning\nremedies for overfitting, including regularization and data augmentation, and\nfind that no approach in isolation improves significantly upon the gains\nachieved by early stopping. All code for reproducing the experiments as well as\npretrained model weights and training logs can be found at\nhttps://github.com/locuslab/robust_overfitting."}, {"title": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks", "authors": "Zitong Yang, Yaodong Yu, Chong You, Jacob Steinhardt, Yi Ma ", "link": "https://arxiv.org/abs/2002.11328", "summary": "The classical bias-variance trade-off predicts that bias decreases and\nvariance increase with model complexity, leading to a U-shaped risk curve.\nRecent work calls this into question for neural networks and other\nover-parameterized models, for which it is often observed that larger models\ngeneralize better. We provide a simple explanation for this by measuring the\nbias and variance of neural networks: while the bias is monotonically\ndecreasing as in the classical theory, the variance is unimodal or bell-shaped:\nit increases then decreases with the width of the network. We vary the network\narchitecture, loss function, and choice of dataset and confirm that variance\nunimodality occurs robustly for all models we considered. The risk curve is the\nsum of the bias and variance curves and displays different qualitative shapes\ndepending on the relative scale of bias and variance, with the double descent\ncurve observed in recent literature as a special case. We corroborate these\nempirical results with a theoretical analysis of two-layer linear networks with\nrandom first layer. Finally, evaluation on out-of-distribution data shows that\nmost of the drop in accuracy comes from increased bias while variance increases\nby a relatively small amount. Moreover, we find that deeper models decrease\nbias and increase variance for both in-distribution and out-of-distribution\ndata."}, {"title": "Boosting for Control of Dynamical Systems", "authors": "Naman Agarwal, Nataly Brukhim, Elad Hazan, Zhou Lu ", "link": "https://arxiv.org/abs/1906.08720", "summary": "We study the question of how to aggregate controllers for dynamical systems\nin order to improve their performance. To this end, we propose a framework of\nboosting for online control. Our main result is an efficient boosting algorithm\nthat combines weak controllers into a provably more accurate one. Empirical\nevaluation on a host of control settings supports our theoretical findings."}, {"title": "Frustratingly Simple Few-Shot Object Detection", "authors": "Xin Wang, Thomas Huang, Joseph Gonzalez, Trevor Darrell, Fisher Yu ", "link": "https://arxiv.org/abs/2003.06957", "summary": "Detecting rare objects from a few examples is an emerging problem. Prior\nworks show meta-learning is a promising approach. But, fine-tuning techniques\nhave drawn scant attention. We find that fine-tuning only the last layer of\nexisting detectors on rare classes is crucial to the few-shot object detection\ntask. Such a simple approach outperforms the meta-learning methods by roughly\n2~20 points on current benchmarks and sometimes even doubles the accuracy of\nthe prior methods. However, the high variance in the few samples often leads to\nthe unreliability of existing benchmarks. We revise the evaluation protocols by\nsampling multiple groups of training examples to obtain stable comparisons and\nbuild new benchmarks based on three datasets: PASCAL VOC, COCO and LVIS. Again,\nour fine-tuning approach establishes a new state of the art on the revised\nbenchmarks. The code as well as the pretrained models are available at\nhttps://github.com/ucbdrive/few-shot-object-detection."}, {"title": "Data-Dependent Differentially Private Parameter Learning for Directed Graphical Models", "authors": "Amrita Roy Chowdhury, Theodoros Rekatsinas, Somesh Jha ", "link": "https://arxiv.org/abs/1905.12813", "summary": "Directed graphical models (DGMs) are a class of probabilistic models that are\nwidely used for predictive analysis in sensitive domains, such as medical\ndiagnostics. In this paper we present an algorithm for differentially private\nlearning of the parameters of a DGM with a publicly known graph structure over\nfully observed data. Our solution optimizes for the utility of inference\nqueries over the DGM and \\textit{adds noise that is customized to the\nproperties of the private input dataset and the graph structure of the DGM}. To\nthe best of our knowledge, this is the first explicit data-dependent privacy\nbudget allocation algorithm for DGMs. We compare our algorithm with a standard\ndata-independent approach over a diverse suite of DGM benchmarks and\ndemonstrate that our solution requires a privacy budget that is $3\\times$\nsmaller to obtain the same or higher utility."}, {"title": "Adversarial Risk via Optimal Transport and Optimal Couplings", "authors": "Muni Sreenivas Pydi, Varun Jog ", "link": "https://arxiv.org/abs/1912.02794", "summary": "The accuracy of modern machine learning algorithms deteriorates severely on\nadversarially manipulated test data. Optimal adversarial risk quantifies the\nbest error rate of any classifier in the presence of adversaries, and optimal\nadversarial classifiers are sought that minimize adversarial risk. In this\npaper, we investigate the optimal adversarial risk and optimal adversarial\nclassifiers from an optimal transport perspective. We present a new and simple\napproach to show that the optimal adversarial risk for binary classification\nwith $0-1$ loss function is completely characterized by an optimal transport\ncost between the probability distributions of the two classes, for a suitably\ndefined cost function. We propose a novel coupling strategy that achieves the\noptimal transport cost for several univariate distributions like Gaussian,\nuniform and triangular. Using the optimal couplings, we obtain the optimal\nadversarial classifiers in these settings and show how they differ from optimal\nclassifiers in the absence of adversaries. Based on our analysis, we evaluate\nalgorithm-independent fundamental limits on adversarial risk for CIFAR-10,\nMNIST, Fashion-MNIST and SVHN datasets, and Gaussian mixtures based on them. In\naddition to the $0-1$ loss, we also derive bounds on the deviation of optimal\nrisk and optimal classifier in the presence of adversaries for continuous loss\nfunctions, that are based on the convexity and smoothness of the loss\nfunctions."}, {"title": "Decoupled Greedy Learning of CNNs", "authors": "Eugene Belilovsky, Michael Eickenberg, Edouard Oyallon ", "link": "https://arxiv.org/abs/1901.08164", "summary": "A commonly cited inefficiency of neural network training by back-propagation\nis the update locking problem: each layer must wait for the signal to propagate\nthrough the network before updating. In recent years multiple authors have\nconsidered alternatives that can alleviate this issue. In this context, we\nconsider a simpler, but more effective, substitute that uses minimal feedback,\nwhich we call Decoupled Greedy Learning (DGL). It is based on a greedy\nrelaxation of the joint training objective, recently shown to be effective in\nthe context of Convolutional Neural Networks (CNNs) on large-scale image\nclassification. We consider an optimization of this objective that permits us\nto decouple the layer training, allowing for layers or modules in networks to\nbe trained with a potentially linear parallelization in layers. We show\ntheoretically and empirically that this approach converges. Then, we\nempirically find that it can lead to better generalization than sequential\ngreedy optimization and sometimes end-to-end back-propagation. We show an\nextension of this approach to asynchronous settings, where modules can operate\nwith large communication delays, is possible with the use of a replay buffer.\nWe demonstrate the effectiveness of DGL on the CIFAR-10 dataset against\nalternatives and on the large-scale ImageNet dataset."}, {"title": "ACFlow: Flow Models for Arbitrary Conditional Likelihoods", "authors": "Yang Li, Shoaib Akbar, Junier Oliva ", "link": "https://arxiv.org/abs/1909.06319", "summary": "Understanding the dependencies among features of a dataset is at the core of\nmost unsupervised learning tasks. However, a majority of generative modeling\napproaches are focused solely on the joint distribution $p(x)$ and utilize\nmodels where it is intractable to obtain the conditional distribution of some\narbitrary subset of features $x_u$ given the rest of the observed covariates\n$x_o$: $p(x_u \\mid x_o)$. Traditional conditional approaches provide a model\nfor a fixed set of covariates conditioned on another fixed set of observed\ncovariates. Instead, in this work we develop a model that is capable of\nyielding all conditional distributions $p(x_u \\mid x_o)$ (for arbitrary $x_u$)\nvia tractable conditional likelihoods. We propose a novel extension of (change\nof variables based) flow generative models, arbitrary conditioning flow models\n(AC-Flow), that can be conditioned on arbitrary subsets of observed covariates,\nwhich was previously infeasible. We apply AC-Flow to the imputation of\nfeatures, and also develop a unified platform for both multiple and single\nimputation by introducing an auxiliary objective that provides a principled\nsingle \"best guess\" for flow models. Extensive empirical evaluations show that\nour models achieve state-of-the-art performance in both single and multiple\nimputation across image inpainting and feature imputation in synthetic and\nreal-world datasets. Code is available at https://github.com/lupalab/ACFlow."}, {"title": "Can autonomous vehicles identify, recover from, and adapt to distribution shifts?", "authors": "Angelos Filos, Panagiotis Tigkas, Rowan McAllister, Nicholas Rhinehart, Sergey Levine, Yarin Gal "}, {"title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning", "authors": "Karl Cobbe, Chris Hesse, Jacob Hilton, John Schulman ", "link": "https://arxiv.org/abs/1912.01588", "summary": "In this report, we introduce Procgen Benchmark, a suite of 16 procedurally\ngenerated game-like environments designed to benchmark both sample efficiency\nand generalization in reinforcement learning. We believe that the community\nwill benefit from increased access to high quality training environments, and\nwe provide detailed experimental protocols for using this benchmark. We\nempirically demonstrate that diverse environment distributions are essential to\nadequately train and evaluate RL agents, thereby motivating the extensive use\nof procedural content generation. We then use this benchmark to investigate the\neffects of scaling model size, finding that larger models significantly improve\nboth sample efficiency and generalization."}, {"title": "The Tree Ensemble Layer: Differentiability meets Conditional Computation", "authors": "Hussein Hazimeh, Natalia Ponomareva, Rahul Mazumder, Zhenyu Tan, Petros Mol ", "link": "https://arxiv.org/abs/2002.07772", "summary": "Neural networks and tree ensembles are state-of-the-art learners, each with\nits unique statistical and computational advantages. We aim to combine these\nadvantages by introducing a new layer for neural networks, composed of an\nensemble of differentiable decision trees (a.k.a. soft trees). While\ndifferentiable trees demonstrate promising results in the literature, in\npractice they are typically slow in training and inference as they do not\nsupport conditional computation. We mitigate this issue by introducing a new\nsparse activation function for sample routing, and implement true conditional\ncomputation by developing specialized forward and backward propagation\nalgorithms that exploit sparsity. Our efficient algorithms pave the way for\njointly training over deep and wide tree ensembles using first-order methods\n(e.g., SGD). Experiments on 23 classification datasets indicate over 10x\nspeed-ups compared to the differentiable trees used in the literature and over\n20x reduction in the number of parameters compared to gradient boosted trees,\nwhile maintaining competitive performance. Moreover, experiments on CIFAR,\nMNIST, and Fashion MNIST indicate that replacing dense layers in CNNs with our\ntree layer reduces the test loss by 7-53% and the number of parameters by 8x.\nWe provide an open-source TensorFlow implementation with a Keras API."}, {"title": "Near-Tight Margin-Based Generalization Bounds for Support Vector Machines", "authors": "Allan Gr\u00f8nlund, Lior Kamma, Kasper Green Larsen "}, {"title": "Error Estimation for Sketched SVD", "authors": "Miles Lopes, N. Benjamin Erichson, Michael Mahoney ", "link": "", "summary": ""}, {"title": "Goal-Aware Prediction: Learning to Model What Matters", "authors": "Suraj Nair, Silvio Savarese, Chelsea Finn "}, {"title": "Combinatorial Pure Exploration for Dueling Bandit", "authors": "Wei Chen, Yihan Du, Longbo Huang, Haoyu Zhao "}, {"title": "Optimal Sequential Maximization: One Interview is Enough!", "authors": "Moein Falahatgar, Alon Orlitsky, Venkatadheeraj Pichapati "}, {"title": "What can I do here? A Theory of Affordances in Reinforcement Learning", "authors": "Khimya Khetarpal, Zafarali Ahmed, Gheorghe Comanici, David Abel, Doina Precup "}, {"title": "An end-to-end approach for the verification problem: learning the right distance", "authors": "Joao Monteiro, Isabela Albuquerque, Jahangir  Alam, Montreal  Canada, R Devon Hjelm, Tiago Falk ", "link": "https://arxiv.org/abs/2002.09469", "summary": "In this contribution, we augment the metric learning setting by introducing a\nparametric pseudo-distance, trained jointly with the encoder. Several\ninterpretations are thus drawn for the learned distance-like model's output. We\nfirst show it approximates a likelihood ratio which can be used for hypothesis\ntests, and that it further induces a large divergence across the joint\ndistributions of pairs of examples from the same and from different classes.\nEvaluation is performed under the verification setting consisting of\ndetermining whether sets of examples belong to the same class, even if such\nclasses are novel and were never presented to the model during training.\nEmpirical evaluation shows such method defines an end-to-end approach for the\nverification problem, able to attain better performance than simple scorers\nsuch as those based on cosine similarity and further outperforming widely used\ndownstream classifiers. We further observe training is much simplified under\nthe proposed approach compared to metric learning with actual distances,\nrequiring no complex scheme to harvest pairs of examples."}, {"title": "Data Valuation using Reinforcement Learning", "authors": "Jinsung Yoon, Sercan O. Arik, Tomas Pfister ", "link": "https://arxiv.org/abs/1909.11671", "summary": "Quantifying the value of data is a fundamental problem in machine learning.\nData valuation has multiple important use cases: (1) building insights about\nthe learning task, (2) domain adaptation, (3) corrupted sample discovery, and\n(4) robust learning. To adaptively learn data values jointly with the target\ntask predictor model, we propose a meta learning framework which we name Data\nValuation using Reinforcement Learning (DVRL). We employ a data value estimator\n(modeled by a deep neural network) to learn how likely each datum is used in\ntraining of the predictor model. We train the data value estimator using a\nreinforcement signal of the reward obtained on a small validation set that\nreflects performance on the target task. We demonstrate that DVRL yields\nsuperior data value estimates compared to alternative methods across different\ntypes of datasets and in a diverse set of application scenarios. The corrupted\nsample discovery performance of DVRL is close to optimal in many regimes (i.e.\nas if the noisy samples were known apriori), and for domain adaptation and\nrobust learning DVRL significantly outperforms state-of-the-art by 14.6% and\n10.8%, respectively."}, {"title": "FormulaZero: Distributionally Robust Online Adaptation via Offline Population Synthesis", "authors": "Aman Sinha, Matthew O'Kelly, Hongrui Zheng, Rahul Mangharam, John Duchi, Russ Tedrake ", "link": "https://arxiv.org/abs/2003.03900", "summary": "Balancing performance and safety is crucial to deploying autonomous vehicles\nin multi-agent environments. In particular, autonomous racing is a domain that\npenalizes safe but conservative policies, highlighting the need for robust,\nadaptive strategies. Current approaches either make simplifying assumptions\nabout other agents or lack robust mechanisms for online adaptation. This work\nmakes algorithmic contributions to both challenges. First, to generate a\nrealistic, diverse set of opponents, we develop a novel method for self-play\nbased on replica-exchange Markov chain Monte Carlo. Second, we propose a\ndistributionally robust bandit optimization procedure that adaptively adjusts\nrisk aversion relative to uncertainty in beliefs about opponents' behaviors. We\nrigorously quantify the tradeoffs in performance and robustness when\napproximating these computations in real-time motion-planning, and we\ndemonstrate our methods experimentally on autonomous vehicles that achieve\nscaled speeds comparable to Formula One racecars."}, {"title": "Latent Bernoulli Autoencoder", "authors": "Jiri Fajtl, Vasileios Argyriou, Dorothy Monekosso, Paolo Remagnino "}, {"title": "Learning to Stop While Learning to Predict", "authors": "Xinshi Chen, Hanjun Dai, Yu Li, Xin Gao, Le Song ", "link": "", "summary": ""}, {"title": "Accelerating the diffusion-based ensemble sampling by non-reversible dynamics", "authors": "Futoshi Futami, Issei Sato, Masashi Sugiyama "}, {"title": "A unified approach for assessing population feature importance using Shapley values", "authors": "Brian Williamson, Jean Feng "}, {"title": "Curse of Dimensionality on Randomized Smoothing for Certifiable Robustness", "authors": "Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi ", "link": "https://arxiv.org/abs/2002.03239", "summary": "Randomized smoothing, using just a simple isotropic Gaussian distribution,\nhas been shown to produce good robustness guarantees against $\\ell_2$-norm\nbounded adversaries. In this work, we show that extending the smoothing\ntechnique to defend against other attack models can be challenging, especially\nin the high-dimensional regime. In particular, for a vast class of i.i.d.\nsmoothing distributions, we prove that the largest $\\ell_p$-radius that can be\ncertified decreases as $O(1/d^{\\frac{1}{2} - \\frac{1}{p}})$ with dimension $d$\nfor $p > 2$. Notably, for $p \\geq 2$, this dependence on $d$ is no better than\nthat of the $\\ell_p$-radius that can be certified using isotropic Gaussian\nsmoothing, essentially putting a matching lower bound on the robustness radius.\nWhen restricted to generalized Gaussian smoothing, these two bounds can be\nshown to be within a constant factor of each other in an asymptotic sense,\nestablishing that Gaussian smoothing provides the best possible results, up to\na constant factor, when $p \\geq 2$. We present experimental results on CIFAR to\nvalidate our theory. For other smoothing distributions, such as, a uniform\ndistribution within an $\\ell_1$ or an $\\ell_\\infty$-norm ball, we show upper\nbounds of the form $O(1 / d)$ and $O(1 / d^{1 - \\frac{1}{p}})$ respectively,\nwhich have an even worse dependence on $d$."}, {"title": "Upper bounds for Model-Free Row-Sparse Principal Component Analysis", "authors": "Guanyi Wang, Santanu  Dey "}, {"title": "Explainable k-Means and k-Medians Clustering", "authors": "Michal Moshkovitz, Sanjoy Dasgupta, Cyrus Rashtchian, Nave Frost ", "link": "https://arxiv.org/abs/2002.12538", "summary": "Clustering is a popular form of unsupervised learning for geometric data.\nUnfortunately, many clustering algorithms lead to cluster assignments that are\nhard to explain, partially because they depend on all the features of the data\nin a complicated way. To improve interpretability, we consider using a small\ndecision tree to partition a data set into clusters, so that clusters can be\ncharacterized in a straightforward manner. We study this problem from a\ntheoretical viewpoint, measuring cluster quality by the $k$-means and\n$k$-medians objectives: Must there exist a tree-induced clustering whose cost\nis comparable to that of the best unconstrained clustering, and if so, how can\nit be found? In terms of negative results, we show, first, that popular\ntop-down decision tree algorithms may lead to clusterings with arbitrarily\nlarge cost, and second, that any tree-induced clustering must in general incur\nan $\\Omega(\\log k)$ approximation factor compared to the optimal clustering. On\nthe positive side, we design an efficient algorithm that produces explainable\nclusters using a tree with $k$ leaves. For two means/medians, we show that a\nsingle threshold cut suffices to achieve a constant factor approximation, and\nwe give nearly-matching lower bounds. For general $k \\geq 2$, our algorithm is\nan $O(k)$ approximation to the optimal $k$-medians and an $O(k^2)$\napproximation to the optimal $k$-means. Prior to our work, no algorithms were\nknown with provable guarantees independent of dimension and input size."}, {"title": "Reward-Free Exploration for Reinforcement Learning", "authors": "Chi Jin, Akshay Krishnamurthy, Max Simchowitz, Tiancheng Yu ", "link": "https://arxiv.org/abs/2002.02794", "summary": "Exploration is widely regarded as one of the most challenging aspects of\nreinforcement learning (RL), with many naive approaches succumbing to\nexponential sample complexity. To isolate the challenges of exploration, we\npropose a new \"reward-free RL\" framework. In the exploration phase, the agent\nfirst collects trajectories from an MDP $\\mathcal{M}$ without a pre-specified\nreward function. After exploration, it is tasked with computing near-optimal\npolicies under for $\\mathcal{M}$ for a collection of given reward functions.\nThis framework is particularly suitable when there are many reward functions of\ninterest, or when the reward function is shaped by an external agent to elicit\ndesired behavior.\n  We give an efficient algorithm that conducts\n$\\tilde{\\mathcal{O}}(S^2A\\mathrm{poly}(H)/\\epsilon^2)$ episodes of exploration\nand returns $\\epsilon$-suboptimal policies for an arbitrary number of reward\nfunctions. We achieve this by finding exploratory policies that visit each\n\"significant\" state with probability proportional to its maximum visitation\nprobability under any possible policy. Moreover, our planning procedure can be\ninstantiated by any black-box approximate planner, such as value iteration or\nnatural policy gradient. We also give a nearly-matching\n$\\Omega(S^2AH^2/\\epsilon^2)$ lower bound, demonstrating the near-optimality of\nour algorithm in this setting."}, {"title": "Parametric Gaussian Process Regressors", "authors": "Martin Jankowiak, Geoff Pleiss, Jacob Gardner ", "link": "https://arxiv.org/abs/1910.07123", "summary": "The combination of inducing point methods with stochastic variational\ninference has enabled approximate Gaussian Process (GP) inference on large\ndatasets. Unfortunately, the resulting predictive distributions often exhibit\nsubstantially underestimated uncertainties. Notably, in the regression case the\npredictive variance is typically dominated by observation noise, yielding\nuncertainty estimates that make little use of the input-dependent function\nuncertainty that makes GP priors attractive. In this work we propose two simple\nmethods for scalable GP regression that address this issue and thus yield\nsubstantially improved predictive uncertainties. The first applies variational\ninference to FITC (Fully Independent Training Conditional; Snelson\net.~al.~2006). The second bypasses posterior approximations and instead\ndirectly targets the posterior predictive distribution. In an extensive\nempirical comparison with a number of alternative methods for scalable GP\nregression, we find that the resulting predictive distributions exhibit\nsignificantly better calibrated uncertainties and higher log likelihoods--often\nby as much as half a nat per datapoint."}, {"title": "p-Norm Flow Diffusion for Local Graph Clustering", "authors": "Kimon Fountoulakis, Di Wang, Shenghao Yang ", "link": "https://arxiv.org/abs/2005.09810", "summary": "Local graph clustering and the closely related seed set expansion problem are\nprimitives on graphs that are central to a wide range of analytic and learning\ntasks such as local clustering, community detection, nodes ranking and feature\ninference. Prior work on local graph clustering mostly falls into two\ncategories with numerical and combinatorial roots respectively. In this work,\nwe draw inspiration from both fields and propose a family of convex\noptimization formulations based on the idea of diffusion with p-norm network\nflow for $p\\in (1,\\infty)$. In the context of local clustering, we characterize\nthe optimal solutions for these optimization problems and show their usefulness\nin finding low conductance cuts around input seed set. In particular, we\nachieve quadratic approximation of conductance in the case of $p=2$ similar to\nthe Cheeger-type bounds of spectral methods, constant factor approximation when\n$p\\rightarrow\\infty$ similar to max-flow based methods, and a smooth transition\nfor general $p$ values in between. Thus, our optimization formulation can be\nviewed as bridging the numerical and combinatorial approaches, and we can\nachieve the best of both worlds in terms of speed and noise robustness. We show\nthat the proposed problem can be solved in strongly local running time for\n$p\\ge 2$ and conduct empirical evaluations on both synthetic and real-world\ngraphs to illustrate our approach compares favorably with existing methods."}, {"title": "Low-Rank Bottleneck in Multi-head Attention Models", "authors": "Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank Jakkam Reddi, Sanjiv Kumar ", "link": "https://arxiv.org/abs/2002.07028", "summary": "Attention based Transformer architecture has enabled significant advances in\nthe field of natural language processing. In addition to new pre-training\ntechniques, recent improvements crucially rely on working with a relatively\nlarger embedding dimension for tokens. Unfortunately, this leads to models that\nare prohibitively large to be employed in the downstream tasks. In this paper\nwe identify one of the important factors contributing to the large embedding\nsize requirement. In particular, our analysis highlights that the scaling\nbetween the number of heads and the size of each head in the current\narchitecture gives rise to a low-rank bottleneck in attention heads, causing\nthis limitation. We further validate this in our experiments. As a solution we\npropose to set the head size of an attention unit to input sequence length, and\nindependent of the number of heads, resulting in multi-head attention layers\nwith provably more expressive power. We empirically show that this allows us to\ntrain models with a relatively smaller embedding dimension and with better\nperformance scaling."}, {"title": "LEEP: A New Measure to Evaluate Transferability of Learned Representations", "authors": "Cuong V Nguyen, Tal Hassner, Cedric Archambeau, Matthias W Seeger ", "link": "https://arxiv.org/abs/2002.12462", "summary": "We introduce a new measure to evaluate the transferability of representations\nlearned by classifiers. Our measure, the Log Expected Empirical Prediction\n(LEEP), is simple and easy to compute: when given a classifier trained on a\nsource data set, it only requires running the target data set through this\nclassifier once. We analyze the properties of LEEP theoretically and\ndemonstrate its effectiveness empirically. Our analysis shows that LEEP can\npredict the performance and convergence speed of both transfer and\nmeta-transfer learning methods, even for small or imbalanced data. Moreover,\nLEEP outperforms recently proposed transferability measures such as negative\nconditional entropy and H scores. Notably, when transferring from ImageNet to\nCIFAR100, LEEP can achieve up to 30% improvement compared to the best competing\nmethod in terms of the correlations with actual transfer accuracy."}, {"title": "The FAST Algorithm for Submodular Maximization", "authors": "Adam Breuer, Eric Balkanski, Yaron Singer ", "link": "https://arxiv.org/abs/1907.06173", "summary": "In this paper we describe a new algorithm called Fast Adaptive Sequencing\nTechnique (FAST) for maximizing a monotone submodular function under a\ncardinality constraint $k$ whose approximation ratio is arbitrarily close to\n$1-1/e$, is $O(\\log(n) \\log^2(\\log k))$ adaptive, and uses a total of $O(n\n\\log\\log(k))$ queries. Recent algorithms have comparable guarantees in terms of\nasymptotic worst case analysis, but their actual number of rounds and query\ncomplexity depend on very large constants and polynomials in terms of precision\nand confidence, making them impractical for large data sets. Our main\ncontribution is a design that is extremely efficient both in terms of its\nnon-asymptotic worst case query complexity and number of rounds, and in terms\nof its practical runtime. We show that this algorithm outperforms any algorithm\nfor submodular maximization we are aware of, including hyper-optimized parallel\nversions of state-of-the-art serial algorithms, by running experiments on large\ndata sets. These experiments show FAST is orders of magnitude faster than the\nstate-of-the-art."}, {"title": "On the Relation between Quality-Diversity Evaluation and Distribution-Fitting Goal in Text Generation", "authors": "Jianing Li, Yanyan Lan, Jiafeng Guo, Xueqi Cheng "}, {"title": "Designing Optimal Dynamic Treatment Regimes: A Causal Reinforcement Learning Approach", "authors": "Junzhe Zhang "}, {"title": "Global Decision-Making via Local Economic Transactions", "authors": "Michael Chang, Sid Kaushik, S. Matthew Weinberg, Sergey Levine, Thomas Griffiths "}, {"title": "Retrieval Augmented Language Model Pre-Training", "authors": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang ", "link": "", "summary": ""}, {"title": "Variational Label Enhancement", "authors": "Ning Xu, Yun-Peng Liu, Jun Shu, Xin Geng ", "link": "", "summary": ""}, {"title": "Bandits with Adversarial Scaling", "authors": "Thodoris Lykouris, Vahab Mirrokni, Renato Leme ", "link": "https://arxiv.org/abs/2003.02287", "summary": "We study \"adversarial scaling\", a multi-armed bandit model where rewards have\na stochastic and an adversarial component. Our model captures display\nadvertising where the \"click-through-rate\" can be decomposed to a (fixed across\ntime) arm-quality component and a non-stochastic user-relevance component\n(fixed across arms). Despite the relative stochasticity of our model, we\ndemonstrate two settings where most bandit algorithms suffer. On the positive\nside, we show that two algorithms, one from the action elimination and one from\nthe mirror descent family are adaptive enough to be robust to adversarial\nscaling. Our results shed light on the robustness of adaptive parameter\nselection in stochastic bandits, which may be of independent interest."}, {"title": "Eliminating the Invariance on the Loss Landscape of Linear Autoencoders", "authors": "Reza Oftadeh, Jiayi Shen, Zhangyang Wang, Dylan Shell "}, {"title": "What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?", "authors": "Chi Jin, Praneeth Netrapalli, Michael Jordan ", "link": "https://arxiv.org/abs/1902.00618", "summary": "Minimax optimization has found extensive applications in modern machine\nlearning, in settings such as generative adversarial networks (GANs),\nadversarial training and multi-agent reinforcement learning. As most of these\napplications involve continuous nonconvex-nonconcave formulations, a very basic\nquestion arises---``what is a proper definition of local optima?''\n  Most previous work answers this question using classical notions of\nequilibria from simultaneous games, where the min-player and the max-player act\nsimultaneously. In contrast, most applications in machine learning, including\nGANs and adversarial training, correspond to sequential games, where the order\nof which player acts first is crucial (since minimax is in general not equal to\nmaximin due to the nonconvex-nonconcave nature of the problems). The main\ncontribution of this paper is to propose a proper mathematical definition of\nlocal optimality for this sequential setting---local minimax, as well as to\npresent its properties and existence results. Finally, we establish a strong\nconnection to a basic local search algorithm---gradient descent ascent (GDA):\nunder mild conditions, all stable limit points of GDA are exactly local minimax\npoints up to some degenerate points."}, {"title": "Lookahead-Bounded Q-learning", "authors": "Ibrahim El Shar, Daniel Jiang "}, {"title": "Learning From Irregularly-Sampled Time Series: A Missing Data Perspective", "authors": "Steven Cheng-Xian Li, Benjamin M Marlin "}, {"title": "Evaluating the Performance of Reinforcement Learning Algorithms", "authors": "Scott Jordan, Yash Chandak, Daniel Cohen, Mengxue Zhang, Philip Thomas "}, {"title": "Unbiased Risk Estimators Can Mislead: A Case Study of Learning with Complementary Labels", "authors": "Yu-Ting Chou, Gang Niu, Hsuan-Tien Lin, Masashi Sugiyama ", "link": "", "summary": ""}, {"title": "Provable Self-Play Algorithms for Competitive Reinforcement Learning", "authors": "Yu Bai, Chi Jin ", "link": "https://arxiv.org/abs/2002.04017", "summary": "Self-play, where the algorithm learns by playing against itself without\nrequiring any direct supervision, has become the new weapon in modern\nReinforcement Learning (RL) for achieving superhuman performance in practice.\nHowever, the majority of exisiting theory in reinforcement learning only\napplies to the setting where the agent plays against a fixed environment. It\nremains largely open whether self-play algorithms can be provably effective,\nespecially when it is necessary to manage the exploration/exploitation\ntradeoff.\n  We study self-play in competitive reinforcement learning under the setting of\nMarkov games, a generalization of Markov decision processes to the two-player\ncase. We introduce a self-play algorithm---Value Iteration with Upper/Lower\nConfidence Bound (VI-ULCB), and show that it achieves regret\n$\\mathcal{\\tilde{O}}(\\sqrt{T})$ after playing $T$ steps of the game. The regret\nis measured by the agent's performance against a \\emph{fully adversarial}\nopponent who can exploit the agent's strategy at \\emph{any} step. We also\nintroduce an explore-then-exploit style algorithm, which achieves a slightly\nworse regret of $\\mathcal{\\tilde{O}}(T^{2/3})$, but is guaranteed to run in\npolynomial time even in the worst case. To the best of our knowledge, our work\npresents the first line of provably sample-efficient self-play algorithms for\ncompetitive reinforcement learning."}, {"title": "Optimizing Long-term Social Welfare in Recommender Systems: A Constrained Matching Approach", "authors": "Martin Mladenov, Elliot Creager, Omer Ben Porat, Kevin Swersky, Richard Zemel, Craig Boutilier "}, {"title": "Semi-Supervised StyleGAN for Disentanglement Learning", "authors": "Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debnath, Anjul Patney, Ankit Patel, Anima Anandkumar ", "link": "https://arxiv.org/abs/2003.03461", "summary": "Disentanglement learning is crucial for obtaining disentangled\nrepresentations and controllable generation. Current disentanglement methods\nface several inherent limitations: difficulty with high-resolution images,\nprimarily on learning disentangled representations, and non-identifiability due\nto the unsupervised setting. To alleviate these limitations, we design new\narchitectures and loss functions based on StyleGAN (Karras et al., 2019), for\nsemi-supervised high-resolution disentanglement learning. We create two complex\nhigh-resolution synthetic datasets for systematic testing. We investigate the\nimpact of limited supervision and find that using only 0.25%~2.5% of labeled\ndata is sufficient for good disentanglement on both synthetic and real\ndatasets. We propose new metrics to quantify generator controllability, and\nobserve there may exist a crucial trade-off between disentangled representation\nlearning and controllable generation. We also consider semantic fine-grained\nimage editing to achieve better generalization to unseen images."}, {"title": "The Non-IID Data Quagmire of Decentralized Machine Learning", "authors": "Kevin Hsieh, Amar Phanishayee, Onur Mutlu, Phillip Gibbons ", "link": "https://arxiv.org/abs/1910.00189", "summary": "Many large-scale machine learning (ML) applications need to train ML models\nover decentralized datasets that are generated at different devices and\nlocations. These decentralized datasets pose a fundamental challenge to ML\nbecause they are typically generated in very different contexts, which leads to\nsignificant differences in data distribution across devices/locations (i.e.,\nthey are not independent and identically distributed (IID)). In this work, we\ntake a step toward better understanding this challenge, by presenting the first\ndetailed experimental study of the impact of such non-IID data on the\ndecentralized training of deep neural networks (DNNs). Our study shows that:\n(i) the problem of non-IID data partitions is fundamental and pervasive, as it\nexists in all ML applications, DNN models, training datasets, and decentralized\nlearning algorithms in our study; (ii) this problem is particularly difficult\nfor DNN models with batch normalization layers; and (iii) the degree of\ndeviation from IID (the skewness) is a key determinant of the difficulty level\nof the problem. With these findings in mind, we present SkewScout, a\nsystem-level approach that adapts the communication frequency of decentralized\nlearning algorithms to the (skew-induced) accuracy loss between data\npartitions. We also show that group normalization can recover much of the\nskew-induced accuracy loss of batch normalization."}, {"title": "On the Noisy Gradient Descent that Generalizes as SGD", "authors": "Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman, Zhanxing Zhu ", "link": "https://arxiv.org/abs/1906.07405", "summary": "The gradient noise of SGD is considered to play a central role in the\nobserved strong generalization abilities of deep learning. While past studies\nconfirm that the magnitude and the covariance structure of gradient noise are\ncritical for regularization, it remains unclear whether or not the class of\nnoise distributions is important. In this work we provide negative results by\nshowing that noises in classes different from the SGD noise can also\neffectively regularize gradient descent. Our finding is based on a novel\nobservation on the structure of the SGD noise: it is the multiplication of the\ngradient matrix and a sampling noise that arises from the mini-batch sampling\nprocedure. Moreover, the sampling noises unify two kinds of gradient\nregularizing noises that belong to the Gaussian class: the one using (scaled)\nFisher as covariance and the one using the gradient covariance of SGD as\ncovariance. Finally, thanks to the flexibility of choosing noise class, an\nalgorithm is proposed to perform noisy gradient descent that generalizes well,\nthe variant of which even benefits large batch SGD training without hurting\ngeneralization."}, {"title": "Safe screening rules for L0-regression", "authors": "Alper Atamturk, Andres Gomez "}, {"title": "Single Point Transductive Prediction", "authors": "Nilesh Tripuraneni, Lester Mackey ", "link": "https://arxiv.org/abs/1908.02341", "summary": "Standard methods in supervised learning separate training and prediction: the\nmodel is fit independently of any test points it may encounter. However, can\nknowledge of the next test point $\\mathbf{x}_{\\star}$ be exploited to improve\nprediction accuracy? We address this question in the context of linear\nprediction, showing how techniques from semi-parametric inference can be used\ntransductively to combat regularization bias. We first lower bound the\n$\\mathbf{x}_{\\star}$ prediction error of ridge regression and the Lasso,\nshowing that they must incur significant bias in certain test directions. We\nthen provide non-asymptotic upper bounds on the $\\mathbf{x}_{\\star}$ prediction\nerror of two transductive prediction rules. We conclude by showing the efficacy\nof our methods on both synthetic and real data, highlighting the improvements\nsingle point transductive prediction can provide in settings with distribution\nshift."}, {"title": "History-Gradient Aided Batch Size Adaptation for Variance Reduced Algorithms", "authors": "Kaiyi Ji, Zhe Wang, Bowen Weng, Yi Zhou, Wei  Zhang, Yingbin LIANG ", "link": "http://arxiv.org/abs/1910.09670", "summary": "Variance-reduced algorithms, although achieve great theoretical performance,\ncan run slowly in practice due to the periodic gradient estimation with a large\nbatch of data. Batch-size adaptation thus arises as a promising approach to\naccelerate such algorithms. However, existing schemes either apply prescribed\nbatch-size adaption rule or exploit the information along optimization path via\nadditional backtracking and condition verification steps. In this paper, we\npropose a novel scheme, which eliminates backtracking line search but still\nexploits the information along optimization path by adapting the batch size via\nhistory stochastic gradients. We further theoretically show that such a scheme\nsubstantially reduces the overall complexity for popular variance-reduced\nalgorithms SVRG and SARAH/SPIDER for both conventional nonconvex optimization\nand reinforcement learning problems. To this end, we develop a new convergence\nanalysis framework to handle the dependence of the batch size on history\nstochastic gradients. Extensive experiments validate the effectiveness of the\nproposed batch-size adaptation scheme."}, {"title": "Batch Stationary Distribution Estimation", "authors": "Junfeng Wen, Bo Dai, Lihong Li, Dale Schuurmans ", "link": "https://arxiv.org/abs/2003.00722", "summary": "We consider the problem of approximating the stationary distribution of an\nergodic Markov chain given a set of sampled transitions. Classical\nsimulation-based approaches assume access to the underlying process so that\ntrajectories of sufficient length can be gathered to approximate stationary\nsampling. Instead, we consider an alternative setting where a fixed set of\ntransitions has been collected beforehand, by a separate, possibly unknown\nprocedure. The goal is still to estimate properties of the stationary\ndistribution, but without additional access to the underlying system. We\npropose a consistent estimator that is based on recovering a correction ratio\nfunction over the given data. In particular, we develop a variational power\nmethod (VPM) that provides provably consistent estimates under general\nconditions. In addition to unifying a number of existing approaches from\ndifferent subfields, we also find that VPM yields significantly better\nestimates across a range of problems, including queueing, stochastic\ndifferential equations, post-processing MCMC, and off-policy evaluation."}, {"title": "Optimal Statistical Guaratees for Adversarially Robust Gaussian Classification", "authors": "Chen Dan, Yuting Wei, Pradeep Ravikumar ", "link": "", "summary": ""}, {"title": "Generative Adversarial Imitation Learning with Neural Network Parameterization: Global Optimality and Convergence Rate", "authors": "Yufeng Zhang, Qi Cai, Zhuoran Yang, Zhaoran Wang ", "link": "https://arxiv.org/abs/2003.03709", "summary": "Generative adversarial imitation learning (GAIL) demonstrates tremendous\nsuccess in practice, especially when combined with neural networks. Different\nfrom reinforcement learning, GAIL learns both policy and reward function from\nexpert (human) demonstration. Despite its empirical success, it remains unclear\nwhether GAIL with neural networks converges to the globally optimal solution.\nThe major difficulty comes from the nonconvex-nonconcave minimax optimization\nstructure. To bridge the gap between practice and theory, we analyze a\ngradient-based algorithm with alternating updates and establish its sublinear\nconvergence to the globally optimal solution. To the best of our knowledge, our\nanalysis establishes the global optimality and convergence rate of GAIL with\nneural networks for the first time."}, {"title": "A Game Theoretic Perspective on Model-Based Reinforcement Learning", "authors": "Aravind Rajeswaran, Igor Mordatch, Vikash Kumar ", "link": "", "summary": ""}, {"title": "(Locally) Differentially Private Combinatorial Semi-Bandits", "authors": "Xiaoyu Chen, Kai Zheng, Zixin Zhou, Yunchang Yang, Wei Chen, Liwei Wang ", "link": "http://arxiv.org/abs/2006.00706", "summary": "In this paper, we study Combinatorial Semi-Bandits (CSB) that is an extension\nof classic Multi-Armed Bandits (MAB) under Differential Privacy (DP) and\nstronger Local Differential Privacy (LDP) setting. Since the server receives\nmore information from users in CSB, it usually causes additional dependence on\nthe dimension of data, which is a notorious side-effect for privacy preserving\nlearning. However for CSB under two common smoothness assumptions\n\\cite{kveton2015tight,chen2016combinatorial}, we show it is possible to remove\nthis side-effect. In detail, for $B_{\\infty}$-bounded smooth CSB under either\n$\\varepsilon$-LDP or $\\varepsilon$-DP, we prove the optimal regret bound is\n$\\Theta(\\frac{mB^2_{\\infty}\\ln T } {\\Delta\\epsilon^2})$ or\n$\\tilde{\\Theta}(\\frac{mB^2_{\\infty}\\ln T} { \\Delta\\epsilon})$ respectively,\nwhere $T$ is time period, $\\Delta$ is the gap of rewards and $m$ is the number\nof base arms, by proposing novel algorithms and matching lower bounds. For\n$B_1$-bounded smooth CSB under $\\varepsilon$-DP, we also prove the optimal\nregret bound is $\\tilde{\\Theta}(\\frac{mKB^2_1\\ln T} {\\Delta\\epsilon})$ with\nboth upper bound and lower bound, where $K$ is the maximum number of feedback\nin each round. All above results nearly match corresponding non-private optimal\nrates, which imply there is no additional price for (locally) differentially\nprivate CSB in above common settings."}, {"title": "Optimizing for the Future in Non-Stationary MDPs", "authors": "Yash Chandak, Georgios Theocharous, Shiv Shankar, Martha White, Sridhar Mahadevan, Philip Thomas "}, {"title": "Learning Task-Agnostic Embedding of Multiple Black-Box Experts for Multi-Task Model Fusion", "authors": "Nghia Hoang, Thanh Lam, Bryan Kian Hsiang Low, Patrick Jaillet  "}, {"title": "Dual-Path Distillation: A Unified Framework to Improve Black-Box Attacks", "authors": "Yonggang Zhang, Ya Li, Tongliang Liu, Xinmei Tian "}, {"title": "Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data", "authors": "Lan-Zhe Guo, Zhen-Yu Zhang, Yuan Jiang, Yufeng Li, Zhi-Hua Zhou "}, {"title": "Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data", "authors": "Marc Finzi, Samuel Stanton, Pavel Izmailov, Andrew Wilson ", "link": "https://arxiv.org/abs/2002.12880", "summary": "The translation equivariance of convolutional layers enables convolutional\nneural networks to generalize well on image problems. While translation\nequivariance provides a powerful inductive bias for images, we often\nadditionally desire equivariance to other transformations, such as rotations,\nespecially for non-image data. We propose a general method to construct a\nconvolutional layer that is equivariant to transformations from any specified\nLie group with a surjective exponential map. Incorporating equivariance to a\nnew group requires implementing only the group exponential and logarithm maps,\nenabling rapid prototyping. Showcasing the simplicity and generality of our\nmethod, we apply the same model architecture to images, ball-and-stick\nmolecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the\nequivariance of our models is especially impactful, leading to exact\nconservation of linear and angular momentum."}, {"title": "Dispersed EM-VAEs for Interpretable Text Generation", "authors": "Wenxian Shi, Hao Zhou, Ning Miao, Lei Li ", "link": "", "summary": ""}, {"title": "Deep Graph Random Process for Relational-Thinking-Based  Speech Recognition", "authors": "Huang Hengguan, Fuzhao Xue, Hao Wang, Ye Wang "}, {"title": "Hypernetwork approach to generating point clouds", "authors": "Przemys\u0142aw Spurek, Sebastian Winczowski, Jacek Tabor, Maciej Zamorski, Maciej Zieba, Tomasz Trzcinski "}, {"title": "On a projective ensemble approach to two sample test for equality of distributions", "authors": "Zhimei Li, Yaowu Zhang ", "link": "", "summary": ""}, {"title": "Coresets for Data-efficient Training of Machine Learning Models", "authors": "Baharan Mirzasoleiman, Jeff Bilmes, Jure Leskovec ", "link": "https://arxiv.org/abs/1906.01827", "summary": "Incremental gradient (IG) methods, such as stochastic gradient descent and\nits variants are commonly used for large scale optimization in machine\nlearning. Despite the sustained effort to make IG methods more data-efficient,\nit remains an open question how to select a training data subset that can\ntheoretically and practically perform on par with the full dataset. Here we\ndevelop CRAIG, a method to select a weighted subset (or coreset) of training\ndata that closely estimates the full gradient by maximizing a submodular\nfunction. We prove that applying IG to this subset is guaranteed to converge to\nthe (near)optimal solution with the same convergence rate as that of IG for\nconvex optimization. As a result, CRAIG achieves a speedup that is inversely\nproportional to the size of the subset. To our knowledge, this is the first\nrigorous method for data-efficient training of general machine learning models.\nOur extensive set of experiments show that CRAIG, while achieving practically\nthe same solution, speeds up various IG methods by up to 6x for logistic\nregression and 3x for training deep neural networks."}, {"title": "Searching to Exploit Memorization Effect in Learning from Noisy Labels", "authors": "QUANMING YAO, Hansi Yang, Bo Han, Gang Niu, James Kwok ", "link": "https://arxiv.org/abs/1911.02377", "summary": "Sample-selection approaches are popular in robust learning from noisy labels.\nHowever, how to properly control the selection process so that deep networks\ncan benefit from the memorization effect is a hard problem. In this paper,\nmotivated by the success of automated machine learning (AutoML), we model the\ncontrolling issue as a function approximation problem. Specifically, we design\na domain-specific search space based on general patterns of the memorization\neffect and propose a novel Newton algorithm to solve the bi-level optimization\nproblem efficiently. We further provide a theoretical analysis of the\nalgorithm, which ensures a good approximation to critical points. Experiments\nare performed on both benchmark and real data sets. Results demonstrate that\nthe proposed method is not only much better than the state-of-the-art noisy\nlabels learning approaches but also much more efficient than existing AutoML\nalgorithms."}, {"title": "Randomized Smoothing of All Shapes and Sizes", "authors": "Greg Yang, Tony Duan, J. Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li ", "link": "https://arxiv.org/abs/2002.08118", "summary": "Randomized smoothing is a recently proposed defense against adversarial\nattacks that has achieved state-of-the-art provable robustness against $\\ell_2$\nperturbations. Soon after, a number of works devised new randomized smoothing\nschemes for other metrics, such as $\\ell_1$ or $\\ell_\\infty$; however, for each\ngeometry, substantial effort was needed to derive new robustness guarantees.\nThis begs the question: can we find a general theory for randomized smoothing?\n  In this work we propose a novel framework for devising and analyzing\nrandomized smoothing schemes, and validate its effectiveness in practice. Our\ntheoretical contributions are as follows: (1) We show that for an appropriate\nnotion of \"optimal\", the optimal smoothing distributions for any \"nice\" norm\nhave level sets given by the *Wulff Crystal* of that norm. (2) We propose two\nnovel and complementary methods for deriving provably robust radii for any\nsmoothing distribution. Finally, (3) we show fundamental limits to current\nrandomized smoothing techniques via the theory of *Banach space cotypes*. By\ncombining (1) and (2), we significantly improve the state-of-the-art certified\naccuracy in $\\ell_1$ on standard datasets. On the other hand, using (3), we\nshow that, without more information than label statistics under random input\nperturbations, randomized smoothing cannot achieve nontrivial certified\naccuracy against perturbations of $\\ell_p$-norm $\\Omega(\\min(1,\nd^{\\frac{1}{p}-\\frac{1}{2}}))$, when the input dimension $d$ is large. We\nprovide code in github.com/tonyduan/rs4a."}, {"title": "DeepCoDA: personalized interpretability for compositional health", "authors": "Thomas Quinn, Dang Nguyen, Santu Rana, Sunil Gupta, Svetha Venkatesh ", "link": "https://arxiv.org/abs/2006.01392", "summary": "Interpretability allows the domain-expert to directly evaluate the model's\nrelevance and reliability, a practice that offers assurance and builds trust.\nIn the healthcare setting, interpretable models should implicate relevant\nbiological mechanisms independent of technical factors like data\npre-processing. We define personalized interpretability as a measure of\nsample-specific feature attribution, and view it as a minimum requirement for a\nprecision health model to justify its conclusions. Some health data, especially\nthose generated by high-throughput sequencing experiments, have nuances that\ncompromise precision health models and their interpretation. These data are\ncompositional, meaning that each feature is conditionally dependent on all\nother features. We propose the DeepCoDA framework to extend precision health\nmodelling to high-dimensional compositional data, and to provide personalized\ninterpretability through patient-specific weights. Our architecture maintains\nstate-of-the-art performance across 25 real-world data sets, all while\nproducing interpretations that are both personalized and fully coherent for\ncompositional data."}, {"title": "Private Query Release Assisted by Public Data", "authors": "Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan Ullman, Steven Wu ", "link": "https://arxiv.org/abs/2004.10941", "summary": "We study the problem of differentially private query release assisted by\naccess to public data. In this problem, the goal is to answer a large class\n$\\mathcal{H}$ of statistical queries with error no more than $\\alpha$ using a\ncombination of public and private samples. The algorithm is required to satisfy\ndifferential privacy only with respect to the private samples. We study the\nlimits of this task in terms of the private and public sample complexities.\n  First, we show that we can solve the problem for any query class\n$\\mathcal{H}$ of finite VC-dimension using only $d/\\alpha$ public samples and\n$\\sqrt{p}d^{3/2}/\\alpha^2$ private samples, where $d$ and $p$ are the\nVC-dimension and dual VC-dimension of $\\mathcal{H}$, respectively. In\ncomparison, with only private samples, this problem cannot be solved even for\nsimple query classes with VC-dimension one, and without any private samples, a\nlarger public sample of size $d/\\alpha^2$ is needed. Next, we give sample\ncomplexity lower bounds that exhibit tight dependence on $p$ and $\\alpha$. For\nthe class of decision stumps, we give a lower bound of $\\sqrt{p}/\\alpha$ on the\nprivate sample complexity whenever the public sample size is less than\n$1/\\alpha^2$. Given our upper bounds, this shows that the dependence on\n$\\sqrt{p}$ is necessary in the private sample complexity. We also give a lower\nbound of $1/\\alpha$ on the public sample complexity for a broad family of query\nclasses, which by our upper bound, is tight in $\\alpha$."}, {"title": "Adaptive Droplet Routing in Digital Microfluidic Biochips Using Deep Reinforcement Learning", "authors": "Tung-Che Liang, Zhanwei Zhong, Yaas Bigdeli, Tsung-Yi Ho, Richard Fair, Krishnendu Chakrabarty "}, {"title": "Continuous-time Lower Bounds for Gradient-based Algorithms", "authors": "Michael Muehlebach, Michael Jordan ", "link": "http://arxiv.org/abs/2002.03546", "summary": "This article derives lower bounds on the convergence rate of continuous-time\ngradient-based optimization algorithms. The algorithms are subjected to a\ntime-normalization constraint that avoids a reparametrization of time in order\nto make the discussion of continuous-time convergence rates meaningful. We\nreduce the multi-dimensional problem to a single dimension, recover well-known\nlower bounds from the discrete-time setting, and provide insights into why\nthese lower bounds occur. We further explicitly provide algorithms that achieve\nthe proposed lower bounds, even when the function class under consideration\nincludes certain non-convex functions."}, {"title": "A Tree-Structured Decoder for Image-to-Markup Generation", "authors": "Jianshu Zhang, Jun Du, Yongxin Yang, Yi-Zhe Song, Si Wei, Lirong Dai "}, {"title": "Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning", "authors": "Aleksei Petrenko, Zhehui Huang, Tushar Kumar, Gaurav Sukhatme, Vladlen Koltun "}, {"title": "Scalable Deep Generative Modeling for Sparse Graphs", "authors": "Hanjun Dai, Azade Nazi, Yujia Li, Bo Dai, Dale Schuurmans ", "link": "", "summary": ""}, {"title": "Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning", "authors": "Qing Li, Siyuan Huang, Yining Hong, Yixin Chen, Ying Nian Wu, Song-Chun Zhu ", "link": "", "summary": ""}, {"title": "NGBoost: Natural Gradient Boosting for Probabilistic Prediction", "authors": "Tony Duan, Avati Anand, Daisy Ding, Khanh K. Thai, Sanjay Basu, Andrew Ng, Alejandro Schuler "}, {"title": "Q-value Path Decomposition for Deep Multiagent Reinforcement Learning", "authors": "Yaodong Yang, Jianye Hao, Guangyong Chen, Hongyao Tang, Yingfeng Chen, Yujing Hu, Changjie Fan, Zhongyu Wei ", "link": "https://arxiv.org/abs/2002.03950", "summary": "Recently, deep multiagent reinforcement learning (MARL) has become a highly\nactive research area as many real-world problems can be inherently viewed as\nmultiagent systems. A particularly interesting and widely applicable class of\nproblems is the partially observable cooperative multiagent setting, in which a\nteam of agents learns to coordinate their behaviors conditioning on their\nprivate observations and commonly shared global reward signals. One natural\nsolution is to resort to the centralized training and decentralized execution\nparadigm. During centralized training, one key challenge is the multiagent\ncredit assignment: how to allocate the global rewards for individual agent\npolicies for better coordination towards maximizing system-level's benefits. In\nthis paper, we propose a new method called Q-value Path Decomposition (QPD) to\ndecompose the system's global Q-values into individual agents' Q-values. Unlike\nprevious works which restrict the representation relation of the individual\nQ-values and the global one, we leverage the integrated gradient attribution\ntechnique into deep MARL to directly decompose global Q-values along trajectory\npaths to assign credits for agents. We evaluate QPD on the challenging\nStarCraft II micromanagement tasks and show that QPD achieves the\nstate-of-the-art performance in both homogeneous and heterogeneous multiagent\nscenarios compared with existing cooperative MARL algorithms."}, {"title": "Online Learned Continual Compression with Adaptive Quantization Modules", "authors": "Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Joelle Pineau ", "link": "https://arxiv.org/abs/1911.08019", "summary": "We introduce and study the problem of Online Continual Compression, where one\nattempts to simultaneously learn to compress and store a representative dataset\nfrom a non i.i.d data stream, while only observing each sample once. A naive\napplication of auto-encoders in this setting encounters a major challenge:\nrepresentations derived from earlier encoder states must be usable by later\ndecoder states. We show how to use discrete auto-encoders to effectively\naddress this challenge and introduce Adaptive Quantization Modules (AQM) to\ncontrol variation in the compression ability of the module at any given stage\nof learning. This enables selecting an appropriate compression for incoming\nsamples, while taking into account overall memory constraints and current\nprogress of the learned compression. Unlike previous methods, our approach does\nnot require any pretraining, even on challenging datasets. We show that using\nAQM to replace standard episodic memory in continual learning settings leads to\nsignificant gains on continual learning benchmarks. Furthermore we demonstrate\nthis approach with larger images, LiDAR, and reinforcement learning agents."}, {"title": "Learning What to Defer for Maximum Independent Sets", "authors": "Sung-Soo Ahn, Younggyo Seo, Jinwoo Shin "}, {"title": "Generalized and Scalable Optimal Sparse Decision Trees", "authors": "Jimmy Lin, Chudi Zhong, Diane Hu, Cynthia Rudin, Margo Seltzer "}, {"title": "The Effect of Natural Distribution Shift on Question Answering Models", "authors": "John Miller, Karl Krauth, Ludwig Schmidt, Benjamin Recht ", "link": "https://arxiv.org/abs/2004.14444", "summary": "We build four new test sets for the Stanford Question Answering Dataset\n(SQuAD) and evaluate the ability of question-answering systems to generalize to\nnew data. Our first test set is from the original Wikipedia domain and measures\nthe extent to which existing systems overfit the original test set. Despite\nseveral years of heavy test set re-use, we find no evidence of adaptive\noverfitting. The remaining three test sets are constructed from New York Times\narticles, Reddit posts, and Amazon product reviews and measure robustness to\nnatural distribution shifts. Across a broad range of models, we observe average\nperformance drops of 3.8, 14.0, and 17.4 F1 points, respectively. In contrast,\na strong human baseline matches or exceeds the performance of SQuAD models on\nthe original domain and exhibits little to no drop in new domains. Taken\ntogether, our results confirm the surprising resilience of the holdout method\nand emphasize the need to move towards evaluation metrics that incorporate\nrobustness to natural distribution shifts."}, {"title": "Quantized Decentralized Stochastic Learning over Directed Graphs", "authors": "Hossein Taheri, Aryan Mokhtari, Hamed Hassani, Ramtin Pedarsani ", "link": "", "summary": ""}, {"title": "Semi-Supervised Learning with Normalizing Flows", "authors": "Pavel Izmailov, Polina Kirichenko, Marc Finzi, Andrew Wilson ", "link": "https://arxiv.org/abs/1912.13025", "summary": "Normalizing flows transform a latent distribution through an invertible\nneural network for a flexible and pleasingly simple approach to generative\nmodelling, while preserving an exact likelihood. We propose FlowGMM, an\nend-to-end approach to generative semi supervised learning with normalizing\nflows, using a latent Gaussian mixture model. FlowGMM is distinct in its\nsimplicity, unified treatment of labelled and unlabelled data with an exact\nlikelihood, interpretability, and broad applicability beyond image data. We\nshow promising results on a wide range of applications, including AG-News and\nYahoo Answers text data, tabular data, and semi-supervised image\nclassification. We also show that FlowGMM can discover interpretable structure,\nprovide real-time optimization-free feature visualizations, and specify well\ncalibrated predictive distributions."}, {"title": "Student Specialization in Deep Rectified Networks With Finite Width and Input Dimension", "authors": "Yuandong Tian ", "link": "https://arxiv.org/abs/1909.13458", "summary": "To analyze deep ReLU network, we adopt a student-teacher setting in which an\nover-parameterized student network learns from the output of a fixed teacher\nnetwork of the same depth, with Stochastic Gradient Descent (SGD). Our\ncontributions are two-fold. First, we prove that when the gradient is small at\nevery training sample, student node \\emph{specializes} to teacher nodes in the\nlowest layer under mild conditions. Second, analysis of noisy recovery and\ntraining dynamics in 2-layer network shows that strong teacher nodes (with\nlarge fan-out weights) are learned first and subtle teacher nodes are left\nunlearned until late stage of training. As a result, it could take a long time\nto converge into these small-gradient critical points. Our analysis shows that\nover-parameterization is a necessary condition for specialization to happen at\nthe critical points, and helps student nodes cover more teacher nodes with\nfewer iterations. Both improve generalization. Different from Neural Tangent\nKernel and statistical mechanics approach, our approach operates on finite\nwidth, mild over-parameterization (as long as there are more student nodes than\nteacher) and finite input dimension. Experiments justify our finding. The code\nis released in https://github.com/facebookresearch/luckmatters."}, {"title": "Sample Amplification: Increasing Dataset Size even when Learning is Impossible", "authors": "Brian Axelrod, Shivam Garg, Vatsal Sharan, Gregory Valiant ", "link": "https://arxiv.org/abs/1904.12053", "summary": "Given data drawn from an unknown distribution, $D$, to what extent is it\npossible to ``amplify'' this dataset and output an even larger set of samples\nthat appear to have been drawn from $D$? We formalize this question as follows:\nan $(n,m)$ $\\text{amplification procedure}$ takes as input $n$ independent\ndraws from an unknown distribution $D$, and outputs a set of $m > n$\n``samples''. An amplification procedure is valid if no algorithm can\ndistinguish the set of $m$ samples produced by the amplifier from a set of $m$\nindependent draws from $D$, with probability greater than $2/3$. Perhaps\nsurprisingly, in many settings, a valid amplification procedure exists, even\nwhen the size of the input dataset, $n$, is significantly less than what would\nbe necessary to learn $D$ to non-trivial accuracy. Specifically we consider two\nfundamental settings: the case where $D$ is an arbitrary discrete distribution\nsupported on $\\le k$ elements, and the case where $D$ is a $d$-dimensional\nGaussian with unknown mean, and fixed covariance. In the first case, we show\nthat an $\\left(n, n + \\Theta(\\frac{n}{\\sqrt{k}})\\right)$ amplifier exists. In\nparticular, given $n=O(\\sqrt{k})$ samples from $D$, one can output a set of\n$m=n+1$ datapoints, whose total variation distance from the distribution of $m$\ni.i.d. draws from $D$ is a small constant, despite the fact that one would need\nquadratically more data, $n=\\Theta(k)$, to learn $D$ up to small constant total\nvariation distance. In the Gaussian case, we show that an\n$\\left(n,n+\\Theta(\\frac{n}{\\sqrt{d}} )\\right)$ amplifier exists, even though\nlearning the distribution to small constant total variation distance requires\n$\\Theta(d)$ samples. In both the discrete and Gaussian settings, we show that\nthese results are tight, to constant factors. Beyond these results, we\nformalize a number of curious directions for future research along this vein."}, {"title": "Alleviating Privacy Attacks via Causal Learning", "authors": "Shruti Tople, Amit Sharma, Aditya Nori ", "link": "https://arxiv.org/abs/1909.12732", "summary": "Machine learning models, especially deep neural networks have been shown to\nreveal membership information of inputs in the training data. Such membership\ninference attacks are a serious privacy concern, for example, patients\nproviding medical records to build a model that detects HIV would not want\ntheir identity to be leaked. Further, we show that the attack accuracy\namplifies when the model is used to predict samples that come from a different\ndistribution than the training set, which is often the case in real world\napplications. Therefore, we propose the use of causal learning approaches where\na model learns the causal relationship between the input features and the\noutcome. An ideal causal model is known to be invariant to the training\ndistribution and hence generalizes well to shifts between samples from the same\ndistribution and across different distributions. First, we prove that models\nlearned using causal structure provide stronger differential privacy guarantees\nthan associational models under reasonable assumptions. Next, we show that\ncausal models trained on sufficiently large samples are robust to membership\ninference attacks across different distributions of datasets and those trained\non smaller sample sizes always have lower attack accuracy than corresponding\nassociational models. Finally, we confirm our theoretical claims with\nexperimental evaluation on 4 moderately complex Bayesian network datasets and a\ncolored MNIST image dataset. Associational models exhibit upto 80\\% attack\naccuracy under different test distributions and sample sizes whereas causal\nmodels exhibit attack accuracy close to a random guess. Our results confirm the\nvalue of the generalizability of causal models in reducing susceptibility to\nprivacy attacks."}, {"title": "The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation", "authors": "Zhe Feng, David Parkes, Haifeng Xu ", "link": "https://arxiv.org/abs/1906.01528", "summary": "We study the behavior of stochastic bandits algorithms under \\emph{strategic\nbehavior} conducted by rational actors, i.e., the arms. Each arm is a strategic\nplayer who can modify its own reward whenever pulled, subject to a cross-period\nbudget constraint. Each arm is \\emph{self-interested} and seeks to maximize its\nown expected number of times of being pulled over a decision horizon. Strategic\nmanipulations naturally arise in various economic applications, e.g.,\nrecommendation systems such as Yelp and Amazon. We analyze the robustness of\nthree popular bandit algorithms: UCB, $\\varepsilon$-Greedy, and Thompson\nSampling. We prove that all three algorithms achieve a regret upper bound\n$\\mathcal{O}(\\max \\{ B, \\ln T\\})$ under \\emph{any} (possibly adaptive) strategy\nof the strategic arms, where $B$ is the total budget across arms. Moreover, we\nprove that our regret upper bound is \\emph{tight}. Our results illustrate the\nintrinsic robustness of bandits algorithms against strategic manipulation so\nlong as $B=o(T)$. This is in sharp contrast to the more pessimistic model of\nadversarial attacks where an attack budget of $\\mathcal{O}(\\ln T) $ can trick\nUCB and $\\varepsilon$-Greedy to pull the optimal arm only $o(T)$ number of\ntimes. Our results hold for both bounded and unbounded rewards."}, {"title": "Normalized Flat Minima: Exploring Scale Invariant Definition of Flat Minima for Neural Networks Using PAC-Bayesian Analysis", "authors": "Yusuke Tsuzuku, Issei Sato, Masashi Sugiyama ", "link": "https://arxiv.org/abs/1901.04653", "summary": "The notion of flat minima has played a key role in the generalization studies\nof deep learning models. However, existing definitions of the flatness are\nknown to be sensitive to the rescaling of parameters. The issue suggests that\nthe previous definitions of the flatness might not be a good measure of\ngeneralization, because generalization is invariant to such rescalings. In this\npaper, from the PAC-Bayesian perspective, we scrutinize the discussion\nconcerning the flat minima and introduce the notion of normalized flat minima,\nwhich is free from the known scale dependence issues. Additionally, we\nhighlight the scale dependence of existing matrix-norm based generalization\nerror bounds similar to the existing flat minima definitions. Our modified\nnotion of the flatness does not suffer from the insufficiency, either,\nsuggesting it might provide better hierarchy in the hypothesis class."}, {"title": "Fiedler Regularization: Learning Neural Networks with Graph Sparsity", "authors": "Edric Tam, David Dunson ", "link": "https://arxiv.org/abs/2003.00992", "summary": "We introduce a novel regularization approach for deep learning that\nincorporates and respects the underlying graphical structure of the neural\nnetwork. Existing regularization methods often focus on dropping/penalizing\nweights in a global manner that ignores the connectivity structure of the\nneural network. We propose to use the Fiedler value of the neural network's\nunderlying graph as a tool for regularization. We provide theoretical support\nfor this approach via spectral graph theory. We list several useful properties\nof the Fiedler value that makes it suitable in regularization. We provide an\napproximate, variational approach for fast computation in practical training of\nneural networks. We provide bounds on such approximations. We provide an\nalternative but equivalent formulation of this framework in the form of a\nstructurally weighted L1 penalty, thus linking our approach to sparsity\ninduction. We performed experiments on datasets that compare Fiedler\nregularization with traditional regularization methods such as dropout and\nweight decay. Results demonstrate the efficacy of Fiedler regularization."}, {"title": "Online Learning with Imperfect Hints", "authors": "Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, Manish Purohit ", "link": "https://arxiv.org/abs/2002.04726", "summary": "We consider a variant of the classical online linear optimization problem in\nwhich at every step, the online player receives a \"hint\" vector before choosing\nthe action for that round. Rather surprisingly, it was shown that if the hint\nvector is guaranteed to have a positive correlation with the cost vector, then\nthe online player can achieve a regret of $O(\\log T)$, thus significantly\nimproving over the $O(\\sqrt{T})$ regret in the general setting. However, the\nresult and analysis require the correlation property at \\emph{all} time steps,\nthus raising the natural question: can we design online learning algorithms\nthat are resilient to bad hints?\n  In this paper we develop algorithms and nearly matching lower bounds for\nonline learning with imperfect directional hints. Our algorithms are oblivious\nto the quality of the hints, and the regret bounds interpolate between the\nalways-correlated hints case and the no-hints case. Our results also\ngeneralize, simplify, and improve upon previous results on optimistic regret\nbounds, which can be viewed as an additive version of hints."}, {"title": "Rate-distortion optimization guided autoencoder for isometric embedding in Euclidean latent space", "authors": "Keizo Kato, Jing Zhou, Tomotake Sasaki, Akira Nakagawa ", "link": "https://arxiv.org/abs/1910.04329", "summary": "To analyze high-dimensional and complex data in the real world, generative\nmodel approach of machine learning aims to reduce the dimension and acquire a\nprobabilistic model of the data. For this purpose, deep-autoencoder based\ngenerative models such as variational autoencoder (VAE) have been proposed.\nHowever, in previous works, the scale of metrics between the real and the\nreduced-dimensional space(latent space) is not well-controlled. Therefore, the\nquantitative impact of the latent variable on real data is unclear. In the end,\nthe probability distribution function (PDF) in the real space cannot be\nestimated from that of the latent space accurately. To overcome this problem,\nwe propose Rate-Distortion Optimization guided autoencoder. We show our method\nhas the following properties theoretically and experimentally: (i) the columns\nof Jacobian matrix between two spaces is constantly-scaled orthonormal system\nand data can be embedded in a Euclidean space isometrically; (ii) the PDF of\nthe latent space is proportional to that of the real space. Furthermore, to\nverify the usefulness in the practical application, we evaluate its performance\nin unsupervised anomaly detection and it outperforms current state-of-the-art\nmethods."}, {"title": "Optimization from Structured Samples for Coverage Functions", "authors": "Wei Chen, Xiaoming Sun, Jialin Zhang, Zhijie Zhang "}, {"title": "Optimal Randomized First-Order Methods for Least-Squares Problems", "authors": "Jonathan Lacotte, Mert Pilanci ", "link": "https://arxiv.org/abs/2002.09488", "summary": "We provide an exact analysis of a class of randomized algorithms for solving\noverdetermined least-squares problems. We consider first-order methods, where\nthe gradients are pre-conditioned by an approximation of the Hessian, based on\na subspace embedding of the data matrix. This class of algorithms encompasses\nseveral randomized methods among the fastest solvers for least-squares\nproblems. We focus on two classical embeddings, namely, Gaussian projections\nand subsampled randomized Hadamard transforms (SRHT). Our key technical\ninnovation is the derivation of the limiting spectral density of SRHT\nembeddings. Leveraging this novel result, we derive the family of normalized\northogonal polynomials of the SRHT density and we find the optimal\npre-conditioned first-order method along with its rate of convergence. Our\nanalysis of Gaussian embeddings proceeds similarly, and leverages classical\nrandom matrix theory results. In particular, we show that for a given sketch\nsize, SRHT embeddings exhibits a faster rate of convergence than Gaussian\nembeddings. Then, we propose a new algorithm by optimizing the computational\ncomplexity over the choice of the sketching dimension. To our knowledge, our\nresulting algorithm yields the best known complexity for solving least-squares\nproblems with no condition number dependence."}, {"title": "Stochastic Optimization for Non-convex Inf-Projection Problems", "authors": "Yan Yan, Yi Xu  Inc., Lijun Zhang, Wang Xiaoyu, Tianbao Yang ", "link": "https://arxiv.org/abs/1908.09941", "summary": "In this paper, we study a family of non-convex and possibly non-smooth\ninf-projection minimization problems, where the target objective function is\nequal to minimization of a joint function over another variable. This problem\nincludes difference of convex (DC) functions and a family of bi-convex\nfunctions as special cases. We develop stochastic algorithms and establish\ntheir first-order convergence for finding a (nearly) stationary solution of the\ntarget non-convex function under different conditions of the component\nfunctions. To the best of our knowledge, this is the first work that\ncomprehensively studies stochastic optimization of non-convex inf-projection\nminimization problems with provable convergence guarantee. Our algorithms\nenable efficient stochastic optimization of a family of non-decomposable DC\nfunctions and a family of bi-convex functions. To demonstrate the power of the\nproposed algorithms we consider an important application in variance-based\nregularization, and experiments verify the effectiveness of our inf-projection\nbased formulation and the proposed stochastic algorithm in comparison with\nprevious stochastic algorithms based on the min-max formulation for achieving\nthe same effect."}, {"title": "Convex Representation Learning for Generalized Invariance in Semi-Inner-Product Space", "authors": "Yingyi Ma, Vignesh Ganapathiraman, Yaoliang Yu, Xinhua Zhang ", "link": "https://arxiv.org/abs/2004.12209", "summary": "Invariance (defined in a general sense) has been one of the most effective\npriors for representation learning. Direct factorization of parametric models\nis feasible only for a small range of invariances, while regularization\napproaches, despite improved generality, lead to nonconvex optimization. In\nthis work, we develop a convex representation learning algorithm for a variety\nof generalized invariances that can be modeled as semi-norms. It is much more\nefficient than Haar kernels and distributionally robust methods. Our approach\nis based on Euclidean embeddings of kernel representers in a semi-inner-product\nspace, and experimental results confirm its effectiveness in learning invariant\nrepresentations and making accurate predictions."}, {"title": "Neural Kernels Without Tangents", "authors": "Vaishaal Shankar, Alex Fang, Wenshuo Guo, Sara Fridovich-Keil, Jonathan Ragan-Kelley, Ludwig Schmidt, Benjamin Recht ", "link": "https://arxiv.org/abs/2003.02237", "summary": "We investigate the connections between neural networks and simple building\nblocks in kernel space. In particular, using well established feature space\ntools such as direct sum, averaging, and moment lifting, we present an algebra\nfor creating \"compositional\" kernels from bags of features. We show that these\noperations correspond to many of the building blocks of \"neural tangent kernels\n(NTK)\". Experimentally, we show that there is a correlation in test error\nbetween neural network architectures and the associated kernels. We construct a\nsimple neural network architecture using only 3x3 convolutions, 2x2 average\npooling, ReLU, and optimized with SGD and MSE loss that achieves 96% accuracy\non CIFAR10, and whose corresponding compositional kernel achieves 90% accuracy.\nWe also use our constructions to investigate the relative performance of neural\nnetworks, NTKs, and compositional kernels in the small dataset regime. In\nparticular, we find that compositional kernels outperform NTKs and neural\nnetworks outperform both kernel methods."}, {"title": "Linear Lower Bounds and Conditioning of Differentiable Games", "authors": "Adam Ibrahim, Wa\u00efss Azizian, Gauthier Gidel, Ioannis Mitliagkas ", "link": "https://arxiv.org/abs/1906.07300", "summary": "Recent successes of game-theoretic formulations in ML have caused a\nresurgence of research interest in differentiable games. Overwhelmingly, that\nresearch focuses on methods and upper bounds. In this work, we approach the\nquestion of fundamental iteration complexity by providing lower bounds to\ncomplement the linear (i.e. geometric) upper bounds observed in the literature\non a wide class of problems. We cast saddle-point and min-max problems as\n2-player games. We leverage tools from single-objective convex optimisation to\npropose new linear lower bounds for convex-concave games. Notably, we give a\nlinear lower bound for $n$-player differentiable games, by using the spectral\nproperties of the update operator. We then propose a new definition of the\ncondition number arising from our lower bound analysis. Unlike past\ndefinitions, our condition number captures the fact that linear rates are\npossible in games, even in the absence of strong convex-concavity."}, {"title": "Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games", "authors": "Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos, Michael Jordan ", "link": "https://arxiv.org/abs/2002.09806", "summary": "We consider multi-agent learning via online gradient descent (OGD) in a class\nof games called $\\lambda$-cocoercive games, a broad class of games that admits\nmany Nash equilibria and that properly includes strongly monotone games. We\ncharacterize the finite-time last-iterate convergence rate for joint OGD\nlearning on $\\lambda$-cocoercive games; further, building on this result, we\ndevelop a fully adaptive OGD learning algorithm that does not require any\nknowledge of the problem parameter (e.g., the cocoercive constant $\\lambda$)\nand show, via a novel double-stopping-time technique, that this adaptive\nalgorithm achieves the same finite-time last-iterate convergence rate as its\nnon-adaptive counterpart. Subsequently, we extend OGD learning to the noisy\ngradient feedback case and establish last-iterate convergence results---first\nqualitative almost sure convergence, then quantitative finite-time convergence\nrates---all under non-decreasing step-sizes. These results fill in several gaps\nin the existing multi-agent online learning literature, where three\naspects---finite-time convergence rates, non-decreasing step-sizes, and fully\nadaptive algorithms---have not been previously explored."}, {"title": "Communication-Efficient Distributed PCA by Riemannian Optimization", "authors": "Long-Kai Huang, Jialin Pan ", "link": "", "summary": ""}, {"title": "Manifold Identification for Ultimately Communication-Efficient Distributed Optimization", "authors": "Yu-Sheng Li, Wei-Lin Chiang, Ching-pei Lee ", "link": "", "summary": ""}, {"title": "When Demands Evolve Larger and Noisier: Learning and Earning in a Growing Environment", "authors": "Feng Zhu, Zeyu Zheng "}, {"title": "Being Bayesian about Categorical Probability", "authors": "Taejong Joo, Uijung Chung, Min-Gwan Seo ", "link": "https://arxiv.org/abs/2002.07965", "summary": "Neural networks utilize the softmax as a building block in classification\ntasks, which contains an overconfidence problem and lacks an uncertainty\nrepresentation ability. As a Bayesian alternative to the softmax, we consider a\nrandom variable of a categorical probability over class labels. In this\nframework, the prior distribution explicitly models the presumed noise inherent\nin the observed label, which provides consistent gains in generalization\nperformance in multiple challenging tasks. The proposed method inherits\nadvantages of Bayesian approaches that achieve better uncertainty estimation\nand model calibration. Our method can be implemented as a plug-and-play loss\nfunction with negligible computational overhead compared to the softmax with\nthe cross-entropy loss function."}, {"title": "Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning", "authors": "Kimin Lee, Younggyo Seo, Seunghyun Lee, Honglak Lee, Jinwoo Shin ", "link": "https://arxiv.org/abs/2005.06800", "summary": "Model-based reinforcement learning (RL) enjoys several benefits, such as\ndata-efficiency and planning, by learning a model of the environment's\ndynamics. However, learning a global model that can generalize across different\ndynamics is a challenging task. To tackle this problem, we decompose the task\nof learning a global dynamics model into two stages: (a) learning a context\nlatent vector that captures the local dynamics, then (b) predicting the next\nstate conditioned on it. In order to encode dynamics-specific information into\nthe context latent vector, we introduce a novel loss function that encourages\nthe context latent vector to be useful for predicting both forward and backward\ndynamics. The proposed method achieves superior generalization ability across\nvarious simulated robotics and control tasks, compared to existing RL schemes."}, {"title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "authors": "Pasquale Minervini, Tim Rockt\u00e4schel, Sebastian Riedel, Edward Grefenstette, Pontus Stenetorp ", "link": "", "summary": ""}, {"title": "Fast and Private Submodular and $k$-Submodular Functions Maximization with Matroid Constraints", "authors": "Akbar Rafiey, Yuichi Yoshida ", "link": "", "summary": ""}, {"title": "Streaming Coresets for Symmetric Tensor Factorization", "authors": "Supratim Shit, Anirban Dasgupta, Rachit Chhaya, Jayesh Choudhari ", "link": "http://arxiv.org/abs/2006.01225", "summary": "Factorizing tensors has recently become an important optimization module in a\nnumber of machine learning pipelines, especially in latent variable models. We\nshow how to do this efficiently in the streaming setting. Given a set of $n$\nvectors, each in $\\mathbb{R}^d$, we present algorithms to select a sublinear\nnumber of these vectors as coreset, while guaranteeing that the CP\ndecomposition of the $p$-moment tensor of the coreset approximates the\ncorresponding decomposition of the $p$-moment tensor computed from the full\ndata. We introduce two novel algorithmic techniques: online filtering and\nkernelization. Using these two, we present four algorithms that achieve\ndifferent tradeoffs of coreset size, update time and working space, beating or\nmatching various state of the art algorithms. In case of matrices (2-ordered\ntensor) our online row sampling algorithm guarantees $(1 \\pm \\epsilon)$\nrelative error spectral approximation. We show applications of our algorithms\nin learning single topic modeling."}, {"title": "How Good is the Bayes Posterior in Deep Neural Networks Really?", "authors": "Florian Wenzel, Kevin Roth, Bastiaan Veeling, Jakub Swiatkowski, Linh Tran, Stephan Mandt, Jasper Snoek, Tim Salimans, Rodolphe Jenatton, Sebastian Nowozin ", "link": "https://arxiv.org/abs/2002.02405", "summary": "During the past five years the Bayesian deep learning community has developed\nincreasingly accurate and efficient approximate inference procedures that allow\nfor Bayesian inference in deep neural networks. However, despite this\nalgorithmic progress and the promise of improved uncertainty quantification and\nsample efficiency there are---as of early 2020---no publicized deployments of\nBayesian neural networks in industrial practice. In this work we cast doubt on\nthe current understanding of Bayes posteriors in popular deep neural networks:\nwe demonstrate through careful MCMC sampling that the posterior predictive\ninduced by the Bayes posterior yields systematically worse predictions compared\nto simpler methods including point estimates obtained from SGD. Furthermore, we\ndemonstrate that predictive performance is improved significantly through the\nuse of a \"cold posterior\" that overcounts evidence. Such cold posteriors\nsharply deviate from the Bayesian paradigm but are commonly used as heuristic\nin Bayesian deep learning papers. We put forward several hypotheses that could\nexplain cold posteriors and evaluate the hypotheses through experiments. Our\nwork questions the goal of accurate posterior approximations in Bayesian deep\nlearning: If the true Bayes posterior is poor, what is the use of more accurate\napproximations? Instead, we argue that it is timely to focus on understanding\nthe origin of the improved performance of cold posteriors."}, {"title": "Optimally Solving Two-Agent Decentralized POMDPs Under One-Sided Information Sharing ", "authors": "Yuxuan Xie, Jilles Dibangoye, Olivier Buffet "}, {"title": "Learning Algebraic Multigrid Using Graph Neural Networks", "authors": "Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh ", "link": "https://arxiv.org/abs/2003.05744", "summary": "Efficient numerical solvers for sparse linear systems are crucial in science\nand engineering. One of the fastest methods for solving large-scale sparse\nlinear systems is algebraic multigrid (AMG). The main challenge in the\nconstruction of AMG algorithms is the selection of the prolongation operator --\na problem-dependent sparse matrix which governs the multiscale hierarchy of the\nsolver and is critical to its efficiency. Over many years, numerous methods\nhave been developed for this task, and yet there is no known single right\nanswer except in very special cases. Here we propose a framework for learning\nAMG prolongation operators for linear systems with sparse symmetric positive\n(semi-) definite matrices. We train a single graph neural network to learn a\nmapping from an entire class of such matrices to prolongation operators, using\nan efficient unsupervised loss function. Experiments on a broad class of\nproblems demonstrate improved convergence rates compared to classical AMG,\ndemonstrating the potential utility of neural networks for developing sparse\nsystem solvers."}, {"title": "Fractal Gaussian Networks: A sparse random graph model based on Gaussian Multiplicative Chaos", "authors": "Subhroshekhar Ghosh, Krishna Balasubramanian, Xiaochuan Yang ", "link": "", "summary": ""}, {"title": "Structured Policy Iteration for Linear Quadratic Regulator", "authors": "Youngsuk Park, Ryan Rossi, Zheng Wen, Gang Wu, Handong Zhao ", "link": "", "summary": ""}, {"title": "T-GD: Transferable GAN-generated Images Detection Framework", "authors": "Hyeonseong Jeon, Young Oh Bang, Junyaup Kim, Simon Woo "}, {"title": "Low Bias Low Variance Gradient Estimates for Hierarchical Boolean Stochastic Networks", "authors": "Adeel Pervez, Taco Cohen, Efstratios Gavves "}, {"title": "Learning Flat Latent Manifolds with VAEs", "authors": "Nutan Chen, Alexej Klushyn, Francesco Ferroni, Justin Bayer, Patrick van der Smagt ", "link": "https://arxiv.org/abs/2002.04881", "summary": "Measuring the similarity between data points often requires domain knowledge.\nThis can in parts be compensated by relying on unsupervised methods such as\nlatent-variable models, where similarity/distance is estimated in a more\ncompact latent space. Prevalent is the use of the Euclidean metric, which has\nthe drawback of ignoring information about similarity of data stored in the\ndecoder, as captured by the framework of Riemannian geometry.\nAlternatives---such as approximating the geodesic---are often computationally\ninefficient, rendering the methods impractical. We propose an extension to the\nframework of variational auto-encoders allows learning flat latent manifolds,\nwhere the Euclidean metric is a proxy for the similarity between data points.\nThis is achieved by defining the latent space as a Riemannian manifold and by\nregularising the metric tensor to be a scaled identity matrix. Additionally, we\nreplace the compact prior typically used in variational auto-encoders with a\nrecently presented, more expressive hierarchical one---and formulate the\nlearning problem as a constrained optimisation problem. We evaluate our method\non a range of data-sets, including a video-tracking benchmark, where the\nperformance of our unsupervised approach nears that of state-of-the-art\nsupervised approaches, while retaining the computational efficiency of\nstraight-line-based approaches."}, {"title": "Multi-Task Learning with User Preferences: Gradient Descent with Controlled Ascent in Pareto Optimization", "authors": "Debabrata Mahapatra, Vaibhav Rajan "}, {"title": "Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources", "authors": "Yun Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho "}, {"title": "On Coresets for Regularized Regression", "authors": "Rachit Chhaya, Supratim Shit, Anirban Dasgupta ", "link": "", "summary": ""}, {"title": "Budgeted Online Influence Maximization", "authors": "Pierre Perrault, Zheng Wen, Michal Valko, Jennifer Healey "}, {"title": "On the (In)tractability of Computing Normalizing Constants for the Product of Determinantal Point Processes", "authors": "Naoto Ohsaka, Tatsuya Matsuoka "}, {"title": "Monte-Carlo Tree Search as Regularized Policy Optimization", "authors": "Jean-Bastien Grill, Florent Altch\u00e9, Yunhao Tang, Thomas Hubert, Michal Valko, Ioannis Antonoglou, Remi Munos ", "link": "", "summary": ""}, {"title": "On the Expressivity of Neural Networks for Deep Reinforcement Learning", "authors": "Kefan Dong, Yuping Luo, Tianhe Yu, Chelsea Finn, Tengyu Ma "}, {"title": "The k-tied Normal Distribution: A Compact Parameterization of Gaussian Mean Field Posteriors in Bayesian Neural Networks", "authors": "Jakub Swiatkowski, Kevin Roth, Bastiaan Veeling, Linh Tran, Joshua V Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Rodolphe Jenatton, Sebastian Nowozin ", "link": "http://arxiv.org/abs/2002.02655", "summary": "Variational Bayesian Inference is a popular methodology for approximating\nposterior distributions over Bayesian neural network weights. Recent work\ndeveloping this class of methods has explored ever richer parameterizations of\nthe approximate posterior in the hope of improving performance. In contrast,\nhere we share a curious experimental finding that suggests instead restricting\nthe variational distribution to a more compact parameterization. For a variety\nof deep Bayesian neural networks trained using Gaussian mean-field variational\ninference, we find that the posterior standard deviations consistently exhibit\nstrong low-rank structure after convergence. This means that by decomposing\nthese variational parameters into a low-rank factorization, we can make our\nvariational approximation more compact without decreasing the models'\nperformance. Furthermore, we find that such factorized parameterizations\nimprove the signal-to-noise ratio of stochastic gradient estimates of the\nvariational lower bound, resulting in faster convergence."}, {"title": "A Generative Model for Molecular Distance Geometry", "authors": "Gregor Simm, Jose Hernandez-Lobato ", "link": "https://arxiv.org/abs/1909.11459", "summary": "Computing equilibrium states for many-body systems, such as molecules, is a\nlong-standing challenge. In the absence of methods for generating statistically\nindependent samples, great computational effort is invested in simulating these\nsystems using, for example, Markov chain Monte Carlo. We present a\nprobabilistic model that generates such samples for molecules from their graph\nrepresentations. Our model learns a low-dimensional manifold that preserves the\ngeometry of local atomic neighborhoods through a principled learning\nrepresentation that is based on Euclidean distance geometry. In a new benchmark\nfor molecular conformation generation, we show experimentally that our\ngenerative model achieves state-of-the-art accuracy. Finally, we show how to\nuse our model as a proposal distribution in an importance sampling scheme to\ncompute molecular properties."}, {"title": "Why bigger is not always better: on finite and infinite neural networks", "authors": "Laurence Aitchison ", "link": "https://arxiv.org/abs/1910.08013", "summary": "Recent work has shown that the outputs of convolutional neural networks\nbecome Gaussian process (GP) distributed when we take the number of channels to\ninfinity. In principle, these infinite networks should perform very well, both\nbecause they allow for exact Bayesian inference, and because widening networks\nis generally thought to improve (or at least not diminish) performance.\nHowever, Bayesian infinite networks perform poorly in comparison to finite\nnetworks, and our goal here is to explain this discrepancy. We note that the\nhigh-level representation induced by an infinite network has very little\nflexibility; it depends only on network hyperparameters such as depth, and as\nsuch cannot learn a good high-level representation of data. In contrast, finite\nnetworks correspond to a rich prior over high-level representations,\ncorresponding to kernel hyperparameters. We analyse this flexibility from the\nperspective of the prior (looking at the structured prior covariance of the\ntop-level kernel), and from the perspective of the posterior, showing that the\nrepresentation in a learned, finite deep linear network slowly transitions from\nthe kernel induced by the inputs towards the kernel induced by the outputs,\nboth for gradient descent, and for Langevin sampling. Finally, we explore\nrepresentation learning in deep, convolutional, nonlinear networks, showing\nthat learned representations differ dramatically from the corresponding\ninfinite network."}, {"title": "Data-Efficient Image Recognition with Contrastive Predictive Coding", "authors": "Olivier Henaff ", "link": "https://arxiv.org/abs/1905.09272", "summary": "Human observers can learn to recognize new categories of images from a\nhandful of examples, yet doing so with machine perception remains an open\nchallenge. We hypothesize that data-efficient recognition is enabled by\nrepresentations which make the variability in natural signals more predictable.\nWe therefore revisit and improve Contrastive Predictive Coding, an unsupervised\nobjective for learning such representations. This new implementation produces\nfeatures which support state-of-the-art linear classification accuracy on the\nImageNet dataset. When used as input for non-linear classification with deep\nneural networks, this representation allows us to use 2-5x less labels than\nclassifiers trained directly on image pixels. Finally, this unsupervised\nrepresentation substantially improves transfer learning to object detection on\nPASCAL VOC-2007, surpassing fully supervised pre-trained ImageNet classifiers."}, {"title": "Intrinsic Reward Driven Imitation Learning via Generative Model", "authors": "Xingrui Yu, Yueming LYU, Ivor Tsang "}, {"title": "Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?", "authors": "Kei Ota, Tomoaki Oiki, Devesh Jha, Toshisada Mariyama, Daniel Nikovski ", "link": "https://arxiv.org/abs/2003.01629", "summary": "Deep reinforcement learning (RL) algorithms have recently achieved remarkable\nsuccesses in various sequential decision making tasks, leveraging advances in\nmethods for training large deep networks. However, these methods usually\nrequire large amounts of training data, which is often a big problem for\nreal-world applications. One natural question to ask is whether learning good\nrepresentations for states and using larger networks helps in learning better\npolicies. In this paper, we try to study if increasing input dimensionality\nhelps improve performance and sample efficiency of model-free deep RL\nalgorithms. To do so, we propose an online feature extractor network (OFENet)\nthat uses neural nets to produce good representations to be used as inputs to\ndeep RL algorithms. Even though the high dimensionality of input is usually\nsupposed to make learning of RL agents more difficult, we show that the RL\nagents in fact learn more efficiently with the high-dimensional representation\nthan with the lower-dimensional state observations. We believe that stronger\nfeature propagation together with larger networks (and thus larger search\nspace) allows RL agents to learn more complex functions of states and thus\nimproves the sample efficiency. Through numerical experiments, we show that the\nproposed method outperforms several other state-of-the-art algorithms in terms\nof both sample efficiency and performance."}, {"title": "Batch Reinforcement Learning with Hyperparameter  Gradients", "authors": "Byung-Jun Lee, Jongmin Lee, Peter Vrancx, Dongho Kim, Kee-Eung Kim "}, {"title": "Sub-Goal Trees -- a Framework for Goal-Based Reinforcement Learning", "authors": "Tom Jurgenson, Or Avner, Edward Groshev, Aviv Tamar ", "link": "https://arxiv.org/abs/2002.12361", "summary": "Many AI problems, in robotics and other domains, are goal-based, essentially\nseeking trajectories leading to various goal states. Reinforcement learning\n(RL), building on Bellman's optimality equation, naturally optimizes for a\nsingle goal, yet can be made multi-goal by augmenting the state with the goal.\nInstead, we propose a new RL framework, derived from a dynamic programming\nequation for the all pairs shortest path (APSP) problem, which naturally solves\nmulti-goal queries. We show that this approach has computational benefits for\nboth standard and approximate dynamic programming. Interestingly, our\nformulation prescribes a novel protocol for computing a trajectory: instead of\npredicting the next state given its predecessor, as in standard RL, a\ngoal-conditioned trajectory is constructed by first predicting an intermediate\nstate between start and goal, partitioning the trajectory into two. Then,\nrecursively, predicting intermediate points on each sub-segment, until a\ncomplete trajectory is obtained. We call this trajectory structure a sub-goal\ntree. Building on it, we additionally extend the policy gradient methodology to\nrecursively predict sub-goals, resulting in novel goal-based algorithms.\nFinally, we apply our method to neural motion planning, where we demonstrate\nsignificant improvements compared to standard RL on navigating a 7-DoF robot\narm between obstacles."}, {"title": "A Geometric Approach to Archetypal Analysis via Sparse Projections", "authors": "Vinayak Abrol, Pulkit Sharma "}, {"title": "Sequence Generation with Mixed Representations", "authors": "Lijun Wu, Shufang Xie, Yingce Xia, Yang Fan, Jian-Huang Lai, Tao Qin, Tie-Yan Liu "}, {"title": "Agent57: Outperforming the Atari Human Benchmark", "authors": "Adri\u00e0 Puigdomenech Badia, Bilal Piot, Steven Kapturowski, Pablo Sprechmann, Oleksandr Vitvitskyi, Zhaohan Guo, Charles Blundell "}, {"title": "RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr", "authors": "Xingjian Li, Haoyi Xiong, Haozhe An, Dejing Dou, Cheng-Zhong Xu "}, {"title": "Fairwashing explanations with off-manifold detergent", "authors": "Christopher Anders, Plamen Plasiliev, Ann-Kathrin Dombrowski, Klaus-robert Mueller, Pan Kessel ", "link": "", "summary": ""}, {"title": "Learning disconnected manifolds: a no GAN's land", "authors": "Ugo Tanielian, Jeremie Mary, Thibaut Issenhuth, Elvis Dohmatob ", "link": "", "summary": ""}, {"title": "Sets Clustering", "authors": "Ibrahim Jubran, Murad Tukan, Alaa Maalouf, Dan Feldman ", "link": "https://arxiv.org/abs/2003.04135", "summary": "The input to the \\emph{sets-$k$-means} problem is an integer $k\\geq 1$ and a\nset $\\mathcal{P}=\\{P_1,\\cdots,P_n\\}$ of sets in $\\mathbb{R}^d$. The goal is to\ncompute a set $C$ of $k$ centers (points) in $\\mathbb{R}^d$ that minimizes the\nsum $\\sum_{P\\in \\mathcal{P}} \\min_{p\\in P, c\\in C}\\left\\| p-c \\right\\|^2$ of\nsquared distances to these sets. An \\emph{$\\varepsilon$-core-set} for this\nproblem is a weighted subset of $\\mathcal{P}$ that approximates this sum up to\n$1\\pm\\varepsilon$ factor, for \\emph{every} set $C$ of $k$ centers in\n$\\mathbb{R}^d$. We prove that such a core-set of $O(\\log^2{n})$ sets always\nexists, and can be computed in $O(n\\log{n})$ time, for every input\n$\\mathcal{P}$ and every fixed $d,k\\geq 1$ and $\\varepsilon \\in (0,1)$. The\nresult easily generalized for any metric space, distances to the power of\n$z>0$, and M-estimators that handle outliers. Applying an inefficient but\noptimal algorithm on this coreset allows us to obtain the first PTAS\n($1+\\varepsilon$ approximation) for the sets-$k$-means problem that takes time\nnear linear in $n$. This is the first result even for sets-mean on the plane\n($k=1$, $d=2$). Open source code and experimental results for document\nclassification and facility locations are also provided."}, {"title": "Variational Autoencoders with Riemannian Brownian Motion Priors", "authors": "Dimitrios Kalatzis, David Eklund, Georgios Arvanitidis, S\u00f8ren Hauberg ", "link": "https://arxiv.org/abs/2002.05227", "summary": "Variational Autoencoders (VAEs) represent the given data in a low-dimensional\nlatent space, which is generally assumed to be Euclidean. This assumption\nnaturally leads to the common choice of a standard Gaussian prior over\ncontinuous latent variables. Recent work has, however, shown that this prior\nhas a detrimental effect on model capacity, leading to subpar performance. We\npropose that the Euclidean assumption lies at the heart of this failure mode.\nTo counter this, we assume a Riemannian structure over the latent space, which\nconstitutes a more principled geometric view of the latent codes, and replace\nthe standard Gaussian prior with a Riemannian Brownian motion prior. We propose\nan efficient inference scheme that does not rely on the unknown normalizing\nfactor of this prior. Finally, we demonstrate that this prior significantly\nincreases model capacity using only one additional scalar parameter."}, {"title": "Non-separable Non-stationary random fields", "authors": "Kangrui Wang, Oliver A Hamelijnck, Theodoros Damoulas, Mark Steel "}, {"title": "Nonparametric Score Estimators", "authors": "Yuhao Zhou, Jiaxin Shi, Jun Zhu ", "link": "https://arxiv.org/abs/2005.10099", "summary": "Estimating the score, i.e., the gradient of log density function, from a set\nof samples generated by an unknown distribution is a fundamental task in\ninference and learning of probabilistic models that involve flexible yet\nintractable densities. Kernel estimators based on Stein's methods or score\nmatching have shown promise, however their theoretical properties and\nrelationships have not been fully-understood. We provide a unifying view of\nthese estimators under the framework of regularized nonparametric regression.\nIt allows us to analyse existing estimators and construct new ones with\ndesirable properties by choosing different hypothesis spaces and regularizers.\nA unified convergence analysis is provided for such estimators. Finally, we\npropose score estimators based on iterative regularization that enjoy\ncomputational benefits from curl-free kernels and fast convergence."}, {"title": "A Free-Energy Principle for Representation Learning", "authors": "Yansong Gao, Pratik Chaudhari ", "link": "http://arxiv.org/abs/2002.12406", "summary": "This paper employs a formal connection of machine learning with\nthermodynamics to characterize the quality of learnt representations for\ntransfer learning. We discuss how information-theoretic functional such as\nrate, distortion and classification loss of a model lie on a convex, so-called\nequilibrium surface.We prescribe dynamical processes to traverse this surface\nunder constraints, e.g., an iso-classification process that trades off rate and\ndistortion to keep the classification loss unchanged. We demonstrate how this\nprocess can be used for transferring representations from a source dataset to a\ntarget dataset while keeping the classification loss constant. Experimental\nvalidation of the theoretical results is provided on standard\nimage-classification datasets."}, {"title": "Scalable Differential Privacy with Certified Robustness in Adversarial Learning", "authors": "Hai Phan, My Thai, Han Hu, Ruoming Jin, Tong Sun, Dejing Dou ", "link": "", "summary": ""}, {"title": "Variational Inference for Sequential Data with Future Likelihood Estimates", "authors": "Geon-Hyeong Kim, Youngsoo Jang, Hongseok Yang, Kee-Eung Kim "}, {"title": "Implicit Learning Dynamics in Stackelberg Games: Equilibria Characterization, Convergence Analysis, and Empirical Study", "authors": "Tanner Fiez, Benjamin Chasnov, Lillian  Ratliff ", "link": "", "summary": ""}, {"title": "Let's Agree to Agree: Neural Networks Share Classification Order on Real Datasets", "authors": "Guy Hacohen, Leshem Choshen, Daphna Weinshall "}, {"title": "Quantile Causal Discovery", "authors": "Natasa Tagasovska, Thibault Vatter, Val\u00e9rie Chavez-Demoulin ", "link": "", "summary": ""}, {"title": "How to Solve Fair k-Center in Massive Data Models", "authors": "Ashish Chiplunkar, Sagar Kale, Sivaramakrishnan Natarajan Ramamoorthy ", "link": "https://arxiv.org/abs/2002.07682", "summary": "Fueled by massive data, important decision making is being automated with the\nhelp of algorithms, therefore, fairness in algorithms has become an especially\nimportant research topic. In this work, we design new streaming and distributed\nalgorithms for the fair $k$-center problem that models fair data summarization.\nThe streaming and distributed models of computation have an attractive feature\nof being able to handle massive data sets that do not fit into main memory. Our\nmain contributions are: (a) the first distributed algorithm; which has provably\nconstant approximation ratio and is extremely parallelizable, and (b) a\ntwo-pass streaming algorithm with a provable approximation guarantee matching\nthe best known algorithm (which is not a streaming algorithm). Our algorithms\nhave the advantages of being easy to implement in practice, being fast with\nlinear running times, having very small working memory and communication, and\noutperforming existing algorithms on several real and synthetic data sets. To\ncomplement our distributed algorithm, we also give a hardness result for\nnatural distributed algorithms, which holds for even the special case of\n$k$-center."}, {"title": "Bayesian Learning from Sequential Data using Gaussian Processes with Signature Covariances", "authors": "Csaba Toth, Harald Oberhauser ", "link": "", "summary": ""}, {"title": "Beyond Signal Propagation: Is Feature Diversity Necessary in Deep Neural Network Initialization?", "authors": "Yaniv Blumenfeld, Dar Gilboa, Daniel Soudry ", "link": "", "summary": ""}, {"title": "Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising", "authors": "Xiaotian Hao, Zhaoqing Peng, Yi Ma, Guan Wang, Junqi Jin, Jianye Hao, Shan Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, HAN LI, Jian Xu, Kun Gai "}, {"title": "Stochastically Dominant Distributional Reinforcement Learning", "authors": "John Martin, Michal Lyskawinski, Xiaohu Li, Brendan Englot ", "link": "https://arxiv.org/abs/1905.07318", "summary": "We describe a new approach for managing aleatoric uncertainty in the\nReinforcement Learning (RL) paradigm. Instead of selecting actions according to\na single statistic, we propose a distributional method based on the\nsecond-order stochastic dominance (SSD) relation. This compares the inherent\ndispersion of random returns induced by actions, producing a more comprehensive\nand robust evaluation of the environment's uncertainty. The necessary\nconditions for SSD require estimators to predict accurate second moments. To\naccommodate this, we map the distributional RL problem to a Wasserstein\ngradient flow, treating the distributional Bellman residual as a potential\nenergy functional. We propose a particle-based algorithm for which we prove\noptimality and convergence. Our experiments characterize the algorithm\nperformance and demonstrate how uncertainty and performance are better balanced\nusing an \\textsc{ssd} policy than with other risk measures."}, {"title": "Adversarial Robustness Against the Union of Multiple Threat Models", "authors": "Pratyush Maini, Eric Wong, Zico Kolter ", "link": "https://arxiv.org/abs/1909.04068", "summary": "Owing to the susceptibility of deep learning systems to adversarial attacks,\nthere has been a great deal of work in developing (both empirically and\ncertifiably) robust classifiers, but the vast majority has defended against\nsingle types of attacks. Recent work has looked at defending against multiple\nattacks, specifically on the MNIST dataset, yet this approach used a relatively\ncomplex architecture, claiming that standard adversarial training can not apply\nbecause it \"overfits\" to a particular norm. In this work, we show that it is\nindeed possible to adversarially train a robust model against a union of\nnorm-bounded attacks, by using a natural generalization of the standard\nPGD-based procedure for adversarial training to multiple threat models. With\nthis approach, we are able to train standard architectures which are robust\nagainst $\\ell_\\infty$, $\\ell_2$, and $\\ell_1$ attacks, outperforming past\napproaches on the MNIST dataset and providing the first CIFAR10 network trained\nto be simultaneously robust against $(\\ell_{\\infty}, \\ell_{2},\\ell_{1})$ threat\nmodels, which achieves adversarial accuracy rates of $(47.6\\%, 64.8\\%, 53.4\\%)$\nfor $(\\ell_{\\infty}, \\ell_{2},\\ell_{1})$ perturbations with radius $\\epsilon =\n(0.03,0.5,12)$."}, {"title": "Student-Teacher Curriculum Learning via Reinforcement Learning: Predicting Hospital Inpatient Admission Location", "authors": "Rasheed El-Bouri, David Eyre, Peter Watkinson, Tingting Zhu, David Clifton "}, {"title": "Option Discovery in the Absence of Rewards with Manifold Analysis", "authors": "Amitay Bar, Ronen  Talmon, Ron Meir ", "link": "http://arxiv.org/abs/2003.05878", "summary": "Options have been shown to be an effective tool in reinforcement learning,\nfacilitating improved exploration and learning. In this paper, we present an\napproach based on spectral graph theory and derive an algorithm that\nsystematically discovers options without access to a specific reward or task\nassignment. As opposed to the common practice used in previous methods, our\nalgorithm makes full use of the spectrum of the graph Laplacian. Incorporating\nmodes associated with higher graph frequencies unravels domain subtleties,\nwhich are shown to be useful for option discovery. Using geometric and\nmanifold-based analysis, we present a theoretical justification for the\nalgorithm. In addition, we showcase its performance in several domains,\ndemonstrating clear improvements compared to competing methods."}, {"title": "Generalisation error in learning with random features and the hidden manifold model", "authors": "Federica Gerace, Bruno Loureiro, Florent Krzakala, Marc Mezard, Lenka Zdeborova ", "link": "https://arxiv.org/abs/2002.09339", "summary": "We study generalised linear regression and classification for a synthetically\ngenerated dataset encompassing different problems of interest, such as learning\nwith random features, neural networks in the lazy training regime, and the\nhidden manifold model. We consider the high-dimensional regime and using the\nreplica method from statistical physics, we provide a closed-form expression\nfor the asymptotic generalisation performance in these problems, valid in both\nthe under- and over-parametrised regimes and for a broad choice of generalised\nlinear model loss functions. In particular, we show how to obtain analytically\nthe so-called double descent behaviour for logistic regression with a peak at\nthe interpolation threshold, we illustrate the superiority of orthogonal\nagainst random Gaussian projections in learning with random features, and\ndiscuss the role played by correlations in the data generated by the hidden\nmanifold model. Beyond the interest in these particular problems, the\ntheoretical formalism introduced in this manuscript provides a path to further\nextensions to more complex tasks."}, {"title": "Fast and Consistent Learning of Hidden Markov Models by Incorporating Non-Consecutive Correlations", "authors": "Robert Mattila, Cristian R. Rojas, Eric Moulines, Vikram Krishnamurthy, Bo Wahlberg "}, {"title": "Gradient-free Online Learning in Continuous Games with Delayed Rewards", "authors": "Am\u00e9lie H\u00e9liou, Panayotis Mertikopoulos, Zhengyuan Zhou "}, {"title": "Pseudo-Masked Language Models for Unified Language Model Pre-Training", "authors": "Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, Hsiao-Wuen Hon ", "link": "https://arxiv.org/abs/2002.12804", "summary": "We propose to pre-train a unified language model for both autoencoding and\npartially autoregressive language modeling tasks using a novel training\nprocedure, referred to as a pseudo-masked language model (PMLM). Given an input\ntext with masked tokens, we rely on conventional masks to learn inter-relations\nbetween corrupted tokens and context via autoencoding, and pseudo masks to\nlearn intra-relations between masked spans via partially autoregressive\nmodeling. With well-designed position embeddings and self-attention masks, the\ncontext encodings are reused to avoid redundant computation. Moreover,\nconventional masks used for autoencoding provide global masking information, so\nthat all the position embeddings are accessible in partially autoregressive\nlanguage modeling. In addition, the two tasks pre-train a unified language\nmodel as a bidirectional encoder and a sequence-to-sequence decoder,\nrespectively. Our experiments show that the unified language models pre-trained\nusing PMLM achieve new state-of-the-art results on a wide range of natural\nlanguage understanding and generation tasks across several widely used\nbenchmarks."}, {"title": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits", "authors": "Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro Molina, Martin Trapp, Guy Van den Broeck, Kristian Kersting, Zoubin Ghahramani "}, {"title": "Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix", "authors": "Insu Han, Haim Avron, Jinwoo Shin ", "link": "https://arxiv.org/abs/1905.11616", "summary": "This paper studies how to sketch element-wise functions of low-rank matrices.\nFormally, given low-rank matrix A = [Aij] and scalar non-linear function f, we\naim for finding an approximated low-rank representation of the (possibly\nhigh-rank) matrix [f(Aij)]. To this end, we propose an efficient\nsketching-based algorithm whose complexity is significantly lower than the\nnumber of entries of A, i.e., it runs without accessing all entries of [f(Aij)]\nexplicitly. The main idea underlying our method is to combine a polynomial\napproximation of f with the existing tensor sketch scheme for approximating\nmonomials of entries of A. To balance the errors of the two approximation\ncomponents in an optimal manner, we propose a novel regression formula to find\npolynomial coefficients given A and f. In particular, we utilize a\ncoreset-based regression with a rigorous approximation guarantee. Finally, we\ndemonstrate the applicability and superiority of the proposed scheme under\nvarious machine learning tasks."}, {"title": "Inexact Tensor Methods with Dynamic Accuracies", "authors": "Nikita Doikov, Yurii Nesterov ", "link": "https://arxiv.org/abs/2002.09403", "summary": "In this paper, we study inexact high-order Tensor Methods for solving convex\noptimization problems with composite objective. At every step of such methods,\nwe use approximate solution of the auxiliary problem, defined by the bound for\nthe residual in function value. We propose two dynamic strategies for choosing\nthe inner accuracy: the first one is decreasing as $1/k^{p + 1}$, where $p \\geq\n1$ is the order of the method and $k$ is the iteration counter, and the second\napproach is using for the inner accuracy the last progress in the target\nobjective. We show that inexact Tensor Methods with these strategies achieve\nthe same global convergence rate as in the error-free case. For the second\napproach we also establish local superlinear rates (for $p \\geq 2$), and\npropose the accelerated scheme. Lastly, we present computational results on a\nvariety of machine learning problems for several methods and different accuracy\npolicies."}, {"title": "k-means++:  few more steps yield constant approximation", "authors": "Davin Choo, Christoph Grunau, Julian Portmann, Vaclav Rozhon ", "link": "https://arxiv.org/abs/2002.07784", "summary": "The k-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is a\nstate-of-the-art algorithm for solving the k-means clustering problem and is\nknown to give an O(log k)-approximation in expectation. Recently, Lattanzi and\nSohler (ICML 2019) proposed augmenting k-means++ with O(k log log k) local\nsearch steps to yield a constant approximation (in expectation) to the k-means\nclustering problem. In this paper, we improve their analysis to show that, for\nany arbitrarily small constant $\\eps > 0$, with only $\\eps k$ additional local\nsearch steps, one can achieve a constant approximation guarantee (with high\nprobability in k), resolving an open problem in their paper."}, {"title": "Radioactive data: tracing through training", "authors": "Alexandre Sablayrolles, Douze Matthijs, Cordelia Schmid, Herve Jegou ", "link": "https://arxiv.org/abs/2002.00937", "summary": "We want to detect whether a particular image dataset has been used to train a\nmodel. We propose a new technique, \\emph{radioactive data}, that makes\nimperceptible changes to this dataset such that any model trained on it will\nbear an identifiable mark. The mark is robust to strong variations such as\ndifferent architectures or optimization methods. Given a trained model, our\ntechnique detects the use of radioactive data and provides a level of\nconfidence (p-value). Our experiments on large-scale benchmarks (Imagenet),\nusing standard architectures (Resnet-18, VGG-16, Densenet-121) and training\nprocedures, show that we can detect usage of radioactive data with high\nconfidence (p<10^-4) even when only 1% of the data used to trained our model is\nradioactive. Our method is robust to data augmentation and the stochasticity of\ndeep network optimization. As a result, it offers a much higher signal-to-noise\nratio than data poisoning and backdoor methods."}, {"title": "Doubly robust off-policy evaluation with shrinkage ", "authors": "Yi Su, Maria Dimakopoulou, Akshay Krishnamurthy, Miroslav Dudik ", "link": "https://arxiv.org/abs/1907.09623", "summary": "We design a new family of estimators for off-policy evaluation in contextual\nbandits. Our estimators are based on the asymptotically optimal approach of\ndoubly robust estimation, but they shrink importance weights to obtain a better\nbias-variance tradeoff in finite samples. Our approach adapts importance\nweights to the quality of a reward predictor, interpolating between doubly\nrobust estimation and direct modeling. When the reward predictor is poor, we\nrecover previously studied weight clipping, but when the reward predictor is\ngood, we obtain a new form of shrinkage. To navigate between these regimes and\ntune the shrinkage coefficient, we design a model selection procedure, which we\nprove is never worse than the doubly robust estimator. Extensive experiments on\nbandit benchmark problems show that our estimators are highly adaptive and\ntypically outperform state-of-the-art methods."}, {"title": "Fast Adaptation to New Environments via Policy-Dynamics Value Functions", "authors": "Roberta Raileanu, Max Goldstein, Arthur Szlam, Facebook Rob Fergus "}, {"title": "Neural Clustering Processes", "authors": "Ari Pakman, Yueqi Wang, Catalin Mitelut, JinHyung Lee, Department of Statistics Liam Paninski ", "link": "https://arxiv.org/abs/1901.00409", "summary": "Probabilistic clustering models (or equivalently, mixture models) are basic\nbuilding blocks in countless statistical models and involve latent random\nvariables over discrete spaces. For these models, posterior inference methods\ncan be inaccurate and/or very slow. In this work we introduce deep network\narchitectures trained with labeled samples from any generative model of\nclustered datasets. At test time, the networks generate approximate posterior\nsamples of cluster labels for any new dataset of arbitrary size. We develop two\ncomplementary approaches to this task, requiring either O(N) or O(K) network\nforward passes per dataset, where N is the dataset size and K the number of\nclusters. Unlike previous approaches, our methods sample the labels of all the\ndata points from a well-defined posterior, and can learn nonparametric Bayesian\nposteriors since they do not limit the number of mixture components. Moreover,\nthe algorithms are easily parallelized with a GPU. As a scientific application,\nwe present a novel approach to neural spike sorting for high-density\nmultielectrode arrays."}, {"title": "Topologically Densified Distributions", "authors": "Christoph Hofer, Florian Graf, Marc Niethammer, Roland Kwitt ", "link": "https://arxiv.org/abs/2002.04805", "summary": "We study regularization in the context of small sample-size learning with\nover-parameterized neural networks. Specifically, we shift focus from\narchitectural properties, such as norms on the network weights, to properties\nof the internal representations before a linear classifier. Specifically, we\nimpose a topological constraint on samples drawn from the probability measure\ninduced in that space. This provably leads to mass concentration effects around\nthe representations of training instances, i.e., a property beneficial for\ngeneralization. By leveraging previous work to impose topological constraints\nin a neural network setting, we provide empirical evidence (across various\nvision benchmarks) to support our claim for better generalization."}, {"title": "Low-loss connection of weight vectors: distribution-based approaches", "authors": "Ivan Anokhin, Dmitry Yarotsky "}, {"title": "Graph Filtration Learning", "authors": "Christoph Hofer, Florian Graf, Bastian Rieck, Marc Niethammer, Roland Kwitt ", "link": "https://arxiv.org/abs/1905.10996", "summary": "We propose an approach to learning with graph-structured data in the problem\ndomain of graph classification. In particular, we present a novel type of\nreadout operation to aggregate node features into a graph-level representation.\nTo this end, we leverage persistent homology computed via a real-valued,\nlearnable, filter function. We establish the theoretical foundation for\ndifferentiating through the persistent homology computation. Empirically, we\nshow that this type of readout operation compares favorably to previous\ntechniques, especially when the graph connectivity structure is informative for\nthe learning problem."}, {"title": "Differentiable Product Quantization for Learning Compact Embedding Layers", "authors": "Ting Chen, Lala Li, Yizhou Sun "}, {"title": "Scalable Exact Inference in Multi-Output Gaussian Processes", "authors": "Wessel Bruinsma, Eric Perim Martins, William Tebbutt, Scott Hosking, Arno Solin, Richard E Turner ", "link": "https://arxiv.org/abs/1911.06287", "summary": "Multi-output Gaussian processes (MOGPs) leverage the flexibility and\ninterpretability of GPs while capturing structure across outputs, which is\ndesirable, for example, in spatio-temporal modelling. The key problem with\nMOGPs is the cubic computational scaling in the number of both inputs (e.g.,\ntime points or locations), n, and outputs, p. Current methods reduce this to\nO(n^3 m^3), where m < p is the desired degrees of freedom. This computational\ncost, however, is still prohibitive in many applications. To address this\nlimitation, we present the Orthogonal Linear Mixing Model (OLMM), an MOGP in\nwhich exact inference scales linearly in m: O(n^3 m). This advance opens up a\nwide range of real-world tasks and can be combined with existing GP\napproximations in a plug-and-play way as demonstrated in the paper.\nAdditionally, the paper organises the existing disparate literature on MOGP\nmodels into a simple taxonomy called the Mixing Model Hierarchy (MMH)."}, {"title": "Lower Complexity Bounds for Finite-Sum Convex-Concave Minimax Optimization Problems", "authors": "Guangzeng Xie, Luo Luo, yijiang lian, Zhihua Zhang "}, {"title": "Near-optimal Regret Bounds for Stochastic Shortest Path", "authors": "Aviv Rosenberg, Alon Cohen, Yishay Mansour, Haim Kaplan ", "link": "https://arxiv.org/abs/2002.09869", "summary": "Stochastic shortest path (SSP) is a well-known problem in planning and\ncontrol, in which an agent has to reach a goal state in minimum total expected\ncost. In the learning formulation of the problem, the agent is unaware of the\nenvironment dynamics (i.e., the transition function) and has to repeatedly play\nfor a given number of episodes while reasoning about the problem's optimal\nsolution. Unlike other well-studied models in reinforcement learning (RL), the\nlength of an episode is not predetermined (or bounded) and is influenced by the\nagent's actions. Recently, Tarbouriech et al. (2019) studied this problem in\nthe context of regret minimization and provided an algorithm whose regret bound\nis inversely proportional to the square root of the minimum instantaneous cost.\nIn this work we remove this dependence on the minimum cost---we give an\nalgorithm that guarantees a regret bound of $\\widetilde{O}(B_\\star |S|\n\\sqrt{|A| K})$, where $B_\\star$ is an upper bound on the expected cost of the\noptimal policy, $S$ is the set of states, $A$ is the set of actions and $K$ is\nthe number of episodes. We additionally show that any learning algorithm must\nhave at least $\\Omega(B_\\star \\sqrt{|S| |A| K})$ regret in the worst case."}, {"title": "The Usual Suspects? Reassessing Blame for VAE Posterior Collapse", "authors": "Bin Dai, Ziyu Wang, David Wipf ", "link": "https://arxiv.org/abs/1912.10702", "summary": "In narrow asymptotic settings Gaussian VAE models of continuous data have\nbeen shown to possess global optima aligned with ground-truth distributions.\nEven so, it is well known that poor solutions whereby the latent posterior\ncollapses to an uninformative prior are sometimes obtained in practice.\nHowever, contrary to conventional wisdom that largely assigns blame for this\nphenomena on the undue influence of KL-divergence regularization, we will argue\nthat posterior collapse is, at least in part, a direct consequence of bad local\nminima inherent to the loss surface of deep autoencoder networks. In\nparticular, we prove that even small nonlinear perturbations of affine VAE\ndecoder models can produce such minima, and in deeper models, analogous minima\ncan force the VAE to behave like an aggressive truncation operator, provably\ndiscarding information along all latent dimensions in certain circumstances.\nRegardless, the underlying message here is not meant to undercut valuable\nexisting explanations of posterior collapse, but rather, to refine the\ndiscussion and elucidate alternative risk factors that may have been previously\nunderappreciated."}, {"title": "It's Not What Machines Can Learn, It's What We Cannot Teach", "authors": "Gal Yehuda, Moshe Gabel, Assaf Schuster ", "link": "https://arxiv.org/abs/2002.09398", "summary": "Can deep neural networks learn to solve any task, and in particular problems\nof high complexity? This question attracts a lot of interest, with recent works\ntackling computationally hard tasks such as the traveling salesman problem and\nsatisfiability. In this work we offer a different perspective on this question.\nGiven the common assumption that $\\textit{NP} \\neq \\textit{coNP}$ we prove that\nany polynomial-time sample generator for an $\\textit{NP}$-hard problem samples,\nin fact, from an easier sub-problem. We empirically explore a case study,\nConjunctive Query Containment, and show how common data generation techniques\ngenerate biased datasets that lead practitioners to over-estimate model\naccuracy. Our results suggest that machine learning approaches that require\ntraining on a dense uniform sampling from the target distribution cannot be\nused to solve computationally hard problems, the reason being the difficulty of\ngenerating sufficiently large and unbiased training sets."}, {"title": "Guided Learning of Nonconvex Models through Successive Functional Gradient Optimization", "authors": "Rie Johnson, Tong Zhang "}, {"title": "A Markov Decision Process Model for Socio-Economic Systems Impacted by Climate Change", "authors": "Salman Sadiq Shuvo, Yasin Yilmaz, Alan Bush, Mark Hafen "}, {"title": "Can Stochastic Zeroth-Order Frank-Wolfe Method Converge Faster for Non-Convex Problems?", "authors": "Hongchang Gao, Heng Huang "}, {"title": "Distance Metric Learning with Joint Representation Diversification", "authors": "Xu Chu, Yang Lin, Xiting Wang, Xin Gao, Qi Tong, Hailong Yu, Yasha Wang "}, {"title": "Meta-Learning with Shared Amortized Variational Inference", "authors": "Ekaterina Iakovleva, Karteek Alahari, Jakob Verbeek "}, {"title": "Causal Effect Identifiability under Partial-Observability", "authors": "Sanghack Lee, Elias Bareinboim "}, {"title": "Continuous Graph Neural Networks", "authors": "Louis-Pascal Xhonneux, Meng Qu, Jian Tang ", "link": "https://arxiv.org/abs/1912.00967", "summary": "This paper builds on the connection between graph neural networks and\ntraditional dynamical systems. We propose continuous graph neural networks\n(CGNN), which generalise existing graph neural networks with discrete dynamics\nin that they can be viewed as a specific discretisation scheme. The key idea is\nhow to characterise the continuous dynamics of node representations, i.e. the\nderivatives of node representations, w.r.t. time. Inspired by existing\ndiffusion-based methods on graphs (e.g. PageRank and epidemic models on social\nnetworks), we define the derivatives as a combination of the current node\nrepresentations, the representations of neighbors, and the initial values of\nthe nodes. We propose and analyse two possible dynamics on graphs---including\neach dimension of node representations (a.k.a. the feature channel) change\nindependently or interact with each other---both with theoretical\njustification. The proposed continuous graph neural networks are robust to\nover-smoothing and hence allow us to build deeper networks, which in turn are\nable to capture the long-range dependencies between nodes. Experimental results\non the task of node classification demonstrate the effectiveness of our\nproposed approach over competitive baselines."}, {"title": "Restarted Bayesian Online Change-point Detector achieves Optimal Detection Delay", "authors": "REDA ALAMI, Odalric-Ambrym Maillard, Raphael Feraud "}, {"title": "Robust learning with the Hilbert-Schmidt independence criterion", "authors": "Daniel Greenfeld, Uri Shalit ", "link": "https://arxiv.org/abs/1910.00270", "summary": "We investigate the use of a non-parametric independence measure, the\nHilbert-Schmidt Independence Criterion (HSIC), as a loss-function for learning\nrobust regression and classification models. This loss-function encourages\nlearning models where the distribution of the residuals between the label and\nthe model prediction is statistically independent of the distribution of the\ninstances themselves. This loss-function was first proposed by Mooij et al.\n(2009) in the context of learning causal graphs. We adapt it to the task of\nlearning for unsupervised covariate shift: learning on a source domain without\naccess to any instances or labels from the unknown target domain, but with the\nassumption that $p(y|x)$ (the conditional probability of labels given\ninstances) remains the same in the target domain. We show that the proposed\nloss is expected to give rise to models that generalize well on a class of\ntarget domains characterised by the complexity of their description within a\nreproducing kernel Hilbert space. Experiments on unsupervised covariate shift\ntasks demonstrate that models learned with the proposed loss-function\noutperform models learned with standard loss functions, achieving\nstate-of-the-art results on a challenging cell-microscopy unsupervised\ncovariate shift task."}, {"title": "Bayesian Experimental Design for Implicit Models by Mutual Information Neural Estimation", "authors": "Steven Kleinegesse, Michael Gutmann ", "link": "https://arxiv.org/abs/2002.08129", "summary": "Implicit stochastic models, where the data-generation distribution is\nintractable but sampling is possible, are ubiquitous in the natural sciences.\nThe models typically have free parameters that need to be inferred from data\ncollected in scientific experiments. A fundamental question is how to design\nthe experiments so that the collected data are most useful. The field of\nBayesian experimental design advocates that, ideally, we should choose designs\nthat maximise the mutual information (MI) between the data and the parameters.\nFor implicit models, however, this approach is severely hampered by the high\ncomputational cost of computing posteriors and maximising MI, in particular\nwhen we have more than a handful of design variables to optimise. In this\npaper, we propose a new approach to Bayesian experimental design for implicit\nmodels that leverages recent advances in neural MI estimation to deal with\nthese issues. We show that training a neural network to maximise a lower bound\non MI allows us to jointly determine the optimal design and the posterior.\nSimulation studies illustrate that this gracefully extends Bayesian\nexperimental design for implicit models to higher design dimensions."}, {"title": "Fast Differentiable Sorting and Ranking", "authors": "Mathieu Blondel, Olivier Teboul, Quentin Berthet, Josip Djolonga ", "link": "https://arxiv.org/abs/2002.08871", "summary": "The sorting operation is one of the most basic and commonly used building\nblocks in computer programming. In machine learning, it is commonly used for\nrobust statistics. However, seen as a function, it is piecewise linear and as a\nresult includes many kinks at which it is non-differentiable. More problematic\nis the related ranking operator, commonly used for order statistics and ranking\nmetrics. It is a piecewise constant function, meaning that its derivatives are\nnull or undefined. While numerous works have proposed differentiable proxies to\nsorting and ranking, they do not achieve the $O(n \\log n)$ time complexity one\nwould expect from sorting and ranking operations. In this paper, we propose the\nfirst differentiable sorting and ranking operators with $O(n \\log n)$ time and\n$O(n)$ space complexity. Our proposal in addition enjoys exact computation and\ndifferentiation. We achieve this feat by constructing differentiable sorting\nand ranking operators as projections onto the permutahedron, the convex hull of\npermutations, and using a reduction to isotonic optimization. Empirically, we\nconfirm that our approach is an order of magnitude faster than existing\napproaches and showcase two novel applications: differentiable Spearman's rank\ncorrelation coefficient and soft least trimmed squares."}, {"title": "Learning for Dose Allocation in Adaptive Clinical Trials with Safety Constraints", "authors": "Cong Shen, Zhiyang Wang, Sofia Villar, M van der Schaar "}, {"title": "Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems", "authors": "Kaixuan Wei, Angelica Aviles-Rivero, Jingwei Liang, Ying Fu, Carola-Bibiane Sch\u00f6nlieb, Hua Huang ", "link": "https://arxiv.org/abs/2002.09611", "summary": "Plug-and-play (PnP) is a non-convex framework that combines ADMM or other\nproximal algorithms with advanced denoiser priors. Recently, PnP has achieved\ngreat empirical success, especially with the integration of deep learning-based\ndenoisers. However, a key problem of PnP based approaches is that they require\nmanual parameter tweaking. It is necessary to obtain high-quality results\nacross the high discrepancy in terms of imaging conditions and varying scene\ncontent. In this work, we present a tuning-free PnP proximal algorithm, which\ncan automatically determine the internal parameters including the penalty\nparameter, the denoising strength and the terminal time. A key part of our\napproach is to develop a policy network for automatic search of parameters,\nwhich can be effectively learned via mixed model-free and model-based deep\nreinforcement learning. We demonstrate, through numerical and visual\nexperiments, that the learned policy can customize different parameters for\ndifferent states, and often more efficient and effective than existing\nhandcrafted criteria. Moreover, we discuss the practical considerations of the\nplugged denoisers, which together with our learned policy yield\nstate-of-the-art results. This is prevalent on both linear and nonlinear\nexemplary inverse imaging problems, and in particular, we show promising\nresults on Compressed Sensing MRI and phase retrieval."}, {"title": "Consistent Estimators for Learning to Defer to an Expert", "authors": "Hussein Mozannar, David Sontag "}, {"title": "A Graph to Graphs Framework for Retrosynthesis Prediction", "authors": "Chence Shi, Minkai Xu, Hongyu Guo, Ming Zhang, Jian Tang ", "link": "https://arxiv.org/abs/2003.12725", "summary": "A fundamental problem in computational chemistry is to find a set of\nreactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.\nExisting state-of-the-art methods rely on matching the target molecule with a\nlarge set of reaction templates, which are very computationally expensive and\nalso suffer from the problem of coverage. In this paper, we propose a novel\ntemplate-free approach called G2Gs by transforming a target molecular graph\ninto a set of reactant molecular graphs. G2Gs first splits the target molecular\ngraph into a set of synthons by identifying the reaction centers, and then\ntranslates the synthons to the final reactant graphs via a variational graph\ntranslation framework. Experimental results show that G2Gs significantly\noutperforms existing template-free approaches by up to 63% in terms of the\ntop-1 accuracy and achieves a performance close to that of state-of-the-art\ntemplate based approaches, but does not require domain knowledge and is much\nmore scalable."}, {"title": "Fast computation of Nash Equilibria in Imperfect Information Games", "authors": "Remi Munos, Julien Perolat, Jean-Baptiste Lespiau, Mark Rowland, Bart De Vylder, Marc Lanctot, Finbarr Timbers, Daniel Hennes, Shayegan Omidshafiei, Audrunas Gruslys, Mohammad Gheshlaghi Azar, Edward Lockhart, Karl Tuyls "}, {"title": "Invariant Rationalization", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi Jaakkola ", "link": "https://arxiv.org/abs/2003.09772", "summary": "Selective rationalization improves neural network interpretability by\nidentifying a small subset of input features -- the rationale -- that best\nexplains or supports the prediction. A typical rationalization criterion, i.e.\nmaximum mutual information (MMI), finds the rationale that maximizes the\nprediction performance based only on the rationale. However, MMI can be\nproblematic because it picks up spurious correlations between the input\nfeatures and the output. Instead, we introduce a game-theoretic invariant\nrationalization criterion where the rationales are constrained to enable the\nsame predictor to be optimal across different environments. We show both\ntheoretically and empirically that the proposed rationales can rule out\nspurious correlations, generalize better to different test scenarios, and align\nbetter with human judgments. Our data and code are available."}, {"title": "Accelerated Stochastic Gradient-free and Projection-free Methods", "authors": "Feihu Huang, Lue Lue, Songcan Chen "}, {"title": "Efficient Optimistic Exploration in Linear-Quadratic Regulators via Lagrangian Relaxation", "authors": "Marc Abeille, Alessandro Lazaric "}, {"title": "Implicit Regularization of Random Feature Models", "authors": "Arthur Jacot, berfin simsek, Francesco Spadaro, Clement Hongler, Franck Gabriel ", "link": "https://arxiv.org/abs/2002.08404", "summary": "Random Feature (RF) models are used as efficient parametric approximations of\nkernel methods. We investigate, by means of random matrix theory, the\nconnection between Gaussian RF models and Kernel Ridge Regression (KRR). For a\nGaussian RF model with $P$ features, $N$ data points, and a ridge $\\lambda$, we\nshow that the average (i.e. expected) RF predictor is close to a KRR predictor\nwith an effective ridge $\\tilde{\\lambda}$. We show that $\\tilde{\\lambda} >\n\\lambda$ and $\\tilde{\\lambda} \\searrow \\lambda$ monotonically as $P$ grows,\nthus revealing the implicit regularization effect of finite RF sampling. We\nthen compare the risk (i.e. test error) of the $\\tilde{\\lambda}$-KRR predictor\nwith the average risk of the $\\lambda$-RF predictor and obtain a precise and\nexplicit bound on their difference. Finally, we empirically find an extremely\ngood agreement between the test errors of the average $\\lambda$-RF predictor\nand $\\tilde{\\lambda}$-KRR predictor."}, {"title": "Missing Data Imputation using Optimal Transport", "authors": "Boris Muzellec, Julie Josse, Claire Boyer, Marco Cuturi ", "link": "https://arxiv.org/abs/2002.03860", "summary": "Missing data is a crucial issue when applying machine learning algorithms to\nreal-world datasets. Starting from the simple assumption that two batches\nextracted randomly from the same dataset should share the same distribution, we\nleverage optimal transport distances to quantify that criterion and turn it\ninto a loss function to impute missing data values. We propose practical\nmethods to minimize these losses using end-to-end learning, that can exploit or\nnot parametric assumptions on the underlying distributions of values. We\nevaluate our methods on datasets from the UCI repository, in MCAR, MAR and MNAR\nsettings. These experiments show that OT-based methods match or out-perform\nstate-of-the-art imputation methods, even for high percentages of missing\nvalues."}, {"title": "Unsupervised Speech Decomposition via Triple Information Bottleneck", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, Mark Hasegawa-Johnson, David Cox ", "link": "https://arxiv.org/abs/2004.11284", "summary": "Speech information can be roughly decomposed into four components: language\ncontent, timbre, pitch, and rhythm. Obtaining disentangled representations of\nthese components is useful in many speech analysis and generation applications.\nRecently, state-of-the-art voice conversion systems have led to speech\nrepresentations that can disentangle speaker-dependent and independent\ninformation. However, these systems can only disentangle timbre, while\ninformation about pitch, rhythm and content is still mixed together. Further\ndisentangling the remaining speech components is an under-determined problem in\nthe absence of explicit annotations for each component, which are difficult and\nexpensive to obtain. In this paper, we propose SpeechSplit, which can blindly\ndecompose speech into its four components by introducing three carefully\ndesigned information bottlenecks. SpeechSplit is among the first algorithms\nthat can separately perform style transfer on timbre, pitch and rhythm without\ntext labels."}, {"title": "Provable Representation Learning for Imitation Learning via Bi-level Optimization", "authors": "Sanjeev Arora, Simon Du, Sham Kakade, Yuping Luo, Nikunj Umesh Saunshi ", "link": "https://arxiv.org/abs/2002.10544", "summary": "A common strategy in modern learning systems is to learn a representation\nthat is useful for many tasks, a.k.a. representation learning. We study this\nstrategy in the imitation learning setting for Markov decision processes (MDPs)\nwhere multiple experts' trajectories are available. We formulate representation\nlearning as a bi-level optimization problem where the \"outer\" optimization\ntries to learn the joint representation and the \"inner\" optimization encodes\nthe imitation learning setup and tries to learn task-specific parameters. We\ninstantiate this framework for the imitation learning settings of behavior\ncloning and observation-alone. Theoretically, we show using our framework that\nrepresentation learning can provide sample complexity benefits for imitation\nlearning in both settings. We also provide proof-of-concept experiments to\nverify our theory."}, {"title": "Convergence of a Stochastic Gradient Method with Momentum for Non-Smooth Non-Convex Optimization", "authors": "Vien Van Mai, Mikael Johansson ", "link": "https://arxiv.org/abs/2002.05466", "summary": "Stochastic gradient methods with momentum are widely used in applications and\nat the core of optimization subroutines in many popular machine learning\nlibraries. However, their sample complexities have never been obtained for\nproblems that are non-convex and non-smooth. This paper establishes the\nconvergence rate of a stochastic subgradient method with a momentum term of\nPolyak type for a broad class of non-smooth, non-convex, and constrained\noptimization problems. Our key innovation is the construction of a special\nLyapunov function for which the proven complexity can be achieved without any\ntunning of the momentum parameter. For smooth problems, we extend the known\ncomplexity bound to the constrained case and demonstrate how the unconstrained\ncase can be analyzed under weaker assumptions than the state-of-the-art.\nNumerical results confirm our theoretical developments."}, {"title": "XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalisation", "authors": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson ", "link": "https://arxiv.org/abs/2003.11080", "summary": "Much recent progress in applications of machine learning models to NLP has\nbeen driven by benchmarks that evaluate models across a wide variety of tasks.\nHowever, these broad-coverage benchmarks have been mostly limited to English,\nand despite an increasing interest in multilingual models, a benchmark that\nenables the comprehensive evaluation of such methods on a diverse range of\nlanguages and tasks is still missing. To this end, we introduce the\nCross-lingual TRansfer Evaluation of Multilingual Encoders XTREME benchmark, a\nmulti-task benchmark for evaluating the cross-lingual generalization\ncapabilities of multilingual representations across 40 languages and 9 tasks.\nWe demonstrate that while models tested on English reach human performance on\nmany tasks, there is still a sizable gap in the performance of cross-lingually\ntransferred models, particularly on syntactic and sentence retrieval tasks.\nThere is also a wide spread of results across languages. We release the\nbenchmark to encourage research on cross-lingual learning methods that transfer\nlinguistic knowledge across a diverse and representative set of languages and\ntasks."}, {"title": "Fair k-Centers via Maximum Matching", "authors": "Matthew Jones, Thy Nguyen, Huy Nguyen "}, {"title": "Efficiently sampling functions from Gaussian process posteriors", "authors": "James Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, Marc Deisenroth ", "link": "https://arxiv.org/abs/2002.09309", "summary": "Gaussian processes are the gold standard for many real-world modeling\nproblems, especially in cases where a model's success hinges upon its ability\nto faithfully represent predictive uncertainty. These problems typically exist\nas parts of larger frameworks, where quantities of interest are ultimately\ndefined by integrating over posterior distributions. However, these algorithms'\ninner workings rarely allow for closed-form integration, giving rise to a need\nfor Monte Carlo methods. Despite substantial progress in scaling up Gaussian\nprocesses to large training sets, methods for accurately generating draws from\ntheir posterior distributions still scale cubically in the number of test\nlocations. We identify a decomposition of Gaussian processes that naturally\nlends itself to scalable sampling by enabling us to efficiently generate\nfunctions that accurately represent their posteriors. Building off of this\nfactorization, we propose decoupled sampling, an easy-to-use and\ngeneral-purpose approach for fast posterior sampling. Decoupled sampling works\nas a drop-in strategy that seamlessly pairs with sparse approximations to\nGaussian processes to afford scalability both during training and at test time.\nIn a series of experiments designed to test competing sampling schemes'\nstatistical behaviors and practical ramifications, we empirically show that\nfunctions drawn using decoupled sampling faithfully represent Gaussian process\nposteriors at a fraction of the usual cost."}, {"title": "Characterizing Distribution Equivalence and Structure Learning for Cyclic and Acyclic Directed Graphs", "authors": "AmirEmad Ghassami, Alan Yang, Negar Kiyavash, Kun Zhang ", "link": "", "summary": ""}, {"title": "Inverse Active Sensing: Modeling and Understanding Timely Decision-Making", "authors": "Daniel Jarrett, Mihaela van der Schaar "}, {"title": "On Second-Order Group Influence Functions for Black-Box Predictions", "authors": "Samyadeep Basu, Xuchen You, Soheil Feizi ", "link": "https://arxiv.org/abs/1911.00418", "summary": "With the rapid adoption of machine learning systems in sensitive\napplications, there is an increasing need to make black-box models explainable.\nOften we want to identify an influential group of training samples in a\nparticular test prediction. Existing influence functions tackle this problem by\nusing first-order approximations of the effect of removing a sample from the\ntraining set on model parameters. To compute the influence of a group of\ntraining samples (rather than an individual point) in model predictions, the\nchange in optimal model parameters after removing that group from the training\nset can be large. Thus, in such cases, the first-order approximation can be\nloose. In this paper, we address this issue and propose second-order influence\nfunctions for identifying influential groups in test-time predictions. For\nlinear models and across different sizes of groups, we show that using the\nproposed second-order influence function improves the correlation between the\ncomputed influence values and the ground truth ones. For nonlinear models based\non neural networks, we empirically show that none of the existing first-order\nand the proposed second-order influence functions provide proper estimates of\nthe ground-truth influences over all training samples. We empirically study\nthis phenomenon by decomposing the influence values over contributions from\ndifferent eigenvectors of the Hessian of the trained model."}, {"title": "Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences", "authors": "Daniel Brown, Scott Niekum, Russell Coleman, Ravi Srinivasan ", "link": "https://arxiv.org/abs/2002.09089", "summary": "Bayesian reward learning from demonstrations enables rigorous safety and\nuncertainty analysis when performing imitation learning. However, Bayesian\nreward learning methods are typically computationally intractable for complex\ncontrol problems. We propose a highly efficient Bayesian reward learning\nalgorithm that scales to high-dimensional imitation learning problems by first\npre-training a low-dimensional feature encoding via self-supervised tasks and\nthen leveraging preferences over demonstrations to perform fast Bayesian\ninference. We evaluate our proposed approach on the task of learning to play\nAtari games from demonstrations, without access to the game score. For Atari\ngames our approach enables us to generate 100,000 samples from the posterior\nover reward functions in only 5 minutes using a personal laptop. Furthermore,\nour proposed approach achieves comparable or better imitation learning\nperformance than state-of-the-art methods that only find a point estimate of\nthe reward function. Finally, we show that our approach enables efficient\nhigh-confidence policy performance bounds. We show that these high-confidence\nperformance bounds can be used to rank the performance and risk of a variety of\nevaluation policies, despite not having samples of the reward function. We also\nshow evidence that high-confidence performance bounds can be used to detect\nreward hacking in complex imitation learning problems."}, {"title": "Randomly Projected Additive Gaussian Processes for Regression", "authors": "Ian Delbridge, David S Bindel, Andrew Wilson ", "link": "https://arxiv.org/abs/1912.12834", "summary": "Gaussian processes (GPs) provide flexible distributions over functions, with\ninductive biases controlled by a kernel. However, in many applications Gaussian\nprocesses can struggle with even moderate input dimensionality. Learning a low\ndimensional projection can help alleviate this curse of dimensionality, but\nintroduces many trainable hyperparameters, which can be cumbersome, especially\nin the small data regime. We use additive sums of kernels for GP regression,\nwhere each kernel operates on a different random projection of its inputs.\nSurprisingly, we find that as the number of random projections increases, the\npredictive performance of this approach quickly converges to the performance of\na kernel operating on the original full dimensional inputs, over a wide range\nof data sets, even if we are projecting into a single dimension. As a\nconsequence, many problems can remarkably be reduced to one dimensional input\nspaces, without learning a transformation. We prove this convergence and its\nrate, and additionally propose a deterministic approach that converges more\nquickly than purely random projections. Moreover, we demonstrate our approach\ncan achieve faster inference and improved predictive accuracy for\nhigh-dimensional inputs compared to kernels in the original input space."}, {"title": "Attentive Group Equivariant Convolutional Networks", "authors": "David W. Romero, Erik Bekkers, Jakub Tomczak, Mark Hoogendoorn ", "link": "https://arxiv.org/abs/2002.03830", "summary": "Although group convolutional networks are able to learn powerful\nrepresentations based on symmetry patterns, they lack explicit means to learn\nmeaningful relationships among them (e.g., relative positions and poses). In\nthis paper, we present attentive group equivariant convolutions, a\ngeneralization of the group convolution, in which attention is applied during\nthe course of convolution to accentuate meaningful symmetry combinations and\nsuppress non-plausible, misleading ones. We indicate that prior work on visual\nattention can be described as special cases of our proposed framework and show\nempirically that our attentive group equivariant convolutional networks\nconsistently outperform conventional group convolutional networks on benchmark\nimage datasets. Simultaneously, we provide interpretability to the learned\nconcepts through the visualization of equivariant attention maps."}, {"title": "Learning Compound Tasks without Task-specific Knowledge via Imitation and Self-supervised Learning", "authors": "Sang-Hyun Lee, Seung-Woo Seo ", "link": "", "summary": ""}, {"title": "Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference Setting", "authors": "Niccolo Dalmasso, Rafael Izbicki, Ann Lee ", "link": "https://arxiv.org/abs/2002.10399", "summary": "Parameter estimation, statistical tests and confidence sets are the\ncornerstones of classical statistics that allow scientists to make inferences\nabout the underlying process that generated the observed data. A key question\nis whether one can still construct hypothesis tests and confidence sets with\nproper coverage and high power in a so-called likelihood-free inference (LFI)\nsetting; that is, a setting where the likelihood is not explicitly known but\none can forward-simulate observable data according to a stochastic model. In\nthis paper, we present $\\texttt{ACORE}$ (Approximate Computation via Odds Ratio\nEstimation), a frequentist approach to LFI that first formulates the classical\nlikelihood ratio test (LRT) as a parametrized classification problem, and then\nuses the equivalence of tests and confidence sets to build confidence regions\nfor parameters of interest. We also present a goodness-of-fit procedure for\nchecking whether the constructed tests and confidence regions are valid.\n$\\texttt{ACORE}$ is based on the key observation that the LRT statistic, the\nrejection probability of the test, and the coverage of the confidence set are\nconditional distribution functions which often vary smoothly as a function of\nthe parameters of interest. Hence, instead of relying solely on samples\nsimulated at fixed parameter settings (as is the convention in standard Monte\nCarlo solutions), one can leverage machine learning tools and data simulated in\nthe neighborhood of a parameter to improve estimates of quantities of interest.\nWe demonstrate the efficacy of $\\texttt{ACORE}$ with both theoretical and\nempirical results. Our implementation is available on Github."}, {"title": "Curvature-corrected learning dynamics in deep neural networks", "authors": "Dongsung Huh "}, {"title": "Tightening Exploration in Upper Confidence Reinforcement Learning", "authors": "Hippolyte Bourel, Odalric-Ambrym Maillard, Mohammad Sadegh Talebi ", "link": "https://arxiv.org/abs/2004.09656", "summary": "The upper confidence reinforcement learning (UCRL2) strategy introduced in\n(Jaksch et al., 2010) is a popular method to perform regret minimization in\nunknown discrete Markov Decision Processes under the average-reward criterion.\nDespite its nice and generic theoretical regret guarantees, this strategy and\nits variants have remained until now mostly theoretical as numerical\nexperiments on simple environments exhibit long burn-in phases before the\nlearning takes place. Motivated by practical efficiency, we present UCRL3,\nfollowing the lines of UCRL2, but with two key modifications: First, it uses\nstate-of-the-art time-uniform concentration inequalities, to compute confidence\nsets on the reward and transition distributions for each state-action pair. To\nfurther tighten exploration, we introduce an adaptive computation of the\nsupport of each transition distributions. This enables to revisit the extended\nvalue iteration procedure to optimize over distributions with reduced support\nby disregarding low probability transitions, while still ensuring\nnear-optimism. We demonstrate, through numerical experiments on standard\nenvironments, that reducing exploration this way yields a substantial numerical\nimprovement compared to UCRL2 and its variants. On the theoretical side, these\nkey modifications enable to derive a regret bound for UCRL3 improving on UCRL2,\nthat for the first time makes appear a notion of local diameter and effective\nsupport, thanks to variance-aware concentration bounds."}, {"title": "Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning", "authors": "Zhaohan Guo, Bernardo Avila Pires, Mohammad Gheshlaghi Azar, Bilal Piot, Florent Altch\u00e9, Jean-Bastien Grill, Remi Munos ", "link": "https://arxiv.org/abs/2004.14646", "summary": "Learning a good representation is an essential component for deep\nreinforcement learning (RL). Representation learning is especially important in\nmultitask and partially observable settings where building a representation of\nthe unknown environment is crucial to solve the tasks. Here we introduce\nPrediction of Bootstrap Latents (PBL), a simple and flexible self-supervised\nrepresentation learning algorithm for multitask deep RL. PBL builds on\nmultistep predictive representations of future observations, and focuses on\ncapturing structured information about environment dynamics. Specifically, PBL\ntrains its representation by predicting latent embeddings of future\nobservations. These latent embeddings are themselves trained to be predictive\nof the aforementioned representations. These predictions form a bootstrapping\neffect, allowing the agent to learn more about the key aspects of the\nenvironment dynamics. In addition, by defining prediction tasks completely in\nlatent space, PBL provides the flexibility of using multimodal observations\ninvolving pixel images, language instructions, rewards and more. We show in our\nexperiments that PBL delivers across-the-board improved performance over state\nof the art deep RL agents in the DMLab-30 and Atari-57 multitask setting."}, {"title": "Discriminative Adversarial Search for Abstractive Summarization", "authors": "Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano ", "link": "https://arxiv.org/abs/2002.10375", "summary": "We introduce a novel approach for sequence decoding, Discriminative\nAdversarial Search (DAS), which has the desirable properties of alleviating the\neffects of exposure bias without requiring external metrics. Inspired by\nGenerative Adversarial Networks (GANs), wherein a discriminator is used to\nimprove the generator, our method differs from GANs in that the generator\nparameters are not updated at training time and the discriminator is only used\nto drive sequence generation at inference time.\n  We investigate the effectiveness of the proposed approach on the task of\nAbstractive Summarization: the results obtained show that a naive application\nof DAS improves over the state-of-the-art methods, with further gains obtained\nvia discriminator retraining. Moreover, we show how DAS can be effective for\ncross-domain adaptation. Finally, all results reported are obtained without\nadditional rule-based filtering strategies, commonly used by the best\nperforming systems available: this indicates that DAS can effectively be\ndeployed without relying on post-hoc modifications of the generated outputs."}, {"title": "A Swiss Army Knife for Minimax Optimal Transport", "authors": "Sofien Dhouib, Ievgen Redko, Tanguy Kerdoncuff, R\u00e9mi Emonet, Marc Sebban ", "link": "", "summary": ""}, {"title": "Invariant Causal Prediction for Block MDPs", "authors": "Clare Lyle, Amy Zhang, Angelos Filos, Shagun Sodhani, Marta Kwiatkowska, Yarin Gal, Doina Precup, Joelle Pineau ", "link": "https://arxiv.org/abs/2003.06016", "summary": "Generalization across environments is critical to the successful application\nof reinforcement learning algorithms to real-world challenges. In this paper,\nwe consider the problem of learning abstractions that generalize in block MDPs,\nfamilies of environments with a shared latent state space and dynamics\nstructure over that latent space, but varying observations. We leverage tools\nfrom causal inference to propose a method of invariant prediction to learn\nmodel-irrelevance state abstractions (MISA) that generalize to novel\nobservations in the multi-environment setting. We prove that for certain\nclasses of environments, this approach outputs with high probability a state\nabstraction corresponding to the causal feature set with respect to the return.\nWe further provide more general bounds on model error and generalization error\nin the multi-environment setting, in the process showing a connection between\ncausal variable selection and the state abstraction framework for MDPs. We give\nempirical evidence that our methods work in both linear and nonlinear settings,\nattaining improved generalization over single- and multi-task baselines."}, {"title": "Involutive MCMC: One Way to Derive Them All", "authors": "Kirill Neklyudov, Max Welling, Evgenii Egorov, Dmitry Vetrov "}, {"title": "Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks", "authors": "Pranjal Awasthi, Natalie Frank, Mehryar Mohri ", "link": "https://arxiv.org/abs/2004.13617", "summary": "Adversarial or test time robustness measures the susceptibility of a\nclassifier to perturbations to the test input. While there has been a flurry of\nrecent work on designing defenses against such perturbations, the theory of\nadversarial robustness is not well understood. In order to make progress on\nthis, we focus on the problem of understanding generalization in adversarial\nsettings, via the lens of Rademacher complexity. We give upper and lower bounds\nfor the adversarial empirical Rademacher complexity of linear hypotheses with\nadversarial perturbations measured in $l_r$-norm for an arbitrary $r \\geq 1$.\nThis generalizes the recent result of [Yin et al.'19] that studies the case of\n$r = \\infty$, and provides a finer analysis of the dependence on the input\ndimensionality as compared to the recent work of [Khim and Loh'19] on linear\nhypothesis classes.\n  We then extend our analysis to provide Rademacher complexity lower and upper\nbounds for a single ReLU unit. Finally, we give adversarial Rademacher\ncomplexity bounds for feed-forward neural networks with one hidden layer.\nUnlike previous works we directly provide bounds on the adversarial Rademacher\ncomplexity of the given network, as opposed to a bound on a surrogate. A\nby-product of our analysis also leads to tighter bounds for the Rademacher\ncomplexity of linear hypotheses, for which we give a detailed analysis and\npresent a comparison with existing bounds."}, {"title": "Deep Reinforcement Learning with Smooth Policy", "authors": "Qianli Shen, Yan Li, Haoming Jiang, Zhaoran Wang, Tuo Zhao ", "link": "https://arxiv.org/abs/2003.09534", "summary": "Deep neural networks have been widely adopted in modern reinforcement\nlearning (RL) algorithms with great empirical successes in various domains.\nHowever, the large search space of training a neural network requires a\nsignificant amount of data, which makes the current RL algorithms not sample\nefficient. Motivated by the fact that many environments with continuous state\nspace have smooth transitions, we propose to learn a smooth policy that behaves\nsmoothly with respect to states. In contrast to policies parameterized by\nlinear/reproducing kernel functions, where simple regularization techniques\nsuffice to control smoothness, for neural network based reinforcement learning\nalgorithms, there is no readily available solution to learn a smooth policy. In\nthis paper, we develop a new training framework --- $\\textbf{S}$mooth\n$\\textbf{R}$egularized $\\textbf{R}$einforcement $\\textbf{L}$earning\n($\\textbf{SR}^2\\textbf{L}$), where the policy is trained with\nsmoothness-inducing regularization. Such regularization effectively constrains\nthe search space of the learning algorithms and enforces smoothness in the\nlearned policy. We apply the proposed framework to both on-policy (TRPO) and\noff-policy algorithm (DDPG). Through extensive experiments, we demonstrate that\nour method achieves improved sample efficiency."}, {"title": "On the Power of Compressed Sensing with Generative Models ", "authors": "Akshay Kamath, Eric Price, Sushrut Karmalkar "}, {"title": "Laplacian Regularized Few-Shot Learning", "authors": "Imtiaz Ziko, Jose Dolz, Eric Granger, Ismail Ben Ayed ", "link": "", "summary": ""}, {"title": "Neural Datalog Through Time: Informed Temporal Modeling via Logical Specification", "authors": "Hongyuan Mei, Guanghui Qin, Minjie Xu, Jason Eisner "}, {"title": "Up or Down? Adaptive Rounding for Post-Training Quantization", "authors": "Markus Nagel, Rana Ali Amjad, Marinus van Baalen, Christos Louizos, Tijmen Blankevoort ", "link": "https://arxiv.org/abs/2004.10568", "summary": "When quantizing neural networks, assigning each floating-point weight to its\nnearest fixed-point value is the predominant approach. We find that, perhaps\nsurprisingly, this is not the best we can do. In this paper, we propose\nAdaRound, a better weight-rounding mechanism for post-training quantization\nthat adapts to the data and the task loss. AdaRound is fast, does not require\nfine-tuning of the network, and only uses a small amount of unlabelled data. We\nstart by theoretically analyzing the rounding problem for a pre-trained neural\nnetwork. By approximating the task loss with a Taylor series expansion, the\nrounding task is posed as a quadratic unconstrained binary optimization\nproblem. We simplify this to a layer-wise local loss and propose to optimize\nthis loss with a soft relaxation. AdaRound not only outperforms\nrounding-to-nearest by a significant margin but also establishes a new\nstate-of-the-art for post-training quantization on several networks and tasks.\nWithout fine-tuning, we can quantize the weights of Resnet18 and Resnet50 to 4\nbits while staying within an accuracy loss of 1%."}, {"title": "A quantile-based approach for hyperparameter transfer learning", "authors": "David Salinas, Huibin Shen, Valerio Perrone ", "link": "http://arxiv.org/abs/1909.13595", "summary": "Bayesian optimization (BO) is a popular methodology to tune the\nhyperparameters of expensive black-box functions. Despite its success, standard\nBO focuses on a single task at a time and is not designed to leverage\ninformation from related functions, such as tuning performance metrics of the\nsame algorithm across multiple datasets. In this work, we introduce a novel\napproach to achieve transfer learning across different datasets as well as\ndifferent metrics. The main idea is to regress the mapping from hyperparameter\nto metric quantiles with a semi-parametric Gaussian Copula distribution, which\nprovides robustness against different scales or outliers that can occur in\ndifferent tasks. We introduce two methods to leverage this estimation: a\nThompson sampling strategy as well as a Gaussian Copula process using such\nquantile estimate as a prior. We show that these strategies can combine the\nestimation of multiple metrics such as runtime and accuracy, steering the\noptimization toward cheaper hyperparameters for the same level of accuracy.\nExperiments on an extensive set of hyperparameter tuning tasks demonstrate\nsignificant improvements over state-of-the-art methods."}, {"title": "Inductive Bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters", "authors": "Subho Banerjee, Saurabh Jha, Zbigniew Kalbarczyk, Ravishankar Iyer ", "link": "http://arxiv.org/abs/1909.02119", "summary": "The problem of scheduling of workloads onto heterogeneous processors (e.g.,\nCPUs, GPUs, FPGAs) is of fundamental importance in modern datacenters. Most\ncurrent approaches rely on building application/system-specific heuristics that\nhave to be reinvented on a case-by-case basis. This can be prohibitively\nexpensive and is untenable going forward. In this paper, we propose a\ndomain-driven reinforcement learning (RL) model for scheduling that can be\nbroadly applied to a large class of heterogeneous processors. The key novelty\nof our approach is (i) the RL model; and (ii) the significant reduction of\ntraining-data (using domain knowledge) and -time (using sampling based\nend-to-end gradient propagation). We demonstrate the approach using real world\nGPU and FPGA accelerated applications to produce scheduling policies that\nsignificantly outperform hand-tuned heuristics."}, {"title": "Adversarial Robustness for Code", "authors": "Pavol Bielik, Martin Vechev ", "link": "https://arxiv.org/abs/2002.04694", "summary": "We propose a novel technique which addresses the challenge of learning\naccurate and robust models of code in a principled way. Our method consists of\nthree key components: (i) learning to abstain from making a prediction if\nuncertain, (ii) adversarial training, and (iii) representation refinement which\nlearns the program parts relevant for the prediction and abstracts the rest.\nThese components are used to iteratively train multiple models, each of which\nlearns a suitable program representation necessary to make robust predictions\non a different subset of the dataset. We instantiated our approach to the task\nof type inference for dynamically typed languages and demonstrate its\neffectiveness by learning a model that achieves 88% accuracy and 84%\nrobustness. Further, our evaluation shows that using the combination of all\nthree components is key to obtaining accurate and robust models."}, {"title": "Nearly Optimal Risk Bounds for Kernel K-Means", "authors": "Yong Liu, Lizhong Ding, Hua Zhang, Wenqi Ren, Xiao Zhang, Shali Jiang, Xinwang Liu, Weiping Wang ", "link": "", "summary": ""}, {"title": "The Boomerang Sampler", "authors": "Joris Bierkens, Sebastiano Grazzi, Kengo Kamatani, Gareth Roberts "}, {"title": "Weakly-Supervised Disentanglement Without Compromises", "authors": "Francesco Locatello, Ben Poole, Gunnar Raetsch, Bernhard Sch\u00f6lkopf, Olivier Bachem, Michael Tschannen ", "link": "https://arxiv.org/abs/2002.02886", "summary": "Intelligent agents should be able to learn useful representations by\nobserving changes in their environment. We model such observations as pairs of\nnon-i.i.d. images sharing at least one of the underlying factors of variation.\nFirst, we theoretically show that only knowing how many factors have changed,\nbut not which ones, is sufficient to learn disentangled representations.\nSecond, we provide practical algorithms that learn disentangled representations\nfrom pairs of images without requiring annotation of groups, individual\nfactors, or the number of factors that have changed. Third, we perform a\nlarge-scale empirical study and show that such pairs of observations are\nsufficient to reliably learn disentangled representations on several benchmark\ndata sets. Finally, we evaluate our learned representations and find that they\nare simultaneously useful on a diverse suite of tasks, including generalization\nunder covariate shifts, fairness, and abstract reasoning. Overall, our results\ndemonstrate that weak supervision enables learning of useful disentangled\nrepresentations in realistic scenarios."}, {"title": "Predictive Sampling with Forecasting Autoregressive Models", "authors": "Auke Wiggers, Emiel Hoogeboom "}, {"title": "InfoGAN-CR: Disentangling Generative Adversarial Networks with Contrastive Regularizers", "authors": "Zinan Lin, Kiran Thekumparampil, Giulia Fanti, Sewoong Oh ", "link": "https://arxiv.org/abs/1906.06034", "summary": "Training disentangled representations with generative adversarial networks\n(GANs) remains challenging, with leading implementations failing to achieve\ncomparable performance to Variational Autoencoder (VAE)-based methods. After\n$\\beta$-VAE and FactorVAE discovered that regularizing the total correlation of\nthe latent vectors promotes disentanglement, numerous VAE-based methods\nemerged. Such a discovery has yet to be made for GANs, and reported\ndisentanglement scores of GAN-based methods are significantly inferior to\nVAE-based methods on benchmark datasets. To this end, we propose a novel\nregularizer that achieves higher disentanglement scores than state-of-the-art\nVAE- and GAN-based approaches. The proposed contrastive regularizer is inspired\nby a natural notion of disentanglement: latent traversal. Latent traversal\nrefers to generating images by varying one latent code while fixing the rest.\nWe turn this intuition into a regularizer by adding a discriminator that\ndetects how the latent codes are coupled together, in paired examples.\nNumerical experiments show that this approach improves upon competing\nstate-of-the-art approaches on benchmark datasets."}, {"title": "TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics", "authors": "Alexander Tong, Jessie Huang, Guy Wolf, David van Dijk, Smita Krishnaswamy ", "link": "https://arxiv.org/abs/2002.04461", "summary": "It is increasingly common to encounter data from dynamic processes captured\nby static cross-sectional measurements over time, particularly in biomedical\nsettings. Recent attempts to model individual trajectories from this data use\noptimal transport to create pairwise matchings between time points. However,\nthese methods cannot model continuous dynamics and non-linear paths that\nentities can take in these systems. To address this issue, we establish a link\nbetween continuous normalizing flows and dynamic optimal transport, that allows\nus to model the expected paths of points over time. Continuous normalizing\nflows are generally under constrained, as they are allowed to take an arbitrary\npath from the source to the target distribution. We present TrajectoryNet,\nwhich controls the continuous paths taken between distributions. We show how\nthis is particularly applicable for studying cellular dynamics in data from\nsingle-cell RNA sequencing (scRNA-seq) technologies, and that TrajectoryNet\nimproves upon recently proposed static optimal transport-based models that can\nbe used for interpolating cellular distributions."}, {"title": "The role of regularization in classification of high-dimensional noisy Gaussian mixture", "authors": "Francesca Mignacco, Florent Krzakala, Yue Lu, Pierfrancesco Urbani, Lenka Zdeborova ", "link": "https://arxiv.org/abs/2002.11544", "summary": "We consider a high-dimensional mixture of two Gaussians in the noisy regime\nwhere even an oracle knowing the centers of the clusters misclassifies a small\nbut finite fraction of the points. We provide a rigorous analysis of the\ngeneralization error of regularized convex classifiers, including ridge, hinge\nand logistic regression, in the high-dimensional limit where the number $n$ of\nsamples and their dimension $d$ go to infinity while their ratio is fixed to\n$\\alpha= n/d$. We discuss surprising effects of the regularization that in some\ncases allows to reach the Bayes-optimal performances. We also illustrate the\ninterpolation peak at low regularization, and analyze the role of the\nrespective sizes of the two clusters."}, {"title": "Normalizing Flows on Tori and Spheres", "authors": "Danilo J. Rezende, George Papamakarios, Sebastien Racaniere, Michael S Albergo, Gurtej Kanwar, Phiala Shanahan, Kyle Cranmer ", "link": "https://arxiv.org/abs/2002.02428", "summary": "Normalizing flows are a powerful tool for building expressive distributions\nin high dimensions. So far, most of the literature has concentrated on learning\nflows on Euclidean spaces. Some problems however, such as those involving\nangles, are defined on spaces with more complex geometries, such as tori or\nspheres. In this paper, we propose and compare expressive and numerically\nstable flows on such spaces. Our flows are built recursively on the dimension\nof the space, starting from flows on circles, closed intervals or spheres."}, {"title": "Structured Linear Contextual Bandits: A Sharp and Geometric Smoothed Analysis", "authors": "Vidyashankar Sivakumar, Steven Wu, Arindam Banerjee ", "link": "https://arxiv.org/abs/2002.11332", "summary": "Bandit learning algorithms typically involve the balance of exploration and\nexploitation. However, in many practical applications, worst-case scenarios\nneeding systematic exploration are seldom encountered. In this work, we\nconsider a smoothed setting for structured linear contextual bandits where the\nadversarial contexts are perturbed by Gaussian noise and the unknown parameter\n$\\theta^*$ has structure, e.g., sparsity, group sparsity, low rank, etc. We\npropose simple greedy algorithms for both the single- and multi-parameter\n(i.e., different parameter for each context) settings and provide a unified\nregret analysis for $\\theta^*$ with any assumed structure. The regret bounds\nare expressed in terms of geometric quantities such as Gaussian widths\nassociated with the structure of $\\theta^*$. We also obtain sharper regret\nbounds compared to earlier work for the unstructured $\\theta^*$ setting as a\nconsequence of our improved analysis. We show there is implicit exploration in\nthe smoothed setting where a simple greedy algorithm works."}, {"title": "Simple and sharp analysis of k-means||", "authors": "V\u00e1clav Rozho\u0148 ", "link": "http://arxiv.org/abs/2003.02518", "summary": "We present a truly simple analysis of k-means|| (Bahmani et al., PVLDB 2012)\n-- a distributed variant of the k-means++ algorithm (Arthur and Vassilvitskii,\nSODA 2007) -- and improve it from $O(\\log\\textrm{Var} X)$, where $\\textrm{Var}\nX$ is the variance of the input data set, to $O(\\log\\textrm{Var} X /\n\\log\\log\\textrm{Var} X)$, which we show to be tight."}, {"title": "Efficient proximal mapping of the path-norm regularizer of shallow networks", "authors": "Fabian Latorre, Paul Rolland, Nadav Hallak, Volkan Cevher "}, {"title": "Regularized Optimal Transport is Ground Cost Adversarial", "authors": "Fran\u00e7ois-Pierre Paty, Marco Cuturi ", "link": "https://arxiv.org/abs/2002.03967", "summary": "Regularizing Wasserstein distances has proved to be the key in the recent\nadvances of optimal transport (OT) in machine learning. Most prominent is the\nentropic regularization of OT, which not only allows for fast computations and\ndifferentiation using Sinkhorn algorithm, but also improves stability with\nrespect to data and accuracy in many numerical experiments. Theoretical\nunderstanding of these benefits remains unclear, although recent statistical\nworks have shown that entropy-regularized OT mitigates classical OT's curse of\ndimensionality. In this paper, we adopt a more geometrical point of view, and\nshow using Fenchel duality that any convex regularization of OT can be\ninterpreted as ground cost adversarial. This incidentally gives access to a\nrobust dissimilarity measure on the ground space, which can in turn be used in\nother applications. We propose algorithms to compute this robust cost, and\nillustrate the interest of this approach empirically."}, {"title": "Automatic Shortcut Removal for Self-Supervised Representation Learning", "authors": " Matthias Minderer, Olivier Bachem, Neil Houlsby, Michael Tschannen ", "link": "https://arxiv.org/abs/2002.08822", "summary": "In self-supervised visual representation learning, a feature extractor is\ntrained on a \"pretext task\" for which labels can be generated cheaply. A\ncentral challenge in this approach is that the feature extractor quickly learns\nto exploit low-level visual features such as color aberrations or watermarks\nand then fails to learn useful semantic representations. Much work has gone\ninto identifying such \"shortcut\" features and hand-designing schemes to reduce\ntheir effect. Here, we propose a general framework for removing shortcut\nfeatures automatically. Our key assumption is that those features which are the\nfirst to be exploited for solving the pretext task may also be the most\nvulnerable to an adversary trained to make the task harder. We show that this\nassumption holds across common pretext tasks and datasets by training a \"lens\"\nnetwork to make small image changes that maximally reduce performance in the\npretext task. Representations learned with the modified images outperform those\nlearned without in all tested cases. Additionally, the modifications made by\nthe lens reveal how the choice of pretext task and dataset affects the features\nlearned by self-supervision."}, {"title": "Fair Learning with Private Demographic Data", "authors": "Hussein Mozannar, Mesrob Ohannessian, Nati Srebro ", "link": "https://arxiv.org/abs/2002.11651", "summary": "Sensitive attributes such as race are rarely available to learners in real\nworld settings as their collection is often restricted by laws and regulations.\nWe give a scheme that allows individuals to release their sensitive information\nprivately while still allowing any downstream entity to learn\nnon-discriminatory predictors. We show how to adapt non-discriminatory learners\nto work with privatized protected attributes giving theoretical guarantees on\nperformance. Finally, we highlight how the methodology could apply to learning\nfair predictors in settings where protected attributes are only available for a\nsubset of the data."}, {"title": "Deep Divergence Learning", "authors": "Hatice Kubra Cilingir, Rachel Manzelli, Brian Kulis ", "link": "https://arxiv.org/abs/2005.02612", "summary": "Classical linear metric learning methods have recently been extended along\ntwo distinct lines: deep metric learning methods for learning embeddings of the\ndata using neural networks, and Bregman divergence learning approaches for\nextending learning Euclidean distances to more general divergence measures such\nas divergences over distributions. In this paper, we introduce deep Bregman\ndivergences, which are based on learning and parameterizing functional Bregman\ndivergences using neural networks, and which unify and extend these existing\nlines of work. We show in particular how deep metric learning formulations,\nkernel metric learning, Mahalanobis metric learning, and moment-matching\nfunctions for comparing distributions arise as special cases of these\ndivergences in the symmetric setting. We then describe a deep learning\nframework for learning general functional Bregman divergences, and show in\nexperiments that this method yields superior performance on benchmark datasets\nas compared to existing deep metric learning approaches. We also discuss novel\napplications, including a semi-supervised distributional clustering problem,\nand a new loss function for unsupervised data generation."}, {"title": "A new regret analysis for Adam-type algorithms", "authors": "Ahmet Alacaoglu, Yura Malitsky, Panayotis Mertikopoulos, Volkan Cevher ", "link": "http://arxiv.org/abs/2003.09729", "summary": "In this paper, we focus on a theory-practice gap for Adam and its variants\n(AMSgrad, AdamNC, etc.). In practice, these algorithms are used with a constant\nfirst-order moment parameter $\\beta_{1}$ (typically between $0.9$ and $0.99$).\nIn theory, regret guarantees for online convex optimization require a rapidly\ndecaying $\\beta_{1}\\to0$ schedule. We show that this is an artifact of the\nstandard analysis and propose a novel framework that allows us to derive\noptimal, data-dependent regret bounds with a constant $\\beta_{1}$, without\nfurther assumptions. We also demonstrate the flexibility of our analysis on a\nwide range of different algorithms and settings."}, {"title": "Accelerated Message Passing for Entropy-Regularized MAP Inference", "authors": "Jonathan Lee, Aldo Pacchiano, Peter Bartlett, Michael Jordan ", "link": "", "summary": ""}, {"title": "Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation", "authors": "Konstantinos Pitas ", "link": "https://arxiv.org/abs/1909.03009", "summary": "Explaining how overparametrized neural networks simultaneously achieve low\nrisk and zero empirical risk on benchmark datasets is an open problem.\nPAC-Bayes bounds optimized using variational inference (VI) have been recently\nproposed as a promising direction in obtaining non-vacuous bounds. We show\nempirically that this approach gives negligible gains when modeling the\nposterior as a Gaussian with diagonal covariance--known as the mean-field\napproximation. We investigate common explanations, such as the failure of VI\ndue to problems in optimization or choosing a suboptimal prior. Our results\nsuggest that investigating richer posteriors is the most promising direction\nforward."}, {"title": "(Individual) Fairness for k-Clustering", "authors": "Sepideh Mahabadi, Ali Vakilian ", "link": "http://arxiv.org/abs/2002.06742", "summary": "We give a local search based algorithm for $k$-median ($k$-means) clustering\nfrom the perspective of individual fairness. More precisely, for a point $x$ in\na point set $P$ of size $n$, let $r(x)$ be the minimum radius such that the\nball of radius $r(x)$ centered at $x$ has at least $n/k$ points from $P$.\nIntuitively, if a set of $k$ random points are chosen from $P$ as centers,\nevery point $x\\in P$ expects to have a center within radius $r(x)$. An\nindividually fair clustering provides such a guarantee for every point $x\\in\nP$. This notion of fairness was introduced in [Jung et al., 2019] where they\nshowed how to get an approximately feasible $k$-clustering with respect to this\nfairness condition.\n  In this work, we show how to get an approximately optimal such fair\n$k$-clustering. The $k$-median ($k$-means) cost of our solution is within a\nconstant factor of the cost of an optimal fair $k$-clustering, and our solution\napproximately satisfies the fairness condition (also within a constant factor).\nFurther, we complement our theoretical bounds with empirical evaluation."}, {"title": "Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows", "authors": "Rob Cornish, Anthony Caterini, George Deligiannidis, Arnaud Doucet ", "link": "http://arxiv.org/abs/1909.13833"}, {"title": "Gamification of Pure Exploration for Linear Bandits", "authors": "R\u00e9my Degenne, Pierre Menard, Xuedong Shang, Michal Valko "}, {"title": "Growing Adaptive Multi-hyperplane Machines", "authors": "Nemanja Djuric, Zhuang Wang, Slobodan Vucetic "}, {"title": "Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data", "authors": "Felipe Petroski Such, Aditya Rawal, Joel Lehman, Kenneth Stanley, Jeffrey Clune ", "link": "https://arxiv.org/abs/1912.07768", "summary": "This paper investigates the intriguing question of whether we can create\nlearning algorithms that automatically generate training data, learning\nenvironments, and curricula in order to help AI agents rapidly learn. We show\nthat such algorithms are possible via Generative Teaching Networks (GTNs), a\ngeneral approach that is, in theory, applicable to supervised, unsupervised,\nand reinforcement learning, although our experiments only focus on the\nsupervised case. GTNs are deep neural networks that generate data and/or\ntraining environments that a learner (e.g. a freshly initialized neural\nnetwork) trains on for a few SGD steps before being tested on a target task. We\nthen differentiate through the entire learning process via meta-gradients to\nupdate the GTN parameters to improve performance on the target task. GTNs have\nthe beneficial property that they can theoretically generate any type of data\nor training environment, making their potential impact large. This paper\nintroduces GTNs, discusses their potential, and showcases that they can\nsubstantially accelerate learning. We also demonstrate a practical and exciting\napplication of GTNs: accelerating the evaluation of candidate architectures for\nneural architecture search (NAS), which is rate-limited by such evaluations,\nenabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art,\nfinding higher performing architectures when controlling for the search\nproposal mechanism. GTN-NAS also is competitive with the overall state of the\nart approaches, which achieve top performance while using orders of magnitude\nless computation than typical NAS methods. Speculating forward, GTNs may\nrepresent a first step toward the ambitious goal of algorithms that generate\ntheir own training data and, in doing so, open a variety of interesting new\nresearch questions and directions."}, {"title": "Structured Prediction with Partial Labelling through the Infimum Loss", "authors": "Vivien Cabannnes, Francis Bach, Alessandro Rudi ", "link": "https://arxiv.org/abs/2003.00920", "summary": "Annotating datasets is one of the main costs in nowadays supervised learning.\nThe goal of weak supervision is to enable models to learn using only forms of\nlabelling which are cheaper to collect, as partial labelling. This is a type of\nincomplete annotation where, for each datapoint, supervision is cast as a set\nof labels containing the real one. The problem of supervised learning with\npartial labelling has been studied for specific instances such as\nclassification, multi-label, ranking or segmentation, but a general framework\nis still missing. This paper provides a unified framework based on structured\nprediction and on the concept of infimum loss to deal with partial labelling\nover a wide family of learning problems and loss functions. The framework leads\nnaturally to explicit algorithms that can be easily implemented and for which\nproved statistical consistency and learning rates. Experiments confirm the\nsuperiority of the proposed approach over commonly used baselines."}, {"title": "ControlVAE: Controllable Variational Autoencoder", "authors": "Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin Liu, Jun Wang, Tarek Abdelzaher ", "link": "", "summary": ""}, {"title": "On Semi-parametric Inference for BART", "authors": "Veronika Rockova ", "link": "", "summary": ""}, {"title": "Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network", "authors": "Joost van Amersfoort, Lewis Smith, Yee Whye Teh, Yarin Gal ", "link": "https://arxiv.org/abs/2003.02037", "summary": "We propose a method for training a deterministic deep model that can find and\nreject out of distribution data points at test time with a single forward pass.\nOur approach, deterministic uncertainty quantification (DUQ), builds upon ideas\nof RBF networks. We scale training in these with a novel loss function and\ncentroid updating scheme. By enforcing detectability of changes in the input\nusing a gradient penalty, we are able to reliably detect out of distribution\ndata. Our uncertainty quantification scales well to large datasets, and using a\nsingle model, we improve upon or match Deep Ensembles on notable difficult\ndataset pairs such as FashionMNIST vs. MNIST, and CIFAR-10 vs. SVHN, while\nmaintaining competitive accuracy."}, {"title": "Ordinal Non-negative Matrix Factorization for Recommendation", "authors": "Olivier Gouvert, Thomas Oberlin, Cedric Fevotte ", "link": "http://arxiv.org/abs/2006.01034", "summary": "We introduce a new non-negative matrix factorization (NMF) method for ordinal\ndata, called OrdNMF. Ordinal data are categorical data which exhibit a natural\nordering between the categories. In particular, they can be found in\nrecommender systems, either with explicit data (such as ratings) or implicit\ndata (such as quantized play counts). OrdNMF is a probabilistic latent factor\nmodel that generalizes Bernoulli-Poisson factorization (BePoF) and Poisson\nfactorization (PF) applied to binarized data. Contrary to these methods, OrdNMF\ncircumvents binarization and can exploit a more informative representation of\nthe data. We design an efficient variational algorithm based on a suitable\nmodel augmentation and related to variational PF. In particular, our algorithm\npreserves the scalability of PF and can be applied to huge sparse datasets. We\nreport recommendation experiments on explicit and implicit datasets, and show\nthat OrdNMF outperforms BePoF and PF applied to binarized data."}, {"title": "NetGAN without GAN: From Random Walks to Low-Rank Approximations", "authors": "Luca Rendsburg, Holger Heidrich, Ulrike von Luxburg ", "link": "", "summary": ""}, {"title": "On the Iteration Complexity of Hypergradient Computations", "authors": "Riccardo Grazzi, Saverio Salzo, Massimiliano Pontil, Luca Franceschi "}, {"title": "Skew-Fit: State-Covering Self-Supervised Reinforcement Learning", "authors": "Vitchyr Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl, Sergey Levine ", "link": "https://arxiv.org/abs/1903.03698", "summary": "Autonomous agents that must exhibit flexible and broad capabilities will need\nto be equipped with large repertoires of skills. Defining each skill with a\nmanually-designed reward function limits this repertoire and imposes a manual\nengineering burden. Self-supervised agents that set their own goals can\nautomate this process, but designing appropriate goal setting objectives can be\ndifficult, and often involves heuristic design decisions. In this paper, we\npropose a formal exploration objective for goal-reaching policies that\nmaximizes state coverage. We show that this objective is equivalent to\nmaximizing goal reaching performance together with the entropy of the goal\ndistribution, where goals correspond to full state observations. To instantiate\nthis principle, we present an algorithm called Skew-Fit for learning a\nmaximum-entropy goal distributions. We prove that, under regularity conditions,\nSkew-Fit converges to a uniform distribution over the set of valid states, even\nwhen we do not know this set beforehand. Our experiments show that combining\nSkew-Fit for learning goal distributions with existing goal-reaching methods\noutperforms a variety of prior methods on open-sourced visual goal-reaching\ntasks. Moreover, we demonstrate that \\METHOD enables a real-world robot to\nlearn to open a door, entirely from scratch, from pixels, and without any\nmanually-designed reward function."}, {"title": "Stochastic Optimization for Regularized Wasserstein Estimators", "authors": "Marin Ballu, Quentin Berthet, Francis Bach ", "link": "https://arxiv.org/abs/2002.08695", "summary": "Optimal transport is a foundational problem in optimization, that allows to\ncompare probability distributions while taking into account geometric aspects.\nIts optimal objective value, the Wasserstein distance, provides an important\nloss between distributions that has been used in many applications throughout\nmachine learning and statistics. Recent algorithmic progress on this problem\nand its regularized versions have made these tools increasingly popular.\nHowever, existing techniques require solving an optimization problem to obtain\na single gradient of the loss, thus slowing down first-order methods to\nminimize the sum of losses, that require many such gradient computations. In\nthis work, we introduce an algorithm to solve a regularized version of this\nproblem of Wasserstein estimators, with a time per step which is sublinear in\nthe natural dimensions of the problem. We introduce a dual formulation, and\noptimize it with stochastic gradient steps that can be computed directly from\nsamples, without solving additional optimization problems at each step. Doing\nso, the estimation and computation tasks are performed jointly. We show that\nthis algorithm can be extended to other tasks, including estimation of\nWasserstein barycenters. We provide theoretical guarantees and illustrate the\nperformance of our algorithm with experiments on synthetic data."}, {"title": "LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured Prediction", "authors": "Vlad Niculae, Andre Filipe Torres Martins ", "link": "https://arxiv.org/abs/2001.04437", "summary": "Structured prediction requires manipulating a large number of combinatorial\nstructures, e.g., dependency trees or alignments, either as latent or output\nvariables. Recently, the SparseMAP method has been proposed as a\ndifferentiable, sparse alternative to maximum a posteriori (MAP) and marginal\ninference. SparseMAP returns a combination of a small number of structures, a\ndesirable property in some downstream applications. However, SparseMAP requires\na tractable MAP inference oracle. This excludes, e.g., loopy graphical models\nor factor graphs with logic constraints, which generally require approximate\ninference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP\nthat addresses this limitation via a local polytope relaxation. LP-SparseMAP\nuses the flexible and powerful domain specific language of factor graphs for\ndefining and backpropagating through arbitrary hidden structure, supporting\ncoarse decompositions, hard logic constraints, and higher-order correlations.\nWe derive the forward and backward algorithms needed for using LP-SparseMAP as\na hidden or output layer. Experiments in three structured prediction tasks show\nbenefits compared to SparseMAP and Structured SVM."}, {"title": "Problems with Shapley-value-based explanations as feature importance measures", "authors": "I. Elizabeth Kumar, Suresh Venkatasubramanian, Carlos  Scheidegger, Sorelle Friedler ", "link": "https://arxiv.org/abs/2002.11097", "summary": "Game-theoretic formulations of feature importance have become popular as a\nway to \"explain\" machine learning models. These methods define a cooperative\ngame between the features of a model and distribute influence among these input\nelements using some form of the game's unique Shapley values. Justification for\nthese methods rests on two pillars: their desirable mathematical properties,\nand their applicability to specific motivations for explanations. We show that\nmathematical problems arise when Shapley values are used for feature importance\nand that the solutions to mitigate these necessarily induce further complexity,\nsuch as the need for causal reasoning. We also draw on additional literature to\nargue that Shapley values do not provide explanations which suit human-centric\ngoals of explainability."}, {"title": "Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes", "authors": "Chen-Yu Wei, Mehdi Jafarnia, Haipeng Luo, Hiteshi Sharma, Rahul Jain ", "link": "https://arxiv.org/abs/1910.07072", "summary": "Model-free reinforcement learning is known to be memory and computation\nefficient and more amendable to large scale problems. In this paper, two\nmodel-free algorithms are introduced for learning infinite-horizon\naverage-reward Markov Decision Processes (MDPs). The first algorithm reduces\nthe problem to the discounted-reward version and achieves\n$\\mathcal{O}(T^{2/3})$ regret after $T$ steps, under the minimal assumption of\nweakly communicating MDPs. To our knowledge, this is the first model-free\nalgorithm for general MDPs in this setting. The second algorithm makes use of\nrecent advances in adaptive algorithms for adversarial multi-armed bandits and\nimproves the regret to $\\mathcal{O}(\\sqrt{T})$, albeit with a stronger ergodic\nassumption. This result significantly improves over the $\\mathcal{O}(T^{3/4})$\nregret achieved by the only existing model-free algorithm by Abbasi-Yadkori et\nal. (2019a) for ergodic MDPs in the infinite-horizon average-reward setting."}, {"title": "Near-linear time Gaussian process optimization with adaptive batching and resparsification", "authors": "Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal Valko, Lorenzo Rosasco ", "link": "https://arxiv.org/abs/2002.09954", "summary": "Gaussian processes (GP) are one of the most successful frameworks to model\nuncertainty. However, GP optimization (e.g., GP-UCB) suffers from major\nscalability issues. Experimental time grows linearly with the number of\nevaluations, unless candidates are selected in batches (e.g., using GP-BUCB)\nand evaluated in parallel. Furthermore, computational cost is often prohibitive\nsince algorithms such as GP-BUCB require a time at least quadratic in the\nnumber of dimensions and iterations to select each batch. In this paper, we\nintroduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP\noptimization algorithm that provably runs in near-linear time and selects\ncandidates in batches. This is obtained with a new guarantee for the tracking\nof the posterior variances that allows BBKB to choose increasingly larger\nbatches, improving over GP-BUCB. Moreover, we show that the same bound can be\nused to adaptively delay costly updates to the sparse GP approximation used by\nBBKB, achieving a near-constant per-step amortized cost. These findings are\nthen confirmed in several experiments, where BBKB is much faster than\nstate-of-the-art methods."}, {"title": "Parallel Algorithm for Non-Monotone DR-Submodular Maximization", "authors": "Alina Ene, Huy Nguyen ", "link": "https://arxiv.org/abs/1905.13272", "summary": "In this work, we give a new parallel algorithm for the problem of maximizing\na non-monotone diminishing returns submodular function subject to a cardinality\nconstraint. For any desired accuracy $\\epsilon$, our algorithm achieves a $1/e\n- \\epsilon$ approximation using $O(\\log{n} \\log(1/\\epsilon) / \\epsilon^3)$\nparallel rounds of function evaluations. The approximation guarantee nearly\nmatches the best approximation guarantee known for the problem in the\nsequential setting and the number of parallel rounds is nearly-optimal for any\nconstant $\\epsilon$. Previous algorithms achieve worse approximation guarantees\nusing $\\Omega(\\log^2{n})$ parallel rounds. Our experimental evaluation suggests\nthat our algorithm obtains solutions whose objective value nearly matches the\nvalue obtained by the state of the art sequential algorithms, and it\noutperforms previous parallel algorithms in number of parallel rounds,\niterations, and solution quality."}, {"title": "Structure Adaptive Algorithms for Stochastic Bandits", "authors": "R\u00e9my Degenne, Han Shao, Wouter Koolen "}, {"title": "Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks", "authors": "Blake Bordelon, Abdulkadir Canatar, Cengiz Pehlevan ", "link": "https://arxiv.org/abs/2002.02561", "summary": "We derive analytical expressions for the generalization performance of kernel\nregression as a function of the number of training samples using theoretical\nmethods from Gaussian processes and statistical physics. Our expressions apply\nto wide neural networks due to an equivalence between training them and kernel\nregression with the Neural Tangent Kernel (NTK). By computing the decomposition\nof the total generalization error due to different spectral components of the\nkernel, we identify a new spectral principle: as the size of the training set\ngrows, kernel machines and neural networks fit successively higher spectral\nmodes of the target function. When data are sampled from a uniform distribution\non a high-dimensional hypersphere, dot product kernels, including NTK, exhibit\nlearning stages where different frequency modes of the target function are\nlearned. We verify our theory with simulations on synthetic data and MNIST\ndataset."}, {"title": "Preference modelling with context-dependent salient features", "authors": "Amanda Bower, Laura Balzano ", "link": "https://arxiv.org/abs/2002.09615", "summary": "We consider the problem of estimating a ranking on a set of items from noisy\npairwise comparisons given item features. We address the fact that pairwise\ncomparison data often reflects irrational choice, e.g. intransitivity. Our key\nobservation is that two items compared in isolation from other items may be\ncompared based on only a salient subset of features. Formalizing this\nframework, we propose the \"salient feature preference model\" and prove a sample\ncomplexity result for learning the parameters of our model and the underlying\nranking with maximum likelihood estimation. We also provide empirical results\nthat support our theoretical bounds and illustrate how our model explains\nsystematic intransitivity. Finally we demonstrate strong performance of maximum\nlikelihood estimation of our model on both synthetic data and two real data\nsets: the UT Zappos50K data set and comparison data about the compactness of\nlegislative districts in the US."}, {"title": "Infinite attention: NNGP and NTK for deep attention networks", "authors": "Jiri Hron, Yasaman Bahri, Jascha Sohl-Dickstein, Roman Novak "}, {"title": "Fast Learning of Graph Neural Networks with Guaranteed Generalizability: One-hidden-layer Case", "authors": "shuai zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, Jinjun Xiong "}, {"title": "Efficient Domain Generalization via Common-Specific Low-Rank Decomposition", "authors": "Vihari Piratla, Praneeth Netrapalli, Sunita Sarawagi ", "link": "https://arxiv.org/abs/2003.12815", "summary": "Domain generalization refers to the task of training a model which\ngeneralizes to new domains that are not seen during training. We present CSD\n(Common Specific Decomposition), for this setting,which jointly learns a common\ncomponent (which generalizes to new domains) and a domain specific component\n(which overfits on training domains). The domain specific components are\ndiscarded after training and only the common component is retained. The\nalgorithm is extremely simple and involves only modifying the final linear\nclassification layer of any given neural network architecture. We present a\nprincipled analysis to understand existing approaches, provide identifiability\nresults of CSD,and study effect of low-rank on domain generalization. We show\nthat CSD either matches or beats state of the art approaches for domain\ngeneralization based on domain erasure, domain perturbed data augmentation, and\nmeta-learning. Further diagnostics on rotated MNIST, where domains are\ninterpretable, confirm the hypothesis that CSD successfully disentangles common\nand domain specific components and hence leads to better domain generalization."}, {"title": "Identifying the Reward Function by Anchor Actions", "authors": "Sinong Geng, Houssam Nassif, Carlos Manzanares, Max Reppen, Ronnie Sircar "}, {"title": "No-Regret and Incentive-Compatible Online Learning", "authors": "Rupert Freeman, David Pennock, Charikleia Podimata, Jennifer Wortman Vaughan ", "link": "https://arxiv.org/abs/2002.08837", "summary": "We study online learning settings in which experts act strategically to\nmaximize their influence on the learning algorithm's predictions by potentially\nmisreporting their beliefs about a sequence of binary events. Our goal is\ntwofold. First, we want the learning algorithm to be no-regret with respect to\nthe best fixed expert in hindsight. Second, we want incentive compatibility, a\nguarantee that each expert's best strategy is to report his true beliefs about\nthe realization of each event. To achieve this goal, we build on the literature\non wagering mechanisms, a type of multi-agent scoring rule. We provide\nalgorithms that achieve no regret and incentive compatibility for myopic\nexperts for both the full and partial information settings. In experiments on\ndatasets from FiveThirtyEight, our algorithms have regret comparable to classic\nno-regret algorithms, which are not incentive-compatible. Finally, we identify\nan incentive-compatible algorithm for forward-looking strategic agents that\nexhibits diminishing regret in practice."}, {"title": "Probing Emergent Semantics in Predictive Agents via Question Answering", "authors": "Abhishek Das, Federico Carnevale, Hamza Merzic, Laura Rimell, Rosalia Schneider, Josh Abramson, Alden Hung, Arun Ahuja, Stephen Clark, Greg Wayne, Feilx Hill ", "link": "https://arxiv.org/abs/2006.01016", "summary": "Recent work has shown how predictive modeling can endow agents with rich\nknowledge of their surroundings, improving their ability to act in complex\nenvironments. We propose question-answering as a general paradigm to decode and\nunderstand the representations that such agents develop, applying our method to\ntwo recent approaches to predictive modeling -action-conditional CPC (Guo et\nal., 2018) and SimCore (Gregor et al., 2019). After training agents with these\npredictive objectives in a visually-rich, 3D environment with an assortment of\nobjects, colors, shapes, and spatial configurations, we probe their internal\nstate representations with synthetic (English) questions, without\nbackpropagating gradients from the question-answering decoder into the agent.\nThe performance of different agents when probed this way reveals that they\nlearn to encode factual, and seemingly compositional, information about\nobjects, properties and spatial relations from their physical environment. Our\napproach is intuitive, i.e. humans can easily interpret responses of the model\nas opposed to inspecting continuous vectors, and model-agnostic, i.e.\napplicable to any modeling approach. By revealing the implicit knowledge of\nobjects, quantities, properties and relations acquired by agents as they learn,\nquestion-conditional agent probing can stimulate the design and development of\nstronger predictive learning objectives."}, {"title": "Meta-learning with Stochastic Linear Bandits", "authors": "Leonardo Cella, Alessandro Lazaric, Massimiliano Pontil ", "link": "https://arxiv.org/abs/2005.08531", "summary": "We investigate meta-learning procedures in the setting of stochastic linear\nbandits tasks. The goal is to select a learning algorithm which works well on\naverage over a class of bandits tasks, that are sampled from a\ntask-distribution. Inspired by recent work on learning-to-learn linear\nregression, we consider a class of bandit algorithms that implement a\nregularized version of the well-known OFUL algorithm, where the regularization\nis a square euclidean distance to a bias vector. We first study the benefit of\nthe biased OFUL algorithm in terms of regret minimization. We then propose two\nstrategies to estimate the bias within the learning-to-learn setting. We show\nboth theoretically and experimentally, that when the number of tasks grows and\nthe variance of the task-distribution is small, our strategies have a\nsignificant advantage over learning the tasks in isolation."}, {"title": "A Unified Theory of Decentralized SGD with Changing Topology and Local Updates", "authors": "Anastasiia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, Sebastian Stich ", "link": "https://arxiv.org/abs/2003.10422", "summary": "Decentralized stochastic optimization methods have gained a lot of attention\nrecently, mainly because of their cheap per iteration cost, data locality, and\ntheir communication-efficiency. In this paper we introduce a unified\nconvergence analysis that covers a large variety of decentralized SGD methods\nwhich so far have required different intuitions, have different applications,\nand which have been developed separately in various communities.\n  Our algorithmic framework covers local SGD updates and synchronous and\npairwise gossip updates on adaptive network topology. We derive universal\nconvergence rates for smooth (convex and non-convex) problems and the rates\ninterpolate between the heterogeneous (non-identically distributed data) and\niid-data settings, recovering linear convergence rates in many special cases,\nfor instance for over-parametrized models. Our proofs rely on weak assumptions\n(typically improving over prior work in several aspects) and recover (and\nimprove) the best known complexity results for a host of important scenarios,\nsuch as for instance coorperative SGD and federated averaging (local SGD)."}, {"title": "AdaScale SGD: A User-Friendly Algorithm for Distributed Training", "authors": "Tyler Johnson, Pulkit Agrawal, Haijie Gu, Carlos Guestrin "}, {"title": "Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning", "authors": "Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy, John Langford ", "link": "https://arxiv.org/abs/1911.05815", "summary": "We present an algorithm, HOMER, for exploration and reinforcement learning in\nrich observation environments that are summarizable by an unknown latent state\nspace. The algorithm interleaves representation learning to identify a new\nnotion of kinematic state abstraction with strategic exploration to reach new\nstates using the learned abstraction. The algorithm provably explores the\nenvironment with sample complexity scaling polynomially in the number of latent\nstates and the time horizon, and, crucially, with no dependence on the size of\nthe observation space, which could be infinitely large. This exploration\nguarantee further enables sample-efficient global policy optimization for any\nreward function. On the computational side, we show that the algorithm can be\nimplemented efficiently whenever certain supervised learning problems are\ntractable. Empirically, we evaluate HOMER on a challenging exploration problem,\nwhere we show that the algorithm is exponentially more sample efficient than\nstandard reinforcement learning baselines."}, {"title": "Logistic Regression for Massive Data with Rare Events", "authors": "HaiYing Wang ", "link": "http://arxiv.org/abs/2006.00683", "summary": "This paper studies binary logistic regression for rare events data, or\nimbalanced data, where the number of events (observations in one class, often\ncalled cases) is significantly smaller than the number of nonevents\n(observations in the other class, often called controls). We first derive the\nasymptotic distribution of the maximum likelihood estimator (MLE) of the\nunknown parameter, which shows that the asymptotic variance convergences to\nzero in a rate of the inverse of the number of the events instead of the\ninverse of the full data sample size. This indicates that the available\ninformation in rare events data is at the scale of the number of events instead\nof the full data sample size. Furthermore, we prove that under-sampling a small\nproportion of the nonevents, the resulting under-sampled estimator may have\nidentical asymptotic distribution to the full data MLE. This demonstrates the\nadvantage of under-sampling nonevents for rare events data, because this\nprocedure may significantly reduce the computation and/or data collection\ncosts. Another common practice in analyzing rare events data is to over-sample\n(replicate) the events, which has a higher computational cost. We show that\nthis procedure may even result in efficiency loss in terms of parameter\nestimation."}, {"title": "Automated Synthetic-to-Real Generalization", "authors": "Wuyang Chen, Zhiding Yu, Zhangyang Wang, Anima Anandkumar "}, {"title": "Online Learning with Dependent Stochastic Feedback Graphs", "authors": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Ningshan Zhang ", "link": "", "summary": ""}, {"title": "Sparse Sinkhorn Attention", "authors": "Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, Da-Cheng Juan ", "link": "https://arxiv.org/abs/2002.11296", "summary": "We propose Sparse Sinkhorn Attention, a new efficient and sparse method for\nlearning to attend. Our method is based on differentiable sorting of internal\nrepresentations. Concretely, we introduce a meta sorting network that learns to\ngenerate latent permutations over sequences. Given sorted sequences, we are\nthen able to compute quasi-global attention with only local windows, improving\nthe memory efficiency of the attention module. To this end, we propose new\nalgorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a\ndynamic sequence truncation method for tailoring Sinkhorn Attention for\nencoding and/or decoding purposes. Via extensive experiments on algorithmic\nseq2seq sorting, language modeling, pixel-wise image generation, document\nclassification and natural language inference, we demonstrate that our memory\nefficient Sinkhorn Attention method is competitive with vanilla attention and\nconsistently outperforms recently proposed efficient Transformer models such as\nSparse Transformers."}, {"title": "Online Continual Learning from Imbalanced Data", "authors": "Aristotelis Chrysakis, Marie-Francine Moens "}, {"title": "Differentially Private Set Union", "authors": "Pankaj  Gulhane, Sivakanth  Gopi, Janardhan Kulkarni, Judy Hanwen Shen, Milad Shokouhi, Sergey Yekhanin ", "link": "https://arxiv.org/abs/2002.09745", "summary": "We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n  Known algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem."}, {"title": "The continuous categorical: a novel simplex-valued exponential family", "authors": "Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, John Cunningham ", "link": "https://arxiv.org/abs/2002.08563", "summary": "Simplex-valued data appear throughout statistics and machine learning, for\nexample in the context of transfer learning and compression of deep networks.\nExisting models for this class of data rely on the Dirichlet distribution or\nother related loss functions; here we show these standard choices suffer\nsystematically from a number of limitations, including bias and numerical\nissues that frustrate the use of flexible network models upstream of these\ndistributions. We resolve these limitations by introducing a novel exponential\nfamily of distributions for modeling simplex-valued data - the continuous\ncategorical, which arises as a nontrivial multivariate generalization of the\nrecently discovered continuous Bernoulli. Unlike the Dirichlet and other\ntypical choices, the continuous categorical results in a well-behaved\nprobabilistic loss function that produces unbiased estimators, while preserving\nthe mathematical simplicity of the Dirichlet. As well as exploring its\ntheoretical properties, we introduce sampling methods for this distribution\nthat are amenable to the reparameterization trick, and evaluate their\nperformance. Lastly, we demonstrate that the continuous categorical outperforms\nstandard choices empirically, across a simulation study, an applied example on\nmulti-party elections, and a neural network compression task."}, {"title": "Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation", "authors": "Yaqi Duan, Zeyu Jia, Mengdi Wang ", "link": "http://arxiv.org/abs/2002.09516", "summary": "This paper studies the statistical theory of batch data reinforcement\nlearning with function approximation. Consider the off-policy evaluation\nproblem, which is to estimate the cumulative value of a new target policy from\nlogged history generated by unknown behavioral policies. We study a\nregression-based fitted Q iteration method, and show that it is equivalent to a\nmodel-based method that estimates a conditional mean embedding of the\ntransition operator. We prove that this method is information-theoretically\noptimal and has nearly minimal estimation error. In particular, by leveraging\ncontraction property of Markov processes and martingale concentration, we\nestablish a finite-sample instance-dependent error upper bound and a\nnearly-matching minimax lower bound. The policy evaluation error depends\nsharply on a restricted $\\chi^2$-divergence over the function class between the\nlong-term distribution of the target policy and the distribution of past data.\nThis restricted $\\chi^2$-divergence is both instance-dependent and\nfunction-class-dependent. It characterizes the statistical limit of off-policy\nevaluation. Further, we provide an easily computable confidence bound for the\npolicy evaluator, which may be useful for optimistic planning and safe policy\nimprovement."}, {"title": "Enhanced POET: Open-ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions", "authors": "Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, Kenneth Stanley ", "link": "https://arxiv.org/abs/2003.08536", "summary": "Creating open-ended algorithms, which generate their own never-ending stream\nof novel and appropriately challenging learning opportunities, could help to\nautomate and accelerate progress in machine learning. A recent step in this\ndirection is the Paired Open-Ended Trailblazer (POET), an algorithm that\ngenerates and solves its own challenges, and allows solutions to goal-switch\nbetween challenges to avoid local optima. However, the original POET was unable\nto demonstrate its full creative potential because of limitations of the\nalgorithm itself and because of external issues including a limited problem\nspace and lack of a universal progress measure. Importantly, both limitations\npose impediments not only for POET, but for the pursuit of open-endedness in\ngeneral. Here we introduce and empirically validate two new innovations to the\noriginal algorithm, as well as two external innovations designed to help\nelucidate its full potential. Together, these four advances enable the most\nopen-ended algorithmic demonstration to date. The algorithmic innovations are\n(1) a domain-general measure of how meaningfully novel new challenges are,\nenabling the system to potentially create and solve interesting challenges\nendlessly, and (2) an efficient heuristic for determining when agents should\ngoal-switch from one problem to another (helping open-ended search better\nscale). Outside the algorithm itself, to enable a more definitive demonstration\nof open-endedness, we introduce (3) a novel, more flexible way to encode\nenvironmental challenges, and (4) a generic measure of the extent to which a\nsystem continues to exhibit open-ended innovation. Enhanced POET produces a\ndiverse range of sophisticated behaviors that solve a wide range of\nenvironmental challenges, many of which cannot be solved through other means."}, {"title": "Set Functions for Time Series ", "authors": "Max Horn, Michael Moor, Christian Bock, Bastian Rieck, Karsten Borgwardt ", "link": "https://arxiv.org/abs/1909.12064", "summary": "Despite the eminent successes of deep neural networks, many architectures are\noften hard to transfer to irregularly-sampled and asynchronous time series that\ncommonly occur in real-world datasets, especially in healthcare applications.\nThis paper proposes a novel approach for classifying irregularly-sampled time\nseries with unaligned measurements, focusing on high scalability and data\nefficiency. Our method SeFT (Set Functions for Time Series) is based on recent\nadvances in differentiable set function learning, extremely parallelizable with\na beneficial memory footprint, thus scaling well to large datasets of long time\nseries and online monitoring scenarios. Furthermore, our approach permits\nquantifying per-observation contributions to the classification outcome. We\nextensively compare our method with existing algorithms on multiple healthcare\ntime series datasets and demonstrate that it performs competitively whilst\nsignificantly reducing runtime."}, {"title": "Individual Calibration with Randomized Forecasting", "authors": "Shengjia Zhao, Tengyu Ma, Stefano Ermon "}, {"title": "Bayesian Differential Privacy for Machine Learning", "authors": "Aleksei Triastcyn, Boi Faltings ", "link": "https://arxiv.org/abs/1901.09697", "summary": "We propose Bayesian differential privacy, a relaxation of differential\nprivacy that provides more practical privacy guarantees for similarly\ndistributed data, especially in difficult scenarios, such as deep learning. We\nderive a general privacy accounting method for iterative learning algorithms\nunder Bayesian differential privacy and show that it is a generalisation of the\nwell-known moments accountant. Our experiments demonstrate significant\nimprovements in privacy guarantees for typical deep learning datasets, such as\nMNIST and CIFAR-10, in some cases bringing the privacy budget from 8 down to\n0.5. Additionally, we demonstrate applicability of Bayesian differential\nprivacy to variational inference and achieve the state-of-the-art\nprivacy-accuracy trade-off."}, {"title": "Causal Modeling for Fairness In Dynamical Systems", "authors": "Elliot Creager, David Madras, Toniann Pitassi, Richard Zemel ", "link": "https://arxiv.org/abs/1909.09141", "summary": "In this work, we present causal directed acyclic graphs (DAGs) as a unifying\nframework for the recent literature on fairness in dynamical systems. We\nadvocate for the use of causal DAGs as a tool in both designing equitable\npolicies and estimating their impacts. By visualizing models of dynamic\nunfairness graphically, we expose implicit causal assumptions which can then be\nmore easily interpreted and scrutinized by domain experts. We demonstrate that\nthis method of reinterpretation can be used to critique the robustness of an\nexisting model/policy, or uncover new policy evaluation questions. Causal\nmodels also enable a rich set of options for evaluating a new candidate policy\nwithout incurring the risk of implementing the policy in the real world. We\nclose the paper with causal analyses of several models from the recent\nliterature, and provide an in-depth case study to demonstrate the utility of\ncausal DAGs for modeling fairness in dynamical systems."}, {"title": "Learning General-Purpose Controllers via Locally Communicating Sensorimotor Modules", "authors": "Wenlong Huang, Igor Mordatch, Deepak Pathak "}, {"title": "Visual Grounding of Learned Physical Models", "authors": "Yunzhu Li, Toru Lin, Kexin Yi, Daniel Bear, Daniel Yamins, Jiajun Wu, Josh Tenenbaum, Antonio Torralba ", "link": "http://arxiv.org/abs/2004.13664", "summary": "Humans intuitively recognize objects' physical properties and predict their\nmotion, even when the objects are engaged in complicated interactions. The\nabilities to perform physical reasoning and to adapt to new environments, while\nintrinsic to humans, remain challenging to state-of-the-art computational\nmodels. In this work, we present a neural model that simultaneously reasons\nabout physics and make future predictions based on visual and dynamics priors.\nThe visual prior predicts a particle-based representation of the system from\nvisual observations. An inference module operates on those particles,\npredicting and refining estimates of particle locations, object states, and\nphysical parameters, subject to the constraints imposed by the dynamics prior,\nwhich we refer to as visual grounding. We demonstrate the effectiveness of our\nmethod in environments involving rigid objects, deformable materials, and\nfluids. Experiments show that our model can infer the physical properties\nwithin a few observations, which allows the model to quickly adapt to unseen\nscenarios and make accurate predictions into the future."}, {"title": "Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics", "authors": "Mahsa Ghasemi, Erdem Bulgur, Ufuk Topcu "}, {"title": "Test-Time Training for Generalization under Distribution Shifts", "authors": "Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, University of California Moritz Hardt ", "link": "", "summary": ""}, {"title": "Auto-GAN-Distiller: Searching to Compress Generative Adversarial Networks", "authors": "Yonggan Fu, Wuyang Chen, Haotao Wang, Haoran Li, Yingyan Lin, Zhangyang Wang ", "link": "", "summary": ""}, {"title": "Associative Memory in Iterated Overparameterized Sigmoid Autoencoders", "authors": "Yibo Jiang, Cengiz Pehlevan ", "link": "", "summary": ""}, {"title": "Adaptive Reward-Poisoning Attacks against Reinforcement Learning", "authors": "Xuezhou Zhang, Yuzhe Ma, Adish Singla, Jerry Zhu ", "link": "https://arxiv.org/abs/2003.12613", "summary": "In reward-poisoning attacks against reinforcement learning (RL), an attacker\ncan perturb the environment reward $r_t$ into $r_t+\\delta_t$ at each step, with\nthe goal of forcing the RL agent to learn a nefarious policy. We categorize\nsuch attacks by the infinity-norm constraint on $\\delta_t$: We provide a lower\nthreshold below which reward-poisoning attack is infeasible and RL is certified\nto be safe; we provide a corresponding upper threshold above which the attack\nis feasible. Feasible attacks can be further categorized as non-adaptive where\n$\\delta_t$ depends only on $(s_t,a_t, s_{t+1})$, or adaptive where $\\delta_t$\ndepends further on the RL agent's learning process at time $t$. Non-adaptive\nattacks have been the focus of prior works. However, we show that under mild\nconditions, adaptive attacks can achieve the nefarious policy in steps\npolynomial in state-space size $|S|$, whereas non-adaptive attacks require\nexponential steps. We provide a constructive proof that a Fast Adaptive Attack\nstrategy achieves the polynomial rate. Finally, we show that empirically an\nattacker can find effective reward-poisoning attacks using state-of-the-art\ndeep RL techniques."}, {"title": "Planning to Explore via Latent Disagreement", "authors": "Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak "}, {"title": "Defense Through Diverse Directions", "authors": "Christopher Bender, Yang Li, Yifeng Shi, Michael K. Reiter, Junier Oliva ", "link": "https://arxiv.org/abs/2003.10602", "summary": "In this work we develop a novel Bayesian neural network methodology to\nachieve strong adversarial robustness without the need for online adversarial\ntraining. Unlike previous efforts in this direction, we do not rely solely on\nthe stochasticity of network weights by minimizing the divergence between the\nlearned parameter distribution and a prior. Instead, we additionally require\nthat the model maintain some expected uncertainty with respect to all input\ncovariates. We demonstrate that by encouraging the network to distribute evenly\nacross inputs, the network becomes less susceptible to localized, brittle\nfeatures which imparts a natural robustness to targeted perturbations. We show\nempirical robustness on several benchmark datasets."}, {"title": "Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels", "authors": "Lu Jiang, Di Huang, Mason Liu, Weilong Yang "}, {"title": "Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks", "authors": "David Stutz, Matthias Hein, Bernt Schiele ", "link": "https://arxiv.org/abs/1910.06259", "summary": "Adversarial training yields robust models against a specific threat model,\ne.g., $L_\\infty$ adversarial examples. Typically robustness does not generalize\nto previously unseen threat models, e.g., other $L_p$ norms, or larger\nperturbations. Our confidence-calibrated adversarial training (CCAT) tackles\nthis problem by biasing the model towards low confidence predictions on\nadversarial examples. By allowing to reject examples with low confidence,\nrobustness generalizes beyond the threat model employed during training. CCAT,\ntrained only on $L_\\infty$ adversarial examples, increases robustness against\nlarger $L_\\infty$, $L_2$, $L_1$ and $L_0$ attacks, adversarial frames, distal\nadversarial examples and corrupted examples and yields better clean accuracy\ncompared to adversarial training. For thorough evaluation we developed novel\nwhite- and black-box attacks directly attacking CCAT by maximizing confidence.\nFor each threat model, we use $7$ attacks with up to $50$ restarts and $5000$\niterations and report worst-case robust test error, extended to our\nconfidence-thresholded setting, across all attacks."}, {"title": "Online Control of the False Coverage Rate and False Sign Rate", "authors": "Asaf Weinstein, Aaditya Ramdas ", "link": "https://arxiv.org/abs/1905.01059", "summary": "The false coverage rate (FCR) is the expected ratio of number of constructed\nconfidence intervals (CIs) that fail to cover their respective parameters to\nthe total number of constructed CIs. Procedures for FCR control exist in the\noffline setting, but none so far have been designed with the online setting in\nmind. In the online setting, there is an infinite sequence of fixed unknown\nparameters $\\theta_t$ ordered by time. At each step, we see independent data\nthat is informative about $\\theta_t$, and must immediately make a decision\nwhether to report a CI for $\\theta_t$ or not. If $\\theta_t$ is selected for\ncoverage, the task is to determine how to construct a CI for $\\theta_t$ such\nthat $\\text{FCR} \\leq \\alpha$ for any $T\\in \\mathbb{N}$. A straightforward\nsolution is to construct at each step a $(1-\\alpha)$ level conditional CI. In\nthis paper, we present a novel solution to the problem inspired by online false\ndiscovery rate (FDR) algorithms, which only requires the statistician to be\nable to construct a marginal CI at any given level. Apart from the fact that\nmarginal CIs are usually simpler to construct than conditional ones, the\nmarginal procedure has an important qualitative advantage over the conditional\nsolution, namely, it allows selection to be determined by the candidate CI\nitself. We take advantage of this to offer solutions to some online problems\nwhich have not been addressed before. For example, we show that our general CI\nprocedure can be used to devise online sign-classification procedures that\ncontrol the false sign rate (FSR). In terms of power and length of the\nconstructed CIs, we demonstrate that the two approaches have complementary\nstrengths and weaknesses using simulations. Last, all of our methodology\napplies equally well to online FCR control for prediction intervals, having\nparticular implications for assumption-free selective conformal inference."}, {"title": "Online Convex Optimization in the Random Order Model", "authors": "Dan Garber, Gal Korcia, Kfir Levy ", "link": "", "summary": ""}, {"title": "A Flexible Latent Space Model for Multilayer Networks", "authors": "Xuefei Zhang, Songkai Xue, Ji Zhu "}, {"title": "Estimation of Bounds on Potential Outcomes For Decision Making", "authors": "Maggie Makar, Fredrik Johansson, John Guttag, David Sontag ", "link": "", "summary": ""}, {"title": "Deep Gaussian Markov random fields", "authors": "Per Sid\u00e9n, Fredrik Lindsten ", "link": "https://arxiv.org/abs/2002.07467", "summary": "Gaussian Markov random fields (GMRFs) are probabilistic graphical models\nwidely used in spatial statistics and related fields to model dependencies over\nspatial structures. We establish a formal connection between GMRFs and\nconvolutional neural networks (CNNs). Common GMRFs are special cases of a\ngenerative model where the inverse mapping from data to latent variables is\ngiven by a 1-layer linear CNN. This connection allows us to generalize GMRFs to\nmulti-layer CNN architectures, effectively increasing the order of the\ncorresponding GMRF in a way which has favorable computational scaling. We\ndescribe how well-established tools, such as autodiff and variational\ninference, can be used for simple and efficient inference and learning of the\ndeep GMRF. We demonstrate the flexibility of the proposed model and show that\nit outperforms the state-of-the-art on a dataset of satellite temperatures, in\nterms of prediction and predictive uncertainty."}, {"title": "Generalization Error of Generalized Linear Models in High Dimensions", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep Rangan, Alyson Fletcher ", "link": "https://arxiv.org/abs/2005.00180", "summary": "At the heart of machine learning lies the question of generalizability of\nlearned rules over previously unseen data. While over-parameterized models\nbased on neural networks are now ubiquitous in machine learning applications,\nour understanding of their generalization capabilities is incomplete. This task\nis made harder by the non-convexity of the underlying learning problems. We\nprovide a general framework to characterize the asymptotic generalization error\nfor single-layer neural networks (i.e., generalized linear models) with\narbitrary non-linearities, making it applicable to regression as well as\nclassification problems. This framework enables analyzing the effect of (i)\nover-parameterization and non-linearity during modeling; and (ii) choices of\nloss function, initialization, and regularizer during learning. Our model also\ncaptures mismatch between training and test distributions. As examples, we\nanalyze a few special cases, namely linear regression and logistic regression.\nWe are also able to rigorously and analytically explain the \\emph{double\ndescent} phenomenon in generalized linear models."}, {"title": "Poisson Learning: Graph Based Semi-Supervised Learning At Very Low Label Rates", "authors": "Jeff Calder, Brendan Cook, Matthew Thorpe, Dejan Slepcev "}, {"title": "Sequential Transfer in Reinforcement Learning with a Generative Model", "authors": "Andrea Tirinzoni, Riccardo Poiani, Marcello Restelli "}, {"title": "Finite-Time Convergence in Continuous-Time Optimization", "authors": "Orlando Romero, mouhacine Benosman ", "link": "", "summary": ""}, {"title": "Feature Quantization Improves GAN Training", "authors": "Yang Zhao, Chunyuan Li, Ping Yu, Jianfeng Gao, Changyou Chen ", "link": "https://arxiv.org/abs/2004.02088", "summary": "The instability in GAN training has been a long-standing problem despite\nremarkable research efforts. We identify that instability issues stem from\ndifficulties of performing feature matching with mini-batch statistics, due to\na fragile balance between the fixed target distribution and the progressively\ngenerated distribution. In this work, we propose Feature Quantization (FQ) for\nthe discriminator, to embed both true and fake data samples into a shared\ndiscrete space. The quantized values of FQ are constructed as an evolving\ndictionary, which is consistent with feature statistics of the recent\ndistribution history. Hence, FQ implicitly enables robust feature matching in a\ncompact space. Our method can be easily plugged into existing GAN models, with\nlittle computational overhead in training. We apply FQ to 3 representative GAN\nmodels on 9 benchmarks: BigGAN for image generation, StyleGAN for face\nsynthesis, and U-GAT-IT for unsupervised image-to-image translation. Extensive\nexperimental results show that the proposed FQ-GAN can improve the FID scores\nof baseline methods by a large margin on a variety of tasks, achieving new\nstate-of-the-art performance."}, {"title": "Temporal Logic Point Processes", "authors": "Shuang Li, Lu Wang, Ruizhi Zhang, xiaofu Chang, Xuqin Liu, Yao Xie, Yuan Qi, Le Song ", "link": "", "summary": ""}, {"title": "Hallucinative Topological Memory for Zero-Shot Visual Planning", "authors": "Thanard Kurutach, Kara Liu, Aviv Tamar, Pieter Abbeel, Christine Tung ", "link": "https://arxiv.org/abs/2002.12336", "summary": "In visual planning (VP), an agent learns to plan goal-directed behavior from\nobservations of a dynamical system obtained offline, e.g., images obtained from\nself-supervised robot interaction. Most previous works on VP approached the\nproblem by planning in a learned latent space, resulting in low-quality visual\nplans, and difficult training algorithms. Here, instead, we propose a simple VP\nmethod that plans directly in image space and displays competitive performance.\nWe build on the semi-parametric topological memory (SPTM) method: image samples\nare treated as nodes in a graph, the graph connectivity is learned from image\nsequence data, and planning can be performed using conventional graph search\nmethods. We propose two modifications on SPTM. First, we train an energy-based\ngraph connectivity function using contrastive predictive coding that admits\nstable training. Second, to allow zero-shot planning in new domains, we learn a\nconditional VAE model that generates images given a context of the domain, and\nuse these hallucinated samples for building the connectivity graph and\nplanning. We show that this simple approach significantly outperform the\nstate-of-the-art VP methods, in terms of both plan interpretability and success\nrate when using the plan to guide a trajectory-following controller.\nInterestingly, our method can pick up non-trivial visual properties of objects,\nsuch as their geometry, and account for it in the plans."}, {"title": "Learning Attentive Meta-Transfer", "authors": "Jaesik Yoon, Gautam Singh, Sungjin Ahn "}, {"title": "Optimizing Dynamic Structures with Bayesian Generative Search", "authors": "Minh Hoang, Carleton Kingsford "}, {"title": "Amortized Finite Element Analysis for Fast PDE-Constrained Optimization", "authors": "Tianju Xue, Alex Beatson, Sigrid Adriaenssens , Ryan P. Adams "}, {"title": "Preselection Bandits", "authors": "Viktor Bengs, Eyke H\u00fcllermeier ", "link": "", "summary": ""}, {"title": "Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates", "authors": "Yang Liu, Hongyi Guo ", "link": "https://arxiv.org/abs/1910.03231", "summary": "Learning with noisy labels is a common problem in supervised learning.\nExisting approaches require practitioners to specify \\emph{noise rates}, i.e.,\na set of parameters controlling the severity of label noises in the problem.\nThe specifications are either assumed to be given or estimated using additional\napproaches. In this work, we introduce a technique to learn from noisy labels\nthat does not require a priori specification of the noise rates. In particular,\nwe introduce a new family of loss functions that we name as \\emph{peer loss}\nfunctions. Our approach then uses a standard empirical risk minimization (ERM)\nframework with peer loss functions. Peer loss functions associate each training\nsample with a certain form of \"peer\" samples, which evaluate a classifier'\npredictions jointly. We show that, under mild conditions, performing ERM with\npeer loss functions on the noisy dataset leads to the optimal or a near optimal\nclassifier as if performing ERM over the clean training data, which we do not\nhave access to. To our best knowledge, this is the first result on \"learning\nwith noisy labels without knowing noise rates\" with theoretical guarantees. We\npair our results with an extensive set of experiments, where we compare with\nstate-of-the-art techniques of learning with noisy labels. Our results show\nthat peer loss functions based method consistently outperforms the baseline\nbenchmarks, as well as some recent new results. Peer loss provides a way to\nsimplify model development when facing potentially noisy training labels, and\ncan be promoted as a robust candidate loss function in such situations."}, {"title": "Rank Aggregation from Pairwise Comparisons in the Presence of Adversarial Corruptions", "authors": "Prathamesh Patil, Arpit Agarwal, Shivani Agarwal, Sanjeev Khanna "}, {"title": "Extrapolation for Large-batch Training in Deep Learning", "authors": "Tao LIN, Lingjing Kong, Sebastian Stich, Martin Jaggi "}, {"title": "VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing", "authors": "Zolt\u00e1n Milacski, Barnab\u00e1s P\u00f3czos, Andras Lorincz ", "link": "", "summary": ""}, {"title": "Bio-Inspired Hashing for Unsupervised Similarity Search", "authors": "Chaitanya Ryali, John Hopfield, Leopold Grinberg, Dmitry Krotov ", "link": "https://arxiv.org/abs/2001.04907", "summary": "The fruit fly Drosophila's olfactory circuit has inspired a new locality\nsensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH\nalgorithms that produce low dimensional hash codes, FlyHash produces sparse\nhigh-dimensional hash codes and has also been shown to have superior empirical\nperformance compared to classical LSH algorithms in similarity search. However,\nFlyHash uses random projections and cannot learn from data. Building on\ninspiration from FlyHash and the ubiquity of sparse expansive representations\nin neurobiology, our work proposes a novel hashing algorithm BioHash that\nproduces sparse high dimensional hash codes in a data-driven manner. We show\nthat BioHash outperforms previously published benchmarks for various hashing\nmethods. Since our learning algorithm is based on a local and biologically\nplausible synaptic plasticity rule, our work provides evidence for the proposal\nthat LSH might be a computational reason for the abundance of sparse expansive\nmotifs in a variety of biological systems. We also propose a convolutional\nvariant BioConvHash that further improves performance. From the perspective of\ncomputer science, BioHash and BioConvHash are fast, scalable and yield\ncompressed binary representations that are useful for similarity search."}, {"title": "MetaFun: Meta-Learning with Iterative Functional Updates", "authors": "Jin Xu, Jean-Francois Ton, Hyunjik Kim, Adam Kosiorek, Yee Whye Teh ", "link": "https://arxiv.org/abs/1912.02738", "summary": "We develop a functional encoder-decoder approach to supervised meta-learning,\nwhere labeled data is encoded into an infinite-dimensional functional\nrepresentation rather than a finite-dimensional one. Furthermore, rather than\ndirectly producing the representation, we learn a neural update rule resembling\nfunctional gradient descent which iteratively improves the representation. The\nfinal representation is used to condition the decoder to make predictions on\nunlabeled data. Our approach is the first to demonstrates the success of\nencoder-decoder style meta-learning methods like conditional neural processes\non large-scale few-shot classification benchmarks such as miniImageNet and\ntieredImageNet, where it achieves state-of-the-art performance."}, {"title": "Learning and Simulation in Generative Structured World Models", "authors": "Zhixuan Lin, Yi-Fu Wu, Skand Peri, Bofeng Fu, Jindong Jiang, Sungjin Ahn "}, {"title": "Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization", "authors": "Richard Zhang, Daniel Golovin "}, {"title": "SGD Learns One-Layer Networks in WGANs", "authors": "Qi Lei, Jason Lee, Alexandros Dimakis, Constantinos Daskalakis ", "link": "", "summary": ""}, {"title": "Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation", "authors": "Xiang Jiang, Qicheng Lao, Stan Matwin, Mohammad Havaei "}, {"title": "Interference and Generalization in Temporal Difference Learning", "authors": "Emmanuel Bengio, Joelle Pineau, Doina Precup ", "link": "https://arxiv.org/abs/2003.06350", "summary": "We study the link between generalization and interference in\ntemporal-difference (TD) learning. Interference is defined as the inner product\nof two different gradients, representing their alignment. This quantity emerges\nas being of interest from a variety of observations about neural networks,\nparameter sharing and the dynamics of learning. We find that TD easily leads to\nlow-interference, under-generalizing parameters, while the effect seems\nreversed in supervised learning. We hypothesize that the cause can be traced\nback to the interplay between the dynamics of interference and bootstrapping.\nThis is supported empirically by several observations: the negative\nrelationship between the generalization gap and interference in TD, the\nnegative effect of bootstrapping on interference and the local coherence of\ntargets, and the contrast between the propagation rate of information in TD(0)\nversus TD($\\lambda$) and regression tasks such as Monte-Carlo policy\nevaluation. We hope that these new findings can guide the future discovery of\nbetter bootstrapping methods."}, {"title": "CoMic: Co-Training and Mimicry for Reusable Skills", "authors": "Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, Josh Merel "}, {"title": "Provably Efficient Model-based Policy Adaptation", "authors": "Yuda Song, Aditi Mavalankar, Wen Sun, Sicun Gao "}, {"title": "Optimizer Benchmarking Needs to Account for Hyperparameter Tuning", "authors": "Prabhu Teja Sivaprasad, Florian Mai, Thijs Vogels, Martin Jaggi, Francois Fleuret ", "link": "https://arxiv.org/abs/1910.11758", "summary": "The performance of optimizers, particularly in deep learning, depends\nconsiderably on their chosen hyperparameter configuration. The efficacy of\noptimizers is often studied under near-optimal problem-specific\nhyperparameters, and finding these settings may be prohibitively costly for\npractitioners. In this work, we argue that a fair assessment of optimizers'\nperformance must take the computational cost of hyperparameter tuning into\naccount, i.e., how easy it is to find good hyperparameter configurations using\nan automatic hyperparameter search. Evaluating a variety of optimizers on an\nextensive set of standard datasets and architectures, our results indicate that\nAdam is the most practical solution, particularly in low-budget scenarios."}, {"title": "From Local SGD to Local Fixed Point Methods for Federated Learning", "authors": "Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent CONDAT, Peter Richtarik ", "link": "https://arxiv.org/abs/2004.01442", "summary": "Most algorithms for solving optimization problems or finding saddle points of\nconvex-concave functions are fixed point algorithms. In this work we consider\nthe generic problem of finding a fixed point of an average of operators, or an\napproximation thereof, in a distributed setting. Our work is motivated by the\nneeds of federated learning. In this context, each local operator models the\ncomputations done locally on a mobile device. We investigate two strategies to\nachieve such a consensus: one based on a fixed number of local steps, and the\nother based on randomized computations. In both cases, the goal is to limit\ncommunication of the locally-computed variables, which is often the bottleneck\nin distributed frameworks. We perform convergence analysis of both methods and\nconduct a number of experiments highlighting the benefits of our approach."}, {"title": "Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks", "authors": "Micah Goldblum, Liam Fowl, Renkun Ni, Steven Reich, Valeriia Cherepanova, Tom Goldstein ", "link": "http://arxiv.org/abs/2002.06753", "summary": "Meta-learning algorithms produce feature extractors which achieve\nstate-of-the-art performance on few-shot classification. While the literature\nis rich with meta-learning methods, little is known about why the resulting\nfeature extractors perform so well. We develop a better understanding of the\nunderlying mechanics of meta-learning and the difference between models trained\nusing meta-learning and models which are trained classically. In doing so, we\ndevelop several hypotheses for why meta-learned models perform better. In\naddition to visualizations, we design several regularizers inspired by our\nhypotheses which improve performance on few-shot classification."}, {"title": "Federated Learning with Only Positive Labels", "authors": "Felix Xinnan Yu, Ankit Singh Rawat, Aditya Menon, Sanjiv Kumar ", "link": "https://arxiv.org/abs/2004.10342", "summary": "We consider learning a multi-class classification model in the federated\nsetting, where each user has access to the positive data associated with only a\nsingle class. As a result, during each federated learning round, the users need\nto locally update the classifier without having access to the features and the\nmodel parameters for the negative classes. Thus, naively employing conventional\ndecentralized learning such as the distributed SGD or Federated Averaging may\nlead to trivial or extremely poor classifiers. In particular, for the embedding\nbased classifiers, all the class embeddings might collapse to a single point.\n  To address this problem, we propose a generic framework for training with\nonly positive labels, namely Federated Averaging with Spreadout (FedAwS), where\nthe server imposes a geometric regularizer after each round to encourage\nclasses to be spreadout in the embedding space. We show, both theoretically and\nempirically, that FedAwS can almost match the performance of conventional\nlearning where users have access to negative labels. We further extend the\nproposed method to the settings with large output spaces."}, {"title": "Causal Inference using Gaussian Processes with Structured Latent Confounders", "authors": "Sam Witty, Kenta Takatsu, David Jensen, Vikash Mansinghka "}, {"title": "T-Basis: a Compact Representation for Neural Networks", "authors": "Anton Obukhov, Maxim Rakhuba, Menelaos Kanakis, Stamatios Georgoulis, Dengxin  Dai, Luc Van Gool "}, {"title": "Familywise Error Rate Control by Interactive Unmasking", "authors": "Boyan Duan, Aaditya Ramdas, Larry Wasserman ", "link": "https://arxiv.org/abs/2002.08545", "summary": "We propose a method for multiple hypothesis testing with familywise error\nrate (FWER) control, called the i-FWER test. Most testing methods are\npredefined algorithms that do not allow modifications after observing the data.\nHowever, in practice, analysts tend to choose a promising algorithm after\nobserving the data; unfortunately, this violates the validity of the\nconclusion. The i-FWER test allows much flexibility: a human (or a computer\nprogram acting on the human's behalf) may adaptively guide the algorithm in a\ndata-dependent manner. We prove that our test controls FWER if the analysts\nadhere to a particular protocol of \"masking\" and \"unmasking\". We demonstrate\nvia numerical experiments the power of our test under structured non-nulls, and\nthen explore new forms of masking."}, {"title": "Learning to Branch for Multi-Task Learning", "authors": "Pengsheng Guo, Chen-Yu Lee, Daniel Ulbricht ", "link": "https://arxiv.org/abs/2006.01895", "summary": "Training multiple tasks jointly in one deep network yields reduced latency\nduring inference and better performance over the single-task counterpart by\nsharing certain layers of a network. However, over-sharing a network could\nerroneously enforce over-generalization, causing negative knowledge transfer\nacross tasks. Prior works rely on human intuition or pre-computed task\nrelatedness scores for ad hoc branching structures. They provide sub-optimal\nend results and often require huge efforts for the trial-and-error process. In\nthis work, we present an automated multi-task learning algorithm that learns\nwhere to share or branch within a network, designing an effective network\ntopology that is directly optimized for multiple objectives across tasks.\nSpecifically, we propose a novel tree-structured design space that casts a tree\nbranching operation as a gumbel-softmax sampling procedure. This enables\ndifferentiable network splitting that is end-to-end trainable. We validate the\nproposed method on controlled synthetic data, CelebA, and Taskonomy."}, {"title": "Augmenting Continuous Time Bayesian Networks with Clocks", "authors": "Nicolai Engelmann, Dominik Linzner, Heinz Koeppl "}, {"title": "IPBoost \u2013 Non-Convex Boosting via Integer Programming", "authors": "Sebastian Pokutta, Marc Pfetsch ", "link": "http://arxiv.org/abs/2002.04679", "summary": "Recently non-convex optimization approaches for solving machine learning\nproblems have gained significant attention. In this paper we explore non-convex\nboosting in classification by means of integer programming and demonstrate\nreal-world practicability of the approach while circumventing shortcomings of\nconvex boosting approaches. We report results that are comparable to or better\nthan the current state-of-the-art."}, {"title": "On Efficient Constructions of Checkpoints", "authors": "Yu Chen, Zhenming LIU, Bin Ren, Xin Jin "}, {"title": "Feature Selection using Stochastic Gates", "authors": "Yutaro Yamada, Ofir Lindenbaum, Sahand Negahban, Yuval Kluger ", "link": "http://arxiv.org/abs/1810.04247", "summary": "Feature selection problems have been extensively studied for linear\nestimation, for instance, Lasso, but less emphasis has been placed on feature\nselection for non-linear functions. In this study, we propose a method for\nfeature selection in high-dimensional non-linear function estimation problems.\nThe new procedure is based on minimizing the $\\ell_0$ norm of the vector of\nindicator variables that represent if a feature is selected or not. Our\napproach relies on the continuous relaxation of Bernoulli distributions, which\nallows our model to learn the parameters of the approximate Bernoulli\ndistributions via gradient descent. This general framework simultaneously\nminimizes a loss function while selecting relevant features. Furthermore, we\nprovide an information-theoretic justification of incorporating Bernoulli\ndistribution into our approach and demonstrate the potential of the approach on\nsynthetic and real-life applications."}, {"title": "How to train your Neural ODE", "authors": "Chris Finlay, Joern-Henrik Jacobsen, Levon Nurbekyan, Adam M Oberman ", "link": "", "summary": ""}, {"title": "Evaluating Lossy Compression Rates of Deep Generative Models", "authors": "Sicong Huang, Alireza Makhzani, Yanshuai Cao, Roger Grosse "}, {"title": "Mix-n-Match : Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning", "authors": "Jize Zhang, Bhavya Kailkhura, T. Yong-Jin Han ", "link": "https://arxiv.org/abs/2003.07329", "summary": "This paper studies the problem of post-hoc calibration of machine learning\nclassifiers. We introduce the following desiderata for uncertainty calibration:\n(a) accuracy-preserving, (b) data-efficient, and (c) high expressive power. We\nshow that none of the existing methods satisfy all three requirements, and\ndemonstrate how Mix-n-Match calibration strategies (i.e., ensemble and\ncomposition) can help achieve remarkably better data-efficiency and expressive\npower while provably preserving classification accuracy of the original\nclassifier. We also show that existing calibration error estimators (e.g.,\nhistogram-based ECE) are unreliable especially in small-data regime. Therefore,\nwe propose an alternative data-efficient kernel density-based estimator for a\nreliable evaluation of the calibration performance and prove its asymptotically\nunbiasedness and consistency."}, {"title": "Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization", "authors": "Sicheng Zhu, Xiao Zhang, David Evans ", "link": "https://arxiv.org/abs/2002.11798", "summary": "Training machine learning models to be robust against adversarial inputs\nposes seemingly insurmountable challenges. To better understand model\nrobustness, we consider the underlying problem of learning robust\nrepresentations. We develop a general definition of representation\nvulnerability that captures the maximum change of mutual information between\nthe input and output distributions, under the worst-case input distribution\nperturbation. We prove a theorem that establishes a lower bound on the minimum\nadversarial risk that can be achieved for any downstream classifier based on\nthis definition. We then propose an unsupervised learning method for obtaining\nintrinsically robust representations by maximizing the worst-case mutual\ninformation between input and output distributions. Experiments on downstream\nclassification tasks and analyses of saliency maps support the robustness of\nthe representations found using unsupervised learning with our training\nprinciple."}, {"title": "Stochastic Regret Minimization in Extensive-Form Games", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm ", "link": "https://arxiv.org/abs/2002.08493", "summary": "Monte-Carlo counterfactual regret minimization (MCCFR) is the\nstate-of-the-art algorithm for solving sequential games that are too large for\nfull tree traversals. It works by using gradient estimates that can be computed\nvia sampling. However, stochastic methods for sequential games have not been\ninvestigated extensively beyond MCCFR. In this paper we develop a new framework\nfor developing stochastic regret minimization methods. This framework allows us\nto use any regret-minimization algorithm, coupled with any gradient estimator.\nThe MCCFR algorithm can be analyzed as a special case of our framework, and\nthis analysis leads to significantly-stronger theoretical on convergence, while\nsimultaneously yielding a simplified proof. Our framework allows us to\ninstantiate several new stochastic methods for solving sequential games. We\nshow extensive experiments on three games, where some variants of our methods\noutperform MCCFR."}, {"title": "Simultaneous Inference for Massive Data: Distributed Bootstrap", "authors": "Yang Yu, Shih-Kang Chao, Guang Cheng ", "link": "http://arxiv.org/abs/2002.08443", "summary": "In this paper, we propose a bootstrap method applied to massive data\nprocessed distributedly in a large number of machines. This new method is\ncomputationally efficient in that we bootstrap on the master machine without\nover-resampling, typically required by existing methods\n\\cite{kleiner2014scalable,sengupta2016subsampled}, while provably achieving\noptimal statistical efficiency with minimal communication. Our method does not\nrequire repeatedly re-fitting the model but only applies multiplier bootstrap\nin the master machine on the gradients received from the worker machines.\nSimulations validate our theory."}, {"title": "Stabilizing Differentiable Architecture Search via Perturbation-based Regularization", "authors": "Xiangning Chen, Cho-Jui Hsieh ", "link": "https://arxiv.org/abs/2002.05283", "summary": "Differentiable architecture search (DARTS) is a prevailing NAS solution to\nidentify architectures. Based on the continuous relaxation of the architecture\nspace, DARTS learns a differentiable architecture weight and largely reduces\nthe search cost. However, its stability and generalizability have been\nchallenged for yielding deteriorating architectures as the search proceeds. We\nfind that the precipitous validation loss landscape, which leads to a dramatic\nperformance drop when distilling the final architecture, is an essential factor\nthat causes instability. Based on this observation, we propose a\nperturbation-based regularization, named SmoothDARTS (SDARTS), to smooth the\nloss landscape and improve the generalizability of DARTS. In particular, our\nnew formulations stabilize DARTS by either random smoothing or adversarial\nattack. The search trajectory on NAS-Bench-1Shot1 demonstrates the\neffectiveness of our approach and due to the improved stability, we achieve\nperformance gain across various search spaces on 4 datasets. Furthermore, we\nmathematically show that SDARTS implicitly regularizes the Hessian norm of the\nvalidation loss, which accounts for a smoother loss landscape and improved\nperformance. The code is available at\nhttps://github.com/xiangning-chen/SmoothDARTS."}, {"title": "Boosting Frank-Wolfe by Chasing Gradients", "authors": "Cyrille Combettes, Sebastian Pokutta ", "link": "https://arxiv.org/abs/2003.06369", "summary": "The Frank-Wolfe algorithm has become a popular first-order optimization\nalgorithm for it is simple and projection-free, and it has been successfully\napplied to a variety of real-world problems. Its main drawback however lies in\nits convergence rate, which can be excessively slow due to naive descent\ndirections. We propose to speed-up the Frank-Wolfe algorithm by better aligning\nthe descent direction with that of the negative gradient via a subroutine. This\nsubroutine chases the negative gradient direction in a matching pursuit-style\nwhile still preserving the projection-free property. Although the approach is\nreasonably natural, it produces very significant results. We derive convergence\nrates $\\mathcal{O}(1/t)$ to $\\mathcal{O}(e^{-\\omega t^p})$ of our method where\n$p\\in\\left]0,1\\right]$, and we demonstrate its competitive advantage both per\niteration and in CPU time over the state-of-the-art in a series of\ncomputational experiments."}, {"title": "Concise Explanations of Neural Networks using Adversarial Training", "authors": "Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury, Xi Wu, Somesh Jha ", "link": "https://arxiv.org/abs/1810.06583", "summary": "We show new connections between adversarial learning and explainability for\ndeep neural networks (DNNs). One form of explanation of the output of a neural\nnetwork model in terms of its input features, is a vector of\nfeature-attributions. Two desirable characteristics of an attribution-based\nexplanation are: (1) $\\textit{sparseness}$: the attributions of irrelevant or\nweakly relevant features should be negligible, thus resulting in\n$\\textit{concise}$ explanations in terms of the significant features, and (2)\n$\\textit{stability}$: it should not vary significantly within a small local\nneighborhood of the input. Our first contribution is a theoretical exploration\nof how these two properties (when using attributions based on Integrated\nGradients, or IG) are related to adversarial training, for a class of 1-layer\nnetworks (which includes logistic regression models for binary and multi-class\nclassification); for these networks we show that (a) adversarial training using\nan $\\ell_\\infty$-bounded adversary produces models with sparse attribution\nvectors, and (b) natural model-training while encouraging stable explanations\n(via an extra term in the loss function), is equivalent to adversarial\ntraining. Our second contribution is an empirical verification of phenomenon\n(a), which we show, somewhat surprisingly, occurs $\\textit{not only}$\n$\\textit{in 1-layer networks}$, $\\textit{but also}$ $\\textit{DNNs trained on}$\n$\\textit{standard image}$ $\\textit{ datasets}$, and extends beyond IG-based\nattributions, to those based on DeepSHAP: adversarial training with\n$\\ell_\\infty$-bounded perturbations yields significantly sparser attribution\nvectors, with little degradation in performance on natural test data, compared\nto natural training. Moreover, the sparseness of the attribution vectors is\nsignificantly better than that achievable via $\\ell_1$-regularized natural\ntraining."}, {"title": "Quantum Boosting", "authors": "Srinivasan Arunachalam, Reevu Maity ", "link": "https://arxiv.org/abs/2002.05056", "summary": "Suppose we have a weak learning algorithm $\\mathcal{A}$ for a Boolean-valued\nproblem: $\\mathcal{A}$ produces hypotheses whose bias $\\gamma$ is small, only\nslightly better than random guessing (this could, for instance, be due to\nimplementing $\\mathcal{A}$ on a noisy device), can we boost the performance of\n$\\mathcal{A}$ so that $\\mathcal{A}$'s output is correct on $2/3$ of the inputs?\n  Boosting is a technique that converts a weak and inaccurate machine learning\nalgorithm into a strong accurate learning algorithm. The AdaBoost algorithm by\nFreund and Schapire (for which they were awarded the G\\\"odel prize in 2003) is\none of the widely used boosting algorithms, with many applications in theory\nand practice. Suppose we have a $\\gamma$-weak learner for a Boolean concept\nclass $C$ that takes time $R(C)$, then the time complexity of AdaBoost scales\nas $VC(C)\\cdot poly(R(C), 1/\\gamma)$, where $VC(C)$ is the $VC$-dimension of\n$C$. In this paper, we show how quantum techniques can improve the time\ncomplexity of classical AdaBoost. To this end, suppose we have a $\\gamma$-weak\nquantum learner for a Boolean concept class $C$ that takes time $Q(C)$, we\nintroduce a quantum boosting algorithm whose complexity scales as\n$\\sqrt{VC(C)}\\cdot poly(Q(C),1/\\gamma);$ thereby achieving a quadratic quantum\nimprovement over classical AdaBoost in terms of $VC(C)$."}, {"title": "Information-Theoretic Local Minima Characterization and Regularization", "authors": "Zhiwei Jia, Hao Su ", "link": "https://arxiv.org/abs/1911.08192", "summary": "Recent advances in deep learning theory have evoked the study of\ngeneralizability across different local minima of deep neural networks (DNNs).\nWhile current work focused on either discovering properties of good local\nminima or developing regularization techniques to induce good local minima, no\napproach exists that can tackle both problems. We achieve these two goals\nsuccessfully in a unified manner. Specifically, based on the Fisher information\nwe propose a metric both strongly indicative of generalizability of local\nminima and effectively applied as a practical regularizer. We provide\ntheoretical analysis including a generalization bound and empirically\ndemonstrate the success of our approach in both capturing and improving the\ngeneralizability of DNNs. Experiments are performed on CIFAR-10 and CIFAR-100\nfor various network architectures."}, {"title": "Kernel interpolation with continuous volume sampling", "authors": "Ayoub Belhadji, R\u00e9mi Bardenet, Pierre Chainais ", "link": "https://arxiv.org/abs/2002.09677", "summary": "A fundamental task in kernel methods is to pick nodes and weights, so as to\napproximate a given function from an RKHS by the weighted sum of kernel\ntranslates located at the nodes. This is the crux of kernel density estimation,\nkernel quadrature, or interpolation from discrete samples. Furthermore, RKHSs\noffer a convenient mathematical and computational framework. We introduce and\nanalyse continuous volume sampling (VS), the continuous counterpart -- for\nchoosing node locations -- of a discrete distribution introduced in (Deshpande\n& Vempala, 2006). Our contribution is theoretical: we prove almost optimal\nbounds for interpolation and quadrature under VS. While similar bounds already\nexist for some specific RKHSs using ad-hoc node constructions, VS offers bounds\nthat apply to any Mercer kernel and depend on the spectrum of the associated\nintegration operator. We emphasize that, unlike previous randomized approaches\nthat rely on regularized leverage scores or determinantal point processes,\nevaluating the pdf of VS only requires pointwise evaluations of the kernel. VS\nis thus naturally amenable to MCMC samplers."}, {"title": "Efficient Identification in Linear Structural Causal Models with Auxiliary Cutsets", "authors": "Daniel Kumor, Carlos Cinelli, Elias Bareinboim "}, {"title": "Partial Trace Regression and Low-Rank Kraus Decomposition", "authors": "Hachem Kadri, Stephane Ayache, Riikka Huusari, alain rakotomamonjy, Ralaivola Liva "}, {"title": "Constant Curvature Graph Convolutional Networks", "authors": "Gregor Bachmann, Gary Becigneul, Octavian Ganea ", "link": "https://arxiv.org/abs/1911.05076", "summary": "Interest has been rising lately towards methods representing data in\nnon-Euclidean spaces, e.g. hyperbolic or spherical, that provide specific\ninductive biases useful for certain real-world data properties, e.g.\nscale-free, hierarchical or cyclical. However, the popular graph neural\nnetworks are currently limited in modeling data only via Euclidean geometry and\nassociated vector space operations. Here, we bridge this gap by proposing\nmathematically grounded generalizations of graph convolutional networks (GCN)\nto (products of) constant curvature spaces. We do this by i) introducing a\nunified formalism that can interpolate smoothly between all geometries of\nconstant curvature, ii) leveraging gyro-barycentric coordinates that generalize\nthe classic Euclidean concept of the center of mass. Our class of models\nsmoothly recover their Euclidean counterparts when the curvature goes to zero\nfrom either side. Empirically, we outperform Euclidean GCNs in the tasks of\nnode classification and distortion minimization for symbolic data exhibiting\nnon-Euclidean behavior, according to their discrete curvature."}, {"title": "Educating Text Autoencoders: Latent Representation Guidance via Denoising", "authors": "Tianxiao Shen, Jonas Mueller, Regina Barzilay, Tommi Jaakkola ", "link": "https://arxiv.org/abs/1905.12777", "summary": "Generative autoencoders offer a promising approach for controllable text\ngeneration by leveraging their latent sentence representations. However,\ncurrent models struggle to maintain coherent latent spaces required to perform\nmeaningful text manipulations via latent vector operations. Specifically, we\ndemonstrate by example that neural encoders do not necessarily map similar\nsentences to nearby latent vectors. A theoretical explanation for this\nphenomenon establishes that high-capacity autoencoders can learn an arbitrary\nmapping between sequences and associated latent representations. To remedy this\nissue, we augment adversarial autoencoders with a denoising objective where\noriginal sentences are reconstructed from perturbed versions (referred to as\nDAAE). We prove that this simple modification guides the latent space geometry\nof the resulting model by encouraging the encoder to map similar texts to\nsimilar latent representations. In empirical comparisons with various types of\nautoencoders, our model provides the best trade-off between generation quality\nand reconstruction capacity. Moreover, the improved geometry of the DAAE latent\nspace enables zero-shot text style transfer via simple latent vector\narithmetic."}, {"title": "Generalization via Derandomization", "authors": "Jeffrey Negrea, Daniel Roy, Gintare Karolina Dziugaite ", "link": "", "summary": ""}, {"title": "Inductive Relation Prediction by Subgraph Reasoning", "authors": "Komal Teru, Etienne Denis, Will Hamilton ", "link": "https://arxiv.org/abs/1911.06962", "summary": "The dominant paradigm for relation prediction in knowledge graphs involves\nlearning and operating on latent representations (i.e., embeddings) of entities\nand relations. However, these embedding-based methods do not explicitly capture\nthe compositional logical rules underlying the knowledge graph, and they are\nlimited to the transductive setting, where the full set of entities must be\nknown during training. Here, we propose a graph neural network based relation\nprediction framework, GraIL, that reasons over local subgraph structures and\nhas a strong inductive bias to learn entity-independent relational semantics.\nUnlike embedding-based models, GraIL is naturally inductive and can generalize\nto unseen entities and graphs after training. We provide theoretical proof and\nstrong empirical evidence that GraIL can represent a useful subset of\nfirst-order logic and show that GraIL outperforms existing rule-induction\nbaselines in the inductive setting. We also demonstrate significant gains\nobtained by ensembling GraIL with various knowledge graph embedding methods in\nthe transductive setting, highlighting the complementary inductive bias of our\nmethod."}, {"title": "Logarithmic Regret for Online Control with Adversarial Noise", "authors": "Dylan Foster, Max Simchowitz "}, {"title": "Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis", "authors": "Jung Yeon Park, Kenneth Carr, Stephan Zheng, Yisong Yue, Rose Yu ", "link": "https://arxiv.org/abs/2002.05578", "summary": "Efficient and interpretable spatial analysis is crucial in many fields such\nas geology, sports, and climate science. Large-scale spatial data often\ncontains complex higher-order correlations across features and locations. While\ntensor latent factor models can describe higher-order correlations, they are\ninherently computationally expensive to train. Furthermore, for spatial\nanalysis, these models should not only be predictive but also be spatially\ncoherent. However, latent factor models are sensitive to initialization and can\nyield inexplicable results. We develop a novel Multi-resolution Tensor Learning\n(MRTL) algorithm for efficiently learning interpretable spatial patterns. MRTL\ninitializes the latent factors from an approximate full-rank tensor model for\nimproved interpretability and progressively learns from a coarse resolution to\nthe fine resolution for an enormous computation speedup. We also prove the\ntheoretical convergence and computational complexity of MRTL. When applied to\ntwo real-world datasets, MRTL demonstrates 4 ~ 5 times speedup compared to a\nfixed resolution while yielding accurate and interpretable models."}, {"title": "Customizing ML Predictions for Online Algorithms", "authors": "Keerti Anand, Rong Ge, Debmalya Panigrahi "}, {"title": "Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning", "authors": "Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie, Jimmy Ba ", "link": "", "summary": ""}, {"title": " Recht-Re Noncommutative Arithmetic-Geometric Mean Conjecture is False", "authors": "Zehua Lai, Lek-Heng Lim ", "link": "http://arxiv.org/abs/2006.01510", "summary": "Stochastic optimization algorithms have become indispensable in modern\nmachine learning. An unresolved foundational question in this area is the\ndifference between with-replacement sampling and without-replacement sampling\n-- does the latter have superior convergence rate compared to the former? A\ngroundbreaking result of Recht and R\\'e reduces the problem to a noncommutative\nanalogue of the arithmetic-geometric mean inequality where $n$ positive numbers\nare replaced by $n$ positive definite matrices. If this inequality holds for\nall $n$, then without-replacement sampling indeed outperforms with-replacement\nsampling. The conjectured Recht-R\\'e inequality has so far only been\nestablished for $n = 2$ and a special case of $n = 3$. We will show that the\nRecht-R\\'e conjecture is false for general $n$. Our approach relies on the\nnoncommutative Positivstellensatz, which allows us to reduce the conjectured\ninequality to a semidefinite program and the validity of the conjecture to\ncertain bounds for the optimum values, which we show are false as soon as $n =\n5$."}, {"title": "Predictive Multiplicity in Classification", "authors": "Charles Marx, Flavio Calmon, Berk Ustun ", "link": "https://arxiv.org/abs/1909.06677", "summary": "In the context of machine learning, a prediction problem exhibits predictive\nmultiplicity if there exist several \"good\" models that attain identical or\nnear-identical performance (i.e., accuracy, AUC, etc.). In this paper, we study\nthe effects of multiplicity in human-facing applications, such as credit\nscoring and recidivism prediction. We introduce a specific notion of\nmultiplicity -- predictive multiplicity -- to describe the existence of good\nmodels that output conflicting predictions. Unlike existing notions of\nmultiplicity (e.g., the Rashomon effect), predictive multiplicity reflects\nirreconcilable differences in the predictions of models with comparable\nperformance, and presents new challenges for common practices such as model\nselection and local explanation. We propose measures to evaluate the predictive\nmultiplicity in classification problems. We present integer programming methods\nto compute these measures for a given datasets by solving empirical risk\nminimization problems with discrete constraints. We demonstrate how these tools\ncan inform stakeholders on a large collection of recidivism prediction\nproblems. Our results show that real-world prediction problems often admit many\ngood models that output wildly conflicting predictions, and support the need to\nreport predictive multiplicity in model development."}, {"title": "Word-Level Speech Recognition With a Letter to Word Encoder", "authors": "Ronan Collobert, Awni Hannun, Gabriel Synnaeve ", "link": "", "summary": ""}, {"title": "Reducing Sampling Error in Batch Temporal Difference Learning", "authors": "Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone "}, {"title": "Adaptive Sampling for Estimating Probability Distributions", "authors": "Shubhanshu Shekhar, Tara Javidi, Mohammad Ghavamzadeh ", "link": "https://arxiv.org/abs/1910.12406", "summary": "We consider the problem of allocating samples to a finite set of discrete\ndistributions in order to learn them uniformly well in terms of four common\ndistance measures: $\\ell_2^2$, $\\ell_1$, $f$-divergence, and separation\ndistance. To present a unified treatment of these distances, we first propose a\ngeneral optimistic tracking algorithm and analyze its sample allocation\nperformance w.r.t.~an oracle. We then instantiate this algorithm for the four\ndistance measures and derive bounds on the regret of their resulting allocation\nschemes. We verify our theoretical findings through some experiments. Finally,\nwe show that the techniques developed in the paper can be easily extended to\nthe related setting of minimizing the average error (in terms of the four\ndistances) in learning a set of distributions."}, {"title": "Adversarial Filters of Dataset Biases", "authors": "Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew Peters, Ashish Sabharwal, Yejin Choi ", "link": "https://arxiv.org/abs/2002.04108", "summary": "Large neural models have demonstrated human-level performance on language and\nvision benchmarks such as ImageNet and Stanford Natural Language Inference\n(SNLI). Yet, their performance degrades considerably when tested on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting on spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. Our experiments show that as a result of\nthe substantial reduction of these biases, models trained on the filtered\ndatasets yield better generalization to out-of-distribution tasks, especially\nwhen the benchmarks used for training are over-populated with biased samples.\nWe show that AFLite is broadly applicable to a variety of both real and\nsynthetic datasets for reduction of measurable dataset biases and provide\nextensive supporting analyses. Finally, filtering results in a large drop in\nmodel performance (e.g., from 92% to 63% for SNLI), while human performance\nstill remains high. Our work thus shows that such filtered datasets can pose\nnew research challenges for robust generalization by serving as upgraded\nbenchmarks."}, {"title": "Black-Box Variational Inference as a Parametric Approximation to Langevin Dynamics", "authors": "Matthew Hoffman, Yian Ma "}, {"title": "Faster Graph Embeddings via Coarsening", "authors": "Matthew Fahrbach, Gramoz Goranci, Sushant Sachdeva, Richard Peng, Chi Wang "}, {"title": "Efficient non-conjugate Gaussian process factor models for spike countdata using polynomial approximations", "authors": "Stephen Keeley, David Zoltowski, Jonathan Pillow, Spencer Smith, Yiyi Yu ", "link": "https://arxiv.org/abs/1906.03318", "summary": "Gaussian Process Factor Analysis (GPFA) has been broadly applied to the\nproblem of identifying smooth, low-dimensional temporal structure underlying\nlarge-scale neural recordings. However, spike trains are non-Gaussian, which\nmotivates combining GPFA with discrete observation models for binned spike\ncount data. The drawback to this approach is that GPFA priors are not conjugate\nto count model likelihoods, which makes inference challenging. Here we address\nthis obstacle by introducing a fast, approximate inference method for\nnon-conjugate GPFA models. Our approach uses orthogonal second-order\npolynomials to approximate the nonlinear terms in the non-conjugate\nlog-likelihood, resulting in a method we refer to as polynomial approximate\nlog-likelihood (PAL) estimators. This approximation allows for accurate\nclosed-form evaluation of marginal likelihood and fast numerical optimization\nfor parameters and hyperparameters. We derive PAL estimators for GPFA models\nwith binomial, Poisson, and negative binomial observations, and additionally\nshow that the parameters obtained can be used to initialize black-box\nvariational inference, which significantly speeds up and stabilizes the\ninference procedure for these factor analytic models. We apply these methods to\ndata from mouse visual cortex and monkey higher-order visual and parietal\ncortices, and compare GPFA under three different spike count observation models\nto traditional GPFA. We demonstrate that PAL estimators achieve fast and\naccurate extraction of latent structure from multi-neuron spike train data."}, {"title": "Multigrid Neural Memory", "authors": "Tri Huynh, Michael Maire, Matthew Walter ", "link": "https://arxiv.org/abs/1906.05948", "summary": "We introduce a radical new approach to endowing neural networks with access\nto long-term and large-scale memory. Architecting networks with internal\nmultigrid structure and connectivity, while distributing memory cells alongside\ncomputation throughout this topology, we observe that coherent memory\nsubsystems emerge as a result of training. Our design both drastically differs\nfrom and is far simpler than prior efforts, such as the recently proposed\nDifferentiable Neural Computer (DNC), which uses intricately crafted\ncontrollers to connect neural networks to external memory banks. Our\nhierarchical spatial organization, parameterized convolutionally, permits\nefficient instantiation of large-capacity memories. Our multigrid topology\nprovides short internal routing pathways, allowing convolutional networks to\nefficiently approximate the behavior of fully connected networks. Such networks\nhave an implicit capacity for internal attention; augmented with memory, they\nlearn to read and write specific memory locations in a dynamic data-dependent\nmanner. We demonstrate these capabilities on synthetic exploration and mapping\ntasks, where our network is able to self-organize and retain long-term memory\nfor trajectories of thousands of time steps, outperforming the DNC. On tasks\nwithout any notion of spatial geometry: sorting, associative recall, and\nquestion answering, our design functions as a truly generic memory and yields\nexcellent results."}, {"title": "Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings", "authors": "Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh Jayaraman "}, {"title": "Adversarial Nonnegative Matrix Factorization", "authors": "lei luo, yanfu Zhang, Heng Huang "}, {"title": "Aligned Cross Entropy for Non-Autoregressive Machine Translation", "authors": "Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, Omer Levy ", "link": "https://arxiv.org/abs/2004.01655", "summary": "Non-autoregressive machine translation models significantly speed up decoding\nby allowing for parallel prediction of the entire target sequence. However,\nmodeling word order is more challenging due to the lack of autoregressive\nfactors in the model. This difficultly is compounded during training with cross\nentropy loss, which can highly penalize small shifts in word order. In this\npaper, we propose aligned cross entropy (AXE) as an alternative loss function\nfor training of non-autoregressive models. AXE uses a differentiable dynamic\nprogram to assign loss based on the best possible monotonic alignment between\ntarget tokens and model predictions. AXE-based training of conditional masked\nlanguage models (CMLMs) substantially improves performance on major WMT\nbenchmarks, while setting a new state of the art for non-autoregressive models."}, {"title": "Model-Agnostic Characterization of Fairness Trade-offs", "authors": "Joon Sik Kim, Jiahao Chen, Ameet Talwalkar ", "link": "https://arxiv.org/abs/2004.03424", "summary": "There exist several inherent trade-offs in designing a fair model, such as\nthose between the model's predictive performance and fairness, or even among\ndifferent notions of fairness. In practice, exploring these trade-offs requires\nsignificant human and computational resources. We propose a diagnostic that\nenables practitioners to explore these trade-offs without training a single\nmodel. Our work hinges on the observation that many widely-used fairness\ndefinitions can be expressed via the fairness-confusion tensor, an object\nobtained by splitting the traditional confusion matrix according to protected\ndata attributes. Optimizing accuracy and fairness objectives directly over the\nelements in this tensor yields a data-dependent yet model-agnostic way of\nunderstanding several types of trade-offs. We further leverage this\ntensor-based perspective to generalize existing theoretical impossibility\nresults to a wider range of fairness definitions. Finally, we demonstrate the\nusefulness of the proposed diagnostic on synthetic and real datasets."}, {"title": "A Distributional Framework For Data Valuation", "authors": "Amirata Ghorbani, Michael Kim, James Zou ", "link": "https://arxiv.org/abs/2002.12334", "summary": "Shapley value is a classic notion from game theory, historically used to\nquantify the contributions of individuals within groups, and more recently\napplied to assign values to data points when training machine learning models.\nDespite its foundational role, a key limitation of the data Shapley framework\nis that it only provides valuations for points within a fixed data set. It does\nnot account for statistical aspects of the data and does not give a way to\nreason about points outside the data set. To address these limitations, we\npropose a novel framework -- distributional Shapley -- where the value of a\npoint is defined in the context of an underlying data distribution. We prove\nthat distributional Shapley has several desirable statistical properties; for\nexample, the values are stable under perturbations to the data points\nthemselves and to the underlying data distribution. We leverage these\nproperties to develop a new algorithm for estimating values from data, which\ncomes with formal guarantees and runs two orders of magnitude faster than\nstate-of-the-art algorithms for computing the (non-distributional) data Shapley\nvalues. We apply distributional Shapley to diverse data sets and demonstrate\nits utility in a data market setting."}, {"title": "Supervised Quantile Normalization for Low Rank Matrix Factorization", "authors": "Marco Cuturi, Olivier Teboul, Jonathan Niles-Weed, Jonathan Weed, Jean-Philippe Vert ", "link": "https://arxiv.org/abs/2002.03229", "summary": "Low rank matrix factorization is a fundamental building block in machine\nlearning, used for instance to summarize gene expression profile data or\nword-document counts. To be robust to outliers and differences in scale across\nfeatures, a matrix factorization step is usually preceded by ad-hoc feature\nnormalization steps, such as \\texttt{tf-idf} scaling or data whitening. We\npropose in this work to learn these normalization operators jointly with the\nfactorization itself. More precisely, given a $d\\times n$ matrix $X$ of $d$\nfeatures measured on $n$ individuals, we propose to learn the parameters of\nquantile normalization operators that can operate row-wise on the values of $X$\nand/or of its factorization $UV$ to improve the quality of the low-rank\nrepresentation of $X$ itself. This optimization is facilitated by the\nintroduction of a differentiable quantile normalization operator built using\noptimal transport, providing new results on top of existing work by Cuturi et\nal. (2019). We demonstrate the applicability of these techniques on synthetic\nand genomics datasets."}, {"title": "AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation", "authors": "Jae Hyun Lim, Aaron Courville, Christopher Pal, Chin-Wei Huang "}, {"title": "Bridging the Gap Between f-GANs and Wasserstein GANs", "authors": "Jiaming Song, Stefano Ermon ", "link": "", "summary": ""}, {"title": "\u201cOther-Play\u201d for Zero-Shot Coordination", "authors": "Hengyuan Hu, Alexander Peysakhovich, Adam Lerer, Jakob Foerster ", "link": "https://arxiv.org/abs/2003.02979", "summary": "We consider the problem of zero-shot coordination - constructing AI agents\nthat can coordinate with novel partners they have not seen before (e.g.\nhumans). Standard Multi-Agent Reinforcement Learning (MARL) methods typically\nfocus on the self-play (SP) setting where agents construct strategies by\nplaying the game with themselves repeatedly. Unfortunately, applying SP naively\nto the zero-shot coordination problem can produce agents that establish highly\nspecialized conventions that do not carry over to novel partners they have not\nbeen trained with. We introduce a novel learning algorithm called other-play\n(OP), that enhances self-play by looking for more robust strategies, exploiting\nthe presence of known symmetries in the underlying problem. We characterize OP\ntheoretically as well as experimentally. We study the cooperative card game\nHanabi and show that OP agents achieve higher scores when paired with\nindependently trained agents. In preliminary results we also show that our OP\nagents obtains higher average scores when paired with human players, compared\nto state-of-the-art SP agents."}, {"title": "Correlation Clustering with Asymmetric Classification Errors", "authors": "Jafar Jafarov, Sanchit Kalhan, Konstantin Makarychev, Yury Makarychev "}, {"title": "An Optimistic Perspective on Offline Deep Reinforcement Learning", "authors": "Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi ", "link": "https://arxiv.org/abs/1907.04543", "summary": "Off-policy reinforcement learning (RL) using a fixed offline dataset of\nlogged interactions is an important consideration in real world applications.\nThis paper studies offline RL using the DQN replay dataset comprising the\nentire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate\nthat recent off-policy deep RL algorithms, even when trained solely on this\nreplay dataset, outperform the fully trained DQN agent. To enhance\ngeneralization in the offline setting, we present Random Ensemble Mixture\n(REM), a robust Q-learning algorithm that enforces optimal Bellman consistency\non random convex combinations of multiple Q-value estimates. Offline REM\ntrained on the DQN replay dataset surpasses strong RL baselines. The results\nhere present an optimistic view that robust RL algorithms trained on\nsufficiently large and diverse offline datasets can lead to high quality\npolicies. The DQN replay dataset can serve as an offline RL benchmark and is\nopen-sourced."}, {"title": "Neural Topic Modeling with Continual Lifelong Learning", "authors": "Pankaj Gupta, Yatin Chaudhary, Thomas Runkler, Hinrich Schuetze ", "link": "", "summary": ""}, {"title": "Learning and Evaluating Contextual Embedding of Source Code", "authors": "Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi ", "link": "", "summary": ""}, {"title": "Uncertainty quantification for nonconvex tensor completion: Confidence intervals, heteroscedasticity and optimality", "authors": "Changxiao Cai, H. Vincent Poor, Yuxin Chen "}, {"title": "Learning with Good Feature Representations in Bandits and in RL with a Generative Model", "authors": "Gell\u00e9rt Weisz, Tor Lattimore, Csaba Szepesvari ", "link": "https://arxiv.org/abs/1911.07676", "summary": "The construction by Du et al. (2019) implies that even if a learner is given\nlinear features in $\\mathbb R^d$ that approximate the rewards in a bandit with\na uniform error of $\\epsilon$, then searching for an action that is optimal up\nto $O(\\epsilon)$ requires examining essentially all actions. We use the\nKiefer-Wolfowitz theorem to prove a positive result that by checking only a few\nactions, a learner can always find an action that is suboptimal with an error\nof at most $O(\\epsilon \\sqrt{d})$. Thus, features are useful when the\napproximation error is small relative to the dimensionality of the features.\nThe idea is applied to stochastic bandits and reinforcement learning with a\ngenerative model where the learner has access to $d$-dimensional linear\nfeatures that approximate the action-value functions for all policies to an\naccuracy of $\\epsilon$. For linear bandits, we prove a bound on the regret of\norder $\\sqrt{dn \\log(k)} + \\epsilon n \\sqrt{d} \\log(n)$ with $k$ the number of\nactions and $n$ the horizon. For RL we show that approximate policy iteration\ncan learn a policy that is optimal up to an additive error of order $\\epsilon\n\\sqrt{d}/(1 - \\gamma)^2$ and using $d/(\\epsilon^2(1 - \\gamma)^4)$ samples from\na generative model. These bounds are independent of the finer details of the\nfeatures. We also investigate how the structure of the feature set impacts the\ntradeoff between sample complexity and estimation error."}, {"title": "Angular Visual Hardness", "authors": "Beidi Chen, Weiyang Liu, Zhiding Yu, Jan Kautz, Anshumali Shrivastava, Animesh Garg, Anima Anandkumar ", "link": "https://arxiv.org/abs/1912.02279", "summary": "Recent convolutional neural networks (CNNs) have led to impressive\nperformance but often suffer from poor calibration. They tend to be\noverconfident, with the model confidence not always reflecting the underlying\ntrue ambiguity and hardness. In this paper, we propose angular visual hardness\n(AVH), a score given by the normalized angular distance between the sample\nfeature embedding and the target classifier to measure sample hardness. We\nvalidate this score with an in-depth and extensive scientific study, and\nobserve that CNN models with the highest accuracy also have the best AVH\nscores. This agrees with an earlier finding that state-of-art models improve on\nthe classification of harder examples. We observe that the training dynamics of\nAVH is vastly different compared to the training loss. Specifically, AVH\nquickly reaches a plateau for all samples even though the training loss keeps\nimproving. This suggests the need for designing better loss functions that can\ntarget harder examples more effectively. We also find that AVH has a\nstatistically significant correlation with human visual hardness. Finally, we\ndemonstrate the benefit of AVH to a variety ofcations such as self-training for\ndomain adaptation and domain generalization."}, {"title": "Cutting out the Middle-Man: Training and Evaluating Energy-Based Models without Sampling", "authors": "Will Grathwohl, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Richard Zemel ", "link": "https://arxiv.org/abs/2002.05616", "summary": "We present a new method for evaluating and training unnormalized density\nmodels. Our approach only requires access to the gradient of the unnormalized\nmodel's log-density. We estimate the Stein discrepancy between the data density\np(x) and the model density q(x) defined by a vector function of the data. We\nparameterize this function with a neural network and fit its parameters to\nmaximize the discrepancy. This yields a novel goodness-of-fit test which\noutperforms existing methods on high dimensional data. Furthermore, optimizing\n$q(x)$ to minimize this discrepancy produces a novel method for training\nunnormalized models which scales more gracefully than existing methods. The\nability to both learn and compare models is a unique feature of the proposed\nmethod."}, {"title": "Variance Reduction and Quasi-Newton for Particle-Based Variational Inference", "authors": "Michael Zhu, Chang Liu, Jun Zhu "}, {"title": "Better depth-width trade-offs for neural networks through the lens of dynamical systems", "authors": "Evangelos Chatziafratis, Ioannis Panageas, Sai Ganesh Nagarajan ", "link": "https://arxiv.org/abs/2003.00777", "summary": "The expressivity of neural networks as a function of their depth, width and\ntype of activation units has been an important question in deep learning\ntheory. Recently, depth separation results for ReLU networks were obtained via\na new connection with dynamical systems, using a generalized notion of fixed\npoints of a continuous map $f$, called periodic points. In this work, we\nstrengthen the connection with dynamical systems and we improve the existing\nwidth lower bounds along several aspects. Our first main result is\nperiod-specific width lower bounds that hold under the stronger notion of\n$L^1$-approximation error, instead of the weaker classification error. Our\nsecond contribution is that we provide sharper width lower bounds, still\nyielding meaningful exponential depth-width separations, in regimes where\nprevious results wouldn't apply. A byproduct of our results is that there\nexists a universal constant characterizing the depth-width trade-offs, as long\nas $f$ has odd periods. Technically, our results follow by unveiling a tighter\nconnection between the following three quantities of a given function: its\nperiod, its Lipschitz constant and the growth rate of the number of\noscillations arising under compositions of the function $f$ with itself."}, {"title": "Stochastic Coordinate Minimization with Progressive Precision for Stochastic Convex Optimization", "authors": "Sudeep Salgia, Qing Zhao, Sattar Vakili ", "link": "https://arxiv.org/abs/2003.05482", "summary": "A framework based on iterative coordinate minimization (CM) is developed for\nstochastic convex optimization. Given that exact coordinate minimization is\nimpossible due to the unknown stochastic nature of the objective function, the\ncrux of the proposed optimization algorithm is an optimal control of the\nminimization precision in each iteration. We establish the optimal precision\ncontrol and the resulting order-optimal regret performance for strongly convex\nand separably nonsmooth functions. An interesting finding is that the optimal\nprogression of precision across iterations is independent of the\nlow-dimensional CM routine employed, suggesting a general framework for\nextending low-dimensional optimization routines to high-dimensional problems.\nThe proposed algorithm is amenable to online implementation and inherits the\nscalability and parallelizability properties of CM for large-scale\noptimization. Requiring only a sublinear order of message exchanges, it also\nlends itself well to distributed computing as compared with the alternative\napproach of coordinate gradient descent."}, {"title": "Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations", "authors": "Florian Tramer, Jens Behrmann, Nicholas Carlini, Nicolas Papernot, Joern-Henrik Jacobsen ", "link": "https://arxiv.org/abs/2002.04599", "summary": "Adversarial examples are malicious inputs crafted to induce\nmisclassification. Commonly studied sensitivity-based adversarial examples\nintroduce semantically-small changes to an input that result in a different\nmodel prediction. This paper studies a complementary failure mode,\ninvariance-based adversarial examples, that introduce minimal semantic changes\nthat modify an input's true label yet preserve the model's prediction. We\ndemonstrate fundamental tradeoffs between these two types of adversarial\nexamples.\n  We show that defenses against sensitivity-based attacks actively harm a\nmodel's accuracy on invariance-based attacks, and that new approaches are\nneeded to resist both attack types. In particular, we break state-of-the-art\nadversarially-trained and certifiably-robust models by generating small\nperturbations that the models are (provably) robust to, yet that change an\ninput's class according to human labelers. Finally, we formally show that the\nexistence of excessively invariant classifiers arises from the presence of\noverly-robust predictive features in standard datasets."}, {"title": "Learning From Strategic Agents: Accuracy, Improvement, and Causality", "authors": "Yonadav Shavit, Benjamin Edelman, Brian Axelrod ", "link": "https://arxiv.org/abs/2002.10066", "summary": "In many predictive decision-making scenarios, such as credit scoring and\nacademic testing, a decision-maker must construct a model (predicting some\noutcome) that accounts for agents' incentives to \"game\" their features in order\nto receive better decisions. Whereas the strategic classification literature\ngenerally assumes that agents' outcomes are not causally dependent on their\nfeatures (and thus strategic behavior is a form of lying), we join concurrent\nwork in modeling agents' outcomes as a function of their changeable attributes.\nOur formulation is the first to incorporate a crucial phenomenon: when agents\nact to change observable features, they may as a side effect perturb hidden\nfeatures that causally affect their true outcomes.\n  We consider three distinct desiderata for a decision-maker's model:\naccurately predicting agents' post-gaming outcomes (accuracy), incentivizing\nagents to improve these outcomes (improvement), and, in the linear setting,\nestimating the visible coefficients of the true causal model (causal\nprecision). As our main contribution, we provide the first algorithms for\nlearning accuracy-optimizing, improvement-optimizing, and\ncausal-precision-optimizing linear regression models directly from data,\nwithout prior knowledge of agents' possible actions. These algorithms\ncircumvent the hardness result of Miller et al. (2019) by allowing the decision\nmaker to observe agents' responses to a sequence of decision rules, in effect\ninducing agents to perform causal interventions for free."}, {"title": "Causal Structure Discovery from Distributions Arising from Mixtures of DAGs", "authors": "Basil Saeed, Snigdha Panigrahi, Caroline Uhler ", "link": "https://arxiv.org/abs/2001.11940", "summary": "We consider distributions arising from a mixture of causal models, where each\nmodel is represented by a directed acyclic graph (DAG). We provide a graphical\nrepresentation of such mixture distributions and prove that this representation\nencodes the conditional independence relations of the mixture distribution. We\nthen consider the problem of structure learning based on samples from such\ndistributions. Since the mixing variable is latent, we consider causal\nstructure discovery algorithms such as FCI that can deal with latent variables.\nWe show that such algorithms recover a \"union\" of the component DAGs and can\nidentify variables whose conditional distribution across the component DAGs\nvary. We demonstrate our results on synthetic and real data showing that the\ninferred graph identifies nodes that vary between the different mixture\ncomponents. As an immediate application, we demonstrate how retrieval of this\ncausal information can be used to cluster samples according to each mixture\ncomponent."}, {"title": "Explainable and Discourse Topic-aware Neural Language Understanding", "authors": "Yatin Chaudhary, Pankaj Gupta, Hinrich Schuetze "}, {"title": "Understanding Contrastive Representation Learning through Geometry on the Hypersphere", "authors": "Tongzhou Wang, Phillip Isola ", "link": "https://arxiv.org/abs/2005.10242", "summary": "Contrastive representation learning has been outstandingly successful in\npractice. In this work, we identify two key properties related to the\ncontrastive loss: (1) alignment (closeness) of features from positive pairs,\nand (2) uniformity of the induced distribution of the (normalized) features on\nthe hypersphere. We prove that, asymptotically, the contrastive loss optimizes\nthese properties, and analyze their positive effects on downstream tasks.\nEmpirically, we introduce an optimizable metric to quantify each property.\nExtensive experiments on standard vision and language datasets confirm the\nstrong agreement between both metrics and downstream task performance.\nRemarkably, directly optimizing for these two metrics leads to representations\nwith comparable or better performance at downstream tasks than contrastive\nlearning.\n  Project Page: https://ssnl.github.io/hypersphere\n  Code: https://github.com/SsnL/align_uniform"}, {"title": "On Learning Language-Invariant Representations for Universal Machine Translation", "authors": "Han Zhao, Junjie Hu, Andrej Risteski ", "link": "", "summary": ""}, {"title": "Compressive sensing with un-trained neural networks: Gradient descent finds a smooth approximation", "authors": "Reinhard Heckel, Mahdi Soltanolkotabi ", "link": "https://arxiv.org/abs/2005.03991", "summary": "Un-trained convolutional neural networks have emerged as highly successful\ntools for image recovery and restoration. They are capable of solving standard\ninverse problems such as denoising and compressive sensing with excellent\nresults by simply fitting a neural network model to measurements from a single\nimage or signal without the need for any additional training data. For some\napplications, this critically requires additional regularization in the form of\nearly stopping the optimization. For signal recovery from a few measurements,\nhowever, un-trained convolutional networks have an intriguing self-regularizing\nproperty: Even though the network can perfectly fit any image, the network\nrecovers a natural image from few measurements when trained with gradient\ndescent until convergence. In this paper, we provide numerical evidence for\nthis property and study it theoretically. We show that---without any further\nregularization---an un-trained convolutional neural network can approximately\nreconstruct signals and images that are sufficiently structured, from a near\nminimal number of random measurements."}, {"title": "Representing Unordered Data Using Multiset Automata and Complex Numbers", "authors": "Justin DeBenedetto, David Chiang ", "link": "https://arxiv.org/abs/2001.00610", "summary": "Unordered, variable-sized inputs arise in many settings across multiple\nfields. The ability for set- and multiset- oriented neural networks to handle\nthis type of input has been the focus of much work in recent years. We propose\nto represent multisets using complex-weighted multiset automata and show how\nthe multiset representations of certain existing neural architectures can be\nviewed as special cases of ours. Namely, (1) we provide a new theoretical and\nintuitive justification for the Transformer model's representation of positions\nusing sinusoidal functions, and (2) we extend the DeepSets model to use complex\nnumbers, enabling it to outperform the existing model on an extension of one of\ntheir tasks."}, {"title": "Mutual Transfer Learning for Massive Data", "authors": "Ching-Wei Cheng, Xingye Qiao, Guang Cheng "}, {"title": "The Differentiable Cross-Entropy Method", "authors": "Brandon Amos, Denis Yarats ", "link": "https://arxiv.org/abs/1909.12830", "summary": "We study the Cross-Entropy Method (CEM) for the non-convex optimization of a\ncontinuous and parameterized objective function and introduce a differentiable\nvariant (DCEM) that enables us to differentiate the output of CEM with respect\nto the objective function's parameters. In the machine learning setting this\nbrings CEM inside of the end-to-end learning pipeline where this has otherwise\nbeen impossible. We show applications in a synthetic energy-based structured\nprediction task and in non-convex continuous control. In the control setting we\nshow on the simulated cheetah and walker tasks that we can embed their optimal\naction sequences with DCEM and then use policy optimization to fine-tune\ncomponents of the controller as a step towards combining model-based and\nmodel-free RL."}, {"title": "A Sample Complexity Separation between Non-Convex and Convex Meta-Learning", "authors": "Nikunj Umesh Saunshi, Yi Zhang, Mikhail Khodak, Sanjeev Arora ", "link": "http://arxiv.org/abs/2002.11172", "summary": "One popular trend in meta-learning is to learn from many training tasks a\ncommon initialization for a gradient-based method that can be used to solve a\nnew task with few samples. The theory of meta-learning is still in its early\nstages, with several recent learning-theoretic analyses of methods such as\nReptile [Nichol et al., 2018] being for convex models. This work shows that\nconvex-case analysis might be insufficient to understand the success of\nmeta-learning, and that even for non-convex models it is important to look\ninside the optimization black-box, specifically at properties of the\noptimization trajectory. We construct a simple meta-learning instance that\ncaptures the problem of one-dimensional subspace learning. For the convex\nformulation of linear regression on this instance, we show that the new task\nsample complexity of any initialization-based meta-learning algorithm is\n$\\Omega(d)$, where $d$ is the input dimension. In contrast, for the non-convex\nformulation of a two layer linear network on the same instance, we show that\nboth Reptile and multi-task representation learning can have new task sample\ncomplexity of $\\mathcal{O}(1)$, demonstrating a separation from convex\nmeta-learning. Crucially, analyses of the training dynamics of these methods\nreveal that they can meta-learn the correct subspace onto which the data should\nbe projected."}, {"title": "On the Convergence of Nesterov's Accelerated Gradient Method in Stochastic Settings", "authors": "Mahmoud Assran, Michael Rabbat ", "link": "https://arxiv.org/abs/2002.12414", "summary": "We study Nesterov's accelerated gradient method in the stochastic\napproximation setting (unbiased gradients with bounded variance) and the\nfinite-sum setting (where randomness is due to sampling mini-batches). To build\nbetter insight into the behavior of Nesterov's method in stochastic settings,\nwe focus throughout on objectives that are smooth, strongly-convex, and twice\ncontinuously differentiable. In the stochastic approximation setting,\nNesterov's method converges to a neighborhood of the optimal point at the same\naccelerated rate as in the deterministic setting. Perhaps surprisingly, in the\nfinite-sum setting, we prove that Nesterov's method may diverge with the usual\nchoice of step-size and momentum, unless additional conditions on the problem\nrelated to conditioning and data coherence are satisfied. Our results shed\nlight as to why Nesterov's method may fail to converge or achieve acceleration\nin the finite-sum setting."}, {"title": "The Buckley-Osthus model and the block preferential attachment model: statistical analysis and application", "authors": "Wenpin Tang, Xin Guo, Fengmin Tang "}, {"title": "Representations for Stable Off-Policy Reinforcement Learning", "authors": "Dibya Ghosh, Marc Bellemare "}, {"title": "Piecewise Linear Regression via a Difference of Convex Functions", "authors": "Ali Siahkamari, Aditya Gangrade, Brian Kulis, Venkatesh Saligrama "}, {"title": "On the consistency of top-k surrogate losses", "authors": "Forest Yang, Sanmi Koyejo ", "link": "https://arxiv.org/abs/1901.11141", "summary": "The top-$k$ error is often employed to evaluate performance for challenging\nclassification tasks in computer vision as it is designed to compensate for\nambiguity in ground truth labels. This practical success motivates our\ntheoretical analysis of consistent top-$k$ classification. To this end, we\ndefine top-$k$ calibration as a necessary and sufficient condition for\nconsistency, for bounded below loss functions. Unlike prior work, our analysis\nof top-$k$ calibration handles non-uniqueness of the predictor scores, and\nextends calibration to consistency -- providing a theoretically sound basis for\nanalysis of this topic. Based on the top-$k$ calibration analysis, we propose a\nrich class of top-$k$ calibrated Bregman divergence surrogates. Our analysis\ncontinues by showing previously proposed hinge-like top-$k$ surrogate losses\nare not top-$k$ calibrated and thus inconsistent. On the other hand, we propose\ntwo new hinge-like losses, one which is similarly inconsistent, and one which\nis consistent. Our empirical results highlight theoretical claims, confirming\nour analysis of the consistency of these losses."}, {"title": "Collapsed Amortized Variational Inference for Switching Nonlinear Dynamical Systems", "authors": "Zhe Dong,  Bryan Seybold, Kevin Murphy, Hung Bui ", "link": "https://arxiv.org/abs/1910.09588", "summary": "We propose an efficient inference method for switching nonlinear dynamical\nsystems. The key idea is to learn an inference network which can be used as a\nproposal distribution for the continuous latent variables, while performing\nexact marginalization of the discrete latent variables. This allows us to use\nthe reparameterization trick, and apply end-to-end training with stochastic\ngradient descent. We show that the proposed method can successfully segment\ntime series data, including videos and 3D human pose, into meaningful\n``regimes'' by using the piece-wise nonlinear dynamics."}, {"title": "Boosting Deep Neural Network Efficiency with Dual-Module Inference", "authors": "Liu Liu, Lei Deng, Zhaodong Chen, yuke wang, Shuangchen Li, Jingwei Zhang, Yihua Yang, Zhenyu Gu, Yufei Ding, Yuan Xie "}, {"title": "Time-Consistent Semi-Supervised Learning", "authors": "Tianyi Zhou, Shengjie Wang, Jeff Bilmes "}, {"title": "Selective Dyna-style Planning Under Limited Model Capacity", "authors": "Muhammad Zaheer, Samuel Sokota, Erin Talvitie, Martha White ", "link": "", "summary": ""}, {"title": "A Pairwise Fair and Community-preserving Approach to k-Center Clustering", "authors": "Brian Brubach, Darshan Chakrabarti, John P Dickerson, Samir Khuller, Aravind Srinivasan, Leonidas Tsepenekas ", "link": "", "summary": ""}, {"title": "How recurrent networks implement contextual processing in sentiment analysis", "authors": "Niru Maheswaranathan, David Sussillo ", "link": "https://arxiv.org/abs/2004.08013", "summary": "Neural networks have a remarkable capacity for contextual processing--using\nrecent or nearby inputs to modify processing of current input. For example, in\nnatural language, contextual processing is necessary to correctly interpret\nnegation (e.g. phrases such as \"not bad\"). However, our ability to understand\nhow networks process context is limited. Here, we propose general methods for\nreverse engineering recurrent neural networks (RNNs) to identify and elucidate\ncontextual processing. We apply these methods to understand RNNs trained on\nsentiment classification. This analysis reveals inputs that induce contextual\neffects, quantifies the strength and timescale of these effects, and identifies\nsets of these inputs with similar properties. Additionally, we analyze\ncontextual effects related to differential processing of the beginning and end\nof documents. Using the insights learned from the RNNs we improve baseline\nBag-of-Words models with simple extensions that incorporate contextual\nmodification, recovering greater than 90% of the RNN's performance increase\nover the baseline. This work yields a new understanding of how RNNs process\ncontextual information, and provides tools that should provide similar insight\nmore broadly."}, {"title": "Smaller, more accurate regression forests using tree alternating optimization", "authors": "Arman Zharmagambetov, Miguel Carreira-Perpinan "}, {"title": "Divide and Conquer: Leveraging Intermediate Feature Representations for Quantized Training of Neural Networks", "authors": "Ahmed T. Elthakeb, Prannoy Pilligundla, FatemehSadat Mireshghallah, Alexander Cloninger, Hadi Esmaeilzadeh ", "link": "https://arxiv.org/abs/1906.06033", "summary": "The deep layers of modern neural networks extract a rather rich set of\nfeatures as an input propagates through the network. This paper sets out to\nharvest these rich intermediate representations for quantization with minimal\naccuracy loss while significantly reducing the memory footprint and compute\nintensity of the DNN. This paper utilizes knowledge distillation through\nteacher-student paradigm (Hinton et al., 2015) in a novel setting that exploits\nthe feature extraction capability of DNNs for higher-accuracy quantization. As\nsuch, our algorithm logically divides a pretrained full-precision DNN to\nmultiple sections, each of which exposes intermediate features to train a team\nof students independently in the quantized domain. This divide and conquer\nstrategy, in fact, makes the training of each student section possible in\nisolation while all these independently trained sections are later stitched\ntogether to form the equivalent fully quantized network. Our algorithm is a\nsectional approach towards knowledge distillation and is not treating the\nintermediate representation as a hint for pretraining before one knowledge\ndistillation pass over the entire network (Romero et al., 2015). Experiments on\nvarious DNNs (AlexNet, LeNet, MobileNet, ResNet-18, ResNet-20, SVHN and VGG-11)\nshow that, this approach -- called DCQ (Divide and Conquer Quantization) -- on\naverage, improves the performance of a state-of-the-art quantized training\ntechnique, DoReFa-Net (Zhou et al., 2016) by 21.6% and 9.3% for binary and\nternary quantization, respectively. Additionally, we show that incorporating\nDCQ to existing quantized training methods leads to improved accuracies as\ncompared to previously reported by multiple state-of-the-art quantized training\nmethods."}, {"title": "From Sets to Multisets: Provable Variational  Inference for Probabilistic Integer Submodular Models", "authors": "Aytunc Sahin, Yatao Bian, Joachim Buhmann, Andreas Krause ", "link": "http://arxiv.org/abs/2006.01293", "summary": "Submodular functions have been studied extensively in machine learning and\ndata mining. In particular, the optimization of submodular functions over the\ninteger lattice (integer submodular functions) has recently attracted much\ninterest, because this domain relates naturally to many practical problem\nsettings, such as multilabel graph cut, budget allocation and revenue\nmaximization with discrete assignments. In contrast, the use of these functions\nfor probabilistic modeling has received surprisingly little attention so far.\nIn this work, we firstly propose the Generalized Multilinear Extension, a\ncontinuous DR-submodular extension for integer submodular functions. We study\ncentral properties of this extension and formulate a new probabilistic model\nwhich is defined through integer submodular functions. Then, we introduce a\nblock-coordinate ascent algorithm to perform approximate inference for those\nclass of models. Finally, we demonstrate its effectiveness and viability on\nseveral real-world social connection graph datasets with integer submodular\nobjectives."}, {"title": "Empirical Study of the Benefits of Overparameterization in Learning Latent Variable Models", "authors": "Rares-Darius Buhai, Yoni Halpern, Yoon Kim, Andrej Risteski, David Sontag "}, {"title": "Improving the Gating Mechanism of Recurrent Neural Networks", "authors": "Albert Gu, Caglar Gulcehre, Thomas Paine, Matthew Hoffman, Razvan Pascanu ", "link": "https://arxiv.org/abs/1910.09890", "summary": "Gating mechanisms are widely used in neural network models, where they allow\ngradients to backpropagate more easily through depth or time. However, their\nsaturation property introduces problems of its own. For example, in recurrent\nmodels these gates need to have outputs near 1 to propagate information over\nlong time-delays, which requires them to operate in their saturation regime and\nhinders gradient-based learning of the gate mechanism. We address this problem\nby deriving two synergistic modifications to the standard gating mechanism that\nare easy to implement, introduce no additional hyperparameters, and improve\nlearnability of the gates when they are close to saturation. We show how these\nchanges are related to and improve on alternative recently proposed gating\nmechanisms such as chrono-initialization and Ordered Neurons. Empirically, our\nsimple gating mechanisms robustly improve the performance of recurrent models\non a range of applications, including synthetic memorization tasks, sequential\nimage classification, language modeling, and reinforcement learning,\nparticularly when long-term dependencies are involved."}, {"title": "Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors", "authors": "Mike Dusenberry, Ghassen Jerfel, Yeming Wen, Yian Ma, Jasper Snoek, Katherine Heller, Balaji Lakshminarayanan, Dustin Tran ", "link": "https://arxiv.org/abs/2005.07186", "summary": "Bayesian neural networks (BNNs) demonstrate promising success in improving\nthe robustness and uncertainty quantification of modern deep learning. However,\nthey generally struggle with underfitting at scale and parameter efficiency. On\nthe other hand, deep ensembles have emerged as alternatives for uncertainty\nquantification that, while outperforming BNNs on certain problems, also suffer\nfrom efficiency issues. It remains unclear how to combine the strengths of\nthese two approaches and remediate their common issues. To tackle this\nchallenge, we propose a rank-1 parameterization of BNNs, where each weight\nmatrix involves only a distribution on a rank-1 subspace. We also revisit the\nuse of mixture approximate posteriors to capture multiple modes, where unlike\ntypical mixtures, this approach admits a significantly smaller memory increase\n(e.g., only a 0.4% increase for a ResNet-50 mixture of size 10). We perform a\nsystematic empirical study on the choices of prior, variational posterior, and\nmethods to improve training. For ResNet-50 on ImageNet, Wide ResNet 28-10 on\nCIFAR-10/100, and an RNN on MIMIC-III, rank-1 BNNs achieve state-of-the-art\nperformance across log-likelihood, accuracy, and calibration on the test sets\nand out-of-distribution variants."}, {"title": "Analyzing the effect of neural network architecture on training performance", "authors": "Karthik Abinav Sankararaman, Soham De, Zheng Xu, W. Ronny Huang, Tom Goldstein "}, {"title": "Born-again Tree Ensembles", "authors": "Thibaut Vidal, Maximilian Schiffer ", "link": "https://arxiv.org/abs/2003.11132", "summary": "The use of machine learning algorithms in finance, medicine, and criminal\njustice can deeply impact human lives. As a consequence, research into\ninterpretable machine learning has rapidly grown in an attempt to better\ncontrol and fix possible sources of mistakes and biases. Tree ensembles offer a\ngood prediction quality in various domains, but the concurrent use of multiple\ntrees reduces the interpretability of the ensemble. Against this background, we\nstudy born-again tree ensembles, i.e., the process of constructing a single\ndecision tree of minimum size that reproduces the exact same behavior as a\ngiven tree ensemble. To find such a tree, we develop a dynamic-programming\nbased algorithm that exploits sophisticated pruning and bounding rules to\nreduce the number of recursive calls. This algorithm generates optimal\nborn-again trees for many datasets of practical interest, leading to\nclassifiers which are typically simpler and more interpretable without any\nother form of compromise."}, {"title": "Accountable Off-Policy Evaluation via a Kernelized Bellman Statistics", "authors": "Yihao Feng, Tongzheng Ren, Ziyang Tang, Qiang Liu "}, {"title": "Improving Transformer Optimization Through Better Initialization ", "authors": "Xiao Shi Huang, Juan Perez , Jimmy Ba, Maksims Volkovs ", "link": "", "summary": ""}, {"title": "Learning to Simulate and Design for Structural Engineering", "authors": "Kai-Hung Chang, Chin-Yi Cheng ", "link": "http://arxiv.org/abs/2003.09103", "summary": "In the architecture and construction industries, structural design for large\nbuildings has always been laborious, time-consuming, and difficult to optimize.\nIt is an iterative process that involves two steps: analyzing the current\nstructural design by a slow and computationally expensive simulation, and then\nmanually revising the design based on professional experience and rules. In\nthis work, we propose an end-to-end learning pipeline to solve the size design\noptimization problem, which is to design the optimal cross-sections for columns\nand beams, given the design objectives and building code as constraints. We\npre-train a graph neural network as a surrogate model to not only replace the\nstructural simulation for speed but also use its differentiable nature to\nprovide gradient signals to the other graph neural network for size\noptimization. Our results show that the pre-trained surrogate model can predict\nsimulation results accurately, and the trained optimization model demonstrates\nthe capability of designing convincing cross-section designs for buildings\nunder various scenarios."}, {"title": "Few-shot Relation Extraction via Bayesian Meta-learning on Task Graphs", "authors": "Meng Qu, Tianyu Gao, Louis-Pascal Xhonneux, Jian Tang "}, {"title": "Optimal Differential Privacy Composition for Exponential Mechanisms", "authors": "Jinshuo Dong, David Durfee, Ryan Rogers ", "link": "", "summary": ""}, {"title": "Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic Constraints via Message Passing", "authors": "Zhe Zeng, Paolo Morettin, Fanqi Yan, Antonio Vergari, Guy Van den Broeck ", "link": "https://arxiv.org/abs/2003.00126", "summary": "Weighted model integration (WMI) is a very appealing framework for\nprobabilistic inference: it allows to express the complex dependencies of\nreal-world problems where variables are both continuous and discrete, via the\nlanguage of Satisfiability Modulo Theories (SMT), as well as to compute\nprobabilistic queries with complex logical and arithmetic constraints. Yet,\nexisting WMI solvers are not ready to scale to these problems. They either\nignore the intrinsic dependency structure of the problem at all, or they are\nlimited to too restrictive structures. To narrow this gap, we derive a\nfactorized formalism of WMI enabling us to devise a scalable WMI solver based\non message passing, MP-WMI. Namely, MP-WMI is the first WMI solver which allows\nto: 1) perform exact inference on the full class of tree-structured WMI\nproblems; 2) compute all marginal densities in linear time; 3) amortize\ninference inter query. Experimental results show that our solver dramatically\noutperforms the existing WMI solvers on a large set of benchmarks."}, {"title": "Accelerating Large-Scale Inference with Anisotropic Vector Quantization", "authors": "Ruiqi Guo, Quan Geng, David Simcha, Felix Chern, Philip Sun, Erik Lindgren, Sanjiv Kumar ", "link": "https://arxiv.org/abs/1908.10396", "summary": "Quantization based techniques are the current state-of-the-art for scaling\nmaximum inner product search to massive databases. Traditional approaches to\nquantization aim to minimize the reconstruction error of the database points.\nBased on the observation that for a given query, the database points that have\nthe largest inner products are more relevant, we develop a family of\nanisotropic quantization loss functions. Under natural statistical assumptions,\nwe show that quantization with these loss functions leads to a new variant of\nvector quantization that more greatly penalizes the parallel component of a\ndatapoint's residual relative to its orthogonal component. The proposed\napproach achieves state-of-the-art results on the public benchmarks available\nat \\url{ann-benchmarks.com}."}, {"title": "Convolutional dictionary learning based auto-encoders for natural exponential-family distributions", "authors": "Bahareh Tolooshams, Andrew Song, Simona Temereanca, Demba Ba ", "link": "https://arxiv.org/abs/1907.03211", "summary": "We introduce a class of auto-encoder neural networks tailored to data from\nthe natural exponential family (e.g., count data). The architectures are\ninspired by the problem of learning the filters in a convolutional generative\nmodel with sparsity constraints, often referred to as convolutional dictionary\nlearning (CDL). Our work is the first to combine ideas from convolutional\ngenerative models and deep learning for data that are naturally modeled with a\nnon-Gaussian distribution (e.g., binomial and Poisson). This perspective\nprovides us with a scalable and flexible framework that can be re-purposed for\na wide range of tasks and assumptions on the generative model. Specifically,\nthe iterative optimization procedure for solving CDL, an unsupervised task, is\nmapped to an unfolded and constrained neural network, with iterative\nadjustments to the inputs to account for the generative distribution. We also\nshow that the framework can easily be extended for discriminative training,\nappropriate for a supervised task. We demonstrate 1) that fitting the\ngenerative model to learn, in an unsupervised fashion, the latent stimulus that\nunderlies neural spiking data leads to better goodness-of-fit compared to other\nbaselines, 2) competitive performance compared to state-of-the-art algorithms\nfor supervised Poisson image denoising, with significantly fewer parameters,\nand 3) gradient dynamics of shallow binomial auto-encoder."}, {"title": "Strength from Weakness: Fast Learning Using Weak Supervision", "authors": "Joshua Robinson, Stefanie Jegelka, Suvrit Sra ", "link": "https://arxiv.org/abs/2002.08483", "summary": "We study generalization properties of weakly supervised learning. That is,\nlearning where only a few \"strong\" labels (the actual target of our prediction)\nare present but many more \"weak\" labels are available. In particular, we show\nthat having access to weak labels can significantly accelerate the learning\nrate for the strong task to the fast rate of $\\mathcal{O}(\\nicefrac1n)$, where\n$n$ denotes the number of strongly labeled data points. This acceleration can\nhappen even if by itself the strongly labeled data admits only the slower\n$\\mathcal{O}(\\nicefrac{1}{\\sqrt{n}})$ rate. The actual acceleration depends\ncontinuously on the number of weak labels available, and on the relation\nbetween the two tasks. Our theoretical results are reflected empirically across\na range of tasks and illustrate how weak labels speed up learning on the strong\ntask."}, {"title": "NADS: Neural Architecture Distribution Search for Uncertainty Awareness", "authors": "Randy Ardywibowo, Shahin Boluki, Xinyu Gong, Zhangyang Wang, Xiaoning Qian "}, {"title": "Approximating Stacked and Bidirectional Recurrent Architectures with the Delayed Recurrent Neural Network", "authors": "Javier Turek, Shailee Jain, Vy Vo, Mihai Capot\u0103, Alexander Huth, Theodore Willke ", "link": "", "summary": ""}, {"title": "Balancing Competing Objectives with Noisy Data: Score-Based Classifiers for Welfare-Aware Machine Learning", "authors": "Esther Rolf, Max Simchowitz, Sarah Dean, Lydia T. Liu, Daniel Bjorkegren, University of California Moritz Hardt, Joshua  Blumenstock ", "link": "https://arxiv.org/abs/2003.06740", "summary": "While real-world decisions involve many competing objectives, algorithmic\ndecisions are often evaluated with a single objective function. In this paper,\nwe study algorithmic policies which explicitly trade off between a private\nobjective (such as profit) and a public objective (such as social welfare). We\nanalyze a natural class of policies which trace an empirical Pareto frontier\nbased on learned scores, and focus on how such decisions can be made in noisy\nor data-limited regimes. Our theoretical results characterize the optimal\nstrategies in this class, bound the Pareto errors due to inaccuracies in the\nscores, and show an equivalence between optimal strategies and a rich class of\nfairness-constrained profit-maximizing policies. We then present empirical\nresults in two different contexts --- online content recommendation and\nsustainable abalone fisheries --- to underscore the applicability of our\napproach to a wide range of practical decisions. Taken together, these results\nshed light on inherent trade-offs in using machine learning for decisions that\nimpact social welfare."}, {"title": "Time-aware Large Kernel Convolutions", "authors": "Vasileios Lioutas, Yuhong Guo ", "link": "https://arxiv.org/abs/2002.03184", "summary": "To date, most state-of-the-art sequence modelling architectures use attention\nto build generative models for language based tasks. Some of these models use\nall the available sequence tokens to generate an attention distribution which\nresults in time complexity of $O(n^2)$. Alternatively, they utilize depthwise\nconvolutions with softmax normalized kernels of size $k$ acting as a\nlimited-window self-attention, resulting in time complexity of $O(k{\\cdot}n)$.\nIn this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a\nnovel adaptive convolution operation that learns to predict the size of a\nsummation kernel instead of using the fixed-sized kernel matrix. This method\nyields a time complexity of $O(n)$, effectively making the sequence encoding\nprocess linear to the number of tokens. We evaluate the proposed method on\nlarge-scale standard machine translation and language modelling datasets and\nshow that TaLK Convolutions constitute an efficient improvement over other\nattention/convolution based approaches."}, {"title": "Amortised Learning by Wake-Sleep", "authors": "Li Kevin Wenliang, Theodore Moskovitz, Heishiro Kanagawa, Maneesh Sahani ", "link": "https://arxiv.org/abs/2002.09737", "summary": "Models that employ latent variables to capture structure in observed data lie\nat the heart of many current unsupervised learning algorithms, but exact\nmaximum-likelihood learning for powerful and flexible latent-variable models is\nalmost always intractable. Thus, state-of-the-art approaches either abandon the\nmaximum-likelihood framework entirely, or else rely on a variety of variational\napproximations to the posterior distribution over the latents. Here, we propose\nan alternative approach that we call amortised learning. Rather than computing\nan approximation to the posterior over latents, we use a wake-sleep Monte-Carlo\nstrategy to learn a function that directly estimates the maximum-likelihood\nparameter updates. Amortised learning is possible whenever samples of latents\nand observations can be simulated from the generative model, treating the model\nas a \"black box\". We demonstrate its effectiveness on a wide range of complex\nmodels, including those with latents that are discrete or supported on\nnon-Euclidean spaces."}, {"title": "Fair Generative Modeling via Weak Supervision", "authors": "Kristy Choi, Aditya Grover, Trisha Singh, Rui Shu, Stefano Ermon ", "link": "https://arxiv.org/abs/1910.12008", "summary": "Real-world datasets are often biased with respect to key demographic factors\nsuch as race and gender. Due to the latent nature of the underlying factors,\ndetecting and mitigating bias is especially challenging for unsupervised\nmachine learning. We present a weakly supervised algorithm for overcoming\ndataset bias for deep generative models. Our approach requires access to an\nadditional small, unlabeled but unbiased dataset as the supervision signal,\nthus sidestepping the need for explicit labels on the underlying bias factors.\nUsing this supplementary dataset, we detect the bias in existing datasets via a\ndensity ratio technique and learn generative models which efficiently achieve\nthe twin goals of: 1) data efficiency by using training examples from both\nbiased and unbiased datasets for learning, 2) unbiased data generation at test\ntime. Empirically, we demonstrate the efficacy of our approach which reduces\nbias w.r.t. latent factors by 57.1% on average over baselines for comparable\nimage generation using generative adversarial networks."}, {"title": "Multi-Step Greedy Reinforcement Learning Algorithms", "authors": "Manan Tomar, Yonathan Efroni, Mohammad Ghavamzadeh "}, {"title": "Linear Mode Connectivity and the Lottery Ticket Hypothesis", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, Michael Carbin ", "link": "https://arxiv.org/abs/1912.05671", "summary": "We introduce \"instability analysis,\" which assesses whether a neural network\noptimizes to the same, linearly connected minimum under different samples of\nSGD noise. We find that standard vision models become \"stable\" in this way\nearly in training. From then on, the outcome of optimization is determined to\nwithin a linearly connected region. We use instability to study \"iterative\nmagnitude pruning\" (IMP), the procedure used by work on the lottery ticket\nhypothesis to identify subnetworks that could have trained to full accuracy\nfrom initialization. We find that these subnetworks only reach full accuracy\nwhen they are stable, which either occurs at initialization for small-scale\nsettings (MNIST) or early in training for large-scale settings (Resnet-50 and\nInception-v3 on ImageNet).\n  This submission subsumes 1903.01611 (\"Stabilizing the Lottery Ticket\nHypothesis\" and \"The Lottery Ticket Hypothesis at Scale\")"}, {"title": "Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent", "authors": "Surbhi Goel, Aravind Gollakota, Zhihan Jin, Sushrut Karmalkar, Adam Klivans "}, {"title": "Learnable Group Transform For Time-Series", "authors": "Romain Cosentino, Behnaam Aazhang "}, {"title": "Optimistic bounds for multi-output learning", "authors": "Henry Reeve, Ata Kaban ", "link": "https://arxiv.org/abs/2002.09769", "summary": "We investigate the challenge of multi-output learning, where the goal is to\nlearn a vector-valued function based on a supervised data set. This includes a\nrange of important problems in Machine Learning including multi-target\nregression, multi-class classification and multi-label classification. We begin\nour analysis by introducing the self-bounding Lipschitz condition for\nmulti-output loss functions, which interpolates continuously between a\nclassical Lipschitz condition and a multi-dimensional analogue of a smoothness\ncondition. We then show that the self-bounding Lipschitz condition gives rise\nto optimistic bounds for multi-output learning, which are minimax optimal up to\nlogarithmic factors. The proof exploits local Rademacher complexity combined\nwith a powerful minoration inequality due to Srebro, Sridharan and Tewari. As\nan application we derive a state-of-the-art generalization bound for\nmulti-class gradient boosting."}, {"title": "Detecting Out-of-Distribution Examples with Gram Matrices", "authors": "Chandramouli Shama Sastry, Sageev Oore ", "link": "", "summary": ""}, {"title": "On Variational Learning of Controllable Representations for Text without Supervision", "authors": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao ", "link": "http://arxiv.org/abs/1905.11975", "summary": "The variational autoencoder (VAE) can learn the manifold of natural images on\ncertain datasets, as evidenced by meaningful interpolation or extrapolation in\nthe continuous latent space. However, on discrete data such as text, it is\nunclear if unsupervised learning can discover a similar latent space that\nallows controllable manipulation. In this work, we find that sequence VAEs\ntrained on text fail to properly decode when the latent codes are manipulated,\nbecause the modified codes often land in holes or vacant regions in the\naggregated posterior latent space, where the decoding network fails to\ngeneralize. Both as a validation of the explanation and as a fix to the\nproblem, we propose to constrain the posterior mean to a learned probability\nsimplex, and perform manipulation within this simplex. Our proposed method\nmitigates the latent vacancy problem and achieves the first success in\nunsupervised learning of controllable representations for text. Empirically,\nour method outperforms unsupervised baselines and strong supervised approaches\non text style transfer. On automatic evaluation metrics used in text style\ntransfer, even with the decoding network trained from scratch, our method\nachieves comparable results with state-of-the-art supervised approaches\nleveraging large-scale pre-trained models for generation. Furthermore, it is\ncapable of performing more flexible fine-grained control over text generation\nthan existing methods."}, {"title": "Model-Based Reinforcement Learning with Value-Targeted Regression", "authors": "Zeyu Jia, Lin Yang, Csaba Szepesvari, Mengdi Wang, Alex Ayoub ", "link": "http://arxiv.org/abs/2006.01107", "summary": "This paper studies model-based reinforcement learning (RL) for regret\nminimization. We focus on finite-horizon episodic RL where the transition model\n$P$ belongs to a known family of models $\\mathcal{P}$, a special case of which\nis when models in $\\mathcal{P}$ take the form of linear mixtures: $P_{\\theta} =\n\\sum_{i=1}^{d} \\theta_{i}P_{i}$. We propose a model based RL algorithm that is\nbased on optimism principle: In each episode, the set of models that are\n`consistent' with the data collected is constructed. The criterion of\nconsistency is based on the total squared error of that the model incurs on the\ntask of predicting \\emph{values} as determined by the last value estimate along\nthe transitions. The next value function is then chosen by solving the\noptimistic planning problem with the constructed set of models. We derive a\nbound on the regret, which, in the special case of linear mixtures, the regret\nbound takes the form $\\tilde{\\mathcal{O}}(d\\sqrt{H^{3}T})$, where $H$, $T$ and\n$d$ are the horizon, total number of steps and dimension of $\\theta$,\nrespectively. In particular, this regret bound is independent of the total\nnumber of states or actions, and is close to a lower bound\n$\\Omega(\\sqrt{HdT})$. For a general model family $\\mathcal{P}$, the regret\nbound is derived using the notion of the so-called Eluder dimension proposed by\nRusso & Van Roy (2014)."}, {"title": "Robust and scalable credit assignment without weight symmetry", "authors": "Daniel Kunin, Aran Nayebi, Javier Sagastuy-Brena, Surya Ganguli, Jonathan Bloom, Daniel Yamins ", "link": "https://arxiv.org/abs/2003.01513", "summary": "The neural plausibility of backpropagation has long been disputed, primarily\nfor its use of non-local weight transport - the biologically dubious\nrequirement that one neuron instantaneously measure the synaptic weights of\nanother. Until recently, attempts to create local learning rules that avoid\nweight transport have typically failed in the large-scale learning scenarios\nwhere backpropagation shines, e.g. ImageNet categorization with deep\nconvolutional networks. Here, we investigate a recently proposed local learning\nrule that yields competitive performance with backpropagation and find that it\nis highly sensitive to metaparameter choices, requiring laborious tuning that\ndoes not transfer across network architecture. Our analysis indicates the\nunderlying mathematical reason for this instability, allowing us to identify a\nmore robust local learning rule that better transfers without metaparameter\ntuning. Nonetheless, we find a performance and stability gap between this local\nrule and backpropagation that widens with increasing model depth. We then\ninvestigate several non-local learning rules that relax the need for\ninstantaneous weight transport into a more biologically-plausible \"weight\nestimation\" process, showing that these rules match state-of-the-art\nperformance on deep networks and operate effectively in the presence of noisy\nupdates. Taken together, our results suggest two routes towards the discovery\nof neural implementations for credit assignment without weight symmetry:\nfurther improvement of local rules so that they perform consistently across\narchitectures and the identification of biological implementations for\nnon-local learning mechanisms."}, {"title": " Predicting deliberative outcomes", "authors": "Vikas K Garg, Tommi Jaakkola "}, {"title": "Black-box Certification and Learning under Adversarial Perturbations", "authors": "Hassan Ashtiani, Vinayak Pathak, Ruth Urner ", "link": "", "summary": ""}, {"title": "When deep denoising meets iterative phase retrieval", "authors": "Yaotian Wang, Xiaohang Sun, Jason Fleischer ", "link": "https://arxiv.org/abs/2003.01792", "summary": "Recovering a signal from its Fourier intensity underlies many important\napplications, including lensless imaging and imaging through scattering media.\nConventional algorithms for retrieving the phase suffer when noise is present\nbut display global convergence when given clean data. Neural networks have been\nused to improve algorithm robustness, but efforts to date are sensitive to\ninitial conditions and give inconsistent performance. Here, we combine\niterative methods from phase retrieval with image statistics from deep\ndenoisers, via regularization-by-denoising. The resulting methods inherit the\nadvantages of each approach and outperform other noise-robust phase retrieval\nalgorithms. Our work paves the way for hybrid imaging methods that integrate\nmachine-learned constraints in conventional algorithms."}, {"title": "The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization", "authors": "Ben Adlam, Jeffrey Pennington "}, {"title": "A Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition", "authors": "Anurag Kumar, Vamsi Ithapu "}, {"title": "On the Global Convergence Rates of Softmax Policy Gradient Methods", "authors": "Jincheng Mei, Chenjun Xiao, Csaba Szepesvari, Dale Schuurmans ", "link": "https://arxiv.org/abs/2005.06392", "summary": "We make three contributions toward better understanding policy gradient\nmethods in the tabular setting. First, we show that with the true gradient,\npolicy gradient with a softmax parametrization converges at a $O(1/t)$ rate,\nwith constants depending on the problem and initialization. This result\nsignificantly expands the recent asymptotic convergence results. The analysis\nrelies on two findings: that the softmax policy gradient satisfies a\n\\L{}ojasiewicz inequality, and the minimum probability of an optimal action\nduring optimization can be bounded in terms of its initial value. Second, we\nanalyze entropy regularized policy gradient and show that it enjoys a\nsignificantly faster linear convergence rate $O(e^{-t})$ toward softmax optimal\npolicy. This result resolves an open question in the recent literature.\nFinally, combining the above two results and additional new $\\Omega(1/t)$ lower\nbound results, we explain how entropy regularization improves policy\noptimization, even with the true gradient, from the perspective of convergence\nrate. The separation of rates is further explained using the notion of\nnon-uniform \\L{}ojasiewicz degree. These results provide a theoretical\nunderstanding of the impact of entropy and corroborate existing empirical\nstudies."}, {"title": "Source Separation with Deep Generative Priors", "authors": "Vivek Jayaram, John Thickstun ", "link": "https://arxiv.org/abs/2002.07942", "summary": "Despite substantial progress in signal source separation, results for richly\nstructured data continue to contain perceptible artifacts. In contrast, recent\ndeep generative models can produce authentic samples in a variety of domains\nthat are indistinguishable from samples of the data distribution. This paper\nintroduces a Bayesian approach to source separation that uses generative models\nas priors over the components of a mixture of sources, and Langevin dynamics to\nsample from the posterior distribution of sources given a mixture. This\ndecouples the source separation problem from generative modeling, enabling us\nto directly use cutting-edge generative models as priors. The method achieves\nstate-of-the-art performance for MNIST digit separation. We introduce new\nmethodology for evaluating separation quality on richer datasets, providing\nquantitative evaluation of separation results on CIFAR-10. We also provide\nqualitative results on LSUN."}, {"title": "Non-Autoregressive Neural Text-to-Speech", "authors": "Kainan Peng, Wei Ping, Zhao Song, Kexin Zhao ", "link": "", "summary": ""}, {"title": "Amortized Population Gibbs Samplers with Neural Sufficient Statistics", "authors": "Hao Wu, Heiko Zimmermann, Eli Sennesh, Tuan Anh Le, Jan-Willem van de Meent ", "link": "https://arxiv.org/abs/1911.01382", "summary": "Amortized variational methods have proven difficult to scale to structured\nproblems, such as inferring positions of multiple objects from video images. We\ndevelop amortized population Gibbs (APG) samplers, a class of scalable methods\nthat frames structured variational inference as adaptive importance sampling.\nAPG samplers construct high-dimensional proposals by iterating over updates to\nlower-dimensional blocks of variables. We train each conditional proposal by\nminimizing the inclusive KL divergence with respect to the conditional\nposterior. To appropriately account for the size of the input data, we develop\na new parameterization in terms of neural sufficient statistics. Experiments\nshow that APG samplers can train highly structured deep generative models in an\nunsupervised manner, and achieve substantial improvements in inference accuracy\nrelative to standard autoencoding variational methods."}, {"title": "Neural Network Control Policy Verification With Persistent Adversarial Perturbation", "authors": "Yuh-Shyang Wang, Tsui-Wei Weng, Luca Daniel ", "link": "", "summary": ""}, {"title": "Circuit-Based Intrinsic Methods to Detect Overfitting", "authors": "Satrajit Chatterjee, Alan Mishchenko ", "link": "https://arxiv.org/abs/1907.01991", "summary": "The focus of this paper is on intrinsic methods to detect overfitting. These\nrely only on the model and the training data, as opposed to traditional\nextrinsic methods that rely on performance on a test set or on bounds from\nmodel complexity. We propose a family of intrinsic methods called\nCounterfactual Simulation (CFS) which analyze the flow of training examples\nthrough the model by identifying and perturbing rare patterns. By applying CFS\nto logic circuits we get a method that has no hyper-parameters and works\nuniformly across different types of models such as neural networks, random\nforests and lookup tables. Experimentally, CFS can separate models with\ndifferent levels of overfit using only their logic circuit representations\nwithout any access to the high level structure. By comparing lookup tables,\nneural networks, and random forests using CFS, we get insight into why neural\nnetworks generalize. In particular, we find that stochastic gradient descent in\nneural nets does not lead to \"brute force\" memorization, but finds common\npatterns (whether we train with actual or randomized labels), and neural\nnetworks are not unlike forests in this regard. Finally, we identify a\nlimitation with our proposal that makes it unsuitable in an adversarial\nsetting, but points the way to future work on robust intrinsic methods."}, {"title": "Inter-domain Deep Gaussian Processes with RKHS Fourier Features", "authors": "Tim Rudner, Dino Sejdinovic, Yarin Gal "}, {"title": "Estimating Q(s,s') with Deterministic Dynamics Gradients", "authors": "Ashley Edwards, Himanshu Sahni, Rosanne Liu, Jane Hung, Ankit Jain, Rui Wang, Adrien Ecoffet, Thomas Miconi, Charles Isbell, Jason Yosinski ", "link": "https://arxiv.org/abs/2002.09505", "summary": "In this paper, we introduce a novel form of value function, $Q(s, s')$, that\nexpresses the utility of transitioning from a state $s$ to a neighboring state\n$s'$ and then acting optimally thereafter. In order to derive an optimal\npolicy, we develop a forward dynamics model that learns to make next-state\npredictions that maximize this value. This formulation decouples actions from\nvalues while still learning off-policy. We highlight the benefits of this\napproach in terms of value function transfer, learning within redundant action\nspaces, and learning off-policy from state observations generated by\nsub-optimal or completely random policies. Code and videos are available at\n\\url{sites.google.com/view/qss-paper}."}, {"title": "On conditional versus marginal bias in multi-armed bandits", "authors": "Jaehyeok Shin, Aaditya Ramdas, Alessandro Rinaldo ", "link": "https://arxiv.org/abs/2002.08422", "summary": "The bias of the sample means of the arms in multi-armed bandits is an\nimportant issue in adaptive data analysis that has recently received\nconsiderable attention in the literature. Existing results relate in precise\nways the sign and magnitude of the bias to various sources of data adaptivity,\nbut do not apply to the conditional inference setting in which the sample means\nare computed only if some specific conditions are satisfied. In this paper, we\ncharacterize the sign of the conditional bias of monotone functions of the\nrewards, including the sample mean. Our results hold for arbitrary conditioning\nevents and leverage natural monotonicity properties of the data collection\npolicy. We further demonstrate, through several examples from sequential\ntesting and best arm identification, that the sign of the conditional and\nunconditional bias of the sample mean of an arm can be different, depending on\nthe conditioning event. Our analysis offers new and interesting perspectives on\nthe subtleties of assessing the bias in data adaptive settings."}, {"title": "Implicit competitive regularization in GANs", "authors": "Florian Schaefer, Hongkai Zheng, Anima Anandkumar ", "link": "https://arxiv.org/abs/1910.05852", "summary": "To improve the stability of GAN training we need to understand why they can\nproduce realistic samples. Presently, this is attributed to properties of the\ndivergence obtained under an optimal discriminator. This argument has a\nfundamental flaw: If we do not impose regularity of the discriminator, it can\nexploit visually imperceptible errors of the generator to always achieve the\nmaximal generator loss. In practice, gradient penalties are used to regularize\nthe discriminator. However, this needs a metric on the space of images that\ncaptures visual similarity. Such a metric is not known, which explains the\nlimited success of gradient penalties in stabilizing GANs. We argue that the\nperformance of GANs is instead due to the implicit competitive regularization\n(ICR) arising from the simultaneous optimization of generator and\ndiscriminator. ICR promotes solutions that look real to the discriminator and\nthus leverages its inductive biases to generate realistic images. We show that\nopponent-aware modelling of generator and discriminator, as present in\ncompetitive gradient descent (CGD), can significantly strengthen ICR and thus\nstabilize GAN training without explicit regularization. In our experiments, we\nuse an existing implementation of WGAN-GP and show that by training it with CGD\nwe can improve the inception score (IS) on CIFAR10 for a wide range of\nscenarios, without any hyperparameter tuning. The highest IS is obtained by\ncombining CGD with the WGAN-loss, without any explicit regularization."}, {"title": "DrRepair: A Self-Supervised, Graph-Attentional Approach to Repairing Programs from Diagnostic Feedback", "authors": "Michihiro Yasunaga, Percy Liang "}, {"title": "Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transitions", "authors": "Omer Gottesman, Joseph Futoma, Yao Liu, Sonali Parbhoo, Leo Celi, Emma Brunskill, Finale Doshi-Velez ", "link": "https://arxiv.org/abs/2002.03478", "summary": "Off-policy evaluation in reinforcement learning offers the chance of using\nobservational data to improve future outcomes in domains such as healthcare and\neducation, but safe deployment in high stakes settings requires ways of\nassessing its validity. Traditional measures such as confidence intervals may\nbe insufficient due to noise, limited data and confounding. In this paper we\ndevelop a method that could serve as a hybrid human-AI system, to enable human\nexperts to analyze the validity of policy evaluation estimates. This is\naccomplished by highlighting observations in the data whose removal will have a\nlarge effect on the OPE estimate, and formulating a set of rules for choosing\nwhich ones to present to domain experts for validation. We develop methods to\ncompute exactly the influence functions for fitted Q-evaluation with two\ndifferent function classes: kernel-based and linear least squares. Experiments\non medical simulations and real-world intensive care unit data demonstrate that\nour method can be used to identify limitations in the evaluation process and\nmake evaluation more robust."}, {"title": "Communication-Efficient Federated Learning with Sketching", "authors": "Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, Vladimir Braverman, Joseph Gonzalez, Ion Stoica, Raman Arora "}, {"title": "Learning Fair Policies in Multi-Objective (Deep) Reinforcement Learning with Average and Discounted Rewards", "authors": "Umer Siddique, Paul Weng, Matthieu Zimmer "}, {"title": "Robust Black Box Explanations Under Distribution Shift", "authors": "Himabindu Lakkaraju, Nino Arsov, Osbert Bastani "}, {"title": "Distributed Online Optimization over a Heterogeneous Network", "authors": "Nima Eshraghi, Ben Liang ", "link": "", "summary": ""}, {"title": "ECLIPSE: An Extreme-Scale Linear Program Solver for Web-Applications", "authors": "Kinjal Basu, Amol Ghoting, Rahul Mazumder, Yao Pan "}, {"title": "CURL: Contrastive Unsupervised Representation Learning for Reinforcement Learning", "authors": "Michael Laskin, Pieter Abbeel, Aravind Srinivas "}, {"title": "Confidence-Aware Learning for Deep Neural Networks", "authors": "Sangheum Hwang, Jooyoung Moon, Jihyo Kim, Younghak Shin "}, {"title": "Online Bayesian Moment Matching based SAT Solver Heuristics", "authors": "Haonan Duan, Saeed Nejati, George Trimponias, Pascal Poupart, Vijay Ganesh "}, {"title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search", "authors": "Binghong Chen, Chengtao Li, Hanjun Dai, Le Song "}, {"title": "FedBoost: A Communication-Efficient Algorithm for Federated Learning", "authors": "Jenny Hamer, Mehryar Mohri, Ananda Theertha Suresh ", "link": "", "summary": ""}, {"title": "Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion", "authors": "Qinqing Zheng, Jinshuo Dong, Qi Long, Weijie Su ", "link": "https://arxiv.org/abs/2003.04493", "summary": "Datasets containing sensitive information are often sequentially analyzed by\nmany algorithms. This raises a fundamental question in differential privacy\nregarding how the overall privacy bound degrades under composition. To address\nthis question, we introduce a family of analytical and sharp privacy bounds\nunder composition using the Edgeworth expansion in the framework of the\nrecently proposed f-differential privacy. In contrast to the existing\ncomposition theorems using the central limit theorem, our new privacy bounds\nunder composition gain improved tightness by leveraging the refined\napproximation accuracy of the Edgeworth expansion. Our approach is easy to\nimplement and computationally efficient for any number of compositions. The\nsuperiority of these new bounds is confirmed by an asymptotic error analysis\nand an application to quantifying the overall privacy guarantees of noisy\nstochastic gradient descent used in training private deep neural networks."}, {"title": "Few-Shot Learning as Domain Adaptation: Algorithm and Analysis", "authors": "Jiechao Guan, Zhiwu Lu, Tao Xiang, Ji-Rong Wen ", "link": "https://arxiv.org/abs/2002.02050", "summary": "To recognize the unseen classes with only few samples, few-shot learning\n(FSL) uses prior knowledge learned from the seen classes. A major challenge for\nFSL is that the distribution of the unseen classes is different from that of\nthose seen, resulting in poor generalization even when a model is meta-trained\non the seen classes. This class-difference-caused distribution shift can be\nconsidered as a special case of domain shift. In this paper, for the first\ntime, we propose a domain adaptation prototypical network with attention\n(DAPNA) to explicitly tackle such a domain shift problem in a meta-learning\nframework. Specifically, armed with a set transformer based attention module,\nwe construct each episode with two sub-episodes without class overlap on the\nseen classes to simulate the domain shift between the seen and unseen classes.\nTo align the feature distributions of the two sub-episodes with limited\ntraining samples, a feature transfer network is employed together with a margin\ndisparity discrepancy (MDD) loss. Importantly, theoretical analysis is provided\nto give the learning bound of our DAPNA. Extensive experiments show that our\nDAPNA outperforms the state-of-the-art FSL alternatives, often by significant\nmargins."}, {"title": "Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods", "authors": "Daniel Fu, Mayee Chen, Frederic Sala, Sarah Hooper, Kayvon  Fatahalian, Christopher Re ", "link": "https://arxiv.org/abs/2002.11955", "summary": "Weak supervision is a popular method for building machine learning models\nwithout relying on ground truth annotations. Instead, it generates\nprobabilistic training labels by estimating the accuracies of multiple noisy\nlabeling sources (e.g., heuristics, crowd workers). Existing approaches use\nlatent variable estimation to model the noisy sources, but these methods can be\ncomputationally expensive, scaling superlinearly in the data. In this work, we\nshow that, for a class of latent variable models highly applicable to weak\nsupervision, we can find a closed-form solution to model parameters, obviating\nthe need for iterative solutions like stochastic gradient descent (SGD). We use\nthis insight to build FlyingSquid, a weak supervision framework that runs\norders of magnitude faster than previous weak supervision approaches and\nrequires fewer assumptions. In particular, we prove bounds on generalization\nerror without assuming that the latent variable model can exactly parameterize\nthe underlying data distribution. Empirically, we validate FlyingSquid on\nbenchmark weak supervision datasets and find that it achieves the same or\nhigher quality compared to previous approaches without the need to tune an SGD\nprocedure, recovers model parameters 170 times faster on average, and enables\nnew video analysis and online learning applications."}, {"title": "Spectral Frank-Wolfe Algorithm: Strict Complementarity and Linear Convergence", "authors": "Lijun Ding, Yingjie Fei, Qiantong Xu, Chengrun Yang ", "link": "https://arxiv.org/abs/2006.01719", "summary": "We develop a novel variant of the classical Frank-Wolfe algorithm, which we\ncall spectral Frank-Wolfe, for convex optimization over a spectrahedron. The\nspectral Frank-Wolfe algorithm has a novel ingredient: it computes a few\neigenvectors of the gradient and solves a small-scale SDP in each iteration.\nSuch procedure overcomes slow convergence of the classical Frank-Wolfe\nalgorithm due to ignoring eigenvalue coalescence. We demonstrate that strict\ncomplementarity of the optimization problem is key to proving linear\nconvergence of various algorithms, such as the spectral Frank-Wolfe algorithm\nas well as the projected gradient method and its accelerated version."}, {"title": "Deep Molecular Programming: A Natural Implementation of Binary-Weight ReLU Neural Networks", "authors": "Marko Vasic, Cameron Chalk, Sarfraz Khurshid, David Soloveichik ", "link": "http://arxiv.org/abs/2003.13720", "summary": "Embedding computation in molecular contexts incompatible with traditional\nelectronics is expected to have wide ranging impact in synthetic biology,\nmedicine, nanofabrication and other fields. A key remaining challenge lies in\ndeveloping programming paradigms for molecular computation that are\nwell-aligned with the underlying chemical hardware and do not attempt to\nshoehorn ill-fitting electronics paradigms. We discover a surprisingly tight\nconnection between a popular class of neural networks (Binary-weight ReLU aka\nBinaryConnect) and a class of coupled chemical reactions that are absolutely\nrobust to reaction rates. The robustness of rate-independent chemical\ncomputation makes it a promising target for bioengineering implementation. We\nshow how a BinaryConnect neural network trained in silico using well-founded\ndeep learning optimization techniques, can be compiled to an equivalent\nchemical reaction network, providing a novel molecular programming paradigm. We\nillustrate such translation on the paradigmatic IRIS and MNIST datasets. Toward\nintended applications of chemical computation, we further use our method to\ngenerate a CRN that can discriminate between different virus types based on\ngene expression levels. Our work sets the stage for rich knowledge transfer\nbetween neural network and molecular programming communities."}, {"title": "Generative Pretraining From Pixels", "authors": "Mark Chen, Alec Radford, Rewon Child, Jeffrey K Wu, Heewoo Jun, David Luan, Ilya Sutskever "}, {"title": "Inferring DQN structure for high-dimensional continuous control", "authors": "Andrey Sakryukin, Chedy Raissi, Mohan Kankanhalli "}, {"title": "Subspace Fitting Meets Regression: The Effects of Supervision and  Orthonormality Constraints on Double Descent of Generalization Errors", "authors": "Yehuda Dar, Paul Mayer, Lorenzo Luzi, Richard Baraniuk ", "link": "https://arxiv.org/abs/2002.10614", "summary": "We study the linear subspace fitting problem in the overparameterized\nsetting, where the estimated subspace can perfectly interpolate the training\nexamples. Our scope includes the least-squares solutions to subspace fitting\ntasks with varying levels of supervision in the training data (i.e., the\nproportion of input-output examples of the desired low-dimensional mapping) and\northonormality of the vectors defining the learned operator. This flexible\nfamily of problems connects standard, unsupervised subspace fitting that\nenforces strict orthonormality with a corresponding regression task that is\nfully supervised and does not constrain the linear operator structure. This\nclass of problems is defined over a supervision-orthonormality plane, where\neach coordinate induces a problem instance with a unique pair of supervision\nlevel and softness of orthonormality constraints. We explore this plane and\nshow that the generalization errors of the corresponding subspace fitting\nproblems follow double descent trends as the settings become more supervised\nand less orthonormally constrained."}, {"title": "Learning Selection Strategies in Buchberger\u2019s Algorithm", "authors": "Dylan Peifer, Michael Stillman, Daniel Halpern-Leistner ", "link": "https://arxiv.org/abs/2005.01917", "summary": "Studying the set of exact solutions of a system of polynomial equations\nlargely depends on a single iterative algorithm, known as Buchberger's\nalgorithm. Optimized versions of this algorithm are crucial for many computer\nalgebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach\nto Buchberger's algorithm that uses reinforcement learning agents to perform\nS-pair selection, a key step in the algorithm. We then study how the difficulty\nof the problem depends on the choices of domain and distribution of\npolynomials, about which little is known. Finally, we train a policy model\nusing proximal policy optimization (PPO) to learn S-pair selection strategies\nfor random systems of binomial equations. In certain domains, the trained model\noutperforms state-of-the-art selection heuristics both in number of iterations\nof the algorithm and total number of polynomial additions performed. These\nresults provide a proof-of-concept that recent developments in machine learning\nhave the potential to improve performance of algorithms in symbolic\ncomputation."}, {"title": "Estimating the Error of Randomized Newton Methods: A Bootstrap Approach", "authors": "Miles Lopes, Xiaotie Chen "}, {"title": "Spectral Subsampling MCMC for Stationary Time Series", "authors": "Robert Salomone, Matias Quiroz, Robert kohn, Mattias Villani, Minh-Ngoc Tran ", "link": "https://arxiv.org/abs/1910.13627", "summary": "Bayesian inference using Markov Chain Monte Carlo (MCMC) on large datasets\nhas developed rapidly in recent years. However, the underlying methods are\ngenerally limited to relatively simple settings where the data have specific\nforms of independence. We propose a novel technique for speeding up MCMC for\ntime series data by efficient data subsampling in the frequency domain. For\nseveral challenging time series models, we demonstrate a speedup of up to two\norders of magnitude while incurring negligible bias compared to MCMC on the\nfull dataset. We also propose alternative control variates for variance\nreduction based on data grouping and coreset constructions."}, {"title": "Progressive Identification of True Labels for Partial-Label Learning", "authors": "Jiaqi Lv, Miao Xu, LEI FENG, Gang Niu, Xin Geng, Masashi Sugiyama ", "link": "https://arxiv.org/abs/2002.08053", "summary": "Partial-label learning is one of the important weakly supervised learning\nproblems, where each training example is equipped with a set of candidate\nlabels that contains the true label. Most existing methods elaborately designed\nlearning objectives as constrained optimizations that must be solved in\nspecific manners, making their computational complexity a bottleneck for\nscaling up to big data. The goal of this paper is to propose a novel framework\nof partial-label learning without implicit assumptions on the model or\noptimization algorithm. More specifically, we propose a general estimator of\nthe classification risk, theoretically analyze the classifier-consistency, and\nestablish an estimation error bound. We then explore a progressive\nidentification method for approximately minimizing the proposed risk estimator,\nwhere the update of the model and identification of true labels are conducted\nin a seamless manner. The resulting algorithm is model-independent and\nloss-independent, and compatible with stochastic optimization. Thorough\nexperiments demonstrate it sets the new state of the art."}, {"title": "R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games", "authors": "Zhongxiang Dai, Yizhou Chen, Bryan Kian Hsiang Low, Patrick Jaillet , Teck-Hua Ho "}, {"title": "Graph Homomorphism Convolution", "authors": "Hoang Nguyen, Takanori Maehara ", "link": "https://arxiv.org/abs/2005.01214", "summary": "In this paper, we study the graph classification problem from the graph\nhomomorphism perspective. We consider the homomorphisms from $F$ to $G$, where\n$G$ is a graph of interest (e.g. molecules or social networks) and $F$ belongs\nto some family of graphs (e.g. paths or non-isomorphic trees). We prove that\ngraph homomorphism numbers provide a natural universally invariant (isomorphism\ninvariant) embedding maps which can be used for graph classifications. In\npractice, by choosing $F$ to have bounded tree-width, we show that the\nhomomorphism method is not only competitive in classification accuracy but also\nrun much faster than other state-of-the-art methods. Finally, based on our\ntheoretical analysis, we propose the Graph Homomorphism Convolution module\nwhich has promising performance in the graph classification task."}, {"title": "Conditional Augmentation for Generative Modeling", "authors": "Heewoo Jun, Rewon Child, Mark Chen, John Schulman, Aditya Ramesh, Alec Radford, Ilya Sutskever ", "link": "", "summary": ""}, {"title": "PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions", "authors": "Zhengyang Shen, Lingshen He, Zhouchen Lin, Jinwen Ma "}, {"title": "Abstraction Mechanisms Predict Generalization in Deep Neural Networks", "authors": "Alex Gain, Hava Siegelmann ", "link": "https://arxiv.org/abs/1905.11515", "summary": "A longstanding problem for Deep Neural Networks (DNNs) is understanding their\npuzzling ability to generalize well. We approach this problem through the\nunconventional angle of \\textit{cognitive abstraction mechanisms}, drawing\ninspiration from recent neuroscience work, allowing us to define the Cognitive\nNeural Activation metric (CNA) for DNNs, which is the correlation between\ninformation complexity (entropy) of given input and the concentration of higher\nactivation values in deeper layers of the network. The CNA is highly predictive\nof generalization ability, outperforming norm-and-margin-based generalization\nmetrics on an extensive evaluation of over 100 dataset-and-network-architecture\ncombinations, especially in cases where additive noise is present and/or\ntraining labels are corrupted. These strong empirical results show the\nusefulness of CNA as a generalization metric, and encourage further research on\nthe connection between information complexity and representations in the deeper\nlayers of networks in order to better understand the generalization\ncapabilities of DNNs."}, {"title": "Revisiting Fundamentals of Experience Replay", "authors": "William Fedus, Prajit Ramachandran, Rishabh Agarwal, Yoshua Bengio, Hugo Larochelle, Mark Rowland, Will Dabney ", "link": "", "summary": ""}, {"title": "Go Wide, Then Narrow: Efficient Training of Deep Thin Networks", "authors": "Denny Zhou, Mao Ye, Chen Chen, Mingxing Tan, Tianjian Meng, Xiaodan Song, Quoc Le, Qiang Liu, Dale Schuurmans "}, {"title": "Meta-learning for mixed linear regression", "authors": "Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, Sewoong Oh ", "link": "https://arxiv.org/abs/2002.08936", "summary": "In modern supervised learning, there are a large number of tasks, but many of\nthem are associated with only a small amount of labeled data. These include\ndata from medical image processing and robotic interaction. Even though each\nindividual task cannot be meaningfully trained in isolation, one seeks to\nmeta-learn across the tasks from past experiences by exploiting some\nsimilarities. We study a fundamental question of interest: When can abundant\ntasks with small data compensate for lack of tasks with big data? We focus on a\ncanonical scenario where each task is drawn from a mixture of $k$ linear\nregressions, and identify sufficient conditions for such a graceful exchange to\nhold; The total number of examples necessary with only small data tasks scales\nsimilarly as when big data tasks are available. To this end, we introduce a\nnovel spectral approach and show that we can efficiently utilize small data\ntasks with the help of $\\tilde\\Omega(k^{3/2})$ medium data tasks each with\n$\\tilde\\Omega(k^{1/2})$ examples."}, {"title": "Efficiently Learning Adversarially Robust Halfspaces with Noise", "authors": "Omar Montasser, Surbhi Goel, Ilias Diakonikolas, Nati Srebro ", "link": "https://arxiv.org/abs/2005.07652", "summary": "We study the problem of learning adversarially robust halfspaces in the\ndistribution-independent setting. In the realizable setting, we provide\nnecessary and sufficient conditions on the adversarial perturbation sets under\nwhich halfspaces are efficiently robustly learnable. In the presence of random\nlabel noise, we give a simple computationally efficient algorithm for this\nproblem with respect to any $\\ell_p$-perturbation."}, {"title": "Bayesian Graph Neural Networks with Adaptive Connection Sampling", "authors": "Arman Hasanzadeh, Ehsan Hajiramezanali, Shahin Boluki, Nick Duffield, Mingyuan Zhou, Krishna Narayanan, Xiaoning Qian "}, {"title": "On the Theoretical Properties of the Network Jackknife", "authors": "Qiaohui Lin, Robert Lunde, Purnamrita Sarkar ", "link": "https://arxiv.org/abs/2004.08935", "summary": "We study the properties of a leave-node-out jackknife procedure for network\ndata. Under the sparse graphon model, we prove an Efron-Stein-type inequality,\nshowing that the network jackknife leads to conservative estimates of the\nvariance (in expectation) for any network functional that is invariant to node\npermutation. For a general class of count functionals, we also establish\nconsistency of the network jackknife. We complement our theoretical analysis\nwith a range of simulated and real-data examples and show that the network\njackknife offers competitive performance in cases where other resampling\nmethods are known to be valid. In fact, for several network statistics, we see\nthat the jackknife provides more accurate inferences compared to related\nmethods such as subsampling."}, {"title": "Thompson Sampling via Local Uncertainty", "authors": "Zhendong Wang, Mingyuan Zhou "}, {"title": "Decision Trees for Decision-Making under the Predict-then-Optimize Framework", "authors": "Adam Elmachtoub, Jason Cheuk Nam Liang, Ryan McNellis ", "link": "https://arxiv.org/abs/2003.00360", "summary": "We consider the use of decision trees for decision-making problems under the\npredict-then-optimize framework. That is, we would like to first use a decision\ntree to predict unknown input parameters of an optimization problem, and then\nmake decisions by solving the optimization problem using the predicted\nparameters. A natural loss function in this framework is to measure the\nsuboptimality of the decisions induced by the predicted input parameters, as\nopposed to measuring loss using input parameter prediction error. This natural\nloss function is known in the literature as the Smart Predict-then-Optimize\n(SPO) loss, and we propose a tractable methodology called SPO Trees (SPOTs) for\ntraining decision trees under this loss. SPOTs benefit from the\ninterpretability of decision trees, providing an interpretable segmentation of\ncontextual features into groups with distinct optimal solutions to the\noptimization problem of interest. We conduct several numerical experiments on\nsynthetic and real data including the prediction of travel times for shortest\npath problems and predicting click probabilities for news article\nrecommendation. We demonstrate on these datasets that SPOTs simultaneously\nprovide higher quality decisions and significantly lower model complexity than\nother machine learning approaches (e.g., CART) trained to minimize prediction\nerror."}, {"title": "Representation Learning via Adversarially-Contrastive Optimal Transport", "authors": "Anoop Cherian, Shuchin Aeron "}, {"title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"", "authors": "Saeed Amizadeh, Hamid Palangi, Oleksandr Polozov, Yichen Huang, Kazuhito Koishida ", "link": "", "summary": ""}, {"title": "Two Simple Ways to Learn Individual Fairness Metric from Data", "authors": "Debarghya Mukherjee, Mikhail Yurochkin, Moulinath Banerjee, Yuekai Sun "}, {"title": "A Simple Framework for Contrastive Learning of Visual Representations", "authors": "Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton ", "link": "https://arxiv.org/abs/2002.05709", "summary": "This paper presents SimCLR: a simple framework for contrastive learning of\nvisual representations. We simplify recently proposed contrastive\nself-supervised learning algorithms without requiring specialized architectures\nor a memory bank. In order to understand what enables the contrastive\nprediction tasks to learn useful representations, we systematically study the\nmajor components of our framework. We show that (1) composition of data\naugmentations plays a critical role in defining effective predictive tasks, (2)\nintroducing a learnable nonlinear transformation between the representation and\nthe contrastive loss substantially improves the quality of the learned\nrepresentations, and (3) contrastive learning benefits from larger batch sizes\nand more training steps compared to supervised learning. By combining these\nfindings, we are able to considerably outperform previous methods for\nself-supervised and semi-supervised learning on ImageNet. A linear classifier\ntrained on self-supervised representations learned by SimCLR achieves 76.5%\ntop-1 accuracy, which is a 7% relative improvement over previous\nstate-of-the-art, matching the performance of a supervised ResNet-50. When\nfine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy,\noutperforming AlexNet with 100X fewer labels."}, {"title": "The Implicit and Explicit Regularization Effects of Dropout", "authors": "Colin Wei, Sham Kakade, Tengyu Ma ", "link": "https://arxiv.org/abs/2002.12915", "summary": "Dropout is a widely-used regularization technique, often required to obtain\nstate-of-the-art for a number of architectures. This work demonstrates that\ndropout introduces two distinct but entangled regularization effects: an\nexplicit effect (also studied in prior work) which occurs since dropout\nmodifies the expected training objective, and, perhaps surprisingly, an\nadditional implicit effect from the stochasticity in the dropout training\nupdate. This implicit regularization effect is analogous to the effect of\nstochasticity in small mini-batch stochastic gradient descent. We disentangle\nthese two effects through controlled experiments. We then derive analytic\nsimplifications which characterize each effect in terms of the derivatives of\nthe model and the loss, for deep neural networks. We demonstrate these\nsimplified, analytic regularizers accurately capture the important aspects of\ndropout, showing they faithfully replace dropout in practice."}, {"title": "Variable-Bitrate Neural Compression via Bayesian Arithmetic Coding", "authors": "Yibo Yang, Robert Bamler, Stephan Mandt ", "link": "http://arxiv.org/abs/2002.08158", "summary": "Deep Bayesian latent variable models have enabled new approaches to both\nmodel and data compression. Here, we propose a new algorithm for compressing\nlatent representations in deep probabilistic models, such as variational\nautoencoders, in post-processing. The approach thus separates model design and\ntraining from the compression task. Our algorithm generalizes arithmetic coding\nto the continuous domain, using adaptive discretization accuracy that exploits\nestimates of posterior uncertainty. A consequence of the \"plug and play\" nature\nof our approach is that various rate-distortion trade-offs can be achieved with\na single trained model, eliminating the need to train multiple models for\ndifferent bit rates. Our experimental results demonstrate the importance of\ntaking into account posterior uncertainties, and show that image compression\nwith the proposed algorithm outperforms JPEG over a wide range of bit rates\nusing only a single machine learning model. Further experiments on Bayesian\nneural word embeddings demonstrate the versatility of the proposed method."}, {"title": "Orthogonalized SGD and Nested Architectures for Anytime Neural Networks", "authors": "Chengcheng Wan, Henry  Hoffmann, Shan Lu, Michael Maire "}, {"title": "Evaluating Machine Accuracy on ImageNet", "authors": "Vaishaal Shankar, Rebecca Roelofs, Horia Mania, Alex Fang, Benjamin Recht, Ludwig Schmidt "}, {"title": "Learning to Navigate in Synthetically Accessible Chemical Space Using Reinforcement Learning", "authors": "Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Haoran Wei, Yashaswi Pathak, Shengchao Liu, Shengchao Liu, Simon Blackburn, Karam Thomas, Connor Coley, Jian Tang, Sarath Chandar, Yoshua Bengio ", "link": "http://arxiv.org/abs/2004.12485", "summary": "Over the last decade, there has been significant progress in the field of\nmachine learning for de novo drug design, particularly in deep generative\nmodels. However, current generative approaches exhibit a significant challenge\nas they do not ensure that the proposed molecular structures can be feasibly\nsynthesized nor do they provide the synthesis routes of the proposed small\nmolecules, thereby seriously limiting their practical applicability. In this\nwork, we propose a novel forward synthesis framework powered by reinforcement\nlearning (RL) for de novo drug design, Policy Gradient for Forward Synthesis\n(PGFS), that addresses this challenge by embedding the concept of synthetic\naccessibility directly into the de novo drug design system. In this setup, the\nagent learns to navigate through the immense synthetically accessible chemical\nspace by subjecting commercially available small molecule building blocks to\nvalid chemical reactions at every time step of the iterative virtual multi-step\nsynthesis process. The proposed environment for drug discovery provides a\nhighly challenging test-bed for RL algorithms owing to the large state space\nand high-dimensional continuous action space with hierarchical actions. PGFS\nachieves state-of-the-art performance in generating structures with high QED\nand penalized clogP. Moreover, we validate PGFS in an in-silico\nproof-of-concept associated with three HIV targets. Finally, we describe how\nthe end-to-end training conceptualized in this study represents an important\nparadigm in radically expanding the synthesizable chemical space and automating\nthe drug discovery process."}, {"title": "Improved Bounds on Minimax Regret under Logarithmic Loss via Self-Concordance", "authors": "Blair Bilodeau, Dylan Foster, Daniel Roy "}, {"title": "Optimization Theory for ReLU Neural Networks Trained with Normalization Layers", "authors": "Yonatan Dukler, Guido Montufar, Quanquan Gu "}, {"title": "Improving Molecular Design by Stochastic Iterative Target Augmentation", "authors": "Kevin Yang, Wengong Jin, Kyle Swanson, Regina Barzilay, Tommi Jaakkola ", "link": "https://arxiv.org/abs/2002.04720", "summary": "Generative models in molecular design tend to be richly parameterized,\ndata-hungry neural models, as they must create complex structured objects as\noutputs. Estimating such models from data may be challenging due to the lack of\nsufficient training data. In this paper, we propose a surprisingly effective\nself-training approach for iteratively creating additional molecular targets.\nWe first pre-train the generative model together with a simple property\npredictor. The property predictor is then used as a likelihood model for\nfiltering candidate structures from the generative model. Additional targets\nare iteratively produced and used in the course of stochastic EM iterations to\nmaximize the log-likelihood that the candidate structures are accepted. A\nsimple rejection (re-weighting) sampler suffices to draw posterior samples\nsince the generative model is already reasonable after pre-training. We\ndemonstrate significant gains over strong baselines for both unconditional and\nconditional molecular design. In particular, our approach outperforms the\nprevious state-of-the-art in conditional molecular design by over 10% in\nabsolute gain."}, {"title": "Don't Waste Your Bits! Squeeze Activations and Gradients for Deep Neural Networks via TinyScript", "authors": "Fangcheng Fu, Yuzheng Hu, Yihan He, Jiawei Jiang, Yingxia Shao, Ce Zhang, Bin Cui "}, {"title": "Robust One-Bit Recovery via ReLU Generative Networks: Near-Optimal Statistical Rate and Global Landscape Analysis", "authors": "Shuang Qiu, Xiaohan Wei, Zhuoran Yang ", "link": "https://arxiv.org/abs/1908.05368", "summary": "We study the robust one-bit compressed sensing problem whose goal is to\ndesign an algorithm that faithfully recovers any sparse target vector\n$\\theta_0\\in\\mathbb{R}^d$ uniformly $m$ quantized noisy measurements. Under the\nassumption that the measurements are sub-Gaussian random vectors, to recover\nany $k$-sparse $\\theta_0$ ($k\\ll d$) uniformly up to an error $\\varepsilon$\nwith high probability, the best known computationally tractable algorithm\nrequires $m\\geq\\tilde{\\mathcal{O}}(k\\log d/\\varepsilon^4)$ measurements. In\nthis paper, we consider a new framework for the one-bit sensing problem where\nthe sparsity is implicitly enforced via mapping a low dimensional\nrepresentation $x_0 \\in \\mathbb{R}^k$ through a known $n$-layer ReLU generative\nnetwork $G:\\mathbb{R}^k\\rightarrow\\mathbb{R}^d$. Such a framework poses\nlow-dimensional priors on $\\theta_0$ without a known basis. We propose to\nrecover the target $G(x_0)$ via an unconstrained empirical risk minimization\n(ERM) problem under a much weaker sub-exponential measurement assumption. For\nsuch a problem, we establish a joint statistical and computational analysis. In\nparticular, we prove that the ERM estimator in this new framework achieves a\nstatistical rate of $m=\\tilde{\\mathcal{O}}(kn \\log d /\\varepsilon^2)$\nrecovering any $G(x_0)$ uniformly up to an error $\\varepsilon$. When network is\nshallow (i.e., $n$ is small), we show this rate matches the\ninformation-theoretic lower bound up to logarithm factors on\n$\\varepsilon^{-1}$. From the lens of computation, despite non-convexity, we\nprove that the objective of our ERM problem has no spurious stationary point,\nthat is, any stationary point are equally good for recovering the true target\nup to scaling with a certain accuracy."}, {"title": "Multi-objective Bayesian Optimization using Pareto-frontier Entropy", "authors": "Shinya Suzuki, shion takeno, Tomoyuki Tamura, Kazuki Shitara, Masayuki Karasuyama ", "link": "https://arxiv.org/abs/1906.00127", "summary": "This paper studies an entropy-based multi-objective Bayesian optimization\n(MBO). The entropy search is successful approach to Bayesian optimization.\nHowever, for MBO, existing entropy-based methods ignore trade-off among\nobjectives or introduce unreliable approximations. We propose a novel\nentropy-based MBO called Pareto-frontier entropy search (PFES) by considering\nthe entropy of Pareto-frontier, which is an essential notion of the optimality\nof the multi-objective problem. Our entropy can incorporate the trade-off\nrelation of the optimal values, and further, we derive an analytical formula\nwithout introducing additional approximations or simplifications to the\nstandard entropy search setting. We also show that our entropy computation is\npractically feasible by using a recursive decomposition technique which has\nbeen known in studies of the Pareto hyper-volume computation. Besides the usual\nMBO setting, in which all the objectives are simultaneously observed, we also\nconsider the \"decoupled\" setting, in which the objective functions can be\nobserved separately. PFES can easily adapt to the decoupled setting by\nconsidering the entropy of the marginal density for each output dimension. This\napproach incorporates dependency among objectives conditioned on\nPareto-frontier, which is ignored by the existing method. Our numerical\nexperiments show effectiveness of PFES through several benchmark datasets."}, {"title": "Closing the convergence gap of SGD without replacement", "authors": "Shashank Rajput, Anant Gupta, Dimitris Papailiopoulos ", "link": "https://arxiv.org/abs/2002.10400", "summary": "Stochastic gradient descent without replacement sampling is widely used in\npractice for model training. However, the vast majority of SGD analyses assumes\ndata sampled with replacement, and when the function minimized is strongly\nconvex, an $\\mathcal{O}\\left(\\frac{1}{T}\\right)$ rate can be established when\nSGD is run for $T$ iterations. A recent line of breakthrough work on SGD\nwithout replacement (SGDo) established an\n$\\mathcal{O}\\left(\\frac{n}{T^2}\\right)$ convergence rate when the function\nminimized is strongly convex and is a sum of $n$ smooth functions, and an\n$\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^3}{T^3}\\right)$ rate for sums of\nquadratics. On the other hand, the tightest known lower bound postulates an\n$\\Omega\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ rate, leaving open the\npossibility of better SGDo convergence rates in the general case. In this\npaper, we close this gap and show that SGD without replacement achieves a rate\nof $\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ when the sum of the\nfunctions is a quadratic, and offer a new lower bound of\n$\\Omega\\left(\\frac{n}{T^2}\\right)$ for strongly convex functions that are sums\nof smooth functions."}, {"title": "Black-Box Methods for Restoring Monotonicity", "authors": "Evangelia Gergatsouli, Brendan Lucier, Christos Tzamos ", "link": "https://arxiv.org/abs/2003.09554", "summary": "In many practical applications, heuristic or approximation algorithms are\nused to efficiently solve the task at hand. However their solutions frequently\ndo not satisfy natural monotonicity properties of optimal solutions. In this\nwork we develop algorithms that are able to restore monotonicity in the\nparameters of interest. Specifically, given oracle access to a (possibly\nnon-monotone) multi-dimensional real-valued function $f$, we provide an\nalgorithm that restores monotonicity while degrading the expected value of the\nfunction by at most $\\varepsilon$. The number of queries required is at most\nlogarithmic in $1/\\varepsilon$ and exponential in the number of parameters. We\nalso give a lower bound showing that this exponential dependence is necessary.\nFinally, we obtain improved query complexity bounds for restoring the weaker\nproperty of $k$-marginal monotonicity. Under this property, every\n$k$-dimensional projection of the function $f$ is required to be monotone. The\nquery complexity we obtain only scales exponentially with $k$."}, {"title": "Flexible and Efficient Long-Range Planning Through Curious Exploration", "authors": "Aidan Curtis, Minjian Xin, Dilip Arumugam, Kevin Feigelis, Daniel Yamins "}, {"title": "Sparse Convex Optimization via Adaptively Regularized Hard Thresholding", "authors": "Kyriakos Axiotis, Maxim Sviridenko "}, {"title": "On Thompson Sampling with Langevin Algorithms", "authors": "Eric Mazumdar, Aldo Pacchiano, Yian Ma, Michael Jordan, Peter Bartlett ", "link": "https://arxiv.org/abs/2002.10002", "summary": "Thompson sampling is a methodology for multi-armed bandit problems that is\nknown to enjoy favorable performance in both theory and practice. It does,\nhowever, have a significant limitation computationally, arising from the need\nfor samples from posterior distributions at every iteration. We propose two\nMarkov Chain Monte Carlo (MCMC) methods tailored to Thompson sampling to\naddress this issue. We construct quickly converging Langevin algorithms to\ngenerate approximate samples that have accuracy guarantees, and we leverage\nnovel posterior concentration rates to analyze the regret of the resulting\napproximate Thompson sampling algorithm. Further, we specify the necessary\nhyper-parameters for the MCMC procedure to guarantee optimal instance-dependent\nfrequentist regret while having low computational complexity. In particular,\nour algorithms take advantage of both posterior concentration and a sample\nreuse mechanism to ensure that only a constant number of iterations and a\nconstant amount of data is needed in each round. The resulting approximate\nThompson sampling algorithm has logarithmic regret and its computational\ncomplexity does not scale with the time horizon of the algorithm."}, {"title": "Strategic Classification is Causal Modeling in Disguise", "authors": "John Miller, Smitha Milli, University of California Moritz Hardt ", "link": "https://arxiv.org/abs/1910.10362", "summary": "Consequential decision-making incentivizes individuals to strategically adapt\ntheir behavior to the specifics of the decision rule. While a long line of work\nhas viewed strategic adaptation as gaming and attempted to mitigate its\neffects, recent work has instead sought to design classifiers that incentivize\nindividuals to improve a desired quality. Key to both accounts is a cost\nfunction that dictates which adaptations are rational to undertake. In this\nwork, we develop a causal framework for strategic adaptation. Our causal\nperspective clearly distinguishes between gaming and improvement and reveals an\nimportant obstacle to incentive design. We prove any procedure for designing\nclassifiers that incentivize improvement must inevitably solve a non-trivial\ncausal inference problem. Moreover, we show a similar result holds for\ndesigning cost functions that satisfy the requirements of previous work. With\nthe benefit of hindsight, our results show much of the prior work on strategic\nclassification is causal modeling in disguise."}, {"title": "Multi-fidelity Bayesian Optimization with Max-value Entropy Search and its Parallelization", "authors": "shion takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki Shiga, Ichiro Takeuchi, Masayuki Karasuyama ", "link": "https://arxiv.org/abs/1901.08275", "summary": "In a standard setting of Bayesian optimization (BO), the objective function\nevaluation is assumed to be highly expensive. Multi-fidelity Bayesian\noptimization (MFBO) accelerates BO by incorporating lower fidelity observations\navailable with a lower sampling cost. In this paper, we focus on the\ninformation-based approach, which is a popular and empirically successful\napproach in BO. For MFBO, however, existing information-based methods are\nplagued by difficulty in estimating the information gain. We propose an\napproach based on max-value entropy search (MES), which greatly facilitates\ncomputations by considering the entropy of the optimal function value instead\nof the optimal input point. We show that, in our multi-fidelity MES (MF-MES),\nmost of additional computations, compared with usual MES, is reduced to\nanalytical computations. Although an additional numerical integration is\nnecessary for the information across different fidelities, this is only in one\ndimensional space, which can be performed efficiently and accurately. Further,\nwe also propose parallelization of MF-MES. Since there exist a variety of\ndifferent sampling costs, queries typically occur asynchronously in MFBO. We\nshow that similar simple computations can be derived for asynchronous parallel\nMFBO. We demonstrate effectiveness of our approach by using benchmark datasets\nand a real-world application to materials science data."}, {"title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "authors": "Junfeng Wen, Russell Greiner, Dale Schuurmans "}, {"title": "Improving Robustness of Deep-Learning-Based Image Reconstruction", "authors": "Ankit Raj, Yoram Bresler, Bo Li ", "link": "https://arxiv.org/abs/2002.11821", "summary": "Deep-learning-based methods for different applications have been shown\nvulnerable to adversarial examples. These examples make deployment of such\nmodels in safety-critical tasks questionable. Use of deep neural networks as\ninverse problem solvers has generated much excitement for medical imaging\nincluding CT and MRI, but recently a similar vulnerability has also been\ndemonstrated for these tasks. We show that for such inverse problem solvers,\none should analyze and study the effect of adversaries in the\nmeasurement-space, instead of the signal-space as in previous work. In this\npaper, we propose to modify the training strategy of end-to-end\ndeep-learning-based inverse problem solvers to improve robustness. We introduce\nan auxiliary network to generate adversarial examples, which is used in a\nmin-max formulation to build robust image reconstruction networks.\nTheoretically, we show for a linear reconstruction scheme the min-max\nformulation results in a singular-value(s) filter regularized solution, which\nsuppresses the effect of adversarial examples occurring because of\nill-conditioning in the measurement matrix. We find that a linear network using\nthe proposed min-max learning scheme indeed converges to the same solution. In\naddition, for non-linear Compressed Sensing (CS) reconstruction using deep\nnetworks, we show significant improvement in robustness using the proposed\napproach over other methods. We complement the theory by experiments for CS on\ntwo different datasets and evaluate the effect of increasing perturbations on\ntrained networks. We find the behavior for ill-conditioned and well-conditioned\nmeasurement matrices to be qualitatively different."}, {"title": "Outsourced Bayesian Optimization", "authors": "Dmitrii Kharkovskii, Zhongxiang Dai, Bryan Kian Hsiang Low "}, {"title": "Learning Near Optimal Policies with Low Inherent Bellman Error", "authors": "Andrea Zanette, Alessandro Lazaric, Mykel Kochenderfer, Emma Brunskill ", "link": "http://arxiv.org/abs/2003.00153", "summary": "We study the exploration problem with approximate linear action-value\nfunctions in episodic reinforcement learning under the notion of low inherent\nBellman error, a condition normally employed to show convergence of approximate\nvalue iteration. First we relate this condition to other common frameworks and\nshow that it is strictly more general than the low rank (or linear) MDP\nassumption of prior work. Second we provide an algorithm with a high\nprobability regret bound $\\widetilde O(\\sum_{t=1}^H d_t \\sqrt{K} + \\sum_{t=1}^H\n\\sqrt{d_t} \\IBE K)$ where $H$ is the horizon, $K$ is the number of episodes,\n$\\IBE$ is the value if the inherent Bellman error and $d_t$ is the feature\ndimension at timestep $t$. In addition, we show that the result is unimprovable\nbeyond constants and logs by showing a matching lower bound. This has two\nimportant consequences: 1) the algorithm has the optimal statistical rate for\nthis setting which is more general than prior work on low-rank MDPs 2) the lack\nof closedness (measured by the inherent Bellman error) is only amplified by\n$\\sqrt{d_t}$ despite working in the online setting. Finally, the algorithm\nreduces to the celebrated \\textsc{LinUCB} when $H=1$ but with a different\nchoice of the exploration parameter that allows handling misspecified\ncontextual linear bandits. While computational tractability questions remain\nopen for the MDP setting, this enriches the class of MDPs with a linear\nrepresentation for the action-value function where statistically efficient\nreinforcement learning is possible."}, {"title": "Message Passing Least Squares: A Unified Framework for Fast and Robust Group Synchronization", "authors": "Yunpeng Shi, Gilad Lerman "}, {"title": "Optimal Estimator for Unlabeled Linear Regression", "authors": "hang zhang, Ping Li "}, {"title": "Recovery of sparse signals from a mixture of linear samples", "authors": "Arya Mazumdar, Soumyabrata Pal "}, {"title": "Recurrent Hierarchical Topic-Guided RNN for Language Generation", "authors": "Dandan Guo, Bo Chen, Ruiying Lu, Mingyuan Zhou "}, {"title": "Predictive Coding for Locally-Linear Control", "authors": "Rui Shu, Tung Nguyen, Yinlam Chow, Tuan Pham, Khoat Than, Mohammad Ghavamzadeh, Stefano Ermon, Hung Bui ", "link": "http://arxiv.org/abs/2003.01086", "summary": "High-dimensional observations and unknown dynamics are major challenges when\napplying optimal control to many real-world decision making tasks. The Learning\nControllable Embedding (LCE) framework addresses these challenges by embedding\nthe observations into a lower dimensional latent space, estimating the latent\ndynamics, and then performing control directly in the latent space. To ensure\nthe learned latent dynamics are predictive of next-observations, all existing\nLCE approaches decode back into the observation space and explicitly perform\nnext-observation prediction---a challenging high-dimensional task that\nfurthermore introduces a large number of nuisance parameters (i.e., the\ndecoder) which are discarded during control. In this paper, we propose a novel\ninformation-theoretic LCE approach and show theoretically that explicit\nnext-observation prediction can be replaced with predictive coding. We then use\npredictive coding to develop a decoder-free LCE model whose latent dynamics are\namenable to locally-linear control. Extensive experiments on benchmark tasks\nshow that our model reliably learns a controllable latent space that leads to\nsuperior performance when compared with state-of-the-art LCE baselines."}, {"title": "Near Input Sparsity Time Kernel Embeddings via Adaptive Sampling", "authors": "Amir Zandieh, David Woodruff "}, {"title": "Near-optimal sample complexity bounds for learning Latent $k-$polytopes and applications to Ad-Mixtures", "authors": "Chiranjib Bhattacharyya, Ravindran Kannan ", "link": "", "summary": ""}, {"title": "Population-Based Black-Box Optimization for Biological Sequence Design", "authors": "Christof Angermueller, David Belanger, Andreea Gane, Zelda Mariet, David Dohan, Kevin Murphy, Lucy Colwell , D. Sculley "}, {"title": "Emergence of Separable Manifolds in Deep Language Representations", "authors": "Jonathan Mamou, Hang Le, Miguel Del Rio, Cory Stephenson, Hanlin Tang, Yoon Kim, Sueyeon Chung ", "link": "https://arxiv.org/abs/2006.01095", "summary": "Artificial neural networks (ANNS have shown much empirical success in solving\nperceptual tasks across various cognitive modalities. While they are only\nloosely inspired by the biological brain, recent studies report considerable\nsimilarities between representation extracted from task-optimized ANNS and\nneural populations in the brain. ANNS have subsequently become a popular model\nclass to infer computational principles underlying complex cognitive functions,\nand in turn they have also emerged as a natural testbed for applying methods\noriginally developed to probe information in neural populations. In this work,\nwe utilize mean-field theoretic manifold analysis, a recent technique from\ncomputational neuroscience, to analyze the high dimensional geometry of\nlanguage representations from large-scale contextual embedding models. We\nexplore representations from different model families (BERT, RoBERTa, GPT-2,\netc. ) and find evidence for emergence of linguistic manifold across layer\ndepth (e.g., manifolds for part-of-speech and combinatory categorical grammar\ntags). We further observe that different encoding schemes used to obtain the\nrepresentations lead to differences in whether these linguistic manifolds\nemerge in earlier or later layers of the network. In addition, we find that the\nemergence of linear separability in these manifolds is driven by a combined\nreduction of manifolds radius, dimensionality and inter-manifold correlations."}, {"title": "Stochastic Hamiltonian Gradient Methods for Smooth Games", "authors": "Nicolas Loizou, Hugo Berard, Alexia Jolicoeur-Martineau, Pascal Vincent, Simon Lacoste-Julien, Ioannis Mitliagkas "}, {"title": "Understanding and Estimating the Adaptability of Domain-Invariant Representations", "authors": "Ching-Yao Chuang, Antonio Torralba, Stefanie Jegelka ", "link": "", "summary": ""}, {"title": "Adversarial Mutual Information for Text Generation", "authors": "Boyuan Pan, Yazheng Yang, Kaizhao Liang, Bhavya Kailkhura, Zhongming Jin, Xian-Sheng Hua, Deng Cai, Bo Li "}, {"title": "Bidirectional Model-based Policy Optimization", "authors": "Hang Lai, Jian Shen, Weinan Zhang, Yong Yu ", "link": "", "summary": ""}, {"title": "Input-Sparsity Low Rank Approximation in Schatten Norm", "authors": "Yi Li, David Woodruff ", "link": "http://arxiv.org/abs/2004.12646", "summary": "We give the first input-sparsity time algorithms for the rank-$k$ low rank\napproximation problem in every Schatten norm. Specifically, for a given\n$n\\times n$ matrix $A$, our algorithm computes $Y,Z\\in \\mathbb{R}^{n\\times k}$,\nwhich, with high probability, satisfy $\\|A-YZ^T\\|_p \\leq\n(1+\\epsilon)\\|A-A_k\\|_p$, where $\\|M\\|_p = \\left (\\sum_{i=1}^n \\sigma_i(M)^p\n\\right )^{1/p}$ is the Schatten $p$-norm of a matrix $M$ with singular values\n$\\sigma_1(M), \\ldots, \\sigma_n(M)$, and where $A_k$ is the best rank-$k$\napproximation to $A$. Our algorithm runs in time\n$\\tilde{O}(\\operatorname{nnz}(A) +\nmn^{\\alpha_p}\\operatorname{poly}(k/\\epsilon))$, where $\\alpha_p = 0$ for $p\\in\n[1,2)$ and $\\alpha_p = (\\omega-1)(1-2/p)$ for $p>2$ and $\\omega \\approx 2.374$\nis the exponent of matrix multiplication. For the important case of $p = 1$,\nwhich corresponds to the more \"robust\" nuclear norm, we obtain\n$\\tilde{O}(\\operatorname{nnz}(A) + m \\cdot \\operatorname{poly}(k/\\epsilon))$\ntime, which was previously only known for the Frobenius norm ($p = 2$).\nMoreover, since $\\alpha_p < \\omega - 1$ for every $p$, our algorithm has a\nbetter dependence on $n$ than that in the singular value decomposition for\nevery $p$. Crucial to our analysis is the use of dimensionality reduction for\nKy-Fan $p$-norms."}, {"title": "Do We Need Zero Training Loss After Achieving Zero Training Error?", "authors": "Takashi Ishida, Ikko Yamane, Tomoya Sakai, Gang Niu, Masashi Sugiyama ", "link": "https://arxiv.org/abs/2002.08709", "summary": "Overparameterized deep networks have the capacity to memorize training data\nwith zero training error. Even after memorization, the training loss continues\nto approach zero, making the model overconfident and the test performance\ndegraded. Since existing regularizers do not directly aim to avoid zero\ntraining loss, they often fail to maintain a moderate level of training loss,\nending up with a too small or too large loss. We propose a direct solution\ncalled flooding that intentionally prevents further reduction of the training\nloss when it reaches a reasonably small value, which we call the flooding\nlevel. Our approach makes the loss float around the flooding level by doing\nmini-batched gradient descent as usual but gradient ascent if the training loss\nis below the flooding level. This can be implemented with one line of code, and\nis compatible with any stochastic optimizer and other regularizers. With\nflooding, the model will continue to \"random walk\" with the same non-zero\ntraining loss, and we expect it to drift into an area with a flat loss\nlandscape that leads to better generalization. We experimentally show that\nflooding improves performance and as a byproduct, induces a double descent\ncurve of the test loss."}, {"title": "Learning and sampling of atomic interventions from observations", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Ashwin Maran, Vinodchandran N. Variyam ", "link": "", "summary": ""}, {"title": "Understanding and Mitigating the Tradeoff between Robustness and Accuracy", "authors": "Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi, Percy Liang ", "link": "https://arxiv.org/abs/2002.10716", "summary": "Adversarial training augments the training set with perturbations to improve\nthe robust error (over worst-case perturbations), but it often leads to an\nincrease in the standard error (on unperturbed test inputs). Previous\nexplanations for this tradeoff rely on the assumption that no predictor in the\nhypothesis class has low standard and robust error. In this work, we precisely\ncharacterize the effect of augmentation on the standard error in linear\nregression when the optimal linear predictor has zero standard and robust\nerror. In particular, we show that the standard error could increase even when\nthe augmented perturbations have noiseless observations from the optimal linear\npredictor. We then prove that the recently proposed robust self-training (RST)\nestimator improves robust error without sacrificing standard error for\nnoiseless linear regression. Empirically, for neural networks, we find that RST\nwith different adversarial training methods improves both standard and robust\nerror for random and adversarial rotations and adversarial $\\ell_\\infty$\nperturbations in CIFAR-10."}, {"title": "Combining Differentiable PDE Solvers and Graph Neural Networks for Fluid Flow Prediction", "authors": "Filipe de Avila Belbute-Peres, Thomas Economon, Zico Kolter "}, {"title": "From ImageNet to Image Classification: Contextualizing Progress on Benchmarks", "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Andrew Ilyas, Aleksander Madry ", "link": "https://arxiv.org/abs/2005.11295", "summary": "Building rich machine learning datasets in a scalable manner often\nnecessitates a crowd-sourced data collection pipeline. In this work, we use\nhuman studies to investigate the consequences of employing such a pipeline,\nfocusing on the popular ImageNet dataset. We study how specific design choices\nin the ImageNet creation process impact the fidelity of the resulting\ndataset---including the introduction of biases that state-of-the-art models\nexploit. Our analysis pinpoints how a noisy data collection pipeline can lead\nto a systematic misalignment between the resulting benchmark and the real-world\ntask it serves as a proxy for. Finally, our findings emphasize the need to\naugment our current model training and evaluation toolkit to take such\nmisalignments into account. To facilitate further research, we release our\nrefined ImageNet annotations at https://github.com/MadryLab/ImageNetMultiLabel."}, {"title": "On Implicit Regularization in $\\beta$-VAEs", "authors": "Abhishek Kumar, Ben Poole ", "link": "", "summary": ""}, {"title": "Data Amplification: Instance-Optimal Property Estimation ", "authors": "Yi Hao, Alon Orlitsky ", "link": "https://arxiv.org/abs/1903.01432", "summary": "The best-known and most commonly used distribution-property estimation\ntechnique uses a plug-in estimator, with empirical frequency replacing the\nunderlying distribution. We present novel linear-time-computable estimators\nthat significantly \"amplify\" the effective amount of data available. For a\nlarge variety of distribution properties including four of the most popular\nones and for every underlying distribution, they achieve the accuracy that the\nempirical-frequency plug-in estimators would attain using a logarithmic-factor\nmore samples.\n  Specifically, for Shannon entropy and a very broad class of properties\nincluding $\\ell_1$-distance, the new estimators use $n$ samples to achieve the\naccuracy attained by the empirical estimators with $n\\log n$ samples. For\nsupport-size and coverage, the new estimators use $n$ samples to achieve the\nperformance of empirical frequency with sample size $n$ times the logarithm of\nthe property value. Significantly strengthening the traditional min-max\nformulation, these results hold not only for the worst distributions, but for\neach and every underlying distribution. Furthermore, the logarithmic\namplification factors are optimal. Experiments on a wide variety of\ndistributions show that the new estimators outperform the previous\nstate-of-the-art estimators designed for each specific property."}, {"title": "Provable guarantees for decision tree induction: the agnostic setting ", "authors": "Guy Blanc, Jane Lange, Li-Yang Tan ", "link": "https://arxiv.org/abs/2006.00743", "summary": "We give strengthened provable guarantees on the performance of widely\nemployed and empirically successful {\\sl top-down decision tree learning\nheuristics}. While prior works have focused on the realizable setting, we\nconsider the more realistic and challenging {\\sl agnostic} setting. We show\nthat for all monotone functions~$f$ and parameters $s\\in \\mathbb{N}$, these\nheuristics construct a decision tree of size $s^{\\tilde{O}((\\log\ns)/\\varepsilon^2)}$ that achieves error $\\le \\mathsf{opt}_s + \\varepsilon$,\nwhere $\\mathsf{opt}_s$ denotes the error of the optimal size-$s$ decision tree\nfor $f$. Previously, such a guarantee was not known to be achievable by any\nalgorithm, even one that is not based on top-down heuristics. We complement our\nalgorithmic guarantee with a near-matching $s^{\\tilde{\\Omega}(\\log s)}$ lower\nbound."}, {"title": "Statistical Bias in Dataset Replication", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Jacob Steinhardt, Aleksander Madry ", "link": "", "summary": ""}, {"title": "Towards Adaptive Residual Network Training: A Neural-ODE Perspective", "authors": "chengyu dong, Liyuan Liu, Zichao Li, Jingbo Shang "}, {"title": "Overparameterization hurts worst-group accuracy with spurious correlations", "authors": "Shiori Sagawa, aditi raghunathan, Pang Wei Koh, Percy Liang "}, {"title": "A Nearly-Linear Time Algorithm for Exact Community Recovery in Stochastic Block Model", "authors": "Peng Wang, Zirui Zhou, Anthony Man-Cho So "}, {"title": "Online Multi-Kernel Learning with Graph-Structured Feedback", "authors": "Pouya Mollaebrahim Ghari, Yanning Shen ", "link": "", "summary": ""}, {"title": "Is Local SGD Better than Minibatch SGD?", "authors": "Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nati Srebro ", "link": "", "summary": ""}, {"title": "On Lp-norm Robustness of Ensemble Decision Stumps and Trees", "authors": "Yihan Wang, Huan Zhang, Hongge Chen, Duane Boning, Cho-Jui Hsieh "}, {"title": "Sub-linear Memory Sketches for Near Neighbor Search on Streaming Data with RACE", "authors": "Benjamin Coleman, Anshumali Shrivastava, Richard Baraniuk ", "link": "", "summary": ""}, {"title": "Understanding Self-Training for Gradual Domain Adaptation", "authors": "Ananya Kumar, Tengyu Ma, Percy Liang ", "link": "https://arxiv.org/abs/2002.11361", "summary": "Machine learning systems must adapt to data distributions that evolve over\ntime, in applications ranging from sensor networks and self-driving car\nperception modules to brain-machine interfaces. We consider gradual domain\nadaptation, where the goal is to adapt an initial classifier trained on a\nsource domain given only unlabeled data that shifts gradually in distribution\ntowards a target domain. We prove the first non-vacuous upper bound on the\nerror of self-training with gradual shifts, under settings where directly\nadapting to the target domain can result in unbounded error. The theoretical\nanalysis leads to algorithmic insights, highlighting that regularization and\nlabel sharpening are essential even when we have infinite data, and suggesting\nthat self-training works particularly well for shifts with small\nWasserstein-infinity distance. Leveraging the gradual shift structure leads to\nhigher accuracies on a rotating MNIST dataset and a realistic Portraits\ndataset."}, {"title": "Concept Bottleneck Models", "authors": "Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, Percy Liang "}, {"title": "Optimal Bounds between f-Divergences and Integral Probability Metrics", "authors": "Rohit Agrawal, Thibaut Horel "}, {"title": "Robustness to Spurious Correlations via Human Annotations", "authors": "Megha Srivastava, Tatsunori Hashimoto, Percy Liang ", "link": "", "summary": ""}, {"title": "DROCC: Deep Robust One-Class Classification", "authors": "Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri, Prateek Jain ", "link": "", "summary": ""}, {"title": "Efficiently Solving MDPs with Stochastic Mirror Descent", "authors": "Yujia Jin, Aaron Sidford "}, {"title": "Handling the Positive-Definite Constraint in the Bayesian Learning Rule", "authors": "Wu Lin, Mark Schmidt, Mohammad Emtiyaz Khan ", "link": "https://arxiv.org/abs/2002.10060", "summary": "The Bayesian learning rule is a recently proposed variational inference\nmethod, which not only contains many existing learning algorithms as special\ncases but also enables the design of new algorithms. Unfortunately, when\nposterior parameters lie in an open constraint set, the rule may not satisfy\nthe constraints and requires line-searches which could slow down the algorithm.\nIn this paper, we fix this issue for the positive-definite constraint by\nproposing an improved rule that naturally handles the constraint. Our\nmodification is obtained using Riemannian gradient methods, and is valid when\nthe approximation attains a \\emph{block-coordinate natural parameterization}\n(e.g., Gaussian distributions and their mixtures). Our method outperforms\nexisting methods without any significant increase in computation. Our work\nmakes it easier to apply the learning rule in the presence of positive-definite\nconstraints in parameter spaces."}, {"title": "A simpler approach to accelerated optimization: iterative averaging meets optimism", "authors": "Pooria Joulani, Anant Raj, Andras Gyorgy, Csaba Szepesvari ", "link": "", "summary": ""}, {"title": "Training Binary Neural Networks using the Bayesian Learning Rule", "authors": "Xiangming Meng, Roman Bachmann, Mohammad Emtiyaz Khan ", "link": "https://arxiv.org/abs/2002.10778", "summary": "Neural networks with binary weights are computation-efficient and\nhardware-friendly, but their training is challenging because it involves a\ndiscrete optimization problem. Surprisingly, ignoring the discrete nature of\nthe problem and using gradient-based methods, such as Straight-Through\nEstimator, still works well in practice. This raises the question: are there\nprincipled approaches which justify such methods? In this paper, we propose\nsuch an approach using the Bayesian learning rule. The rule, when applied to\nestimate a Bernoulli distribution over the binary weights, results in an\nalgorithm which justifies some of the algorithmic choices made by the previous\napproaches. The algorithm not only obtains state-of-the-art performance, but\nalso enables uncertainty estimation for continual learning to avoid\ncatastrophic forgetting. Our work provides a principled approach for training\nbinary neural networks which justifies and extends existing approaches."}, {"title": "High-dimensional Robust Mean Estimation via Gradient Descent", "authors": "Yu Cheng, Ilias Diakonikolas, Rong Ge, Mahdi Soltanolkotabi ", "link": "https://arxiv.org/abs/2005.01378", "summary": "We study the problem of high-dimensional robust mean estimation in the\npresence of a constant fraction of adversarial outliers. A recent line of work\nhas provided sophisticated polynomial-time algorithms for this problem with\ndimension-independent error guarantees for a range of natural distribution\nfamilies.\n  In this work, we show that a natural non-convex formulation of the problem\ncan be solved directly by gradient descent. Our approach leverages a novel\nstructural lemma, roughly showing that any approximate stationary point of our\nnon-convex objective gives a near-optimal solution to the underlying robust\nestimation task. Our work establishes an intriguing connection between\nalgorithmic high-dimensional robust statistics and non-convex optimization,\nwhich may have broader applications to other robust estimation tasks."}, {"title": "From Chaos to Order: Symmetry and Conservation Laws in Game Dynamics", "authors": "Sai Ganesh Nagarajan, David Balduzzi, Georgios Piliouras ", "link": "", "summary": ""}, {"title": "Hierarchically Decoupled Morphological Transfer", "authors": "Donald Hejna, Lerrel Pinto, Pieter Abbeel ", "link": "", "summary": ""}, {"title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup", "authors": "Jang-Hyun Kim, Wonho Choo, Hyun Oh Song "}, {"title": "Train Big, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers", "authors": "Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer, Dan Klein, Joseph E. Gonzalez ", "link": "https://arxiv.org/abs/2002.11794", "summary": "Since hardware resources are limited, the objective of training deep learning\nmodels is typically to maximize accuracy subject to the time and memory\nconstraints of training and inference. We study the impact of model size in\nthis setting, focusing on Transformer models for NLP tasks that are limited by\ncompute: self-supervised pretraining and high-resource machine translation. We\nfirst show that even though smaller Transformer models execute faster per\niteration, wider and deeper models converge in significantly fewer steps.\nMoreover, this acceleration in convergence typically outpaces the additional\ncomputational overhead of using larger models. Therefore, the most\ncompute-efficient training strategy is to counterintuitively train extremely\nlarge models but stop after a small number of iterations.\n  This leads to an apparent trade-off between the training efficiency of large\nTransformer models and the inference efficiency of small Transformer models.\nHowever, we show that large models are more robust to compression techniques\nsuch as quantization and pruning than small models. Consequently, one can get\nthe best of both worlds: heavily compressed, large models achieve higher\naccuracy than lightly compressed, small models."}, {"title": "Interpolation between CNNs and ResNets", "authors": "Zonghan Yang, Yang Liu, Chenglong Bao, Zuoqiang Shi "}, {"title": "Online metric algorithms with untrusted predictions", "authors": "Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, Bertrand Simon ", "link": "https://arxiv.org/abs/2003.02144", "summary": "Machine-learned predictors, although achieving very good results for inputs\nresembling training data, cannot possibly provide perfect predictions in all\nsituations. Still, decision-making systems that are based on such predictors\nneed not only to benefit from good predictions but also to achieve a decent\nperformance when the predictions are inadequate. In this paper, we propose a\nprediction setup for arbitrary metrical task systems (MTS) (e.g., caching,\nk-server and convex body chasing) and online matching on the line. We utilize\nresults from the theory of online algorithms to show how to make the setup\nrobust. Specifically for caching, we present an algorithm whose performance, as\na function of the prediction error, is exponentially better than what is\nachievable for general MTS. Finally, we present an empirical evaluation of our\nmethods on real world datasets, which suggests practicality."}, {"title": "Collaborative Machine Learning with Incentive-Aware Model Rewards", "authors": "Rachael Hwee Ling Sim, Yehong Zhang, Bryan Kian Hsiang Low, Mun Choon Chan "}, {"title": "On Convergence-Diagnostic based Step Sizes for Stochastic Gradient Descent", "authors": "Scott Pesme, Aymeric Dieuleveut, Nicolas Flammarion "}, {"title": "The Performance Analysis of Generalized Margin Maximizers on Separable Data", "authors": "Fariborz Salehi, Ehsan Abbasi, Babak Hassibi ", "link": "", "summary": ""}, {"title": "Equivariant Flows: exact likelihood generative learning for symmetric densities.", "authors": "Jonas K\u00f6hler, Leon Klein, Frank Noe "}, {"title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination", "authors": "Saurabh Goyal, Anamitra Roy Choudhury, Venkatesan Chakaravarthy, Saurabh Raje, Yogish Sabharwal, Ashish Verma "}, {"title": "Bayesian Sparsification of Deep C-valued networks", "authors": "Ivan Nazarov, Evgeny Burnaev ", "link": "", "summary": ""}, {"title": "Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack", "authors": "Francesco Croce, Matthias Hein ", "link": "https://arxiv.org/abs/1907.02044", "summary": "The evaluation of robustness against adversarial manipulation of neural\nnetworks-based classifiers is mainly tested with empirical attacks as the\nmethods for the exact computation, even when available, do not scale to large\nnetworks. We propose in this paper a new white-box adversarial attack wrt the\n$l_p$-norms for $p \\in \\{1,2,\\infty\\}$ aiming at finding the minimal\nperturbation necessary to change the class of a given input. It has an\nintuitive geometric meaning, yields high quality results already with one\nrestart, minimizes the size of the perturbation, so that the robust accuracy\ncan be evaluated at all possible thresholds with a single run, and comes with\nalmost no free parameters except number of iterations and restarts. It achieves\nbetter or similar robust test accuracy compared to state-of-the-art attacks\nwhich are partially specialized to one $l_p$-norm."}, {"title": "A distributional view on multi objective policy optimization", "authors": "Abbas Abdolmaleki, Sandy Huang, Leonard Hasenclever, Michael Neunert, Martina Zambelli, Murilo Martins, Francis Song, Nicolas Heess, Raia Hadsell, Martin Riedmiller ", "link": "https://arxiv.org/abs/2005.07513", "summary": "Many real-world problems require trading off multiple competing objectives.\nHowever, these objectives are often in different units and/or scales, which can\nmake it challenging for practitioners to express numerical preferences over\nobjectives in their native units. In this paper we propose a novel algorithm\nfor multi-objective reinforcement learning that enables setting desired\npreferences for objectives in a scale-invariant way. We propose to learn an\naction distribution for each objective, and we use supervised learning to fit a\nparametric policy to a combination of these distributions. We demonstrate the\neffectiveness of our approach on challenging high-dimensional real and\nsimulated robotics tasks, and show that setting different preferences in our\nframework allows us to trace out the space of nondominated solutions."}, {"title": "On the Sample Complexity of Adversarial Multi-Source PAC Learning", "authors": "Nikola Konstantinov, Elias Frantar, Dan Alistarh, Christoph H. Lampert ", "link": "https://arxiv.org/abs/2002.10384", "summary": "We study the problem of learning from multiple untrusted data sources, a\nscenario of increasing practical relevance given the recent emergence of\ncrowdsourcing and collaborative learning paradigms. Specifically, we analyze\nthe situation in which a learning system obtains datasets from multiple\nsources, some of which might be biased or even adversarially perturbed. It is\nknown that in the single-source case, an adversary with the power to corrupt a\nfixed fraction of the training data can prevent PAC-learnability, that is, even\nin the limit of infinitely much training data, no learning system can approach\nthe optimal test error. In this work we show that, surprisingly, the same is\nnot true in the multi-source setting, where the adversary can arbitrarily\ncorrupt a fixed fraction of the data sources. Our main results are a\ngeneralization bound that provides finite-sample guarantees for this learning\nsetting, as well as corresponding lower bounds. Besides establishing\nPAC-learnability our results also show that in a cooperative learning setting\nsharing data with other parties has provable benefits, even if some\nparticipants are malicious."}, {"title": "Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks", "authors": "Mark Kurtz, Justin Kopinsky, Rati Gelashvili, Alexander Matveev, John Carr, Michael Goin, William Leiserson, Sage Moore, Nir Shavit, Dan Alistarh "}, {"title": "Constructive universal distribution generation through deep ReLU networks", "authors": "Dmytro Perekrestenko, Stephan M\u00fcller, Helmut B\u00f6lcskei "}, {"title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks", "authors": "Francesco Croce, Matthias Hein ", "link": "https://arxiv.org/abs/2003.01690", "summary": "The field of defense strategies against adversarial attacks has significantly\ngrown over the last years, but progress is hampered as the evaluation of\nadversarial defenses is often insufficient and thus gives a wrong impression of\nrobustness. Many promising defenses could be broken later on, making it\ndifficult to identify the state-of-the-art. Frequent pitfalls in the evaluation\nare improper tuning of hyperparameters of the attacks, gradient obfuscation or\nmasking. In this paper we first propose two extensions of the PGD-attack\novercoming failures due to suboptimal step size and problems of the objective\nfunction. We then combine our novel attacks with two complementary existing\nones to form a parameter-free, computationally affordable and user-independent\nensemble of attacks to test adversarial robustness. We apply our ensemble to\nover 40 models from papers published at recent top machine learning and\ncomputer vision venues. In all except one of the cases we achieve lower robust\ntest accuracy than reported in these papers, often by more than $10\\%$,\nidentifying several broken defenses."}, {"title": "Multiclass Neural Network Minimization via Tropical Newton Polytope Approximation", "authors": "Georgios Smyrnis, Petros Maragos "}, {"title": "Finding trainable sparse networks through Neural Tangent Transfer ", "authors": "Tianlin Liu, Friedemann Zenke "}, {"title": "Towards a General Theory of Infinite-Width Limits of Neural Classifiers", "authors": "Eugene Golikov ", "link": "https://arxiv.org/abs/2003.05884", "summary": "Obtaining theoretical guarantees for neural networks training appears to be a\nhard problem in a general case. Recent research has been focused on studying\nthis problem in the limit of infinite width and two different theories have\nbeen developed: mean-field (MF) and kernel limit theories. We propose a general\nframework that provides a link between these seemingly distinct theories. Our\nframework out of the box gives rise to a discrete-time MF limit which was not\npreviously explored in the literature. We prove a convergence theorem for it\nand show that it provides a more reasonable approximation for finite-width nets\ncompared to NTK limit if learning rates are not very small. Also, our analysis\nsuggests that all infinite-width limits of a network with a single hidden layer\nare covered by either mean-field limit theory or kernel limit theory. We show\nthat for networks with more than two hidden layers RMSProp training has a\nnon-trivial MF limit, but GD training does not have one. Overall, our framework\ndemonstrates that both MF and NTK limits have considerable limitations in\napproximating finite-sized neural nets, indicating the need for designing more\naccurate infinite-width approximations for them. Source code to reproduce all\nthe reported results is available on GitHub."}, {"title": "Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics", "authors": "Arsenii Kuznetsov, Pavel Shvechikov, Alexander Grishin, Dmitry Vetrov ", "link": "https://arxiv.org/abs/2005.04269", "summary": "The overestimation bias is one of the major impediments to accurate\noff-policy learning. This paper investigates a novel way to alleviate the\noverestimation bias in a continuous control setting. Our method---Truncated\nQuantile Critics, TQC,---blends three ideas: distributional representation of a\ncritic, truncation of critics prediction, and ensembling of multiple critics.\nDistributional representation and truncation allow for arbitrary granular\noverestimation control, while ensembling provides additional score\nimprovements. TQC outperforms the current state of the art on all environments\nfrom the continuous control benchmark suite, demonstrating 25% improvement on\nthe most challenging Humanoid environment."}, {"title": "Learning to Learn Kernels with Variational Random Features", "authors": "Xiantong Zhen, Haoliang Sun, Yingjun Du, Jun Xu, Yilong Yin, Ling Shao, Cees Snoek "}, {"title": "Efficient Robustness Certificates for Graph Neural Networks via Sparsity-Aware Randomized Smoothing", "authors": "Aleksandar Bojchevski, Johannes Klicpera, Stephan G\u00fcnnemann ", "link": "", "summary": ""}, {"title": "Learning to Simulate Complex Physics with Graph Networks", "authors": "Alvaro Sanchez, Jonathan Godwin, Tobias Pfaff, Rex  Ying, Jure Leskovec, Peter Battaglia ", "link": "https://arxiv.org/abs/2002.09405", "summary": "Here we present a general framework for learning simulation, and provide a\nsingle model implementation that yields state-of-the-art performance across a\nvariety of challenging physical domains, involving fluids, rigid solids, and\ndeformable materials interacting with one another. Our framework---which we\nterm \"Graph Network-based Simulators\" (GNS)---represents the state of a\nphysical system with particles, expressed as nodes in a graph, and computes\ndynamics via learned message-passing. Our results show that our model can\ngeneralize from single-timestep predictions with thousands of particles during\ntraining, to different initial conditions, thousands of timesteps, and at least\nan order of magnitude more particles at test time. Our model was robust to\nhyperparameter choices across various evaluation metrics: the main determinants\nof long-term performance were the number of message-passing steps, and\nmitigating the accumulation of error by corrupting the training data with\nnoise. Our GNS framework is the most accurate general-purpose learned physics\nsimulator to date, and holds promise for solving a wide range of complex\nforward and inverse problems."}, {"title": "Small Data, Big Decisions: Model Selection in the Small-Data Regime", "authors": "Jorg Bornschein, Francesco Visin, Simon Osindero "}, {"title": "PolyGen: An Autoregressive Generative Model of 3D Meshes", "authors": "Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, Peter Battaglia ", "link": "https://arxiv.org/abs/2002.10880", "summary": "Polygon meshes are an efficient representation of 3D geometry, and are of\ncentral importance in computer graphics, robotics and games development.\nExisting learning-based approaches have avoided the challenges of working with\n3D meshes, instead using alternative object representations that are more\ncompatible with neural architectures and training approaches. We present an\napproach which models the mesh directly, predicting mesh vertices and faces\nsequentially using a Transformer-based architecture. Our model can condition on\na range of inputs, including object classes, voxels, and images, and because\nthe model is probabilistic it can produce samples that capture uncertainty in\nambiguous scenarios. We show that the model is capable of producing\nhigh-quality, usable meshes, and establish log-likelihood benchmarks for the\nmesh-modelling task. We also evaluate the conditional models on surface\nreconstruction metrics against alternative methods, and demonstrate competitive\nperformance despite not training directly on this task."}, {"title": "XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning", "authors": "Sung Whan Yoon, Jun Seo, Doyeon Kim, Jaekyun Moon ", "link": "https://arxiv.org/abs/2003.08561", "summary": "Learning novel concepts while preserving prior knowledge is a long-standing\nchallenge in machine learning. The challenge gets greater when a novel task is\ngiven with only a few labeled examples, a problem known as incremental few-shot\nlearning. We propose XtarNet, which learns to extract task-adaptive\nrepresentation (TAR) for facilitating incremental few-shot learning. The method\nutilizes a backbone network pretrained on a set of base categories while also\nemploying additional modules that are meta-trained across episodes. Given a new\ntask, the novel feature extracted from the meta-trained modules is mixed with\nthe base feature obtained from the pretrained model. The process of combining\ntwo different features provides TAR and is also controlled by meta-trained\nmodules. The TAR contains effective information for classifying both novel and\nbase categories. The base and novel classifiers quickly adapt to a given task\nby utilizing the TAR. Experiments on standard image datasets indicate that\nXtarNet achieves state-of-the-art incremental few-shot learning performance.\nThe concept of TAR can also be used in conjunction with existing incremental\nfew-shot learning methods; extensive simulation results in fact show that\napplying TAR enhances the known methods significantly."}]